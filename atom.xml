<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>飘逸峰的博客</title>
  
  <subtitle>Spring--Java程序员的春天</subtitle>
  <link href="https://blog.hanqunfeng.com/atom.xml" rel="self"/>
  
  <link href="https://blog.hanqunfeng.com/"/>
  <updated>2025-10-24T11:50:46.835Z</updated>
  <id>https://blog.hanqunfeng.com/</id>
  
  <author>
    <name>飘逸峰</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RocketMQ Dashboard 的安装及使用</title>
    <link href="https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/"/>
    <id>https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/</id>
    <published>2025-10-24T13:30:05.000Z</published>
    <updated>2025-10-24T11:50:46.835Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。</p></li><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/">RocketMQ官网</a></p></li><li class="lvl-2"><p>本文使用的 RocketMQ 版本为 5.3.2。</p></li></ul><span id="more"></span><h2 id="RocketMQ-Dashboard-简介">RocketMQ Dashboard 简介</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/docs/deploymentOperations/04Dashboard">官方文档</a></p></li><li class="lvl-2"><p>RocketMQ Dashboard 是 RocketMQ 的管控利器，为用户提供客户端和应用程序的各种事件、性能的统计信息，支持以可视化工具代替 Topic 配置、Broker 管理等命令行操作。</p></li><li class="lvl-2"><p>功能概览</p></li></ul><table><thead><tr><th>面板</th><th>功能说明</th></tr></thead><tbody><tr><td><strong>运维</strong></td><td>修改 <strong>NameServer 地址</strong>；选择 <strong>VIPChannel</strong> 等运维配置。</td></tr><tr><td><strong>驾驶舱</strong></td><td>查看 <strong>Broker、Topic 消息量</strong> 等运行总览信息。</td></tr><tr><td><strong>集群</strong></td><td>查看 <strong>集群分布</strong>、Broker 配置、运行状态及详细信息。</td></tr><tr><td><strong>主题（Topic）</strong></td><td>搜索、筛选、删除、更新/新增主题；查看 <strong>消息路由</strong>；执行 <strong>发送消息</strong>、<strong>重置消费位点</strong> 等操作。</td></tr><tr><td><strong>消费者（Consumer）</strong></td><td>搜索、删除、新增/更新消费者组；查看 <strong>终端信息、消费详情、配置项</strong>。</td></tr><tr><td><strong>消息（Message）</strong></td><td>查看 <strong>消息记录、死信消息、消息轨迹</strong> 等消息级详情。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>系统要求 与 网络配置</p></li></ul><table><thead><tr><th>类别</th><th>项目</th><th>说明</th></tr></thead><tbody><tr><td><strong>系统要求</strong></td><td>操作系统</td><td>Linux / Unix / macOS</td></tr><tr><td></td><td>JDK</td><td>64 位 JDK, 1.x 版本需要<strong>1.8+</strong>，2.x版本需要 <strong>17+</strong></td></tr><tr><td></td><td>构建工具</td><td><strong>Maven 3.2.x</strong> 或更高版本</td></tr><tr><td></td><td>启动项</td><td>启动 <strong>RocketMQ</strong>（包括 NameServer 与 Broker）</td></tr><tr><td><strong>网络配置</strong></td><td>网络访问</td><td>云服务器需可远程访问，或本地虚拟机需可 <strong>PING 通外网</strong></td></tr></tbody></table><h2 id="RocketMQ-Dashboard-的安装">RocketMQ Dashboard 的安装</h2><ul class="lvl-0"><li class="lvl-2"><p>部署 RocketMQ Dashboard 2.x，需要安装 JDK17</p></li><li class="lvl-2"><p>源码安装，<a href="https://github.com/apache/rocketmq-dashboard">源码下载</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载源码</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/rocketmq</span><br><span class="line">wget https://github.com/apache/rocketmq-dashboard/archive/refs/tags/rocketmq-dashboard-2.1.0.tar.gz</span><br><span class="line">tar -zxvf rocketmq-dashboard-2.1.0.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -s rocketmq-dashboard-rocketmq-dashboard-2.1.0 rocketmq-dashboard</span><br><span class="line"><span class="built_in">cd</span> rocketmq-dashboard</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>bug 修复，当前<code>2.1.0</code>版本存在bug，只能通过<code>http://localhost:8082</code>访问，如果需要ip或域名访问，则需要修改源码</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> frontend-new/src/api/remoteApi</span><br><span class="line">sed -i <span class="string">&#x27;s|apiBaseUrl: &#x27;</span>\&#x27;<span class="string">&#x27;http://localhost:8082&#x27;</span>\&#x27;<span class="string">&#x27;|apiBaseUrl: process.env.REACT_APP_API_BASE_URL \|\| window.location.origin|&#x27;</span> remoteApi.js.bck</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换前：</span></span><br><span class="line">const appConfig = &#123;</span><br><span class="line">    apiBaseUrl: <span class="string">&#x27;http://localhost:8082&#x27;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment"># 替换后：</span></span><br><span class="line">const appConfig = &#123;</span><br><span class="line">    apiBaseUrl: process.env.REACT_APP_API_BASE_URL || window.location.origin</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><table><thead><tr><th>环境</th><th>环境变量值</th><th>结果 (<code>appConfig.apiBaseUrl</code>)</th></tr></thead><tbody><tr><td>开发环境</td><td><code>REACT_APP_API_BASE_URL=http://localhost:8080</code></td><td><code>http://localhost:8080</code></td></tr><tr><td>测试环境</td><td><code>REACT_APP_API_BASE_URL=https://api.test.example.com</code></td><td><code>https://api.test.example.com</code></td></tr><tr><td>未设置变量</td><td><em>(无该环境变量)</em> 则使用默认的 <code>window.location.origin</code>，其表示 当前网页的 协议 + 域名 + 端口号</td><td>自动使用当前网站地址，如 <code>https://myapp.example.com</code></td></tr></tbody></table><blockquote><p>目前<code>2.1.0</code>版本的bug还比较多，GitHub仓库中的代码已经修复了包括该bug在内的部分bug，不过还没有发布到 release。<br>着急的小伙伴可以通过 <code>git clone</code> 项目，编译并运行，或者等待作者发布新版本。</p></blockquote><ul class="lvl-0"><li class="lvl-2"><p>编译</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/soft/rocketmq/rocketmq-dashboard</span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">JAVA_HOME=/usr/local/jdk/jdk17 mvn clean package -Dmaven.test.skip=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 将jar包复制到run目录下，以避免重新编译时被覆盖</span></span><br><span class="line"><span class="built_in">mkdir</span> run</span><br><span class="line"><span class="built_in">cp</span> target/rocketmq-dashboard-2.1.0.jar run/</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>按需替换配置，</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim run/application.yaml # 按需替换配置</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rocketmq:</span></span><br><span class="line">  <span class="attr">config:</span></span><br><span class="line">    <span class="attr">namesrvAddrs:</span>                <span class="comment"># 填写NameServer地址列表</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.175</span><span class="string">:9876</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.188</span><span class="string">:9876</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.131</span><span class="string">:9876</span></span><br><span class="line">    <span class="attr">proxyAddrs:</span>                  <span class="comment"># 填写Proxy地址列表</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.175</span><span class="string">:8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.188</span><span class="string">:8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10.250</span><span class="number">.0</span><span class="number">.131</span><span class="string">:8080</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> run</span><br><span class="line"><span class="comment"># 启动，默认会加载与jar包同级目录下的application.yaml文件</span></span><br><span class="line"><span class="built_in">nohup</span> /usr/local/jdk/jdk17/bin/java -jar rocketmq-dashboard-2.1.0.jar 1&gt;dashboard.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line"><span class="built_in">tail</span> -f dashboard.log</span><br></pre></td></tr></table></figure><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/9F26eh.png" alt="" width="1400" height="800"></p>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://rocketmq.apache.org/zh/&quot;&gt;RocketMQ官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RocketMQ 版本为 5.3.2。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rocketmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rocketmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rocketmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rocketmq" scheme="https://blog.hanqunfeng.com/tags/rocketmq/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ 的安装及使用</title>
    <link href="https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/"/>
    <id>https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/</id>
    <published>2025-10-23T13:30:05.000Z</published>
    <updated>2025-10-25T06:39:02.558Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 RocketMQ 的安装与使用。</p></li><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/">RocketMQ官网</a></p></li><li class="lvl-2"><p>本文使用的 RocketMQ 版本为 5.3.2。</p></li></ul><span id="more"></span><h2 id="Apache-RocketMQ-简介">Apache RocketMQ 简介</h2><h3 id="一、RocketMQ-是什么？">一、RocketMQ 是什么？</h3><p>RocketMQ 是一个<strong>分布式、队列模型的消息中间件</strong>。它由阿里巴巴在2012年开源，并于2017年正式成为 Apache 基金会的顶级项目。</p><p>你可以把它想象成一个在分布式系统中负责可靠传递消息的“邮局”或“快递系统”。当系统A需要发送数据给系统B，但它们之间不直接通信时，就可以通过 RocketMQ 来中转，确保消息不丢失、不重复，并且能按顺序送达。</p><p><strong>RocketMQ 是一个高性能、高可靠、高实时的分布式消息中间件</strong>。它就像分布式系统的“中枢神经系统”，负责在各个服务之间可靠、高效地传递数据，是现代互联网架构中不可或缺的基础组件之一。</p><p><strong>RocketMQ 5.x 通过引入 Proxy 模式，极大地提升了架构的灵活性、多语言支持能力和云原生亲和力</strong>，是其在消息中间件领域持续演进的重要里程碑。</p><p>它与 Kafka、RabbitMQ 等都是业界顶级的消息队列，但各有侧重。RocketMQ 在事务消息、顺序消息和对在线业务的稳定性支持方面表现尤为出色。</p><hr><h3 id="二、核心特点与优势">二、核心特点与优势</h3><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:left">特性</th><th style="text-align:left">典型场景</th><th style="text-align:left">主要作用</th></tr></thead><tbody><tr><td style="text-align:center"><strong>1</strong></td><td style="text-align:left"><strong>削峰填谷</strong></td><td style="text-align:left">电商秒杀、大促活动时大量下单请求瞬间涌入</td><td style="text-align:left">将突发请求先缓存为消息，后端系统按自身能力平稳消费，避免系统过载崩溃</td></tr><tr><td style="text-align:center"><strong>2</strong></td><td style="text-align:left"><strong>异步解耦</strong></td><td style="text-align:left">用户注册后触发多系统任务（邮件、优惠券、积分）</td><td style="text-align:left">主流程只负责发送消息，其他系统独立异步处理，降低系统间耦合、提高扩展性</td></tr><tr><td style="text-align:center"><strong>3</strong></td><td style="text-align:left"><strong>顺序消息</strong></td><td style="text-align:left">订单状态变更（创建 → 付款 → 发货 → 收货）</td><td style="text-align:left">同一业务键（如订单ID）的消息按顺序发送和消费，保证业务逻辑正确性</td></tr><tr><td style="text-align:center"><strong>4</strong></td><td style="text-align:left"><strong>持久化与高可靠性</strong></td><td style="text-align:left">关键业务消息必须不丢失（交易、支付、日志）</td><td style="text-align:left">所有消息写入磁盘并支持主从复制，即使服务器重启也能恢复，保证高可用</td></tr><tr><td style="text-align:center"><strong>5</strong></td><td style="text-align:left"><strong>消息回溯</strong></td><td style="text-align:left">消费逻辑出错、数据重算、补偿任务</td><td style="text-align:left">支持重置消费位点，重新消费历史消息，实现业务补偿与追溯</td></tr><tr><td style="text-align:center"><strong>6</strong></td><td style="text-align:left"><strong>海量消息堆积能力</strong></td><td style="text-align:left">大规模异步日志收集、IoT 数据汇聚、埋点分析</td><td style="text-align:left">支持万亿级消息堆积，性能稳定不衰减，适用于大规模数据场景</td></tr></tbody></table><hr><h3 id="三、核心架构与概念">三、核心架构与概念</h3><p>要理解 RocketMQ，需要知道几个关键角色：<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/frTwo1.png" alt=""></p><h4 id="经典核心组件">经典核心组件</h4><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:left">组件名称</th><th style="text-align:left">主要作用</th><th style="text-align:left">说明 / 特点</th></tr></thead><tbody><tr><td style="text-align:center"><strong>1</strong></td><td style="text-align:left"><strong>Producer（生产者）</strong></td><td style="text-align:left">发送消息的客户端</td><td style="text-align:left">负责将业务系统的消息发送到指定的 <strong>Topic</strong>，支持同步、异步、单向三种发送方式</td></tr><tr><td style="text-align:center"><strong>2</strong></td><td style="text-align:left"><strong>Consumer（消费者）</strong></td><td style="text-align:left">接收并消费消息的客户端</td><td style="text-align:left">从 Broker 拉取消息并进行业务处理，可分为 <strong>Push</strong> 和 <strong>Pull</strong> 两种消费模式</td></tr><tr><td style="text-align:center"><strong>3</strong></td><td style="text-align:left"><strong>Consumer Group（消费者组）</strong></td><td style="text-align:left">实现负载均衡与高可用消费</td><td style="text-align:left">多个消费者订阅同一 Topic 时组成消费者组，一个分区只会被组内一个消费者消费</td></tr><tr><td style="text-align:center"><strong>4</strong></td><td style="text-align:left"><strong>Broker（消息服务器）</strong></td><td style="text-align:left">存储和转发消息</td><td style="text-align:left">RocketMQ 的核心组件，负责消息的持久化、转发、主从复制和高可用</td></tr><tr><td style="text-align:center"><strong>5</strong></td><td style="text-align:left"><strong>Topic（主题）</strong></td><td style="text-align:left">消息的分类与路由单元</td><td style="text-align:left">Producer 发送消息到指定 Topic，Consumer 订阅 Topic 消费消息；一个 Topic 可包含多个消息队列（分区）</td></tr><tr><td style="text-align:center"><strong>6</strong></td><td style="text-align:left"><strong>Name Server（名字服务）</strong></td><td style="text-align:left">管理 Broker 地址信息</td><td style="text-align:left">类似轻量级注册中心，维护 Broker 元数据，帮助 Producer 和 Consumer 定位消息存储位置</td></tr><tr><td style="text-align:center"><strong>7</strong></td><td style="text-align:left"><strong>Controller（控制器）</strong></td><td style="text-align:left">主从自动切换与高可用控制</td><td style="text-align:left">RocketMQ 5.x 引入，基于 Raft（DLedger）协议实现 Broker 自动选主和元数据管理</td></tr><tr><td style="text-align:center"><strong>8</strong></td><td style="text-align:left"><strong>Proxy（代理层）</strong></td><td style="text-align:left">客户端访问入口与协议转换</td><td style="text-align:left">RocketMQ 5.x 新组件，无状态，可横向扩展；统一接入层，支持多协议（如 HTTP、gRPC），隔离客户端与 Broker</td></tr></tbody></table><blockquote><p><strong>引入 Proxy 模式的优势：</strong></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">**架构解耦与语言无关**：Proxy 作为通用代理，将复杂的 Broker 协议封装成更简单的接口（如 gRPC），使得用不同编程语言（如 Go, Python, C++ 等）开发的客户端更容易接入，而无需实现复杂的原生协议。</span><br><span class="line">**简化客户端**：客户端不再需要感知 Name Server 和 Broker 的地址变化，只需连接固定的 Proxy 地址即可，大大降低了客户端的复杂度。</span><br><span class="line">**增强安全性**：可以在 Proxy 层统一实现安全认证、限流、审计等策略，作为Broker集群的安全屏障。</span><br><span class="line">**云原生友好**：无状态的 Proxy 非常适合在 Kubernetes 等容器化环境中进行部署和弹性伸缩。</span><br></pre></td></tr></table></figure><hr><h2 id="RocketMQ-的安装">RocketMQ 的安装</h2><ul class="lvl-0"><li class="lvl-2"><p>RocketMQ 5.x 依赖 JDK 1.8+。</p></li></ul><h3 id="单机安装">单机安装</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/docs/quickStart/01quickstart">官方文档</a></p></li><li class="lvl-2"><p>下载RocketMQ</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /usr/local/soft/rocketmq/</span><br><span class="line">wget https://dist.apache.org/repos/dist/release/rocketmq/5.3.2/rocketmq-all-5.3.2-bin-release.zip</span><br><span class="line">unzip rocketmq-all-5.3.2-bin-release.zip</span><br><span class="line"><span class="built_in">ln</span> -s rocketmq-all-5.3.2-bin-release rocketmq5</span><br><span class="line"><span class="built_in">cd</span> rocketmq5</span><br></pre></td></tr></table></figure><div class="tips"><p><em><strong>小贴士</strong></em><br>默认脚本中，NameServer需要4G内存，Broker 需要8G内存，如果内存不够，可以进入bin目录，对其中的<code>runserver.sh</code>和<code>runbroker.sh</code>两个脚本进行一下修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用vi runserver.sh指令，编辑这个脚本，找到下面的一行配置，调整Java进程的内存大小。</span></span><br><span class="line">JAVA_OPT=<span class="string">&quot;<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms4g -Xmx4g -Xmn2G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class="line">修改为：</span><br><span class="line">JAVA_OPT=<span class="string">&quot;<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms1g -Xmx1g -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，同样调整runbroker.sh中的内存大小。</span></span><br><span class="line">JAVA_OPT=<span class="string">&quot;<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g&quot;</span></span><br><span class="line">修改为：</span><br><span class="line">JAVA_OPT=<span class="string">&quot;<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms2g -Xmx2g&quot;</span></span><br></pre></td></tr></table></figure></div><ul class="lvl-0"><li class="lvl-2"><p>启动 NameServer</p></li></ul><blockquote><p>安装完RocketMQ包后，我们启动NameServer</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 启动namesrv</span></span><br><span class="line">$ <span class="built_in">nohup</span> sh bin/mqnamesrv &amp;</span><br><span class="line"><span class="comment">## 指定配置文件</span></span><br><span class="line">$ <span class="built_in">nohup</span> sh bin/mqnamesrv -c namesrv.conf &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">### 验证namesrv是否启动成功</span></span><br><span class="line">$ <span class="built_in">tail</span> -f ~/logs/rocketmqlogs/namesrv.log</span><br><span class="line"><span class="comment"># 我们可以在namesrv.log 中看到 &#x27;The Name Server boot success..&#x27;， 表示NameServer 已成功启动。</span></span><br><span class="line">The Name Server boot success. serializeType=JSON, address 0.0.0.0:9876</span><br></pre></td></tr></table></figure><blockquote><p>namesrv.conf 示例</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The port of nameserver</span></span><br><span class="line">listenPort = 9876</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 Broker+Proxy</p></li></ul><blockquote><p>NameServer成功启动后，我们启动Broker和Proxy。这里我们使用 Local 模式部署，即 Broker 和 Proxy 同进程部署。5.x 版本也支持 Broker 和 Proxy 分离部署以实现更灵活的集群能力。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 先启动broker</span></span><br><span class="line">$ <span class="built_in">nohup</span> sh bin/mqbroker -n localhost:9876 --enable-proxy &amp;</span><br><span class="line"><span class="comment"># 指定配置文件</span></span><br><span class="line">$ <span class="built_in">nohup</span> sh bin/mqbroker -n localhost:9876 -c conf/broker.conf --enable-proxy &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">### 验证broker是否启动成功, 比如, broker的ip是192.168.1.2 然后名字是broker-a</span></span><br><span class="line">$ <span class="built_in">tail</span> -f ~/logs/rocketmqlogs/proxy.log</span><br><span class="line"><span class="comment"># 我们可以在 proxy.log 中看到“The broker[brokerName,ip:port] boot success..”，这表明 broker 已成功启动。</span></span><br><span class="line">The broker[broker-a, 10.250.0.175:10911] boot success. serializeType=JSON and name server is localhost:9876</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>关闭服务器</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先停止 Broker</span></span><br><span class="line">$ sh bin/mqshutdown broker</span><br><span class="line"><span class="comment"># 停止 NameServer</span></span><br><span class="line">$ sh bin/mqshutdown namesrv</span><br></pre></td></tr></table></figure><h3 id="集群安装-多节点（集群）多副本模式-异步复制">集群安装:多节点（集群）多副本模式-异步复制</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/docs/deploymentOperations/01deploy">官网文档</a> 对集群安装的方式介绍了多种，本文仅实战一种：<code>多节点（集群）多副本模式-异步复制</code></p></li><li class="lvl-2"><p>每个Master配置一个Slave，有多组 Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：</p><ul class="lvl-2"><li class="lvl-6">优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；</li><li class="lvl-6">缺点：Master宕机，磁盘损坏情况下会丢失少量消息。</li></ul></li><li class="lvl-2"><p>该模式下，Master 节点和 Slave 节点之间是异步复制的，Master 节点挂掉后，Slave 节点不会自动切换为 Master 节点。</p></li><li class="lvl-2"><p>集群规划</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NameServer 3 台</span></span><br><span class="line">NameServer1 10.250.0.175</span><br><span class="line">NameServer2 10.250.0.188</span><br><span class="line">NameServer3 10.250.0.31</span><br><span class="line"></span><br><span class="line"><span class="comment"># Broker 2 Master 2 Replicas</span></span><br><span class="line">Broker1 10.250.0.188 broker-a,broker-b-s</span><br><span class="line">Broker2 10.250.0.31  broker-b,broker-a-s</span><br><span class="line"></span><br><span class="line"><span class="comment"># Proxy 3 台</span></span><br><span class="line">Proxy1 10.250.0.175</span><br><span class="line">Proxy2 10.250.0.188</span><br><span class="line">Proxy3 10.250.0.31</span><br></pre></td></tr></table></figure><h4 id="部署-NameServer">部署 NameServer</h4><ul class="lvl-0"><li class="lvl-2"><p>在三台服务器上分别启动RocketMQ NameServer</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/soft/rocketmq/rocketmq5</span><br><span class="line"><span class="built_in">nohup</span> sh bin/mqnamesrv &amp;</span><br></pre></td></tr></table></figure><h4 id="部署Broker">部署Broker</h4><ul class="lvl-0"><li class="lvl-2"><p>broker-a.properties</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName=DefaultCluster <span class="comment"># 集群名称必须一致</span></span><br><span class="line">brokerName=broker-a              <span class="comment"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class="line">brokerId=0                       <span class="comment"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class="line">deleteWhen=04                    <span class="comment"># 表示凌晨 4 点清理</span></span><br><span class="line">fileReservedTime=48              <span class="comment"># 表示保存 48 小时的数据</span></span><br><span class="line">brokerRole=ASYNC_MASTER          <span class="comment"># 角色，表示异步复制的主节点</span></span><br><span class="line">flushDiskType=ASYNC_FLUSH        <span class="comment"># 表示异步刷盘</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class="line"><span class="comment"># 存储数据路径，后面会介绍</span></span><br><span class="line">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class="line">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class="line">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class="line">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class="line">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class="line">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class="line">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class="line"><span class="comment">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class="line">listenPort=10911</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>broker-a-s.properties</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName=DefaultCluster <span class="comment"># 集群名称必须一致</span></span><br><span class="line">brokerName=broker-a              <span class="comment"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class="line">brokerId=1                       <span class="comment"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class="line">deleteWhen=04</span><br><span class="line">fileReservedTime=48</span><br><span class="line">brokerRole=SLAVE                 <span class="comment"># 角色，表示异步复制的从节点</span></span><br><span class="line">flushDiskType=ASYNC_FLUSH</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class="line"><span class="comment"># 存储数据路径</span></span><br><span class="line">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class="line">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class="line">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class="line">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class="line">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class="line">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class="line">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class="line"><span class="comment">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class="line">listenPort=11011</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>broker-b.properties</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName=DefaultCluster <span class="comment"># 集群名称必须一致</span></span><br><span class="line">brokerName=broker-b              <span class="comment"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class="line">brokerId=0                       <span class="comment"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class="line">deleteWhen=04                    <span class="comment"># 表示凌晨 4 点清理</span></span><br><span class="line">fileReservedTime=48              <span class="comment"># 表示保存 48 小时的数据</span></span><br><span class="line">brokerRole=ASYNC_MASTER          <span class="comment"># 角色，表示异步复制的主节点</span></span><br><span class="line">flushDiskType=ASYNC_FLUSH        <span class="comment"># 表示异步刷盘</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class="line"><span class="comment"># 存储数据路径</span></span><br><span class="line">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class="line">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class="line">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class="line">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class="line">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class="line">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class="line">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class="line"></span><br><span class="line"><span class="comment">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class="line">listenPort=10911</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>broker-b-s.properties</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName=DefaultCluster <span class="comment"># 集群名称必须一致</span></span><br><span class="line">brokerName=broker-b              <span class="comment"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class="line">brokerId=1                       <span class="comment"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class="line">deleteWhen=04</span><br><span class="line">fileReservedTime=48</span><br><span class="line">brokerRole=SLAVE                 <span class="comment"># 角色，表示异步复制的从节点</span></span><br><span class="line">flushDiskType=ASYNC_FLUSH</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class="line"><span class="comment"># 存储数据路径</span></span><br><span class="line">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class="line">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class="line">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class="line">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class="line">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class="line">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class="line">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class="line"></span><br><span class="line"><span class="comment">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class="line">listenPort=11011</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>在 Broker1 10.250.0.188 上启动 broker-a 和 broker-b-s</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 broker-a</span></span><br><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a.properties &amp;</span><br><span class="line"><span class="comment"># 启动 broker-b-s</span></span><br><span class="line">  <span class="built_in">nohup</span> sh bin/mqbroker -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b-s.properties &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">## nohup.out 中的输出类似与下面这种就表示启动成功</span></span><br><span class="line">The broker[broker-a, 10.250.0.31:11011] boot success. serializeType=JSON and name server is 10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>在 Broker2 10.250.0.31 上启动 broker-b 和 broker-a-s</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 broker-b</span></span><br><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b.properties &amp;</span><br><span class="line"><span class="comment"># 启动 broker-a-s</span></span><br><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a-s.properties &amp;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动成功后，可以通过如下命令检查机器状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）</span></span><br><span class="line">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class="line"><span class="comment">## 输出类似如下</span></span><br><span class="line"><span class="comment">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class="line">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900          <span class="literal">true</span></span><br><span class="line">DefaultCluster          broker-a                1     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600         <span class="literal">false</span></span><br><span class="line">DefaultCluster          broker-b                0     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600          <span class="literal">true</span></span><br><span class="line">DefaultCluster          broker-b                1     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900         <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="配置-Proxy">配置 Proxy</h4><ul class="lvl-0"><li class="lvl-2"><p>在三台服务器上分别启动RocketMQ NameServer</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> sh bin/mqproxy -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定配置文件，这里要注意，集群的名称要与 conf/proxy.conf 中配置的集群名称必须一致，默认是 DefaultCluster</span></span><br><span class="line"><span class="built_in">nohup</span> sh bin/mqproxy -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -pc conf/proxy.conf &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看日志，输出如下内容就表示启动成功，tail -f nohup.out</span></span><br><span class="line">rocketmq-proxy startup successfully</span><br></pre></td></tr></table></figure><h3 id="集群安装-主备自动切换模式部署">集群安装:主备自动切换模式部署</h3><ul class="lvl-0"><li class="lvl-2"><p>RocketMQ 5.x 提供了一种新的部署方式 <code>Controller</code>，可以在主从模式下实现主备自动切换，当主节点挂掉时，自动切换到从节点上运行。</p></li><li class="lvl-2"><p><a href="https://rocketmq.apache.org/zh/docs/deploymentOperations/03autofailover">官方文档:主备自动切换模式部署</a></p></li><li class="lvl-2"><p>Controller 组件提供选主能力，若需要保证 Controller 具备容错能力，Controller 部署需要三副本及以上（遵循 Raft 的多数派协议）。</p></li><li class="lvl-2"><p>本文在上文“集群安装:多节点（集群）多副本模式-异步复制”的基础上进行修改</p></li><li class="lvl-2"><p>Controller 部署有两种方式。一种是嵌入于 NameServer 进行部署，另一种是独立部署，本文采用独立部署 Controller 组件的方式。</p></li><li class="lvl-2"><p>集群规划</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Controller 3 台</span></span><br><span class="line">Controller1 10.250.0.175</span><br><span class="line">Controller2 10.250.0.188</span><br><span class="line">Controller3 10.250.0.31</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别在每台机器上创建<code>controller.conf</code>配置文件，内容如下(注意修改节点Id)</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># controller.conf</span></span><br><span class="line"><span class="comment"># ---------------------------------------------------------</span></span><br><span class="line"><span class="comment"># DLedger Raft Group 的名字，同一集群保持一致</span></span><br><span class="line">controllerDLegerGroup = group1</span><br><span class="line"><span class="comment"># 集群中三个节点的成员定义，每个节点都必须一致</span></span><br><span class="line">controllerDLegerPeers = n0-10.250.0.175:9877;n1-10.250.0.188:9877;n2-10.250.0.31:9877</span><br><span class="line"><span class="comment"># 节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一</span></span><br><span class="line">controllerDLegerSelfId = n0</span><br><span class="line"><span class="comment"># Controller 数据存储路径（非常关键！不要删除）</span></span><br><span class="line">controllerStorePath = /usr/local/soft/rocketmq/data/DledgerController</span><br><span class="line"><span class="comment"># 是否允许从 SyncStateSet 外选举 Master</span></span><br><span class="line"><span class="comment"># true 会加快选举但可能丢消息，建议生产保持 false</span></span><br><span class="line">enableElectUncleanMaster = <span class="literal">false</span></span><br><span class="line"><span class="comment"># 当 Broker 副本角色变化时是否主动通知（建议开启）</span></span><br><span class="line">notifyBrokerRoleChanged = <span class="literal">true</span></span><br><span class="line"><span class="comment"># 启动端口，端口不能与 NameServer、Broker、Proxy 端口冲突</span></span><br><span class="line">listenPort = 9877</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别启动每台机器上的 Controller</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> sh bin/mqcontroller -n <span class="string">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/controller.conf &amp;</span><br><span class="line"><span class="comment">## 启动成功后，查看 nohup.out 文件，输出如下内容就表示启动成功</span></span><br><span class="line">load config properties file OK, conf/controller.conf</span><br><span class="line">The Controller Server boot success. serializeType=JSON</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改 broker 配置文件，以 <code>broker-a.properties</code> 为例</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去掉如下配置，Controller 模式下 会自动分配</span></span><br><span class="line"><span class="comment"># brokerId=1                       # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class="line"><span class="comment"># brokerRole=ASYNC_MASTER          # 角色，表示异步复制的主节点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下配置</span></span><br><span class="line"><span class="comment"># 启用 Controller 模式（自动主从切换模式的总开关）</span></span><br><span class="line">enableControllerMode = <span class="literal">true</span></span><br><span class="line"><span class="comment"># Controller 集群地址列表（建议与 Controller 集群保持一致）</span></span><br><span class="line">controllerAddr = 10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877</span><br></pre></td></tr></table></figure><blockquote><p>RocketMQ 5 Broker Controller 模式配置参数表</p></blockquote><table><thead><tr><th style="text-align:left">参数名</th><th style="text-align:left">说明</th><th style="text-align:center">默认值</th><th style="text-align:left">备注 / 建议</th></tr></thead><tbody><tr><td style="text-align:left"><strong>enableControllerMode</strong></td><td style="text-align:left">是否启用 Controller 模式（自动主从切换总开关）</td><td style="text-align:center"><code>false</code></td><td style="text-align:left">必须设为 <code>true</code> 才能启用自动主从切换</td></tr><tr><td style="text-align:left"><strong>controllerAddr</strong></td><td style="text-align:left">Controller 集群地址列表（以分号分隔）</td><td style="text-align:center">无</td><td style="text-align:left">所有 Broker 配置应一致，例如 <code>10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877</code></td></tr><tr><td style="text-align:left"><strong>syncBrokerMetadataPeriod</strong></td><td style="text-align:left">向 Controller 同步 Broker 副本信息的时间间隔（毫秒）</td><td style="text-align:center"><code>5000</code> (5s)</td><td style="text-align:left">保持默认即可；用于上报心跳与元数据</td></tr><tr><td style="text-align:left"><strong>checkSyncStateSetPeriod</strong></td><td style="text-align:left">检查同步状态集（SyncStateSet）的时间间隔（毫秒）</td><td style="text-align:center"><code>5000</code> (5s)</td><td style="text-align:left">Controller 会定期剔除落后副本</td></tr><tr><td style="text-align:left"><strong>syncControllerMetadataPeriod</strong></td><td style="text-align:left">同步 Controller 元数据的时间间隔（毫秒）</td><td style="text-align:center"><code>10000</code> (10s)</td><td style="text-align:left">Broker 定期从集群获取当前活跃 Controller 地址</td></tr><tr><td style="text-align:left"><strong>haMaxTimeSlaveNotCatchup</strong></td><td style="text-align:left">Slave 未跟上 Master 的最大时间间隔（毫秒）</td><td style="text-align:center"><code>15000</code> (15s)</td><td style="text-align:left">超过该时间将 Slave 移出 SyncStateSet</td></tr><tr><td style="text-align:left"><strong>storePathEpochFile</strong></td><td style="text-align:left">Epoch 文件存储路径</td><td style="text-align:center"><code>store/epochFile</code></td><td style="text-align:left">非常重要！不要删除；存储主从任期、epoch 等元信息</td></tr><tr><td style="text-align:left"><strong>allAckInSyncStateSet</strong></td><td style="text-align:left">是否要求所有同步副本都 ACK 后才返回成功</td><td style="text-align:center"><code>false</code></td><td style="text-align:left"><code>true</code> 可保证强一致但性能下降；建议保持默认</td></tr><tr><td style="text-align:left"><strong>syncFromLastFile</strong></td><td style="text-align:left">Slave 是否从最后一个文件开始复制（空盘启动时）</td><td style="text-align:center"><code>false</code></td><td style="text-align:left">若历史日志很大且 Slave 新建，可设为 <code>true</code></td></tr><tr><td style="text-align:left"><strong>asyncLearner</strong></td><td style="text-align:left">是否为异步 learner 副本（不参与选主）</td><td style="text-align:center"><code>false</code></td><td style="text-align:left">用于远程灾备副本，不会被选举为 Master</td></tr><tr><td style="text-align:left"><strong>inSyncReplicas</strong></td><td style="text-align:left">需保持同步的副本组数量</td><td style="text-align:center"><code>1</code></td><td style="text-align:left">若 <code>allAckInSyncStateSet=true</code>，该参数无效</td></tr><tr><td style="text-align:left"><strong>minInSyncReplicas</strong></td><td style="text-align:left">最小同步副本数量，低于该值则拒绝写入</td><td style="text-align:center"><code>1</code></td><td style="text-align:left">防止写入过多未同步副本导致数据丢失风险</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>重新启动 Broker，为保证主从数据一致性在重启时不被破坏，启动顺序应为先重新原Master，再重启原Slave</p></li><li class="lvl-2"><p>启动成功后，可以通过如下命令检查机器状态，可以看到集群内部自动分配了主从</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）</span></span><br><span class="line">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class="line"><span class="comment">## 输出类似如下</span></span><br><span class="line"><span class="comment">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class="line">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.48     0.2900          <span class="literal">true</span></span><br><span class="line">DefaultCluster          broker-a                2     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  2-0(0.0w, 0.0, 0.0)               0  489268.48     0.2700         <span class="literal">false</span></span><br><span class="line">DefaultCluster          broker-b                0     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.48     0.2700          <span class="literal">true</span></span><br><span class="line">DefaultCluster          broker-b                2     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489268.48     0.2900         <span class="literal">false</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>验证主备自动切换，此时关闭 <code>broker-b</code> 的 Master，并查看集群状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class="line"><span class="comment">## 输出类似如下，可以看到`broker-b`原来的 Slave 被切换为 Master</span></span><br><span class="line"><span class="comment">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class="line">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.58     0.2900          <span class="literal">true</span></span><br><span class="line">DefaultCluster          broker-a                2     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  1-0(0.0w, 0.0, 0.0)               0  489268.58     0.2700         <span class="literal">false</span></span><br><span class="line">DefaultCluster          broker-b                0     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.58     0.2900          <span class="literal">true</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>重新启动刚才关闭的 <code>broker-b</code> ，节点会自动加入集群，角色为 Slave</p></li></ul><h2 id="端口说明">端口说明</h2><table><thead><tr><th>端口号</th><th>协议</th><th>组件/服务</th><th>作用说明</th></tr></thead><tbody><tr><td><strong>9876</strong></td><td>TCP</td><td><strong>NameServer</strong></td><td>RocketMQ 集群的 <strong>NameServer</strong> 服务端口。<br>用于 Broker 注册、客户端路由发现。<br>Producer/Consumer 连接此端口以获取 Broker 地址。</td></tr><tr><td><strong>8080</strong></td><td>TCP</td><td><strong>Proxy (gRPC / HTTP)</strong></td><td>RocketMQ 5 引入的 <strong>Proxy 服务</strong> 默认端口之一。<br>用于 <strong>HTTP/gRPC 客户端接入</strong>，例如 RocketMQ Proxy REST API、异步消息接口等。</td></tr><tr><td><strong>8081</strong></td><td>TCP</td><td><strong>Proxy Admin / Dashboard / gRPC Alt</strong></td><td>通常是 Proxy 的 <strong>管理接口</strong> 或 <strong>gRPC 辅助端口</strong>（依配置而定）。<br>也可能是控制面接口，用于与 Console 或控制工具通信。</td></tr><tr><td><strong>10909</strong></td><td>TCP</td><td><strong>Broker HA (High Availability)</strong></td><td>Broker <strong>主从同步端口</strong>（Master ↔ Slave 之间的数据复制）。<br>用于消息数据与元数据的同步。</td></tr><tr><td><strong>10911</strong></td><td>TCP</td><td><strong>Broker 服务端口</strong></td><td>Broker 的 <strong>主通信端口</strong>，客户端连接发送消息、消费消息、心跳等。<br>Producer 和 Consumer 通过 NameServer 获取该端口地址后进行通信。</td></tr><tr><td><strong>10912</strong></td><td>TCP</td><td><strong>Broker HA 客户端端口</strong></td><td>Broker <strong>主从复制中的 Slave 连接 Master</strong> 时使用的 <strong>客户端监听端口</strong>。<br>通常与 10909 配合使用，一主多从模式中 Slave 主动连接 Master。</td></tr></tbody></table><h2 id="日志及数据存储路径">日志及数据存储路径</h2><ul class="lvl-0"><li class="lvl-2"><p>RocketMQ 5 主要有三类服务组件需要关注它们的存储目录</p></li></ul><table><thead><tr><th style="text-align:left">组件</th><th style="text-align:left">功能</th><th style="text-align:left">默认存储内容</th><th style="text-align:left">默认路径（Linux 环境）</th></tr></thead><tbody><tr><td style="text-align:left"><strong>NameServer</strong></td><td style="text-align:left">路由服务（注册中心）</td><td style="text-align:left">各个组件的的注册</td><td style="text-align:left">日志文件：<code>~/logs/rocketmqlogs/namesrv.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.namesrv.logback.xml</code> <br> 配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/namesrv.conf</code>（可选）</td></tr><tr><td style="text-align:left"><strong>Broker</strong></td><td style="text-align:left">核心消息存储与转发服务</td><td style="text-align:left">消息数据（CommitLog、ConsumeQueue、Index、Config）<br><strong>目录结构：</strong><br>├── <code>commitlog/</code> → 消息物理文件<br>├── <code>consumequeue/</code> → 消费队列索引<br>├── <code>index/</code> → 消息索引<br>├── <code>config/</code> → topic、offset、subscription 信息<br>├── <code>checkpoint</code> → 存储校验点<br>├── <code>abort</code> → 异常退出标志</td><td style="text-align:left"><strong>数据目录</strong>：<code>~/store</code><br>日志文件：<code>~/logs/rocketmqlogs/broker.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.broker.logback.xml</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/broker.conf</code></td></tr><tr><td style="text-align:left"><strong>Proxy</strong></td><td style="text-align:left">客户端访问入口层（无状态代理）<br>（5.x 新引入组件）</td><td style="text-align:left">转发日志、访问日志</td><td style="text-align:left">日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.proxy.logback.xml</code><br>日志文件：<code>~/logs/rocketmqlogs/proxy.log</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq-proxy.json</code></td></tr><tr><td style="text-align:left"><strong>Controller</strong></td><td style="text-align:left"><strong>Broker 主从协调与高可用管理</strong><br>（5.x 新引入组件）</td><td style="text-align:left">- 集群主从元数据（主从关系、broker注册信息）<br>- Controller 自身运行状态与选举元数据</td><td style="text-align:left"><strong>数据目录</strong>：<code>~/store/controller</code><br>日志文件：<code>~/logs/rocketmqlogs/controller.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.controller.logback.xml</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/controller.conf</code></td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>NameServer 和 Proxy 都是无状态（stateless）组件，不会持久化业务数据。</p></li><li class="lvl-2"><p>Broker 数据路径说明</p></li></ul><table><thead><tr><th style="text-align:left">配置项</th><th style="text-align:left">默认路径</th><th style="text-align:left">说明</th><th style="text-align:left">主要作用</th></tr></thead><tbody><tr><td style="text-align:left"><strong>storePathRootDir</strong></td><td style="text-align:left"><code>/home/rocketmq/store</code><br>（默认）</td><td style="text-align:left">消息存储的根目录</td><td style="text-align:left">作为所有存储文件的父级目录，其他路径若未单独配置，则在此目录下创建</td></tr><tr><td style="text-align:left"><strong>storePathCommitLog</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/commitlog</code></td><td style="text-align:left">CommitLog 文件存放路径</td><td style="text-align:left">存储消息主体内容，是最核心的数据文件（顺序写入）</td></tr><tr><td style="text-align:left"><strong>storePathConsumeQueue</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/consumequeue</code></td><td style="text-align:left">消费队列文件存放路径</td><td style="text-align:left">存储消息在队列中的索引（逻辑队列），指向 CommitLog 的物理位置</td></tr><tr><td style="text-align:left"><strong>storePathIndex</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/index</code></td><td style="text-align:left">索引文件存放路径</td><td style="text-align:left">提供按 Key 查询消息的索引结构，便于通过 Message Key 快速检索消息</td></tr><tr><td style="text-align:left"><strong>storePathConfig</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/config</code></td><td style="text-align:left">Broker 运行时配置存储路径</td><td style="text-align:left">存储运行时生成的配置文件，如 topic、consumerOffset、subscriptionGroup 等</td></tr><tr><td style="text-align:left"><strong>storeCheckpoint</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/checkpoint</code></td><td style="text-align:left">Checkpoint 文件路径</td><td style="text-align:left">记录 CommitLog、ConsumeQueue、Index 三者的刷盘进度，用于崩溃恢复</td></tr><tr><td style="text-align:left"><strong>abortFile</strong></td><td style="text-align:left"><code>$&#123;storePathRootDir&#125;/abort</code></td><td style="text-align:left">异常退出标志文件路径</td><td style="text-align:left">用于标识 Broker 是否异常退出，启动时据此判断是否执行恢复流程</td></tr></tbody></table><hr><h2 id="安装过程中遇到的问题">安装过程中遇到的问题</h2><h3 id="1-启动-Proxy-失败">1.启动 Proxy 失败</h3><ul class="lvl-0"><li class="lvl-2"><p>无论是 <code>Broker+Proxy</code> 启动，还是 单独启动 <code>Proxy</code>，都报如下错误：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 错误会在 nohup.out 中输出</span></span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.UnsatisfiedLinkError: failed to load the required native library</span><br><span class="line"></span><br><span class="line">Caused by: java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_x86_64_fedora, netty_tcnative_linux_x86_64, netty_tcnative_x86_64, netty_tcnative]</span><br><span class="line"></span><br><span class="line">Suppressed: java.lang.UnsatisfiedLinkError: /tmp/libnetty_tcnative_linux_x86_642308675901892111861.so: libcrypt.so.1: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>原因分析</p><ul class="lvl-2"><li class="lvl-4"><ol><li class="lvl-7">Netty-tcnative 的编译依赖：RocketMQ 使用的 Netty 的 tcnative 模块是在较旧的环境中编译的，而动态链接的版本锁定：编译时链接的是 libcrypt.so.1，运行时必须找到相同主版本号的库</li></ol></li><li class="lvl-4"><ol start="2"><li class="lvl-7">而我当前使用的系统为 Amazon Linux 2023，基于更新的 glibc，其加密功能已经迁移到 libcrypt.so.2。（Amazon Linux 2：基于较旧的 glibc 版本，libcrypt.so.1 是主要的加密库）</li></ol></li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查 libcrypt 是否存在</span></span><br><span class="line">$ ldconfig -p | grep libcrypt</span><br><span class="line"><span class="comment">## 输出</span></span><br><span class="line">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class="line">libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class="line">libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class="line">libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class="line">libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>解决办法</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装兼容性包</span></span><br><span class="line"><span class="built_in">sudo</span> yum install libxcrypt-compat</span><br><span class="line"><span class="comment"># 检查 libcrypt 是否存在</span></span><br><span class="line">$ ldconfig -p | grep libcrypt</span><br><span class="line"><span class="comment">## 输出</span></span><br><span class="line">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class="line">libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class="line">libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class="line">libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class="line">libcrypt.so.1 (libc6,x86-64) =&gt; /lib64/libcrypt.so.1</span><br><span class="line">libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure><h3 id="2-写入消息失败，并报如下错误">2.写入消息失败，并报如下错误</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.apache.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now. It may be caused by one of the following reasons: the broker<span class="string">&#x27;s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00], messages are put to the slave, message store has been shut down, etc. BROKER: 10.250.0.175:10911</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>错误原因</p><ul class="lvl-2"><li class="lvl-4">RocketMQ 返回的 CODE: 14 表示：Broker 当前 不接受消息写入（服务暂不可用）。</li><li class="lvl-4">the broker’s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00]: Broker 的磁盘已满</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CL: 0.95 → CommitLog 95% 已使用</span><br><span class="line">CQ: 0.95 → ConsumeQueue 95% 已使用</span><br><span class="line">INDEX: -1.00 → 索引异常或未采集</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>配置项</th><th>含义</th><th>默认值</th></tr></thead><tbody><tr><td><code>diskMaxUsedSpaceRatio</code></td><td>Broker 磁盘最大可用比例（超过后禁止写入）</td><td><strong>75%</strong></td></tr><tr><td><code>storePathCommitLog</code></td><td>消息存储路径（CommitLog）</td><td><code>~/store/commitlog</code></td></tr><tr><td><code>storePathConsumeQueue</code></td><td>消费队列路径（ConsumeQueue）</td><td><code>~/store/consumequeue</code></td></tr><tr><td><code>storePathIndex</code></td><td>索引路径</td><td><code>~/store/index</code></td></tr></tbody></table><ul class="lvl-0"><li class="lvl-4"><p>总结：可以确认是 磁盘使用率过高 导致 Broker 自动进入 “写保护” 模式。</p></li></ul><ul class="lvl-0"><li class="lvl-2"><p>解决方法</p><ul class="lvl-2"><li class="lvl-6"><ol><li class="lvl-9">清理磁盘：确认磁盘使用率过高，并清理磁盘空间，既降低磁盘使用率</li></ol></li><li class="lvl-6"><ol start="2"><li class="lvl-9">磁盘扩容：如果清理磁盘空间后，磁盘使用率依然过高，则需要扩容磁盘</li></ol></li><li class="lvl-6"><ol start="3"><li class="lvl-9">配置调整：调整 Broker 配置(<code>broker.conf</code>)，将 <code>diskMaxUsedSpaceRatio</code> 配置适当提高，如 96%(<code>diskMaxUsedSpaceRatio=96</code>)，调整后重启 Broker。仅建议在紧急情况下临时解决。</li></ol></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 RocketMQ 的安装与使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://rocketmq.apache.org/zh/&quot;&gt;RocketMQ官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RocketMQ 版本为 5.3.2。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rocketmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rocketmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rocketmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rocketmq" scheme="https://blog.hanqunfeng.com/tags/rocketmq/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 从 Zookeeper 迁移到 KRaft</title>
    <link href="https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/"/>
    <id>https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/</id>
    <published>2025-10-16T14:30:05.000Z</published>
    <updated>2025-10-20T02:50:02.041Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org/39/documentation.html#kraft_zk_migration">官方文档：ZooKeeper到KRaft迁移</a></p></li></ul><span id="more"></span><h2 id="从-Zookeeper-模式迁移到-KRaft-模式（平滑迁移）">从 Zookeeper 模式迁移到 KRaft 模式（平滑迁移）</h2><p><em><strong>！！！迁移后将无法再恢复到 ZooKeeper 模式！！！</strong></em></p><ul class="lvl-0"><li class="lvl-2"><p>Kafka 官方在 3.4+ 引入了完整的 Zookeeper → KRaft 平滑迁移机制，称为 <code>ZK to KRaft (ZkMigration)</code>。</p></li><li class="lvl-2"><p>迁移背景与前提</p></li></ul><table><thead><tr><th style="text-align:left">项目</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">支持版本</td><td style="text-align:left">Kafka <strong>3.4.0+</strong>（建议至少使用 <strong>3.6.x ，目前最新版为 3.9.x</strong>）</td></tr><tr><td style="text-align:left">迁移目的</td><td style="text-align:left">摆脱 ZooKeeper，完全切换为 KRaft 自管理模式</td></tr><tr><td style="text-align:left">迁移模式</td><td style="text-align:left"><strong>在线迁移</strong>（无停机或最小停机）</td></tr><tr><td style="text-align:left">最终目标</td><td style="text-align:left">Kafka 的控制器与元数据完全由 KRaft 管理，不再依赖 ZooKeeper。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>整体迁移流程概览</p></li></ul><table><thead><tr><th>阶段</th><th>控制器类型</th><th>Broker 模式</th><th>ZooKeeper 角色</th><th>KRaft 角色</th><th>特征说明</th></tr></thead><tbody><tr><td><strong>初始阶段</strong></td><td>ZooKeeper 控制器</td><td>全部为 ZK 模式</td><td>管理所有元数据</td><td>尚未启用</td><td>所有 Broker 都运行在 ZK 模式下，由 ZK 控制器管理集群。</td></tr><tr><td><strong>初始元数据加载阶段</strong></td><td>KRaft 控制器开始加载</td><td>部分（或全部）仍为 ZK 模式</td><td>提供元数据源</td><td>从 ZK 加载元数据</td><td>KRaft 法定节点（controller.quorum.voters）从 ZK 中读取并同步当前集群元数据。</td></tr><tr><td><strong>混合阶段</strong></td><td>KRaft 控制器</td><td>部分 ZK 模式，部分 KRaft 模式</td><td>保留只读元数据</td><td>管理并更新元数据</td><td>KRaft 控制器成为主控，ZK 仍存在但只提供读取，Broker 可处于不同模式（混合状态）。</td></tr><tr><td><strong>双写阶段</strong></td><td>KRaft 控制器</td><td>全部为 KRaft 模式</td><td>接收 KRaft 同步写入</td><td>管理元数据并写入 ZK</td><td>所有 Broker 都运行在 KRaft 模式，控制器将元数据同时写入 ZK 和 KRaft 日志。</td></tr><tr><td><strong>迁移完成阶段</strong></td><td>KRaft 控制器</td><td>全部为 KRaft 模式</td><td>不再使用</td><td>独立运行</td><td>停止向 ZK 写入元数据，ZK 可安全关闭，Kafka 完全运行在无 Zookeeper 的 KRaft 模式下。</td></tr></tbody></table><h2 id="开始迁移">开始迁移</h2><ul class="lvl-0"><li class="lvl-2"><p>这里以前文 <a href="/2025/10/13/kafka-01-install-zookeeper/" title="Kafka 的安装：基于 Zookeeper">Kafka 的安装：基于 Zookeeper</a> 中的3个节点的集群为例。</p></li></ul><h3 id="启动一个-Controller-节点">启动一个 Controller 节点</h3><ul class="lvl-0"><li class="lvl-2"><p>在任意一个节点上启动一个 Controller 节点，这里为 worker1</p></li><li class="lvl-2"><p>启动前需要先获取当前 Kafka 集群的 Cluster ID</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ zookeeper-shell.sh localhost:2181 get /cluster/id</span><br><span class="line">Connecting to localhost:2181</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line">&#123;<span class="string">&quot;version&quot;</span>:<span class="string">&quot;1&quot;</span>,<span class="string">&quot;id&quot;</span>:<span class="string">&quot;hp_Q0pihQ0ORcIvXlfHobQ&quot;</span>&#125;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>准备好 Controller 节点的配置文件，这里可以用 <code>config/kraft/controller.properties</code> 为模板进行修改</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置当前节点的角色，这里只能是controller</span></span><br><span class="line">process.roles=controller</span><br><span class="line"><span class="comment"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class="line">node.id=3000</span><br><span class="line"><span class="comment"># 配置集群的投票节点，因为我们当前只启动了一个controller节点，所以只能配置一个投票节点</span></span><br><span class="line">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class="line"><span class="comment"># 配置监听器，注意端口不能重复</span></span><br><span class="line">listeners=CONTROLLER://:9098</span><br><span class="line">advertised.listeners=CONTROLLER://worker1:9098</span><br><span class="line">controller.listener.names=CONTROLLER</span><br><span class="line"><span class="comment"># 日志存放目录，这里存放的是元数据，在格式化时这个目录必须为空目录</span></span><br><span class="line">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class="line"></span><br><span class="line"><span class="comment"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class="line">zookeeper.metadata.migration.enable=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ZooKeeper client 连接</span></span><br><span class="line">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class="line"><span class="comment"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class="line">inter.broker.listener.name=PLAINTEXT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其它参数尽量保持与旧集群的配置一致</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 Controller 节点</p></li></ul><blockquote><p>千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 <a href="http://kafka-storage.sh">kafka-storage.sh</a> format ，那会把原有数据结构重置或踩坏。<br>必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式化元数据目录，log.dirs 参数指定元数据存放目录，首次运行前必须为空目录</span></span><br><span class="line"><span class="comment"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class="line">kafka-storage.sh format --standalone -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br><span class="line"><span class="comment"># 启动，这里没有后台启动是为了方便观察日志输出</span></span><br><span class="line">kafka-server-start.sh /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure><table><thead><tr><th>模式</th><th>format 命令</th><th>quorum 状态</th><th>是否从 ZK 加载</th></tr></thead><tbody><tr><td>迁移阶段（standalone）</td><td><code>--standalone</code></td><td>无（单节点）</td><td>✅ 是</td></tr><tr><td>正式 KRaft 模式</td><td>无 <code>--standalone</code></td><td>✅ 多节点</td><td>❌ 否（独立运行）</td></tr></tbody></table><h3 id="将原先的三个节点作为-Broker-节点重新启动">将原先的三个节点作为 Broker 节点重新启动</h3><ul class="lvl-0"><li class="lvl-2"><p>修改原先的配置文件 <code>server.properties</code>，只需要修改如下内容即可</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在最后加入 CONTROLLER:PLAINTEXT</span></span><br><span class="line">listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,CONTROLLER:PLAINTEXT</span><br><span class="line"></span><br><span class="line"><span class="comment">## 以下是新加入的 配置项</span></span><br><span class="line"><span class="comment"># Set the IBP，当前 kafka 版本是 3.9.1，所以这里设置为 3.9</span></span><br><span class="line">inter.broker.protocol.version=3.9</span><br><span class="line"></span><br><span class="line"><span class="comment"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class="line">zookeeper.metadata.migration.enable=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># KRaft controller quorum configuration，因为目前只启动了一个 controller 节点，所以只能配置一个投票节点</span></span><br><span class="line">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class="line"><span class="comment"># 控制器监听器名称，要与 contreller 节点配置文件 controller.properties 中的配置一致</span></span><br><span class="line">controller.listener.names=CONTROLLER</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别重新启动三个节点</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭 kafka</span></span><br><span class="line">kafka-server-stop.sh</span><br><span class="line"><span class="comment"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class="line">ps -ef | grep kafka | grep  <span class="string">&quot;server\.properties&quot;</span> | grep -v grep | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class="built_in">kill</span> -9</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新启动 kafka</span></span><br><span class="line">kafka-server-start.sh /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>当三个节点都以必要的配置重新启动后，迁移将自动开始。迁移完成后，可以在 Controller(worker1)节点 上看到类似如下日志：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ✅ 意味：从 ZooKeeper 到 KRaft 的初始元数据迁移已成功，共写入 62 条记录，当前 KRaft metadata offset 为 3179。这是迁移成功的明确证据。</span></span><br><span class="line">Completed migration of metadata from ZooKeeper to KRaft. 62 records were generated <span class="keyword">in</span> 300 ms across 1 batches. The average time spent waiting on a batch was 97.00 ms. The record types were &#123;TOPIC_RECORD=3, PARTITION_RECORD=56, CONFIG_RECORD=3&#125;. The current metadata offset is now 3179 with an epoch of 2. Saw 3 brokers <span class="keyword">in</span> the migrated metadata [1, 2, 3]. (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 意味：控制器已加载并生效新元数据与 feature set（与 offset 3179 对应）。</span></span><br><span class="line">Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures=&#123;metadata.version=21&#125;, finalizedFeaturesEpoch=3179). (org.apache.kafka.metadata.publisher.FeaturesPublisher)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 意味：内部迁移状态已更新，KRaft 上有了写入位置记录。</span></span><br><span class="line">Finished initial migration of ZK metadata to KRaft <span class="keyword">in</span> 3486479 ns. Transitioned migration state from ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=-1, kraftMetadataEpoch=-1, lastUpdatedTimeMs=1760682050169, migrationZkVersion=1, controllerZkEpoch=3, controllerZkVersion=3&#125; to ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=3179, kraftMetadataEpoch=2, lastUpdatedTimeMs=1760682050169, migrationZkVersion=2, controllerZkEpoch=3, controllerZkVersion=3&#125; (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 意味：迁移流程按预期推进：先把 KRaft 的元数据与 ZK 对齐（sync），然后与 brokers 建立通信，最终进入 DUAL_WRITE（双写）。DUAL_WRITE 阶段表示控制器在写入 KRaft metadata log 的同时，仍然会把必要的写操作也写回 ZooKeeper（双写）——直到迁移完全完成并确认可以停止写 ZK 为止。</span></span><br><span class="line">3000 transitioning from ZK_MIGRATION to SYNC_KRAFT_TO_ZK state</span><br><span class="line">...</span><br><span class="line">Performing a full metadata <span class="built_in">sync</span> from KRaft to ZK.</span><br><span class="line">Did not make any ZK writes when reconciling with KRaft state.</span><br><span class="line">3000 transitioning ... to KRAFT_CONTROLLER_TO_BROKER_COMM</span><br><span class="line">...</span><br><span class="line">Sending RPCs to broker before moving to dual-write mode using at offset and epoch OffsetAndEpoch(offset=3179, epoch=2)</span><br><span class="line">...</span><br><span class="line">3000 transitioning ... to DUAL_WRITE state</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>上面的日志总体上表明，元数据迁移已成功完成并且控制器进入了双写（DUAL_WRITE）阶段。</p></li></ul><h3 id="将三个Broker节点的配置修改为-KRaft-模式的-broker-节点">将三个Broker节点的配置修改为 KRaft 模式的 broker 节点</h3><ul class="lvl-0"><li class="lvl-2"><p>修改三个节点的配置文件 <code>server.properties</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加process.roles=broker</span></span><br><span class="line">process.roles=broker</span><br><span class="line"><span class="comment"># 用 node.id 替换 broker.id，注意，node.id 需要与 broker.id 一致</span></span><br><span class="line"><span class="comment"># broker.id=1</span></span><br><span class="line">node.id=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去掉 zookeeper 相关配置</span></span><br><span class="line"><span class="comment"># Don&#x27;t set the IBP, KRaft uses &quot;metadata.version&quot; feature flag</span></span><br><span class="line"><span class="comment"># inter.broker.protocol.version=3.9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove the migration enabled flag</span></span><br><span class="line"><span class="comment"># zookeeper.metadata.migration.enable=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove ZooKeeper client configuration</span></span><br><span class="line"><span class="comment"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别重新启动三个节点</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭 kafka</span></span><br><span class="line">kafka-server-stop.sh</span><br><span class="line"><span class="comment"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class="line">ps -ef | grep kafka | grep  <span class="string">&quot;server\.properties&quot;</span> | grep -v grep | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class="built_in">kill</span> -9</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新启动 kafka</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure><h3 id="将-Controller-节点的配置修改为-KRaft-模式的-controller-节点">将 Controller 节点的配置修改为 KRaft 模式的 controller 节点</h3><ul class="lvl-0"><li class="lvl-2"><p>修改 controller 节点的配置文件 <code>controller.properties</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 去掉去下内容</span></span><br><span class="line"><span class="comment"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class="line"><span class="comment"># zookeeper.metadata.migration.enable=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ZooKeeper client 连接</span></span><br><span class="line"><span class="comment"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>重启启动 controller 节点</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭后重新启动</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>此时你可以关闭 zookeeper 集群了，新的 kafka 集群将不再使用 ZooKeeper，也无法在恢复到 ZooKeeper 模式。</p></li></ul><h3 id="加入新的-Controller-节点">加入新的 Controller 节点</h3><ul class="lvl-0"><li class="lvl-2"><p>Controller 尽量保持 奇数个节点。</p></li><li class="lvl-2"><p>之前已经在 <code>worker1</code> 节点上启动了 controller ，现在 <code>worker2</code> 和 <code>worker3</code> 上也来启动 controller 节点，并将它们加入到 kafka 集群中。</p></li><li class="lvl-2"><p>在开始配置前，先将上面的 controller 节点 和 三个 broker 节点 的如下配置进行修改，并重启启动。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 controller.quorum.bootstrap.servers 替换为 controller.quorum.voters</span></span><br><span class="line">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class="line"><span class="comment"># controller.quorum.bootstrap.servers=worker1:9098</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># controller.quorum.voters = 谁是正式投票成员（固定配置）</span></span><br><span class="line"><span class="comment"># controller.quorum.bootstrap.servers = 临时找谁引导连接（迁移或初始化用）</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>配置项</th><th>作用</th><th>适用阶段</th><th>是否必需</th><th>说明</th></tr></thead><tbody><tr><td><strong><code>controller.quorum.voters</code></strong></td><td>定义 <strong>正式的 KRaft 控制器投票成员列表（voter set）</strong></td><td>集群正常运行时</td><td>✅ 是</td><td>所有节点必须配置相同的值</td></tr><tr><td><strong><code>controller.quorum.bootstrap.servers</code></strong></td><td>定义 <strong>迁移阶段或初始化阶段的控制器连接地址（bootstrap controller endpoint）</strong></td><td><strong>ZK → KRaft 迁移阶段</strong> 或 <strong>KRaft 集群初次启动</strong></td><td>⚙️ 可选（仅特定阶段）</td><td>用于在 controller quorum 尚未形成时的临时发现</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>参考 worker1 上的 controller 节点的配置文件 <code>controller.properties</code>，配置 woker2 的 controller 节点配置文件<code>controller.properties</code> ，worker3 也是类似的。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置当前节点的角色，这里只能是controller</span></span><br><span class="line">process.roles=controller</span><br><span class="line"><span class="comment"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class="line">node.id=3001</span><br><span class="line"><span class="comment"># 配置集群的投票节点</span></span><br><span class="line">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class="line"><span class="comment"># 配置监听器，注意端口不能重复</span></span><br><span class="line">listeners=CONTROLLER://:9098</span><br><span class="line">advertised.listeners=CONTROLLER://worker2:9098</span><br><span class="line">controller.listener.names=CONTROLLER</span><br><span class="line"><span class="comment"># 日志存放目录，这里存放的是元数据</span></span><br><span class="line">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class="line"><span class="comment"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class="line">inter.broker.listener.name=PLAINTEXT</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>初始化日志目录</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只有 Controller 节点才需要初始化日志目录</span></span><br><span class="line"><span class="comment"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class="line">kafka-storage.sh format -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别启动 worker2 和 worker3 上的 controller 节点</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>此时新的 controller 节点不会立刻加入选举队列，新节点初始状态默认是 observer，需要执行下面的命令将节点加入选举队列</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分别在 worker2 和 worker3 上执行</span></span><br><span class="line">kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config /usr/local/kafka/kafka3/config/kraft/controller.properties add-controller</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查看集群节点状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --replication</span><br><span class="line">NodeIdDirectoryId           LogEndOffsetLagLastFetchTimestampLastCaughtUpTimestampStatus</span><br><span class="line">3000  RJ4oOPGgTw-KxHFNn4SmiQ27820       0  1760696136345     1760696136345        Leader</span><br><span class="line">3001  zGnWA7zYmRHG6bcTlFV2qA27820       0  1760696136259     1760696136259        Follower</span><br><span class="line">3002  gIDkhOQJEHqg-GJBdezU1Q27820       0  1760696136257     1760696136257        Follower</span><br><span class="line">2     9KeeAYKEQHT92DxqNSwYuA27820       0  1760696136257     1760696136257        Observer</span><br><span class="line">1     Q8lr8JQ2vrDS35_DrI1MxA27820       0  1760696136257     1760696136257        Observer</span><br><span class="line">3     rgQR5wd_i5hLgU97dCKIvA27820       0  1760696136257     1760696136257        Observer</span><br><span class="line"></span><br><span class="line">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --status</span><br><span class="line">ClusterId:              hp_Q0pihQ0ORcIvXlfHobQ</span><br><span class="line">LeaderId:               3000</span><br><span class="line">LeaderEpoch:            5</span><br><span class="line">HighWatermark:          30094</span><br><span class="line">MaxFollowerLag:         0</span><br><span class="line">MaxFollowerLagTimeMs:   0</span><br><span class="line">CurrentVoters:          [&#123;<span class="string">&quot;id&quot;</span>: 3000, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;RJ4oOPGgTw-KxHFNn4SmiQ&quot;</span>, <span class="string">&quot;endpoints&quot;</span>: [<span class="string">&quot;CONTROLLER://worker1:9098&quot;</span>]&#125;, &#123;<span class="string">&quot;id&quot;</span>: 3001, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;zGnWA7zYmRHG6bcTlFV2qA&quot;</span>, <span class="string">&quot;endpoints&quot;</span>: [<span class="string">&quot;CONTROLLER://worker2:9098&quot;</span>]&#125;, &#123;<span class="string">&quot;id&quot;</span>: 3002, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;gIDkhOQJEHqg-GJBdezU1Q&quot;</span>, <span class="string">&quot;endpoints&quot;</span>: [<span class="string">&quot;CONTROLLER://worker3:9098&quot;</span>]&#125;]</span><br><span class="line">CurrentObservers:       [&#123;<span class="string">&quot;id&quot;</span>: 2, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;9KeeAYKEQHT92DxqNSwYuA&quot;</span>&#125;, &#123;<span class="string">&quot;id&quot;</span>: 1, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;Q8lr8JQ2vrDS35_DrI1MxA&quot;</span>&#125;, &#123;<span class="string">&quot;id&quot;</span>: 3, <span class="string">&quot;directoryId&quot;</span>: <span class="string">&quot;rgQR5wd_i5hLgU97dCKIvA&quot;</span>&#125;]</span><br></pre></td></tr></table></figure><h3 id="加入-新的-Broker-节点">加入 新的 Broker 节点</h3><ul class="lvl-0"><li class="lvl-2"><p>创建新的 Broker 节点时，参考其它 Broker 节点 配置好配置文件 <code>server.properties</code>，并启动 Broker 节点即可。</p></li><li class="lvl-2"><p>无需运行日志目录初始化命令，因为 Broker 节点只存放 消息 数据。</p></li></ul><h2 id="迁移后注意事项">迁移后注意事项</h2><ul class="lvl-0"><li class="lvl-2"><p>迁移完成后，Kafka 客户端（Producer / Consumer / AdminClient）依然连接的是 Broker 节点，而不是 Controller 节点。</p></li><li class="lvl-2"><p>Kafka 在 ZooKeeper 模式与 KRaft 模式下的区别主要在于：</p><ul class="lvl-2"><li class="lvl-4">控制平面（Control Plane）：ZK 模式下由 ZooKeeper + Controller Broker 共同管理；KRaft 模式下由 独立的 Controller 进程或角色 管理（通过 Raft 协议同步元数据）。</li><li class="lvl-4">数据平面（Data Plane）：无论是哪个模式，客户端发送、消费消息仍然是通过 Broker 节点 完成的。</li><li class="lvl-4">也就是说，Controller 管理集群元数据（主题、分区、副本、Leader 选举等），而 Broker 节点处理实际的消息流。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/39/documentation.html#kraft_zk_migration&quot;&gt;官方文档：ZooKeeper到KRaft迁移&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 的安装：基于 KRaft 模式</title>
    <link href="https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/"/>
    <id>https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/</id>
    <published>2025-10-16T13:30:05.000Z</published>
    <updated>2025-10-19T02:48:43.911Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li><li class="lvl-2"><p>本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。</p></li></ul><span id="more"></span><h2 id="KRaft-简介">KRaft 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>Kraft 是 Kafka 从 2.8.0 版本 开始⽀持的⼀种新的集群架构⽅式。其⽬的主要是为了摆脱Kafka对Zookeeper的依赖。因为以往基于Zookeeper搭建的集群，增加了Kafka演进与运维的难度，逐渐开始成为Kakfa拥抱云原⽣的⼀种障碍。使⽤Kraft集群后，Kafka集群就不再需要依赖Zookeeper，将之前基于Zookeeper管理的集群数据，转为由Kafka集群⾃⼰管理。</p></li><li class="lvl-2"><p>传统的Kafka集群，会将每个节点的状态信息统一保存在Zookeeper中，并通过Zookeeper动态选举产生一个Controller节点，通过Controller节点来管理Kafka集群，比如触发Partition的选举。而在Kraft集群中，会固定配置几台Broker节点来共同担任Controller的角色，各组Partition的Leader节点就会由这些Controller选举产生。原本保存在Zookeeper中的元数据也转而保存到Controller节点中。</p></li><li class="lvl-2"><p>🧭 Kafka KRaft 模式 vs Zookeeper 模式 对比表</p></li></ul><table><thead><tr><th style="text-align:left">对比项</th><th style="text-align:left"><strong>KRaft 模式（Kafka Raft 模式）</strong></th><th style="text-align:left"><strong>Zookeeper 模式（传统模式）</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>架构结构</strong></td><td style="text-align:left">去中心化架构，Kafka 自身内置控制平面，不依赖外部 Zookeeper。</td><td style="text-align:left">控制平面依赖外部 Zookeeper 集群，Kafka Broker 只负责数据平面。</td></tr><tr><td style="text-align:left"><strong>组件数量</strong></td><td style="text-align:left">无需部署 Zookeeper，只有 Kafka Broker 节点。</td><td style="text-align:left">需要单独维护 Zookeeper 集群。</td></tr><tr><td style="text-align:left"><strong>元数据存储</strong></td><td style="text-align:left">元数据存储在 Kafka 自身的内置日志中（<code>__cluster_metadata</code> topic）。</td><td style="text-align:left">元数据存储在 Zookeeper 的 znode 树结构中。</td></tr><tr><td style="text-align:left"><strong>一致性协议</strong></td><td style="text-align:left">使用 Kafka 自己实现的 Raft 协议（KRaft）来保证元数据一致性。</td><td style="text-align:left">使用 ZAB（Zookeeper Atomic Broadcast）协议保证一致性。</td></tr><tr><td style="text-align:left"><strong>启动速度</strong></td><td style="text-align:left">更快，控制器内嵌于 Broker 中，不需要等待外部 Zookeeper 启动。</td><td style="text-align:left">启动依赖 Zookeeper，启动顺序和连通性要求更严格。</td></tr><tr><td style="text-align:left"><strong>容错性</strong></td><td style="text-align:left">Raft 控制器具备日志复制机制，容错性与 Kafka 数据副本一致。</td><td style="text-align:left">容错性由 Zookeeper 决定，Zookeeper 挂掉可能导致 Kafka 控制面不可用。</td></tr><tr><td style="text-align:left"><strong>扩展性</strong></td><td style="text-align:left">元数据存储在 Kafka 主题中，水平扩展能力更强。</td><td style="text-align:left">Zookeeper 在高分区数场景下易成为性能瓶颈。</td></tr><tr><td style="text-align:left"><strong>运维复杂度</strong></td><td style="text-align:left">无需维护 Zookeeper 集群，统一运维 Kafka 即可。</td><td style="text-align:left">需要额外维护 Zookeeper 集群（监控、扩容、升级）。</td></tr><tr><td style="text-align:left"><strong>数据恢复</strong></td><td style="text-align:left">元数据恢复与 Kafka 主题一致，可通过日志回放恢复。</td><td style="text-align:left">Zookeeper 数据恢复相对复杂，依赖快照和事务日志。</td></tr><tr><td style="text-align:left"><strong>安全机制</strong></td><td style="text-align:left">统一 Kafka 的安全机制（SASL、SSL、ACL 等）。</td><td style="text-align:left">Zookeeper 有独立的安全配置体系，需单独管理。</td></tr><tr><td style="text-align:left"><strong>性能表现</strong></td><td style="text-align:left">元数据操作延迟更低（控制器与 Broker 本地通信）。</td><td style="text-align:left">元数据操作需要跨进程网络通信，延迟更高。</td></tr><tr><td style="text-align:left"><strong>控制器角色</strong></td><td style="text-align:left">由 Broker 中的控制器 quorum 选举产生（支持多控制器候选）。</td><td style="text-align:left">由 Zookeeper 选举控制器（单点控制器）。</td></tr><tr><td style="text-align:left"><strong>分区与副本管理</strong></td><td style="text-align:left">全部元数据存储在 Kafka 自身，可实现更快的分区变更和扩容。</td><td style="text-align:left">分区、副本元数据同步依赖 Zookeeper，性能相对较低。</td></tr><tr><td style="text-align:left"><strong>版本支持</strong></td><td style="text-align:left">从 Kafka 2.8 开始引入，Kafka 3.3+ 已经非常稳定，Kafka 3.5+ 默认推荐。</td><td style="text-align:left">Kafka 3.5 开始标记为“Legacy”，未来版本计划移除支持。</td></tr><tr><td style="text-align:left"><strong>兼容性</strong></td><td style="text-align:left">可通过元数据迁移工具从 Zookeeper 模式平滑迁移。</td><td style="text-align:left">不能直接迁移到 KRaft，需要工具辅助。</td></tr><tr><td style="text-align:left"><strong>运维监控</strong></td><td style="text-align:left">单一系统可监控（Kafka 自带的 JMX、Prometheus 等）。</td><td style="text-align:left">Kafka 与 Zookeeper 各自需要独立监控体系。</td></tr><tr><td style="text-align:left"><strong>未来发展方向</strong></td><td style="text-align:left">官方推荐和默认模式（Zookeeper 模式将逐步淘汰）。</td><td style="text-align:left">官方已不再建议新集群使用。</td></tr></tbody></table><h2 id="Kafka-的-KRaft-集群配置">Kafka 的 KRaft 集群配置</h2><ul class="lvl-0"><li class="lvl-2"><p>在Kafka的config目录下，提供了一个kraft的文件夹，在这里面提供了三个Kraft协议的参考配置文件</p><ul class="lvl-2"><li class="lvl-4">broker.properties: 数据节点，client连接时只连接broker数据节点</li><li class="lvl-4">controller.properties: Controller控制节点</li><li class="lvl-4">server.properties: 即可以是数据节点，又可以是Controller控制节点。</li></ul></li><li class="lvl-2"><p>实际上这些配置文件中的配置项基本与 serrver.properties 一致，只是去除了与 zookeeper 相关的配置项，同时增加了一些 Kraft 模式下的配置项。关于 server.properties 的配置项，请参考 <a href="https://kafka.apache.org/39/documentation/#brokerconfigs">Kafka 官方文档</a></p></li><li class="lvl-2"><p>这里以 <code>kraft/serrver.properties</code> 为例进行修改，配置三个节点的Kafka集群，每个节点即是 controller 节点，也可以是 broker 节点</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面这四个配置项是 kraft 模式下新增加的</span></span><br><span class="line"><span class="comment"># 配置当前节点的角色。Controller相当于Zookeeper的功能，负责集群管理。Broker提供具体的消息转发服务。</span></span><br><span class="line"><span class="comment"># 一个节点可以即是 Controller 又是 Broker，也可以只是 Controller 或 Broker。</span></span><br><span class="line">process.roles=broker,controller</span><br><span class="line"><span class="comment"># 配置当前节点的id。与普通集群一样，要求集群内每个节点的ID不能重复。</span></span><br><span class="line">node.id=1</span><br><span class="line"><span class="comment"># 配置集群的投票节点。其中@前面的是节点的id，后面是节点的地址和端口，这个端口跟客户端访问的端口是不一样的，要与 CONTROLLER 协议对应的端口一致，这里配置为 9098</span></span><br><span class="line"><span class="comment"># 通常将集群内的所有Controllor节点都配置进去。</span></span><br><span class="line">controller.quorum.voters=1@worker1:9098,2@worker2:9098,3@worker3:9098</span><br><span class="line"><span class="comment"># Controller服务协议的别名。默认就是CONTROLLER</span></span><br><span class="line">controller.listener.names=CONTROLLER</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下配置项与之前一样，按需进行配置即可</span></span><br><span class="line"><span class="comment"># 集群间通信仍使用内网</span></span><br><span class="line">inter.broker.listener.name=PLAINTEXT</span><br><span class="line"><span class="comment"># 配置监听服务。不同的服务可以绑定不同的接口。这种配置方式在端口前面是省略了一个主机IP的，主机IP默认是使用的java.net.InetAddress.getCanonicalHostName()，这里同时开启外网访问，关于 sasl_plaintext 、sasl_ssl协议 的配置方式参考前文 kafka 通信协议</span></span><br><span class="line">listeners=PLAINTEXT://:9092,CONTROLLER://:9098,EXTERNAL://0.0.0.0:9093</span><br><span class="line"><span class="comment"># Broker对客户端暴露的服务地址。基于PLAINTEXT协议。这里要替换为各个节点的IP地址</span></span><br><span class="line">advertised.listeners=PLAINTEXT://worker1:9092,CONTROLLER://worker1:9098,EXTERNAL://161.189.227.200:9093</span><br><span class="line"><span class="comment"># 将监听器名称映射到安全协议类型，这里 CONTROLLER 协议对应的安全协议类型为 PLAINTEXT</span></span><br><span class="line">listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT</span><br><span class="line"><span class="comment"># 数据文件地址。默认配置在/tmp目录下。</span></span><br><span class="line">log.dirs=/usr/local/kafka/dataDir/kraft-logs</span><br><span class="line"><span class="comment"># topic默认的partition分区数。</span></span><br><span class="line">num.partitions=2</span><br></pre></td></tr></table></figure><h2 id="启动Kafka集群">启动Kafka集群</h2><ul class="lvl-0"><li class="lvl-2"><p>启动前要对日志目录进行格式化</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在worker1节点上生成集群ID</span></span><br><span class="line">$ kafka-storage.sh random-uuid</span><br><span class="line">oGwJsVANRDKYwE7Lhn2zIA</span><br><span class="line"><span class="comment"># 然后在集群的每个节点上执行如下命令，格式化日志目录，注意 --cluster-id 必须一致</span></span><br><span class="line"><span class="comment"># 必须在第一次启动前执行</span></span><br><span class="line"><span class="comment"># 不可以重复执行，否则会清空数据目录并破坏已有元数据</span></span><br><span class="line"><span class="comment"># 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。</span></span><br><span class="line"><span class="comment"># 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</span></span><br><span class="line">$ kafka-storage.sh format --cluster-id oGwJsVANRDKYwE7Lhn2zIA --config /usr/local/kafka/kafka3/config/kraft/server.properties</span><br><span class="line"><span class="comment">## 格式化后会在日志目录下生成两个文件</span></span><br><span class="line"><span class="comment"># bootstrap.checkpoint # 存储元数据日志（Metadata Log）对应的初始快照偏移量（snapshot offset）。用于控制器在启动时恢复状态的起点。</span></span><br><span class="line"><span class="comment"># meta.properties # 存储节点元信息：cluster.id、node.id、version 等</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动集群，所以节点启动 kafka 服务</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/server.properties</span><br></pre></td></tr></table></figure><h2 id="注意事项">注意事项</h2><ul class="lvl-0"><li class="lvl-2"><p>Kafka 集群的启动顺序不能乱，必须先启动 Controller 节点，再启动 Broker 节点，我们这里是将节点同时做为Controller 和 Broker ，实际生产环境建议分开。</p></li><li class="lvl-2"><p>Controller 节点至少3个，建议配置为奇数个。Broker 节点数量任意，但建议至少2个以上，以保证分区的备份可以分开存储。</p></li><li class="lvl-2"><p>Client 仅能与 Broker 节点通信，不能与 Controller 节点通信。</p></li></ul><h2 id="Kafka-4-0-的新特性">Kafka 4.0 的新特性</h2><ul class="lvl-0"><li class="lvl-2"><p>彻底以 KRaft（Kafka Raft）取代 ZooKeeper（KRaft 成为默认且唯一的元数据管理）</p><ul class="lvl-2"><li class="lvl-4">说明：4.x 系列标志性变化是完全移除 ZooKeeper，元数据由 KRaft 管理（Controller 与 Broker 更紧密集成）。对运维而言：不再部署/维护 ZooKeeper 集群、元数据迁移/格式化步骤是升级时的关键。</li><li class="lvl-4">影响/提示：必须按官方迁移流程把元数据从 ZK 导入 KRaft（若从旧版本升级）。测试迁移/备份元数据是必须项。</li></ul></li><li class="lvl-2"><p>新的 consumer-group 协议（更高效的 rebalance/群组管理）与消费模型改进（包括“Queues/Shared Group”支持）</p><ul class="lvl-2"><li class="lvl-4">说明：引入/稳定了新的 Consumer Group 协议（相关 KIP），显著改善大群组下的重平衡延迟与稳定性；同时引入了类似“队列/共享组（Queues for Kafka）”的消费模式（用例：点对点消费），允许多消费者同时处理同一分区消息。</li><li class="lvl-4">影响/提示：如果你有大规模消费者群组或依赖旧 rebalance 行为，需要测试新协议行为；某些客户端配置/行为可能需要调整。</li></ul></li></ul><table><thead><tr><th>指标类别</th><th>旧协议（Eager Rebalance）</th><th>新协议（Incremental / Cooperative Rebalance）</th></tr></thead><tbody><tr><td>重平衡延迟（大规模群组）</td><td>约 <strong>60 秒</strong>（万级消费者规模）</td><td>小于 <strong>1 秒</strong>（测试显示在千级任务时可在一分钟内完成） (<a href="https://www.confluent.io/blog/incremental-cooperative-rebalancing-in-kafka/?utm_source=chatgpt.com" title="Incremental Cooperative Rebalancing in Apache Kafka">Confluent</a>)</td></tr><tr><td>资源消耗（CPU）</td><td>较高（在重平衡期间系统停止或大规模迁移资源）</td><td>据称可降低约 <strong>70%</strong> 的 CPU／系统中断负荷（社区经验）</td></tr><tr><td>消费者群组扩展上限</td><td>适用于“千级消费者”规模</td><td>可扩展至“十万级消费者”规模（理论/社区宣称）</td></tr></tbody></table><table><thead><tr><th><strong>特性</strong></th><th><strong>传统消费者组（Consumer Group）</strong></th><th><strong>共享组（Shared Group / Queues for Kafka）</strong></th></tr></thead><tbody><tr><td><strong>并行消费模型</strong></td><td>分区数 = 消费者数（一个分区只能被一个消费者消费）</td><td>消费者数 &gt; 分区数（同一分区可由多个消费者并行处理）</td></tr><tr><td><strong>消息确认机制</strong></td><td>通过提交偏移量（Offset Commit）实现确认</td><td>每条消息单独确认（ACK/NACK 机制）</td></tr><tr><td><strong>投递语义</strong></td><td><strong>At-Least-Once</strong>（至少一次投递）</td><td><strong>Exactly-Once（可选）</strong>，支持精确一次处理</td></tr><tr><td><strong>典型场景</strong></td><td>流式日志、监控、顺序性要求高的场景</td><td>任务队列、并行计算、高吞吐任务处理</td></tr><tr><td><strong>实现方式</strong></td><td>基于 Topic-Partition 分配与偏移管理</td><td>基于共享队列模型，允许多消费者竞争消费同一分区</td></tr><tr><td><strong>Kafka 版本支持</strong></td><td>Kafka ≤ 3.x</td><td>Kafka 4.x 引入（KIP-932 “Queues for Kafka”）</td></tr><tr><td><strong>优势</strong></td><td>顺序保证强、模型成熟稳定</td><td>并行能力强、吞吐提升、支持精确一次语义</td></tr><tr><td><strong>劣势</strong></td><td>分区限制吞吐，扩展受限</td><td>顺序性可能减弱，实现更复杂</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>删除长期弃用的旧 API / 协议（向后不兼容的清理）</p><ul class="lvl-2"><li class="lvl-4">说明：4.x 移除了那些已弃用 ≥12 个月的接口/协议，旨在简化代码库并鼓励采用新功能。</li><li class="lvl-4">影响/提示：升级前务必检查你使用到的 Broker/Client/Streams/Connect API 是否依赖被移除的功能；测试客户端与第三方 Connector/插件兼容性。</li></ul></li><li class="lvl-2"><p>Java 运行环境最低版本更新：Clients/Streams 与 Broker/Tools 的 JDK 要求提高</p><ul class="lvl-2"><li class="lvl-4">说明：Kafka 4.x 将客户端（Kafka Clients、Kafka Streams）与 Broker/Connect/工具分别提出了更高的 Java baseline（Clients/Streams 最低 Java 11，Broker/Connect/Tools 最低 Java 17 等）。</li><li class="lvl-4">影响/提示：升级集群前先统一平台 JDK 版本，CI/CD/容器镜像也要对应更新。</li></ul></li><li class="lvl-2"><p>许多新的 KIP（功能增强）与性能/可观测性改进</p><ul class="lvl-2"><li class="lvl-4">说明：包含改进的 Streams rebalance、更多 Admin/运维命令、节点注册/列举能力、插件/指标扩展点等（多项 KIP 在 4.0/4.1 陆续落地）。这些改进覆盖 Broker、Controller、Producer、Consumer、Admin 和 Streams 子系统。</li><li class="lvl-4">影响/提示：运维与监控面板可能受益（新增可观测指标/API）；如果你有自定义插件或监控接入，需要检查新的插件/metrics 注册机制。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 的 常用命令</title>
    <link href="https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/"/>
    <id>https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/</id>
    <published>2025-10-15T12:30:05.000Z</published>
    <updated>2025-10-16T06:05:44.574Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 Kafka 的 常用命令</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/kafka-3-demo">Java-Client 代码示例</a></p></li></ul><span id="more"></span><h2 id="topic">topic</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 topic</span></span><br><span class="line">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class="built_in">test</span> --partitions 3 --replication-factor 2</span><br><span class="line"><span class="comment"># --bootstrap-server 指定 kafka 集群地址</span></span><br><span class="line"><span class="comment"># --topic 创建的 topic 名称</span></span><br><span class="line"><span class="comment"># --partitions 指定分区数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class="line"><span class="comment"># --replication-factor 指定副本数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出 topic</span></span><br><span class="line">kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># 查看 topic 详情</span></span><br><span class="line">kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment">## 输出</span></span><br><span class="line">Topic: <span class="built_in">test</span>TopicId: Ru0tWQJ4RMWcjjGsKAdWQgPartitionCount: 3ReplicationFactor: 3Configs:</span><br><span class="line">Topic: <span class="built_in">test</span>Partition: 0Leader: 3Replicas: 3,1,2Isr: 3,2,1Elr: N/ALastKnownElr: N/A</span><br><span class="line">Topic: <span class="built_in">test</span>Partition: 1Leader: 1Replicas: 1,2,3Isr: 3,2,1Elr: N/ALastKnownElr: N/A</span><br><span class="line">Topic: <span class="built_in">test</span>Partition: 2Leader: 2Replicas: 2,3,1Isr: 3,2,1Elr: N/ALastKnownElr: N/A</span><br><span class="line"><span class="comment">## 输出说明</span></span><br><span class="line"><span class="comment"># 总体信息（Topic 概览）Topic: testTopicId: Ru0tWQJ4RMWcjjGsKAdWQgPartitionCount: 3ReplicationFactor: 3Configs:</span></span><br><span class="line">| 字段                                  | 含义                                                            |</span><br><span class="line">| ----------------------------------- | ------------------------------------------------------------- |</span><br><span class="line">| **Topic: disTopic**                 | Topic 名称，即当前描述的主题。                                            |</span><br><span class="line">| **TopicId: VUK7Mc9oQdS1mjGG7OhQzQ** | Kafka 内部自动生成的唯一标识符（UUID），Kafka 3.x 之后引入，用于区分同名但不同生命周期的 topic。 |</span><br><span class="line">| **PartitionCount: 3**               | 该主题有 3 个分区（partition）。每个分区存储一部分消息。                            |</span><br><span class="line">| **ReplicationFactor:**              | 副本因子。这里虽然输出中没显示具体值，但可从每行分区配置推断是 **3**（每个分区有 3 个副本）。           |</span><br><span class="line">| **Configs:**                        | topic 的配置项（例如清理策略、压缩类型等），如果为空，说明使用默认配置。                       |</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分区详情（每个 Partition 一行）</span></span><br><span class="line"></span><br><span class="line">| 字段                                | 含义                                                          |</span><br><span class="line">| --------------------------------- | ----------------------------------------------------------- |</span><br><span class="line">| **Partition: 0**                  | 第 0 号分区。                                                    |</span><br><span class="line">| **Leader: 2**                     | 该分区当前的 **Leader Broker 是 broker ID = 2**，只有 Leader 才处理读写请求。 |</span><br><span class="line">| **Replicas: 2,3,1**               | 该分区的所有副本存放在哪些 Broker 上（即副本分布,AR），分别是 broker 2、3、1。             |</span><br><span class="line">| **Isr (In-Sync Replicas): 2,3,1** | 当前与 Leader 保持同步的副本集合。这里所有副本都在同步中（健康状态 👍）。                  |</span><br><span class="line">| **Elr / LastKnownElr**            | Kafka 新版本中引入的 <span class="string">&quot;Enhanced Leader Replica&quot;</span> 状态，目前未启用（N/A）。      |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 topic</span></span><br><span class="line">kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="consumer">consumer</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 consumer</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span> --group <span class="built_in">test</span></span><br><span class="line"><span class="comment"># --topic 指定 topic</span></span><br><span class="line"><span class="comment"># --group 指定 consumer 组</span></span><br><span class="line"></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span>  --from-beginning</span><br><span class="line"><span class="comment"># --from-beginning 从 topic 的最开始消费</span></span><br></pre></td></tr></table></figure><h2 id="consumer-group">consumer-group</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出 consumer 组</span></span><br><span class="line">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span><br><span class="line"><span class="comment"># --bootstrap-server 集群地址</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 consumer 组详情</span></span><br><span class="line">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group <span class="built_in">test</span></span><br><span class="line"><span class="comment">## 输出</span></span><br><span class="line">GROUP  TOPIC  PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                             HOST         CLIENT-ID</span><br><span class="line"><span class="built_in">test</span>   <span class="built_in">test</span>   0          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class="line"><span class="built_in">test</span>   <span class="built_in">test</span>   1          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class="line"><span class="built_in">test</span>   <span class="built_in">test</span>   2          1               1               0    console-consumer-9ac45b29-d8f3-4649-ab09-7b567aa2ba53  /10.250.0.108 console-consumer</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出说明</span></span><br><span class="line"><span class="comment"># GROUP       消费组名称</span></span><br><span class="line"><span class="comment"># TOPIC       topic 名称</span></span><br><span class="line"><span class="comment"># PARTITION   分区编号</span></span><br><span class="line"><span class="comment"># CURRENT-OFFSET  当前消费的 offset</span></span><br><span class="line"><span class="comment"># LOG-END-OFFSET   topic 中最大的 offset</span></span><br><span class="line"><span class="comment"># LAG         当前消费的 offset 与 topic 中最大的 offset 的差值，即剩余未消费的 消息数量</span></span><br><span class="line"><span class="comment"># CONSUMER-ID  当前消费的 consumer 的 id</span></span><br><span class="line"><span class="comment"># HOST        当前消费的 consumer 的主机名</span></span><br><span class="line"><span class="comment"># CLIENT-ID   当前消费的 consumer 的客户端名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 consumer 组</span></span><br><span class="line">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="producer">producer</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 producer</span></span><br><span class="line">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># --topic 指定 topic</span></span><br></pre></td></tr></table></figure><h2 id="手动触发-Kafka-Partitoin-的-Leader-选举-自平衡">手动触发 Kafka Partitoin 的 Leader 选举(自平衡)</h2><ul class="lvl-0"><li class="lvl-2"><p>kafka的自平衡默认开启，每隔 300秒扫描一次，如果需要平衡的比例高于 10%，则会触发一次</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启自动平衡</span></span><br><span class="line">auto.leader.rebalance.enable=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 间隔扫描时间 默认 300 秒</span></span><br><span class="line">eader.imbalance.check.interval.seconds=300</span><br><span class="line"><span class="comment"># 触发比例，即扫描的 broker 上需要平衡的 partition 占当前 broker 全部 partition 的比例，默认 10%</span></span><br><span class="line">leader.imbalance.per.broker.percentage=10</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>建议关闭，改为业务低峰时手动触发</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自动平衡</span></span><br><span class="line">kafka-leader-election.sh --bootstrap-server localhost:9092  --election-type preferred --topic <span class="built_in">test</span> --partition 0</span><br><span class="line"><span class="comment"># --topic 指定要触发的 topic</span></span><br><span class="line"><span class="comment"># --partition 0 触发 partition 0 的 leader 选举</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>🧩 参数说明：–election-type</p></li></ul><table><thead><tr><th>参数值</th><th>含义</th><th>触发条件</th><th>典型使用场景</th></tr></thead><tbody><tr><td><strong><code>preferred</code></strong></td><td><strong>首选 Leader 选举</strong>（Preferred Leader Election）<br>Kafka 会尝试将分区的 leader 重新切换为「首选副本」（通常是第一个副本）。</td><td>只有当前 leader <strong>不是</strong> 首选副本时才执行。</td><td>某些副本被自动选举成 leader 后，希望恢复原有「首选 leader」结构，以实现负载均衡。</td></tr><tr><td><strong><code>unclean</code></strong></td><td><strong>非干净 Leader 选举</strong>（Unclean Leader Election）<br>允许从不同步的副本中选举新的 leader。</td><td>仅在分区 <strong>没有可用 leader</strong> 时执行。</td><td>在紧急恢复场景下（比如所有 ISR 副本都下线），为了恢复服务可用性，即使会导致数据丢失。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>Leader Partition⾃动平衡机制</p><ul class="lvl-2"><li class="lvl-6">Leader Partitoin选举机制能够保证每⼀个Partition同⼀时刻有且仅有⼀个Leader Partition。但是，是不是只要分配好了Leader Partition就够了呢？</li><li class="lvl-6">在⼀组Partiton中，Leader Partition通常是⽐较繁忙的节点，因为他要负责与客户端的数据交互，以及向Follower同步数据。默认情况下，Kafka会尽量将Leader Partition分配到不同的Broker节点上，⽤以保证整个集群的性能压⼒能够⽐较平均。</li><li class="lvl-6">但是，经过Leader Partition选举后，这种平衡就有可能会被打破，让Leader Partition过多的集中到同⼀个Broker上。这样，这个Broker的压⼒就会明显⾼于其他Broker，从⽽影响到集群的整体性能。</li><li class="lvl-6">为此，Kafka设计了Leader Partition⾃动平衡机制，当发现Leader分配不均衡时，⾃动进⾏Leader Partition调整。</li><li class="lvl-6">Kafka在进⾏Leader Partition⾃平衡时的逻辑是这样的：他会认为AR(Replicas副本集)当中的第⼀个节点就应该是Leader节点。这种选举结果成为preferred election 理想选举结果。</li><li class="lvl-6">Controller会定期检测集群的Partition平衡情况，在开始检测时，Controller会依次检查所有的Broker。当发现这个Broker上的不平衡的Partition⽐例⾼于<code>leader.imbalance.per.broker.percentage</code>阈值时，就会触发⼀次Leader Partiton的⾃平衡。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 Kafka 的 常用命令&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/kafka-3-demo&quot;&gt;Java-Client 代码示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 的 server.properties 配置项</title>
    <link href="https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/"/>
    <id>https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/</id>
    <published>2025-10-14T13:30:05.000Z</published>
    <updated>2025-10-18T12:00:31.595Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li></ul><span id="more"></span><h2 id="Kafka-3-x-server-properties-主要配置项清单">Kafka 3.x server.properties 主要配置项清单</h2><ul class="lvl-0"><li class="lvl-2"><p>关于 server.properties 的配置项，请参考 <a href="https://kafka.apache.org/39/documentation/#brokerconfigs">Kafka 官方文档</a></p></li></ul><table><thead><tr><th>分类</th><th>参数名</th><th>默认值</th><th>说明</th><th>推荐/备注</th></tr></thead><tbody><tr><td>🗂️ <strong>基本信息</strong></td><td><code>broker.id</code></td><td>0</td><td>Broker 唯一标识</td><td>集群中必须唯一</td></tr><tr><td></td><td><code>node.id</code></td><td>-</td><td>Raft 模式（KRaft）下使用</td><td>ZK 模式忽略</td></tr><tr><td></td><td><code>process.roles</code></td><td>-</td><td>KRaft 模式角色（controller, broker）</td><td>ZK 模式不配置</td></tr><tr><td>🔌 <strong>网络与监听配置</strong></td><td><code>listeners</code></td><td>PLAINTEXT://:9092</td><td>Broker 监听地址</td><td>可用多个协议，如 SASL_PLAINTEXT, SSL</td></tr><tr><td></td><td><code>advertised.listeners</code></td><td>-</td><td>客户端连接时看到的地址</td><td>外网访问需配置</td></tr><tr><td></td><td><code>listener.security.protocol.map</code></td><td>PLAINTEXT:PLAINTEXT</td><td>映射监听器协议</td><td>多协议时配置</td></tr><tr><td></td><td><code>inter.broker.listener.name</code></td><td>-（Kafka 2.4+ 默认第一个 listener）</td><td>指定 broker 间通信使用哪个 listener（如 INTERNAL）</td><td>集群内部通信必须一致；常配合多 listener 使用</td></tr><tr><td></td><td><code>num.network.threads</code></td><td>3</td><td>网络线程数</td><td>一般不需修改</td></tr><tr><td></td><td><code>num.io.threads</code></td><td>8</td><td>处理请求的 IO 线程数</td><td>根据 CPU 调整</td></tr><tr><td></td><td><code>socket.send.buffer.bytes</code></td><td>102400</td><td>发送缓冲区大小</td><td>网络优化参数</td></tr><tr><td></td><td><code>socket.receive.buffer.bytes</code></td><td>102400</td><td>接收缓冲区大小</td><td>网络优化参数</td></tr><tr><td></td><td><code>socket.request.max.bytes</code></td><td>104857600</td><td>单请求最大大小 (100MB)</td><td>大消息需调大</td></tr><tr><td>⚙️ <strong>集群与元数据</strong></td><td><code>log.dirs</code></td><td>/tmp/kafka-logs</td><td>数据存储路径</td><td>多目录可提升性能</td></tr><tr><td></td><td><code>num.recovery.threads.per.data.dir</code></td><td>1</td><td>每个数据目录的恢复线程数</td><td>多磁盘时可增加</td></tr><tr><td></td><td><code>auto.create.topics.enable</code></td><td>true</td><td>是否允许自动创建 Topic</td><td>生产建议禁用</td></tr><tr><td></td><td><code>controlled.shutdown.enable</code></td><td>true</td><td>优雅关闭 Broker</td><td>建议开启</td></tr><tr><td></td><td><code>delete.topic.enable</code></td><td>true</td><td>是否允许删除 Topic</td><td>生产慎用</td></tr><tr><td></td><td><code>auto.leader.rebalance.enable</code></td><td>true</td><td>是否自动均衡 Leader</td><td>建议开启</td></tr><tr><td></td><td><code>leader.imbalance.check.interval.seconds</code></td><td>300</td><td>检查 leader 失衡间隔</td><td>与上配合使用</td></tr><tr><td></td><td><code>leader.imbalance.per.broker.percentage</code></td><td>10</td><td>触发 leader 重平衡的阈值</td><td>默认即可</td></tr><tr><td>🧱 <strong>副本与复制机制</strong></td><td><code>default.replication.factor</code></td><td>1</td><td>新 Topic 默认副本数</td><td>生产建议 3</td></tr><tr><td></td><td><code>offsets.topic.replication.factor</code></td><td>1</td><td>消费组偏移主题副本数</td><td>建议 3</td></tr><tr><td></td><td><code>transaction.state.log.replication.factor</code></td><td>1</td><td>事务状态主题副本数</td><td>建议 3</td></tr><tr><td></td><td><code>transaction.state.log.min.isr</code></td><td>1</td><td>事务状态日志最小 ISR 数</td><td>建议 2</td></tr><tr><td></td><td><code>min.insync.replicas</code></td><td>1</td><td>Leader 写入时要求的最小 ISR 副本数</td><td>建议 <code>replication.factor - 1</code></td></tr><tr><td></td><td><code>unclean.leader.election.enable</code></td><td>false</td><td>是否允许非同步副本选为 leader</td><td>生产建议 false</td></tr><tr><td></td><td><code>num.replica.fetchers</code></td><td>1</td><td>follower 拉取线程数</td><td>可提升复制性能</td></tr><tr><td></td><td><code>replica.fetch.max.bytes</code></td><td>1048576 (1MB)</td><td>follower 拉取单分区最大数据量</td><td>增大可提速</td></tr><tr><td></td><td><code>replica.fetch.response.max.bytes</code></td><td>10485760 (10MB)</td><td>follower 一次拉取响应总量</td><td>可调大</td></tr><tr><td></td><td><code>replica.fetch.wait.max.ms</code></td><td>500</td><td>follower 等待新数据的最大时长</td><td>延迟与吞吐折中</td></tr><tr><td></td><td><code>replica.fetch.backoff.ms</code></td><td>1000</td><td>拉取失败后退避时间</td><td>网络不稳时调整</td></tr><tr><td></td><td><code>replica.socket.timeout.ms</code></td><td>30000</td><td>follower 与 leader 通信超时</td><td>≥ <a href="http://fetch.wait.ms">fetch.wait.ms</a></td></tr><tr><td></td><td><code>replica.socket.receive.buffer.bytes</code></td><td>65536</td><td>拉取 socket 缓冲区</td><td>调大可提速</td></tr><tr><td></td><td><code>replica.lag.time.max.ms</code></td><td>10000</td><td>follower 落后 leader 的最大时间</td><td>影响 ISR</td></tr><tr><td></td><td><code>replica.high.watermark.checkpoint.interval.ms</code></td><td>5000</td><td>高水位写入 checkpoint 周期</td><td>影响恢复速度</td></tr><tr><td></td><td><code>replica.selector.class</code></td><td>-</td><td>自定义副本选择类</td><td>一般保持默认</td></tr><tr><td>🧮 <strong>日志与段文件</strong></td><td><code>log.segment.bytes</code></td><td>1073741824 (1GB)</td><td>单日志段文件大小</td><td>调小便于删除</td></tr><tr><td></td><td><code>log.segment.ms</code></td><td>604800000 (7天)</td><td>强制滚动日志的时间</td><td>适用于时间控制</td></tr><tr><td></td><td><code>log.retention.hours</code></td><td>168</td><td>日志保留时间（小时）</td><td>与磁盘空间相关</td></tr><tr><td></td><td><code>log.retention.bytes</code></td><td>-1</td><td>日志总大小限制</td><td>-1 表示不限制</td></tr><tr><td></td><td><code>log.retention.check.interval.ms</code></td><td>300000</td><td>检查日志保留策略间隔</td><td>默认即可</td></tr><tr><td></td><td><code>log.cleaner.enable</code></td><td>true</td><td>是否启用日志压缩</td><td>compact 主题需启用</td></tr><tr><td></td><td><code>log.cleaner.threads</code></td><td>1</td><td>清理线程数</td><td>大集群可增加</td></tr><tr><td></td><td><code>log.cleaner.io.max.bytes.per.second</code></td><td>None</td><td>限制清理 IO 带宽</td><td>控制磁盘负载</td></tr><tr><td></td><td><code>log.flush.interval.messages</code></td><td>Long.MAX_VALUE</td><td>累计消息数达到后强制 flush</td><td>通常保持默认</td></tr><tr><td></td><td><code>log.flush.interval.ms</code></td><td>None</td><td>每隔多久强制 flush</td><td>SSD 可调大</td></tr><tr><td></td><td><code>num.partitions</code></td><td>1</td><td>新 Topic 默认分区数</td><td>通常 3~6 起步</td></tr><tr><td>🧵 <strong>生产与消费相关</strong></td><td><code>message.max.bytes</code></td><td>1048576</td><td>允许的最大消息大小</td><td>与 Producer <code>max.request.size</code> 对齐</td></tr><tr><td></td><td><code>replica.fetch.max.bytes</code></td><td>1048576</td><td>与 Producer/Consumer 对应的限制</td><td>防止大消息卡死</td></tr><tr><td></td><td><code>compression.type</code></td><td>producer</td><td>压缩算法（none, gzip, snappy, lz4, zstd）</td><td>建议 zstd</td></tr><tr><td></td><td><code>queued.max.requests</code></td><td>500</td><td>Broker 最大排队请求数</td><td>默认即可</td></tr><tr><td>🛠️ <strong>控制器与协调器</strong></td><td><code>controller.socket.timeout.ms</code></td><td>30000</td><td>控制器通信超时</td><td>默认即可</td></tr><tr><td></td><td><code>controller.quorum.voters</code></td><td>-</td><td>KRaft 模式选举成员</td><td>ZK 模式不需</td></tr><tr><td></td><td><code>controller.listener.names</code></td><td>-</td><td>控制器监听名</td><td>ZK 模式忽略</td></tr><tr><td>📈 <strong>监控与指标</strong></td><td><code>metric.reporters</code></td><td>空</td><td>指标上报类</td><td>可接 Prometheus</td></tr><tr><td></td><td><code>metrics.num.samples</code></td><td>2</td><td>指标采样数</td><td>默认即可</td></tr><tr><td></td><td><code>metrics.sample.window.ms</code></td><td>30000</td><td>指标采样窗口</td><td>默认即可</td></tr><tr><td></td><td><code>replica.fetchers.metrics.enabled</code></td><td>true</td><td>是否启用副本拉取指标</td><td>Kafka 3.x 新增</td></tr><tr><td>🔒 <strong>安全</strong></td><td><code>authorizer.class.name</code></td><td>空</td><td>授权类实现</td><td>开启 ACL 时配置</td></tr><tr><td></td><td><code>super.users</code></td><td>空</td><td>超级用户列表</td><td>ACL 模式下配置</td></tr><tr><td></td><td><code>ssl.keystore.location</code></td><td>-</td><td>SSL 证书路径</td><td>启用 SSL 时使用</td></tr><tr><td></td><td><code>ssl.truststore.location</code></td><td>-</td><td>信任证书路径</td><td>启用 SSL 时使用</td></tr></tbody></table><h2 id="参数使用建议总结">参数使用建议总结</h2><table><thead><tr><th>场景</th><th>推荐配置</th></tr></thead><tbody><tr><td><strong>高可靠性集群</strong></td><td><code>default.replication.factor=3</code>, <code>min.insync.replicas=2</code>, <code>unclean.leader.election.enable=false</code></td></tr><tr><td><strong>吞吐优先</strong></td><td>提高 <code>num.replica.fetchers</code>、<code>replica.fetch.max.bytes</code></td></tr><tr><td><strong>快速恢复</strong></td><td>减少 <code>replica.high.watermark.checkpoint.interval.ms</code></td></tr><tr><td><strong>节省磁盘</strong></td><td>启用 <code>log.cleaner.enable</code> 并设置 <code>log.retention.hours</code></td></tr><tr><td><strong>事务或精确一次语义</strong></td><td>设置 <code>transaction.state.log.replication.factor=3</code>、<code>transaction.state.log.min.isr=2</code></td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 的 Web UI 之 Kafbat UI</title>
    <link href="https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/"/>
    <id>https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/</id>
    <published>2025-10-13T15:30:05.000Z</published>
    <updated>2025-10-18T12:19:42.683Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 Kafka 的 Web UI 之 Kafbat UI</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li><li class="lvl-2"><p><a href="https://kafbat.io">Kafbat UI 官网</a>，<a href="https://github.com/kafbat/kafka-ui">Kafbat UI Github</a>，<a href="https://ui.docs.kafbat.io">Kafbat UI 文档</a>，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。</p></li><li class="lvl-2"><p>与 Kafbat UI 类似的 Kafka Web UI 还有一个 <a href="https://github.com/obsidiandynamics/kafdrop">kafdrop</a>，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。</p></li></ul><span id="more"></span><h2 id="Kafbat-UI-简介">Kafbat UI 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>Kafbat UI 是一个免费的开源 Web 用户界面，用于监控和管理 Apache Kafka 集群。</p></li><li class="lvl-2"><p>Kafbat UI 是一个简单的工具，使您的数据流变得可观察，帮助更快地发现和排除问题，并提供最佳性能。其轻量级的仪表盘使您能够轻松跟踪 Kafka 集群的关键指标: 包括 Brokers、Topics、Partitions、生产和消费情况。</p></li></ul><h2 id="运行-Kafbat-UI">运行 Kafbat UI</h2><h3 id="Docker-运行">Docker 运行</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -p 8080:8080 \</span><br><span class="line">    --name kafka-ui \</span><br><span class="line">    -e KAFKA_CLUSTERS_0_NAME=kafka_c01 \</span><br><span class="line">    -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092 \</span><br><span class="line">    -e TZ=Asia/Shanghai \</span><br><span class="line">    -d ghcr.io/kafbat/kafka-ui:latest</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Jar-运行">Jar 运行</h3><ul class="lvl-0"><li class="lvl-2"><p>从<a href="https://github.com/kafbat/kafka-ui/releases">Github</a>上下载最新版jar包，要求 <code>jdk 21+</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /Users/hanqf/myservice_dir/kafka_webui</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置kafka集群，可以同时配置多个，序号从0开始依次递增</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_NAME=kafka_c01</span><br><span class="line"><span class="comment"># =============================================================================================================</span></span><br><span class="line"><span class="comment"># 外网PLAINTEXT访问</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span></span><br><span class="line"><span class="comment"># =============================================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># =============================================================================================================</span></span><br><span class="line"><span class="comment"># 外网SASL_PLAINTEXT访问</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9094,68.79.13.235:9094,43.192.84.195:9094</span></span><br><span class="line"><span class="comment"># # SASL_PLAINTEXT认证配置</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class="line"><span class="comment"># =============================================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># =============================================================================================================</span></span><br><span class="line"><span class="comment"># 外网SASL_SSL访问</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9095,68.79.13.235:9095,43.192.84.195:9095</span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_SSL</span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=<span class="string">&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class="line"><span class="comment"># SSL配置</span></span><br><span class="line"><span class="comment"># JKS 格式证书</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=123456</span><br><span class="line"></span><br><span class="line"><span class="comment"># PEM 格式证书</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span></span><br><span class="line"><span class="comment"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_TYPE=PEM</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用主机名验证</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># ============================================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个集群配置示例</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_1_NAME=kafka_c02</span><br><span class="line"><span class="built_in">export</span> KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时区</span></span><br><span class="line"><span class="built_in">export</span> TZ=Asia/Shanghai</span><br><span class="line"><span class="comment"># 语言</span></span><br><span class="line"><span class="built_in">export</span> LANG=zh_CN.UTF-8</span><br><span class="line"></span><br><span class="line"><span class="comment"># webui访问路径</span></span><br><span class="line"><span class="built_in">export</span> SERVER_SERVLET_CONTEXT_PATH=/</span><br><span class="line"><span class="comment"># 认证方式，支持NONE(无认证)，LOGIN_FORM(登录表单认证)</span></span><br><span class="line"><span class="built_in">export</span> AUTH_TYPE=LOGIN_FORM</span><br><span class="line"><span class="comment"># webui认证用户名密码</span></span><br><span class="line"><span class="built_in">export</span> SPRING_SECURITY_USER_NAME=admin</span><br><span class="line"><span class="built_in">export</span> SPRING_SECURITY_USER_PASSWORD=admin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">JAVA_OPTS=<span class="string">&quot;-Xms512m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m&quot;</span></span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">/Users/hanqf/develop_soft/jdk21/bin/java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED  <span class="variable">$JAVA_OPTS</span> -jar api-v1.3.0.jar</span><br></pre></td></tr></table></figure><h2 id="访问-Kafbat-UI">访问 Kafbat UI</h2><ul class="lvl-0"><li class="lvl-2"><p>访问 <a href="http://localhost:8080">http://localhost:8080</a><br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/ykd6F4.png" alt=""></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 Kafka 的 Web UI 之 Kafbat UI&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafbat.io&quot;&gt;Kafbat UI 官网&lt;/a&gt;，&lt;a href=&quot;https://github.com/kafbat/kafka-ui&quot;&gt;Kafbat UI Github&lt;/a&gt;，&lt;a href=&quot;https://ui.docs.kafbat.io&quot;&gt;Kafbat UI 文档&lt;/a&gt;，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;与 Kafbat UI 类似的 Kafka Web UI 还有一个 &lt;a href=&quot;https://github.com/obsidiandynamics/kafdrop&quot;&gt;kafdrop&lt;/a&gt;，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 通信协议、SSL加密和身份验证</title>
    <link href="https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/"/>
    <id>https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/</id>
    <published>2025-10-13T14:30:05.000Z</published>
    <updated>2025-10-16T08:58:11.618Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 Kafka 的 通信协议，以及如何开启外网访问。</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li></ul><span id="more"></span><h2 id="Kafka-的-通信协议">Kafka 的 通信协议</h2><ul class="lvl-0"><li class="lvl-2"><p>Kafka 主要支持四种安全协议</p></li></ul><table><thead><tr><th>协议名称</th><th>加密</th><th>认证</th><th>说明</th><th>推荐场景</th><th>理由</th></tr></thead><tbody><tr><td><strong>PLAINTEXT</strong></td><td>❌ 否</td><td>❌ 否</td><td>无加密、无认证（默认最简单）</td><td>开发 / 测试环境、内网集群通信</td><td>简单、易调试；网络可信，性能优先</td></tr><tr><td><strong>SSL</strong></td><td>✅ 是</td><td>✅ 可选</td><td>使用 TLS/SSL 加密通信，可配置客户端证书认证</td><td>外网客户端访问</td><td>支持数据加密，可选认证，保证安全</td></tr><tr><td><strong>SASL_PLAINTEXT</strong></td><td>❌ 否</td><td>✅ 是</td><td>使用 SASL（用户名密码）认证，但不加密数据</td><td>需要用户认证但局域网环境</td><td>有认证，但不加密，性能开销低</td></tr><tr><td><strong>SASL_SSL</strong></td><td>✅ 是</td><td>✅ 是</td><td>同时支持 SASL 认证和 SSL 加密（最安全）</td><td>外网客户端访问</td><td>既有认证又加密，安全性最高</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>在 <code>config/server.properties</code> 文件中 可以看到如下配置</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 套接字服务器监听的地址。</span></span><br><span class="line"><span class="comment"># 如果未配置，则主机名默认等于 `java.net.InetAddress.getCanonicalHostName()` 的返回值，</span></span><br><span class="line"><span class="comment"># 使用监听器名称 `PLAINTEXT`，端口号为 9092。</span></span><br><span class="line"><span class="comment">#   格式：</span></span><br><span class="line"><span class="comment">#     listeners = listener_name://host_name:port</span></span><br><span class="line"><span class="comment">#   示例：</span></span><br><span class="line"><span class="comment">#     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class="line"><span class="comment">#listeners=PLAINTEXT://:9092</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Broker 向客户端“通告”的监听器名称、主机名和端口。</span></span><br><span class="line"><span class="comment"># 客户端实际会连接这个地址，而不是直接使用 listeners 的地址。</span></span><br><span class="line"><span class="comment"># 如果未设置，则默认使用 `listeners` 的值。</span></span><br><span class="line"><span class="comment">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将监听器名称映射到安全协议类型。</span></span><br><span class="line"><span class="comment"># 默认情况下，监听器名称与安全协议同名。</span></span><br><span class="line"><span class="comment"># 例如：PLAINTEXT→PLAINTEXT、SSL→SSL、SASL_PLAINTEXT→SASL_PLAINTEXT、SASL_SSL→SASL_SSL。</span></span><br><span class="line"><span class="comment"># 更多细节可参考 Kafka 官方配置文档。</span></span><br><span class="line"><span class="comment">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>配置项</th><th>作用</th><th>说明值</th></tr></thead><tbody><tr><td><code>listeners</code></td><td>Kafka 实际监听的地址（Broker 对外开放的端口）</td><td><code>PLAINTEXT://:9092</code>这里 PLAINTEXT 是监听器名称，并不是协议名称，实际上可以配置为任何值，具体协议是通过 <code>listener.security.protocol.map</code> 配置的映射关系来确定。</td></tr><tr><td><code>advertised.listeners</code></td><td>Kafka 告诉客户端应该用哪个地址连接（客户端最终连的）</td><td>默认使用 <code>listeners</code> 的值</td></tr><tr><td><code>listener.security.protocol.map</code></td><td>映射监听器名称到通信安全协议（如明文、SSL、SASL 等）</td><td><code>PLAINTEXT:PLAINTEXT</code>，前面是监听器名称，后面是协议名称</td></tr></tbody></table><h2 id="仅需内网访问">仅需内网访问</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://worker1:9092 <span class="comment"># 这里是内网ip</span></span><br></pre></td></tr></table></figure><h2 id="允许外网访问">允许外网访问</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://161.189.227.200:9092 <span class="comment"># 这里是外网ip</span></span><br></pre></td></tr></table></figure><h2 id="内外网都要访问（推荐双通道方式）">内外网都要访问（推荐双通道方式）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里 INTERNAL 和 EXTERNAL 分别是自定义的监听器名称，此时内网端口为 9092，外网端口为 9093</span></span><br><span class="line">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093</span><br><span class="line"><span class="comment"># 告诉客户端应该用哪个地址连接</span></span><br><span class="line">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9093</span><br><span class="line"><span class="comment"># 映射监听器名称到通信安全协议的映射关系</span></span><br><span class="line">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT</span><br><span class="line"><span class="comment"># 集群间通信仍使用内网</span></span><br><span class="line">inter.broker.listener.name=INTERNAL</span><br></pre></td></tr></table></figure><h2 id="开启-SASL-PLAINTEXT">开启 SASL_PLAINTEXT</h2><ul class="lvl-0"><li class="lvl-2"><p>这里设置外网访问时开启 SASL_PLAINTEXT</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class="line">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094</span><br><span class="line"><span class="comment"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class="line">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9094</span><br><span class="line">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT</span><br><span class="line"><span class="comment"># 集群间通信 still use INTERNAL</span></span><br><span class="line">inter.broker.listener.name=INTERNAL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class="line"><span class="comment"># client 连接时</span></span><br><span class="line">sasl.enabled.mechanisms=PLAIN</span><br><span class="line"><span class="comment"># broker 之间连接时，因为 inter.broker.listener.name=INTERNAL，所以 INTERNAL:SASL_PLAINTEXT 才有效</span></span><br><span class="line"><span class="comment">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>创建 kafka_jaas.conf</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Kafka Broker (服务端)</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line">KafkaServer &#123;</span><br><span class="line">    <span class="comment"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">    <span class="comment"># Broker 自己的身份（用于 broker 之间通信，本示例中没有使用）</span></span><br><span class="line">    username=<span class="string">&quot;admin&quot;</span></span><br><span class="line">    password=<span class="string">&quot;admin-secret&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 客户端可用账号，即 user_xxx，这里 xxx 为用户名，= 右边的为密码</span></span><br><span class="line">    user_admin=<span class="string">&quot;admin-secret&quot;</span></span><br><span class="line">    user_alice=<span class="string">&quot;alice-secret&quot;</span></span><br><span class="line">    user_bob=<span class="string">&quot;bob-secret&quot;</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 kafka</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在启动 Kafka Broker 前，设置环境变量指向 JAAS 文件</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_OPTS=<span class="string">&quot;-Djava.security.auth.login.config=/usr/local/kafka/kafka3/config/kafka_jaas.conf&quot;</span></span><br><span class="line">kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure><h3 id="客户端访问">客户端访问</h3><ul class="lvl-0"><li class="lvl-2"><p>创建 client.conf</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SASL_PLAINTEXT</span><br><span class="line"><span class="comment"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class="line">sasl.mechanism=PLAIN</span><br><span class="line"><span class="comment"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class="string">&quot;admin&quot;</span> password=<span class="string">&quot;admin-secret&quot;</span>;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>命令行访问</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建topic</span></span><br><span class="line">kafka-topics.sh --create --topic test-topic --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class="line"><span class="comment"># 查看topic</span></span><br><span class="line">kafka-topics.sh --list --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class="line"><span class="comment"># 创建消费者，--group 指定消费者组名称</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --consumer.config=client.conf --group=test-group</span><br><span class="line"><span class="comment"># 创建生产者</span></span><br><span class="line">kafka-console-producer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --producer.config=client.conf</span><br></pre></td></tr></table></figure><h2 id="开启-SASL-SSL">开启 SASL_SSL</h2><ul class="lvl-0"><li class="lvl-2"><p>这里设置外网访问时开启 SASL_SSL</p></li></ul><h3 id="创建证书">创建证书</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://kafka.apache.org/39/documentation.html#security_ssl">官方文档</a></p></li><li class="lvl-2"><p>生成 Broker keystore，用于 存储 broker 的私钥和证书。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">keytool -keystore kafka.server.keystore.jks \</span><br><span class="line">  -<span class="built_in">alias</span> broker -validity 3650 \</span><br><span class="line">  -genkey -keyalg RSA \</span><br><span class="line">  -dname <span class="string">&quot;CN=broker, OU=Kafka, O=YourOrg, L=City, ST=State, C=CN&quot;</span> \</span><br><span class="line">  -storepass 123456 \</span><br><span class="line">  -keypass 123456</span><br><span class="line"><span class="comment">## 参数说明：</span></span><br><span class="line"><span class="comment"># -keystore：生成的 keystore 文件路径</span></span><br><span class="line"><span class="comment"># -alias broker：证书别名</span></span><br><span class="line"><span class="comment"># -validity 3650：有效期 3650 天</span></span><br><span class="line"><span class="comment"># -keyalg RSA：密钥算法</span></span><br><span class="line"><span class="comment"># -dname：证书信息</span></span><br><span class="line"><span class="comment"># -storepass：keystore 密码</span></span><br><span class="line"><span class="comment"># -keypass：密钥密码</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>导出 Broker 证书（用于客户端 truststore）,生成 kafka.server.crt，客户端会用它来验证 broker。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">keytool -keystore kafka.server.keystore.jks \</span><br><span class="line">  -<span class="built_in">alias</span> broker -<span class="built_in">export</span> -file kafka.server.crt \</span><br><span class="line">  -storepass 123456</span><br><span class="line"><span class="comment">## 参数说明：</span></span><br><span class="line"><span class="comment"># -keystore：keystore 文件路径</span></span><br><span class="line"><span class="comment"># -alias broker：证书别名</span></span><br><span class="line"><span class="comment"># -file kafka.server.crt：导出的证书文件路径</span></span><br><span class="line"><span class="comment"># -storepass：keystore 密码</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>生成 Broker truststore，truststore 用于 存储信任的证书（这里把自己生成的证书导入进去即可）,生成 kafka.truststore.jks</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：这里 server 端 和 client 端 可以共用一个 truststore，也可以分别创建</span></span><br><span class="line">keytool -keystore kafka.truststore.jks \</span><br><span class="line">  -<span class="built_in">alias</span> broker -import -file kafka.server.crt \</span><br><span class="line">  -storepass 123456 -noprompt</span><br><span class="line"><span class="comment"># 参数说明：</span></span><br><span class="line"><span class="comment"># -keystore：生成的 truststore 文件路径</span></span><br><span class="line"><span class="comment"># -alias broker：证书别名</span></span><br><span class="line"><span class="comment"># -file kafka.server.crt：导入的证书文件路径</span></span><br><span class="line"><span class="comment"># -storepass：truststore 密码</span></span><br><span class="line"><span class="comment"># -noprompt：不提示</span></span><br></pre></td></tr></table></figure><h3 id="server-properties-配置-SASL-SSL">server.properties 配置 SASL_SSL</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class="line">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class="line"><span class="comment"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class="line">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class="line">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class="line">inter.broker.listener.name=INTERNAL</span><br><span class="line"></span><br><span class="line"><span class="comment"># SASL</span></span><br><span class="line"><span class="comment"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class="line"><span class="comment"># client 连接时</span></span><br><span class="line">sasl.enabled.mechanisms=PLAIN</span><br><span class="line"><span class="comment"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class="line"><span class="comment">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSL</span></span><br><span class="line">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/kafka.server.keystore.jks</span><br><span class="line">ssl.keystore.password=123456</span><br><span class="line">ssl.key.password=123456</span><br><span class="line">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class="line">ssl.truststore.password=123456</span><br><span class="line"><span class="comment"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class="line">ssl.client.auth=none</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 kafka 前同样需要先创建好 kafka_jaas.conf，与 SASL_PLAINTEXT 一样。</p></li></ul><h3 id="客户端访问-2">客户端访问</h3><ul class="lvl-0"><li class="lvl-2"><p>将 <code>kafka.truststore.jks</code> 拷贝到客户端</p></li><li class="lvl-2"><p>与 SASL_PLAINTEXT 一样，创建 client.conf，并添加如下信息</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SASL_SSL</span><br><span class="line"><span class="comment"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class="line">sasl.mechanism=PLAIN</span><br><span class="line"><span class="comment"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class="string">&quot;admin&quot;</span> password=<span class="string">&quot;admin-secret&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># SSL 配置</span></span><br><span class="line">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class="line">ssl.truststore.password=123456</span><br><span class="line"><span class="comment"># 禁用主机名验证，否则会校验证书的 SAN，证书域名校验开关，为空则表示关闭，这里需要保持关闭状态，必须设置为空</span></span><br><span class="line">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>命令行访问 与 SASL_PLAINTEXT 一样，这里不再赘述</p></li><li class="lvl-2"><p>关于 Kafka JKS格式的SSL证书的创建及配置可以参考<a href="https://support.huaweicloud.com/usermanual-kafka/kafka-ug-0008.html">制作和替换Kafka JKS格式的SSL证书</a></p></li></ul><h4 id="PEM-证书">PEM 证书</h4><ul class="lvl-0"><li class="lvl-2"><p>Kafka 的 证书 默认使用 JKS 格式，但从 2.7.0 开始支持 PEM 格式</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class="line">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class="line"><span class="comment"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class="line">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class="line">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class="line">inter.broker.listener.name=INTERNAL</span><br><span class="line"></span><br><span class="line"><span class="comment"># SASL</span></span><br><span class="line"><span class="comment"># 认证机制（常见为 PLAIN，也可以是 CRAM-SHA-256、SCRAM-SHA-512）</span></span><br><span class="line"><span class="comment"># client 连接时</span></span><br><span class="line">sasl.enabled.mechanisms=PLAIN</span><br><span class="line"><span class="comment"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class="line"><span class="comment">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSL-PEM</span></span><br><span class="line">ssl.keystore.type=PEM <span class="comment"># 指定证书类型是PEM，支持的类型 PEM、JKS</span></span><br><span class="line">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/fullchain.pem <span class="comment"># 包含私钥和公钥</span></span><br><span class="line"><span class="comment"># 指定客户端使用的证书类型是PEM</span></span><br><span class="line">ssl.truststore.type=PEM</span><br><span class="line">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/server.crt <span class="comment"># 公钥</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class="line">ssl.client.auth=none</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>client.conf 配置如下：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SASL_SSL</span><br><span class="line"><span class="comment"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class="line">sasl.mechanism=PLAIN</span><br><span class="line"><span class="comment"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class="string">&quot;admin&quot;</span> password=<span class="string">&quot;admin-secret&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># SSL 配置，将 server 端的 server.crt 拷贝到 client 端</span></span><br><span class="line">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span><br><span class="line">ssl.truststore.type=PEM</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用主机名验证</span></span><br><span class="line">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure><div class="tips"><p><em><strong>jks 证书转换为 pem 格式</strong></em></p><ul class="lvl-1"><li class="lvl-2">从 JKS 导出为 PKCS#12 (.p12)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">keytool -importkeystore \</span><br><span class="line">  -srckeystore kafka.server.keystore.jks \</span><br><span class="line">  -srcstoretype JKS \</span><br><span class="line">  -destkeystore kafka.server.p12 \</span><br><span class="line">  -deststoretype PKCS12 \</span><br><span class="line">  -srcstorepass 123456 \</span><br><span class="line">  -deststorepass 123456 \</span><br><span class="line">  -J<span class="string">&quot;-Djdk.tls.disabledAlgorithms=&quot;</span> \</span><br><span class="line">  -J<span class="string">&quot;-Dkeystore.pkcs12.legacy=false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 说明：</span></span><br><span class="line">  <span class="comment"># -srcstoretype JKS：原始格式；</span></span><br><span class="line">  <span class="comment"># -deststoretype PKCS12：转换为通用格式；</span></span><br><span class="line">  <span class="comment"># .p12 是 PEM 的“中间格式”。</span></span><br></pre></td></tr></table></figure><ul class="lvl-1"><li class="lvl-2">导出证书[公钥] (.crt，这里是 PEM 格式)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -<span class="keyword">in</span> kafka.server.p12 -clcerts -nokeys -out server.crt -password pass:123456 -provider legacy -provider default</span><br><span class="line"><span class="comment">## 说明：</span></span><br><span class="line"><span class="comment"># -clcerts：只导出证书；</span></span><br><span class="line"><span class="comment"># -nokeys：不导出密钥；</span></span><br><span class="line"><span class="comment"># -out server.crt：导出文件名；</span></span><br><span class="line"><span class="comment"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br><span class="line"><span class="comment"># -provider legacy：启用旧算法支持模块，在 OpenSSL 3.0（及更高版本）中，引入了一个新机制 —— Provider（算法提供者）,默认情况下，OpenSSL 只加载 modern provider（default provider），而许多老旧算法（例如 RC2、MD5、DES、SHA1）被移到了一个单独的 legacy provider 模块中。</span></span><br><span class="line"><span class="comment"># -provider default：同时启用默认 provider，因为有些命令（比如涉及现代加密算法或证书签名）还依赖默认 provider，所以两者一起使用最安全、最兼容</span></span><br></pre></td></tr></table></figure><ul class="lvl-1"><li class="lvl-2">导出私钥 (.key，这里是 PEM 格式)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -<span class="keyword">in</span> kafka.server.p12 -nocerts -out server.key -nodes -password pass:123456 -provider legacy -provider default</span><br><span class="line"><span class="comment">## 说明：</span></span><br><span class="line"><span class="comment"># -nocerts：只导出密钥；</span></span><br><span class="line"><span class="comment"># -out server.key：导出文件名；</span></span><br><span class="line"><span class="comment"># -nodes：不加密导出的密钥文件</span></span><br><span class="line"><span class="comment"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br></pre></td></tr></table></figure><ul class="lvl-1"><li class="lvl-2">fullchain.pem</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -<span class="keyword">in</span> kafka.server.p12 -out fullchain.pem -nodes -password pass:123456 -provider legacy -provider default</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 Kafka 的 通信协议，以及如何开启外网访问。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 的安装：基于 Zookeeper</title>
    <link href="https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/"/>
    <id>https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/</id>
    <published>2025-10-13T13:30:05.000Z</published>
    <updated>2025-10-20T02:47:41.647Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。</p></li><li class="lvl-2"><p><a href="https://kafka.apache.org">Kafka官网</a></p></li><li class="lvl-2"><p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p></li></ul><span id="more"></span><h2 id="Kafka-简介">Kafka 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>Apache Kafka 是一个 <code>分布式的流处理/事件流平台</code>，既可以作为<code>消息系统</code>，也可以作为持久化的 <code>日志/记录存储与流处理平台</code>。</p></li><li class="lvl-2"><p>它的设计目标是高吞吐、低延迟、可水平扩展、容错，以及可持久化数据。</p></li><li class="lvl-2"><p>在 Kafka 中，消息被归类为 <code>主题（Topic）</code>，每个主题可以根据配置被拆分为多个 <code>分区（Partition）</code>，每个分区内部消息是<code>严格有序</code>的，并以<code>追加</code>方式写入。消费者可以按<code>偏移量（offset）</code>读取消息。</p></li><li class="lvl-2"><p>Kafka 提供多个 API：Producer、Consumer、Streams（流处理）、Connect（与外部系统整合）等。</p></li><li class="lvl-2"><p>Kafka 的核心架构要素与工作机制</p></li></ul><table><thead><tr><th>组件 / 概念</th><th>作用 / 描述</th></tr></thead><tbody><tr><td>Broker（节点 / 服务器）</td><td>Kafka 集群中的服务器实例，负责接收、存储、分发消息</td></tr><tr><td>Topic</td><td>消息的“分类”逻辑单元，Producer 写入、Consumer 读取</td></tr><tr><td>Partition</td><td>一个 Topic 被划分的子单元。分区使得主题可以横向扩展，并支持并行读写</td></tr><tr><td>Offset</td><td>每条消息在某个分区中的唯一位置标识，消费者根据 offset 来决定下一条读取</td></tr><tr><td>Replication（副本）</td><td>为了容错性，每个分区可以有多个副本（副本分布在不同 Broker 上）</td></tr><tr><td>Leader / Follower</td><td>在副本中，一个副本为 Leader，接受读写请求；其他为 Follower，从 Leader 同步数据</td></tr><tr><td>Consumer Group</td><td>一组消费者共同消费一个 Topic。每个分区在同一个消费者组中通常只被一个消费者 “拥有”</td></tr><tr><td>ZooKeeper / KRaft</td><td>用于元数据管理、集群协调（在较老版本中是 ZooKeeper；新版本推向 KRaft）</td></tr></tbody></table><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Xe43JY.png" alt="" width="900" height="600"></p><ul class="lvl-0"><li class="lvl-2"><p>消息写入流程（简化）：</p><ul class="lvl-2"><li class="lvl-4">Producer 将消息发送给某个 Topic 的 Leader 分区节点</li><li class="lvl-4">Leader 接收到消息后，将其追加写入本地日志，并返回确认（ACK）</li><li class="lvl-4">Follower 副本从 Leader 拉取数据进行同步</li><li class="lvl-4">消费者根据自己的 offset 从对应 Partition 中读取消息</li></ul></li><li class="lvl-2"><p>消费控制与容错：</p><ul class="lvl-2"><li class="lvl-4">消费者维护自己的 offset（可以自动提交，也可手动控制），这样即使消费者重启，也可以从上次停止的位置继续。</li><li class="lvl-4">如果某个 Broker 宕机，副本可以切换（Leader 选举），保证服务继续。</li><li class="lvl-4">分区与副本机制使得 Kafka 能够扩展容量 &amp; 提高可靠性。</li></ul></li><li class="lvl-2"><p>Kafka 的典型使用场景</p></li></ul><table><thead><tr><th>场景类别</th><th>说明</th></tr></thead><tbody><tr><td><strong>实时数据管道 / 数据集成</strong></td><td>用于将各种数据源（如日志、数据库变更、传感器、用户事件等）实时采集、传输、分发到下游系统（如 OLAP、搜索引擎、监控平台等），构建高效的数据通道。</td></tr><tr><td><strong>事件驱动 / 事件溯源</strong></td><td>记录系统内部或跨系统的事件（状态变化），实现事件驱动架构（EDA）或事件溯源（Event Sourcing），可用于审计、回放、状态重建等。</td></tr><tr><td><strong>日志聚合 / 分析</strong></td><td>将分布式系统中的应用日志、监控指标、操作日志等统一收集到 Kafka 中，集中存储与分析，常与 ELK、ClickHouse 等结合。</td></tr><tr><td><strong>流处理</strong></td><td>与 Kafka Streams、Apache Flink、Spark Streaming 等流处理框架配合，对流经 Kafka 的数据进行实时计算、聚合、过滤、窗口统计等操作。</td></tr><tr><td><strong>系统解耦 / 异步通信</strong></td><td>作为系统间的消息中间件，实现发布-订阅模式，减少系统间耦合，支持异步通信、流量削峰、缓冲等，提升系统稳定性与扩展性。</td></tr></tbody></table><h2 id="Kafka-安装">Kafka 安装</h2><ul class="lvl-0"><li class="lvl-2"><p>这里先介绍基于 Zookeeper 的安装方式，下文会介绍基于 KRaft 的安装方式。</p></li><li class="lvl-2"><p>Kafka 3.9.1 的安装与运行需要 JDK 8+，所有我们需要提前安装 JDK 8+。可以选择OpenJDK，<a href="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/">清华大学镜像站</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># root 用户</span></span><br><span class="line"><span class="comment"># 创建安装目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /usr/local/jdk</span><br><span class="line"><span class="built_in">cd</span> /usr/local/jdk</span><br><span class="line"><span class="comment"># 下载JDK</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class="line">tar -zxvf OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -s jdk8u462-b08 jdk8</span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export JAVA_HOME=/usr/local/jdk/jdk8&#x27;</span> &gt;&gt; /etc/profile</span><br><span class="line"><span class="comment"># 注意这里是 单引号，双引号会解析变量，导致配置失败</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=$JAVA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># 检查JDK安装</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>安装过程参考官网文档<a href="https://kafka.apache.org/39/documentation.html#quickstart">Kafka Quick Start</a>。</p></li></ul><h3 id="单机安装">单机安装</h3><ul class="lvl-0"><li class="lvl-2"><p>部署kafka都会使用集群模式，单机模式只作为学习试用。</p></li><li class="lvl-2"><p>下载Kafka，<a href="https://kafka.apache.org/downloads">下载页面</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># root 用户</span></span><br><span class="line"><span class="comment"># 创建安装目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /usr/local/kafka</span><br><span class="line"><span class="built_in">cd</span> /usr/local/kafka</span><br><span class="line"><span class="comment"># 下载Kafka</span></span><br><span class="line">wget https://dlcdn.apache.org/kafka/3.9.1/kafka_2.13-3.9.1.tgz</span><br><span class="line">tar -zxvf kafka_2.13-3.9.1.tgz</span><br><span class="line"><span class="built_in">ln</span> -s kafka_2.13-3.9.1 kafka3</span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export KAFKA_HOME=/usr/local/kafka/kafka3&#x27;</span> &gt;&gt; /etc/profile</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=$KAFKA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># 查看Kafka版本</span></span><br><span class="line">kafka-topics.sh --version</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 Zookeeper，kafka内置了zookeeper，所以不需要单独安装。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前台运行</span></span><br><span class="line">zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties</span><br><span class="line"><span class="comment"># 后台运行</span></span><br><span class="line"><span class="built_in">nohup</span> zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties &gt; zookeeper.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭zookeeper，kill进程，过滤 java &amp; QuorumPeerMain</span></span><br><span class="line">zookeeper-server-stop.sh</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 kafka</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -daemon 后台运行</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查kafka是否启动成功</span></span><br><span class="line">jps -l | grep kafka</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止 kafka，kill进程，过滤 java &amp; &#x27;kafka\.Kafka&#x27;</span></span><br><span class="line">kafka-server-stop.sh</span><br></pre></td></tr></table></figure><div class="tips"><p><em><strong>小贴士</strong></em></p><ul class="lvl-1"><li class="lvl-2">注意：默认情况下 启动 kafka 需要的内存大小为 1G，这一点可以在 <a href="http://kafka-server-start.sh">kafka-server-start.sh</a> 脚本中查看到</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;x<span class="variable">$KAFKA_HEAP_OPTS</span>&quot;</span> = <span class="string">&quot;x&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">&quot;-Xmx1G -Xms1G&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><ul class="lvl-1"><li class="lvl-2">所以如果内存不够，可以设置环境变量后再启动kafka</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">&quot;-Xmx512M -Xms512M&quot;</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure></div><ul class="lvl-0"><li class="lvl-2"><p>测试</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 topic</span></span><br><span class="line">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动消费者</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span> --from-beginning</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动生产者</span></span><br><span class="line">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line">&gt; hello world <span class="comment"># 输入内容，消费者会收到</span></span><br></pre></td></tr></table></figure><h3 id="集群安装">集群安装</h3><ul class="lvl-0"><li class="lvl-2"><p>集群安装需要准备多个节点，这里我准备三个节点，分别如下：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.7</span><br><span class="line">10.250.0.174</span><br><span class="line">10.250.0.108</span><br></pre></td></tr></table></figure><h4 id="搭建-Zookeeper-集群">搭建 Zookeeper 集群</h4><ul class="lvl-0"><li class="lvl-2"><p>关于如何搭建 Zookeeper 集群，可以参考我之前的文章 <a href="/2025/09/15/zookeeper-study/" title="Zookeeper 的安装及使用">Zookeeper 的安装及使用</a></p></li><li class="lvl-2"><p>如果图省事也可以直接使用 Kafka 自带的 zookeeper，编辑其配置文件 <code>config/zookeeper.properties</code>如下，注意要在 <code>dataDir</code> 目录下创建<code>myid</code>文件</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/usr/local/kafka/dataDir/zookeeper</span><br><span class="line"><span class="comment"># the port at which the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="comment"># disable the per-ip limit on the number of connections since this is a non-production config</span></span><br><span class="line">maxClientCnxns=0</span><br><span class="line"><span class="comment"># Disable the adminserver by default to avoid port conflicts.</span></span><br><span class="line"><span class="comment"># Set the port to something non-conflicting if choosing to enable this</span></span><br><span class="line">admin.enableServer=<span class="literal">false</span></span><br><span class="line"><span class="comment"># admin.serverPort=8080</span></span><br><span class="line"></span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line"></span><br><span class="line">server.1=10.250.0.7:2888:3888</span><br><span class="line">server.2=10.250.0.174:2888:3888</span><br><span class="line">server.3=10.250.0.108:2888:3888</span><br></pre></td></tr></table></figure><h4 id="配置-Kafka-集群">配置 Kafka 集群</h4><ul class="lvl-0"><li class="lvl-2"><p>修改主机的主机名</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl hostname worker1</span><br><span class="line"><span class="comment"># hostnamectl hostname worker2</span></span><br><span class="line"><span class="comment"># hostnamectl hostname worker3</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>为了后续方便维护，将ip地址映射到 hosts 文件中</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.7 worker1</span><br><span class="line">10.250.0.174 worker2</span><br><span class="line">10.250.0.108 worker3</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>编辑 <code>config/server.properties</code> 文件，需要修改如下配置项</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker 的全局唯⼀编号，不能重复，只能是数字。</span></span><br><span class="line">broker.id=1 <span class="comment"># 这里分别设置为1、2、3</span></span><br><span class="line"><span class="comment">#服务监听地址</span></span><br><span class="line">listeners=PLAINTEXT://worker1:9092</span><br><span class="line"><span class="comment">#数据⽂件地址。同样默认是给的/tmp⽬录。</span></span><br><span class="line">log.dirs=/usr/local/kafka/dataDir/kafka-logs</span><br><span class="line"><span class="comment">#默认的每个Topic的分区数，创建Topic时，如果未指定分区数，则默认为1个分区。</span></span><br><span class="line">num.partitions=1</span><br><span class="line"><span class="comment"># 每个⽇志⽂件删除之前保存的时间，默认是168小时，即7天。</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="comment">#zookeeper的服务地址，如果是自建的 Zookeeper 集群，则这里需要填写集群的连接地址</span></span><br><span class="line">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别在三个节点上启动 Kafka</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>测试</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 topic</span></span><br><span class="line">kafka-topics.sh --bootstrap-server worker1:9092 --create --replication-factor 3 --partitions 3 --topic disTopic</span><br><span class="line"><span class="comment">## 参数说明</span></span><br><span class="line"><span class="comment"># --replication-factor 3 表示创建的副本数</span></span><br><span class="line"><span class="comment"># --partitions 3 表示创建的分区数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 topic 详情</span></span><br><span class="line">kafka-topics.sh --bootstrap-server worker1:9092 --describe --topic disTopic</span><br><span class="line">Topic: disTopicTopicId: VUK7Mc9oQdS1mjGG7OhQzQPartitionCount: 3ReplicationFactor: Configs:</span><br><span class="line">Topic: disTopicPartition: 0Leader: 2Replicas: 2,3,1Isr: 2,3,1Elr: N/ALastKnownElr: N/A</span><br><span class="line">Topic: disTopicPartition: 1Leader: 3Replicas: 3,1,2Isr: 3,1,2Elr: N/ALastKnownElr: N/A</span><br><span class="line">Topic: disTopicPartition: 2Leader: 1Replicas: 1,2,3Isr: 1,2,3Elr: N/ALastKnownElr: N/A</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org&quot;&gt;Kafka官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/kafka/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="kafka" scheme="https://blog.hanqunfeng.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 之 Cluster</title>
    <link href="https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/"/>
    <id>https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/</id>
    <published>2025-09-25T14:30:05.000Z</published>
    <updated>2025-09-28T02:31:18.783Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 RabbitMQ 版本为 4.1.4。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo">Java Client 示例</a></p></li></ul><span id="more"></span><h2 id="RabbitMQ-Cluster-集群-简介">RabbitMQ Cluster(集群) 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>在 RabbitMQ 中，<a href="https://www.rabbitmq.com/docs/clustering">Cluster（集群）</a> 是多个节点组成的集合，用于实现高可用和负载均衡。</p></li><li class="lvl-2"><p>RabbitMQ 集群是一个或多个（三个、五个、七个或更多）节点的逻辑分组， 每个节点共享 用户、虚拟主机、队列、流、交换、绑定、运行时参数和其他分布式状态。</p></li><li class="lvl-2"><p>在 RabbitMQ 中，Cluster（集群）的节点分为两种：</p><ul class="lvl-2"><li class="lvl-4">磁盘节点(disk)：会把集群的所有元数据信息（比如交换机、绑定、队列、虚拟主机等信息）持久化到磁盘中。Master 节点必须是磁盘节点。</li><li class="lvl-4">内存节点(ram)：只会将这些信息保存到内存中，如果该节点宕机或重启，内存节点的数据会全部丢失，而磁盘节点的数据不会丢失。Slave 节点可以是内存节点。</li></ul></li><li class="lvl-2"><p>RabbitMQ 4.0 开始， 集群不再区分 <code>普通集群模式（Classic Cluster）</code> 与 <code>镜像集群模式（Mirrored Queue Cluster）</code> ，集群创建好后，会根据队列的<code>初始复制因子参数</code>决定为该队列创建多少个副本，比如 <code>Quroum Queue</code> 的参数是 <code>x-quorum-initial-group-size</code>，默认为3。</p></li><li class="lvl-2"><p>RabbitMQ 4.0 开始，<code>Quroum Queue</code> 和 <code>Stream Queue</code> 默认开启节点间<code>消息复制</code>，但是 <code>Classic Queue</code> 队列不支持节点间的<code>消息复制</code>;</p></li></ul><div class="tips"><p><em><strong>RabbitMQ 4.0以前的 集群分为两种模式</strong></em></p><ul class="lvl-1"><li class="lvl-2"><ol><li class="lvl-5">普通集群模式（Classic Cluster）</li></ol><ul class="lvl-3"><li class="lvl-4">在 普通集群模式下，RabbitMQ 节点通过 Erlang 分布式系统实现互联，集群内的各个节点共享 消息队列、交换机、绑定等元素。</li><li class="lvl-4">普通集群的特点：<ul class="lvl-5"><li class="lvl-6">共享队列：队列数据仅存储在单一节点上，只有该节点可以处理队列中的消息。</li><li class="lvl-6">不自动复制数据：在普通集群中，消息并不会自动复制到其他节点。如果某个节点挂掉，队列上的消息就会丢失，无法恢复。</li><li class="lvl-6">负载均衡：交换机（Exchange）会把消息发送到不同的队列，但队列数据仍然只在一个节点上。因此，普通集群适合不要求极高可用性的场景。</li><li class="lvl-6">不具备高可用性：由于数据不会在集群的其他节点中复制，普通集群在某个节点宕机时，可能会导致消息丢失和系统不可用。</li></ul></li></ul></li><li class="lvl-2"><ol start="2"><li class="lvl-5">镜像集群模式（Mirrored Queue Cluster）</li></ol><ul class="lvl-3"><li class="lvl-4">镜像集群模式 是为了 高可用性 设计的，在该模式下，队列的数据会在集群中的多个节点上进行 复制（镜像），从而保证即使某个节点出现故障，数据也不会丢失。</li><li class="lvl-4">镜像集群的特点：<ul class="lvl-5"><li class="lvl-6">队列镜像：在镜像集群模式中，队列数据会在集群中的多个节点上复制。每个队列都有一个主节点和多个镜像节点。</li><li class="lvl-6">高可用性：消息会被复制到集群的其他节点上，从而保证如果一个节点宕机，数据不会丢失，系统能迅速恢复。</li><li class="lvl-6">节点故障恢复：当一个节点挂掉时，其他节点会继续处理该队列的消息，保证业务的高可用性。</li><li class="lvl-6">网络负担较重：由于需要在多个节点之间进行数据同步和复制，所以镜像队列模式会增加集群的网络负担和磁盘 I/O。</li><li class="lvl-6">性能影响：镜像队列模式会稍微影响性能，因为每次消息处理后，都需要将数据同步到其他镜像节点，增加了延迟。</li></ul></li></ul></li></ul></div><h2 id="集群搭建">集群搭建</h2><ul class="lvl-0"><li class="lvl-2"><p>准备三台服务器，分别安装 RabbitMQ ，安装方法参看 <a href="/2025/09/18/rabbitmq-install-01/" title="RabbitMQ 的安装及使用">RabbitMQ 的安装及使用</a></p></li><li class="lvl-2"><p>开放端口</p></li></ul><table><thead><tr><th><strong>端口范围</strong></th><th><strong>用途</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td><strong>4369</strong></td><td>epmd（Erlang Port Mapper Daemon）</td><td>RabbitMQ 节点和 CLI 工具使用的帮助程序发现守护进程。</td></tr><tr><td><strong>6000-6500</strong></td><td>RabbitMQ Stream 复制使用</td><td>用于 RabbitMQ Stream 的数据复制。</td></tr><tr><td><strong>25672</strong></td><td>Erlang 分发服务器端口</td><td>用于节点间和 CLI 工具通信，默认情况下仅限于单个端口（AMQP端口 + 20000）。</td></tr><tr><td><strong>35672-35682</strong></td><td>Erlang 分发客户端端口</td><td>用于 CLI 工具与节点通信，计算为服务器分发端口 + 10000 到 服务器分发端口 + 10010。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>分别修改三台服务器的 <code>hostname</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl hostname rabbitmq01</span><br><span class="line"><span class="comment"># hostnamectl hostname rabbitmq02</span></span><br><span class="line"><span class="comment"># hostnamectl hostname rabbitmq03</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别修改三台服务器的 <code>/etc/hosts</code> 文件</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.56  rabbitmq01</span><br><span class="line">10.250.0.232 rabbitmq02</span><br><span class="line">10.250.0.97  rabbitmq03</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>同步集群节点中的cookie</p><ul class="lvl-2"><li class="lvl-4">默认会在 <code>/var/lib/rabbitmq/</code>目录下生成一个<code>.erlang.cookie</code>，里面有一个字符串。</li><li class="lvl-4">我们使用 <code>rabbitmq01</code> 节点作为集群的主节点，其他节点作为集群的成员节点，我们要做的就是保证集群中三个节点的这个<code>cookie字符串一致</code>。</li><li class="lvl-4">将 <code>rabbitmq01</code> 的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中的<code>cookie字符串</code>复制到其他节点的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中。</li></ul></li><li class="lvl-2"><p>分别启动三台服务器的 RabbitMQ 服务</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start rabbitmq-server</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别登录 <code>rabbitmq02</code> 和 <code>rabbitmq03</code> 节点，执行如下命令，将节点加入集群</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停掉rabbitmq应用</span></span><br><span class="line">rabbitmqctl stop_app</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置rabbitmq、交换机、队列</span></span><br><span class="line">rabbitmqctl reset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入集群，注意此时 rabbitmq01 是主节点，必须处于运行状态，</span></span><br><span class="line"><span class="comment"># --ram 表示以 ram 内存节点 加入集群。如果不带参数默认为 disk 磁盘节点</span></span><br><span class="line"><span class="comment"># RabbitMQ的集群节点分为 disk 和 ram，disk节点会将元数据保存到硬盘当中，而ram节点只是在内存中保存元数据。</span></span><br><span class="line">rabbitmqctl join_cluster rabbit@rabbitmq01 --ram</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动rabbitmq应用</span></span><br><span class="line">rabbitmqctl start_app</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>登录 任意 节点，执行如下命令，查看集群状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqctl cluster_status</span><br><span class="line"><span class="comment">## 输出类似</span></span><br><span class="line">Cluster status of node rabbit@rabbitmq01 ...</span><br><span class="line">Basics</span><br><span class="line"></span><br><span class="line">Cluster name: rabbit@rabbitmq01</span><br><span class="line">Total CPU cores available cluster-wide: 6</span><br><span class="line"></span><br><span class="line">Cluster Tags</span><br><span class="line"></span><br><span class="line">(none)</span><br><span class="line"></span><br><span class="line">Disk Nodes</span><br><span class="line"></span><br><span class="line">rabbit@rabbitmq01</span><br><span class="line"></span><br><span class="line">RAM Nodes</span><br><span class="line"></span><br><span class="line">rabbit@rabbitmq02</span><br><span class="line">rabbit@rabbitmq03</span><br><span class="line"></span><br><span class="line">Running Nodes</span><br><span class="line"></span><br><span class="line">rabbit@rabbitmq01</span><br><span class="line">rabbit@rabbitmq02</span><br><span class="line">rabbit@rabbitmq03</span><br></pre></td></tr></table></figure><blockquote><p>PS: 由于ram节点减少了很多与硬盘的交互，所以，ram节点的元数据使用性能会比较高。但是，同时，这也意味着元数据的安全性是不如disk节点的。在我们这个集群中， rabbitmq02 和 rabbitmq03 都以 ram节点 的身份加入到 rabbitmq01 集群里，因此，是存在单点故障的。如果 rabbitmq01 节点服务崩溃，那么元数据就有可能丢失。在企业进行部署时，性能与安全性需要自己进行平衡。</p></blockquote><ul class="lvl-0"><li class="lvl-2"><p>登录任意节点的管理页面，查看集群状态<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/R195gJ.png" alt=""></p></li><li class="lvl-2"><p>此时我们在任意节点中创建虚拟主机、队列、交换机和绑定关系 等元数据，都会自动同步到其他节点中。</p></li><li class="lvl-2"><p>我们也可以在 管理控制台 中查看队列时看到，此时多个一列，<code>Node</code>列，显示该队列在哪些节点中存在。只有 <code>Quorum 队列</code> 和 <code>Stream 队列</code> 才会显示多个节点，因为 <code>Classic 队列</code> 不支持多节点复制。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/GjHcLN.png" alt=""></p></li><li class="lvl-2"><p>查看某个具体的 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，可以看到更详细的说明<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/XtIkpp.png" alt=""></p></li><li class="lvl-2"><p>此时新建队列，会要求我们指定主节点(Leader)，即负责存储消息的的节点，而 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，会自动将消息复制到其它节点(Members)。</p><ul class="lvl-2"><li class="lvl-4">Leader: 队列的主节点，负责存储消息。</li><li class="lvl-4">Members: 队列的成员节点，负责存储消息的副本。</li></ul></li></ul><h2 id="演示队列复制">演示队列复制</h2><ul class="lvl-0"><li class="lvl-2"><p>默认情况下，<code>Quorum 队列</code> 和 <code>Stream 队列</code> 的 复制数 都为 3，这里为了演示，我在增加一个节点 <code>rabbitmq04</code>，请自行按上面的方法添加。</p></li></ul><h3 id="Quorum-队列">Quorum 队列</h3><ul class="lvl-0"><li class="lvl-2"><p>在页面上创建一个 <code>Quorum 队列</code>，与单节点上创建队列的区别就是需要我们选择主节点。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/JYfKgg.png" alt=""></p></li><li class="lvl-2"><p>通过 客户端 创建队列时，默认情况下，连接哪个节点，哪个节点就是Leader，但也可以通过参数<code>x-queue-leader-locator</code>指定主节点的选择策略。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqadmin queues <span class="built_in">declare</span> --vhost <span class="string">&quot;/vtest&quot;</span> --name <span class="string">&quot;target.quorum.queue.name&quot;</span> --<span class="built_in">type</span> <span class="string">&quot;quorum&quot;</span> --durable <span class="literal">true</span> --arguments <span class="string">&#x27;&#123;&quot;x-queue-leader-locator&quot;:&quot;balanced&quot;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># x-queue-leader-locator 有两种选择策略</span></span><br><span class="line"><span class="comment">## client-local：选择声明队列的客户端所连接的节点。这是默认值。</span></span><br><span class="line"><span class="comment">## balanced：如果队列总数少于 1000 个（经典队列、仲裁队列和流）， 选择托管最小数量的仲裁队列领导者的节点。 如果队列总体超过 1000 个，则随机选择一个节点。</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>创建成功后，可以看到 <code>Quorum 队列</code> 的主节点和成员节点，可以看到这里成员节点有三个，除了主节点外，其余节点由集群自动选择。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qBfNNh.png" alt=""></p></li><li class="lvl-2"><p>也就是说，默认情况下，<code>Quorum 队列</code> 的复制数是 <code>3</code>，如果我们希望改变复制数，可以在创建队列时指定参数 <code>x-quorum-initial-group-size</code>，其值为 <code>大于 0 的整数</code>，若设置值大于实际成员节点数，则以实际成员节点数为准。<code>x-quorum-initial-group-size</code> 设置为 <code>1</code> 时便不进行复制了。</p></li><li class="lvl-2"><p>如果集群中增加了新的节点，希望队列也被复制到新的节点中，可以通过如下命令，将新的节点加入成员节点中:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-queues add_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class="line">rabbitmq-queues add_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>如果希望将节点从成员节点中移除，可以通过如下命令:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-queues delete_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class="line">rabbitmq-queues delete_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>另外，当通过 <code>forget_cluster_node</code> 命令从集群中永久删除节点时，会自动将队列关联的节点从成员节点中移除。</p></li><li class="lvl-2"><p>删除节点时，请使用如下命令:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为要删除 rabbitmq04 节点，所以以下命令不能在 rabbitmq04 节点执行</span></span><br><span class="line"><span class="comment"># 删除前需要先关闭应用</span></span><br><span class="line">rabbitmqctl -n rabbit@rabbitmq04 stop_app</span><br><span class="line"><span class="comment"># 删除节点</span></span><br><span class="line"><span class="comment"># rabbitmqctl forget_cluster_node &lt;node&gt;</span></span><br><span class="line">rabbitmqctl forget_cluster_node rabbit@rabbitmq04</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>新增节点后，一个个的对原有的队列进行复制扩展非常麻烦，可以通过如下命令快速对符合条件的队列进行复制扩展:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-queues grow &lt;node&gt; &lt;all | even&gt; [--vhost-pattern &lt;pattern&gt;] [--queue-pattern &lt;pattern&gt;]</span></span><br><span class="line"><span class="comment">## 参数说明：</span></span><br><span class="line"><span class="comment"># &lt;node&gt;: 这个参数指定了 RabbitMQ 节点的名称，通常是 rabbit@&lt;hostname&gt;。它表示在哪个节点上执行增长操作。</span></span><br><span class="line"><span class="comment"># &lt;all | even&gt;: 这个参数指定了要扩展的队列类型。all 表示扩展所有队列，even 表示扩展偶数编号的队列。</span></span><br><span class="line"><span class="comment"># --vhost-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的虚拟主机名称。</span></span><br><span class="line"><span class="comment"># --queue-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的队列名称。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 示例</span></span><br><span class="line"><span class="comment"># 扩展所有虚拟主机下的所有队列的副本：</span></span><br><span class="line">rabbitmq-queues grow rabbit@rabbitmq04 all</span><br><span class="line"><span class="comment"># 扩展所有虚拟主机下的偶数编号的队列的副本：</span></span><br><span class="line">rabbitmq-queues grow rabbit@rabbitmq04 even</span><br><span class="line"><span class="comment"># 扩展特定虚拟主机和队列名称的队列</span></span><br><span class="line">rabbitmq-queues grow rabbit@rabbitmq04 all --vhost-pattern /vtest --queue-pattern <span class="string">&quot;^q_&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Stream-队列">Stream 队列</h3><ul class="lvl-0"><li class="lvl-2"><p>Stream 队列 与 Quorum 队列 类似，通过哪个节点创建队列，哪个节点就是 Leader，但也是可以通过参数 <code>x-queue-leader-locator</code> 指定主节点的选择策略。</p></li><li class="lvl-2"><p>创建 Stream 队列时，默认复制数就是当前集群的节点数（Quorum 队列 默认是 3），可以通过指定参数 <code>x-initial-cluster-size</code> 进行初始设置。</p></li><li class="lvl-2"><p>添加新的节点时，与 Quorum 队列 类似，Stream 队列 也不会自动进行复制，可以通过如下命令手动复制</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class="line">rabbitmq-streams add_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除成员节点时，请使用如下命令:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class="line">rabbitmq-streams delete_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查看节点复制状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class="line">rabbitmq-streams stream_status -p /vtest sq_2</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>当流出现异常状态（如副本分布异常、领导节点挂掉）时，为了恢复可用性，可以重启流</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-streams restart_stream [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class="line">rabbitmq-streams restart_stream -p /vtest sq_2</span><br><span class="line"><span class="comment">## 重启操作</span></span><br><span class="line"><span class="comment"># 1.停止流的当前副本/分区。</span></span><br><span class="line"><span class="comment"># 2.重新初始化流的存储和元数据。</span></span><br><span class="line"><span class="comment"># 3.让流在集群中恢复为可用状态。</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RabbitMQ 版本为 4.1.4。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo&quot;&gt;Java Client 示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 之 Message</title>
    <link href="https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/"/>
    <id>https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/</id>
    <published>2025-09-21T14:30:05.000Z</published>
    <updated>2025-09-22T13:15:32.412Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 RabbitMQ 的 Message 的基本概念和用法。</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 RabbitMQ 版本为 4.1.4。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo">Java Client 示例</a></p></li></ul><span id="more"></span><h2 id="Message-消息-是什么？">Message(消息) 是什么？</h2><ul class="lvl-0"><li class="lvl-2"><p>在 RabbitMQ 中，Message（消息）是消息队列中的数据单元。消息包含消息内容、消息属性等信息。</p></li><li class="lvl-2"><p>Message 组成：</p><ul class="lvl-2"><li class="lvl-4"><ol><li class="lvl-7">消息内容：消息的内容，可以是任意数据。</li></ol></li><li class="lvl-4"><ol start="2"><li class="lvl-7">消息属性：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</li></ol></li></ul></li></ul><h2 id="Web-控制台-中-Message-的使用">Web 控制台 中 Message 的使用</h2><ul class="lvl-0"><li class="lvl-2"><p>在 Exchange 和 Queue 的管理界面中，都可以在其详情页面测试 Message 的使用。</p></li><li class="lvl-2"><p>关于如何在代码中使用 Message，我会在下一节中详细介绍。</p></li></ul><h3 id="Publish-message">Publish message</h3><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/dHsDyt.png" alt=""></p><ul class="lvl-0"><li class="lvl-2"><p>Payload：消息的内容，可以是任意数据。</p></li><li class="lvl-2"><p>Payload encoding：消息内容的编码方式，<code>String</code> 或者 <code>Base64</code>，默认为 <code>String</code>。</p></li><li class="lvl-2"><p>Delivery mode：消息的持久化模式，1-Non-persistent 表示非持久化，2-Persistent 表示持久化。</p></li><li class="lvl-2"><p>Headers：消息的头信息，用于与 <code>Headers Exchange（头部交换机）</code>中的配置进行匹配。</p></li><li class="lvl-2"><p>Properties：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</p></li></ul><table><thead><tr><th>属性名</th><th>中文含义</th><th>数据类型</th><th>默认值</th><th>典型用途</th></tr></thead><tbody><tr><td>content_type</td><td>内容类型</td><td>String</td><td>null</td><td>指定消息的 MIME 类型，如 <code>&quot;text/plain&quot;</code>、<code>&quot;application/json&quot;</code></td></tr><tr><td>content_encoding</td><td>内容编码</td><td>String</td><td>null</td><td>指定消息内容的编码方式，如 <code>&quot;gzip&quot;</code></td></tr><tr><td>priority</td><td>消息优先级</td><td>Integer (0-255)</td><td>0</td><td>结合 <code>x-max-priority</code> 控制消息处理顺序，数值越大优先级越高</td></tr><tr><td>correlation_id</td><td>关联 ID</td><td>String</td><td>null</td><td>RPC 模式中关联请求与响应</td></tr><tr><td>reply_to</td><td>回复队列名</td><td>String</td><td>null</td><td>RPC 模式中指定响应消息的返回队列</td></tr><tr><td>expiration</td><td>消息过期时间</td><td>String (ms)</td><td>null</td><td>消息的 TTL，毫秒为单位，过期后将被丢弃或进入死信队列</td></tr><tr><td>message_id</td><td>消息 ID</td><td>String</td><td>null</td><td>唯一标识一条消息，通常由生产者指定</td></tr><tr><td>timestamp</td><td>时间戳</td><td>Date / Long</td><td>null</td><td>消息发送时间，通常是 Unix 时间戳</td></tr><tr><td>type</td><td>消息类型</td><td>String</td><td>null</td><td>描述消息类型，如 <code>&quot;order&quot;</code> 或 <code>&quot;event&quot;</code></td></tr><tr><td>user_id</td><td>用户 ID</td><td>String</td><td>null</td><td>标识发送消息的用户，通常用于安全或审计</td></tr><tr><td>app_id</td><td>应用 ID</td><td>String</td><td>null</td><td>标识发送消息的应用程序</td></tr><tr><td>cluster_id</td><td>集群 ID</td><td>String</td><td>null</td><td>RabbitMQ 集群 ID，实际中很少使用</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>与队列重叠的属性：</p></li></ul><table><thead><tr><th>参数名称</th><th>队列参数（Queue Arguments）</th><th>消息属性（Message Properties）</th><th>谁的优先级更高 / 生效方式</th></tr></thead><tbody><tr><td><strong>priority / x-max-priority</strong></td><td><code>x-max-priority</code>: 定义队列支持的<strong>最大优先级值</strong></td><td><code>priority</code>: 为单个消息设置优先级</td><td>队列先定义范围，消息只能在这个范围内取值 <br> 若 <code>priority &gt; x-max-priority</code>，则以<code>x-max-priority</code>为准</td></tr><tr><td><strong>expiration / x-message-ttl</strong></td><td><code>x-message-ttl</code>: 队列级别的消息<strong>统一 TTL</strong></td><td><code>expiration</code>: 为单个消息设置 TTL（毫秒）</td><td>如果同时设置，<strong>较短的 TTL</strong> 会生效</td></tr></tbody></table><h3 id="Get-message">Get message</h3><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Ar9qob.png" alt=""></p><ul class="lvl-0"><li class="lvl-2"><p>Ack Mode：消息确认模式</p><ul class="lvl-2"><li class="lvl-4">Nack message requeue true: 确认失败，消息重新入队，这是默认选择，主要是为了测试后消息依旧存在。</li><li class="lvl-4">Automatic ack: 自动确认</li><li class="lvl-4">Reject requeue true: 拒绝，消息重新入队</li><li class="lvl-4">Reject requeue false: 拒绝，消息不重新入队</li></ul></li><li class="lvl-2"><p>Encoding：消息内容编码方式</p><ul class="lvl-2"><li class="lvl-4"><code>Auto String / Base64</code>，默认。如果消息载荷可以解释为UTF-8编码的字符串，就是 <code>String</code>，否则就是 <code>Base64</code>。</li><li class="lvl-4"><code>Base64</code>。</li></ul></li><li class="lvl-2"><p>Messages: 一次获取消息数量，默认为 1。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 RabbitMQ 的 Message 的基本概念和用法。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RabbitMQ 版本为 4.1.4。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo&quot;&gt;Java Client 示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 之 Exchange</title>
    <link href="https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/"/>
    <id>https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/</id>
    <published>2025-09-21T13:30:05.000Z</published>
    <updated>2025-09-22T13:17:07.914Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 RabbitMQ 版本为 4.1.4。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo">Java Client 示例</a></p></li></ul><span id="more"></span><h2 id="Exchange-交换机-是什么？">Exchange(交换机) 是什么？</h2><ul class="lvl-0"><li class="lvl-2"><p>在 RabbitMQ 中，<a href="https://www.rabbitmq.com/docs/exchanges">Exchange（交换机）</a> 是消息路由的核心组件。它负责接收生产者发送的消息，并根据预定义的路由规则将消息转发到一个或多个队列。</p></li><li class="lvl-2"><p>Exchange 类型决定了消息的路由方式。RabbitMQ 支持的 Exchange 类型</p></li></ul><table><thead><tr><th>Exchange 类型</th><th>声明类型</th><th>路由规则描述</th><th>典型用途</th></tr></thead><tbody><tr><td><strong>Direct</strong></td><td><code>direct</code></td><td>消息根据 <strong>路由键（routing key）</strong> 精确匹配绑定键（binding key）进行路由。</td><td>精确消息传递，如日志分类、任务分发等。</td></tr><tr><td><strong>Fanout</strong></td><td><code>fanout</code></td><td>消息广播到所有绑定的队列，<strong>忽略路由键</strong>。</td><td>广播消息，如发布/订阅模式、实时通知等。</td></tr><tr><td><strong>Topic</strong></td><td><code>topic</code></td><td>消息根据路由键与绑定键模式的匹配进行路由，支持通配符 <code>*</code>（匹配一个词）和 <code>#</code>（匹配零个或多个词）。</td><td>模块化路由，如日志系统、事件驱动架构等。</td></tr><tr><td><strong>Headers</strong></td><td><code>headers</code></td><td>消息根据 <strong>消息头部（headers）</strong> 与绑定时指定的头部匹配进行路由，支持 <code>x-match</code> 参数（<code>any</code> 或 <code>all</code>）。</td><td>多条件路由，如复杂过滤、动态路由等。</td></tr><tr><td><strong>Local Random Exchange</strong></td><td><code>x-local-random</code></td><td>消息始终被路由到本地队列，如果有多个本地队列绑定，则随机选择一个进行投递。</td><td>请求-响应（RPC）模式，低延迟通信</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 默认为我们提供了如下的交换机<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/SKlqQK.png" alt=""></p></li><li class="lvl-2"><p>每新创建一个 Vhost，RabbitMQ 就会自动创建以下交换机，比如 <code>/vtest</code><br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oGJ1oj.png" alt=""></p></li><li class="lvl-2"><p>当然我们也可以根据需要创建新的交换机<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QjnZin.png" alt=""></p></li><li class="lvl-2"><p>配置说明</p><ul class="lvl-2"><li class="lvl-4">Durability: 指定 Exchange 是否持久化。<ul class="lvl-4"><li class="lvl-6">Durable: 持久化的 Exchange 会被保存在磁盘上，重启 RabbitMQ 时会自动恢复。</li><li class="lvl-6">Transient: 非持久化的 Exchange 会被保存在内存中，重启 RabbitMQ 时会丢失。</li></ul></li><li class="lvl-4">Auto-delete: 指定 Exchange 是否自动删除。<ul class="lvl-4"><li class="lvl-6">yes: 如果没有队列或交换机绑定该 Exchange，则该 Exchange 会自动删除。</li><li class="lvl-6">no: 该 Exchange 不会自动删除。</li></ul></li><li class="lvl-4">Internal: 用于控制交换机是否可以被生产者直接发布消息<ul class="lvl-4"><li class="lvl-6">yes: 不能被生产者直接发送消息，该交换机只能用于 将消息从其他交换机转发到该交换机。</li><li class="lvl-6">no: 可以被生产者直接发送消息。</li></ul></li><li class="lvl-4">Arguments: 用于设置 Exchange 的其他参数，目前仅支持一个参数<ul class="lvl-4"><li class="lvl-6">Alternate exchange(alternate-exchange): 指定该 Exchange 的备用交换机，如果无法以其他方式将发往此交换机的消息路由出去，则将它们发送至此处指定的备用交换机。</li></ul></li></ul></li></ul><h2 id="Direct-Exchange（直接交换机）">Direct Exchange（直接交换机）</h2><ul class="lvl-0"><li class="lvl-2"><p>路由规则：消息的路由键与队列的绑定键完全匹配时，消息被路由到该队列。</p></li><li class="lvl-2"><p>示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。</p></li><li class="lvl-2"><p>适用场景：需要精确匹配的场景，如日志分类、任务分发等。</p></li></ul><h2 id="Fanout-Exchange（扇出交换机）">Fanout Exchange（扇出交换机）</h2><ul class="lvl-0"><li class="lvl-2"><p>路由规则：消息广播到所有绑定的队列，忽略路由键。</p></li><li class="lvl-2"><p>示例：无论消息的路由键是什么，都会被路由到所有绑定的队列。</p></li><li class="lvl-2"><p>适用场景：广播消息，如发布/订阅模式、实时通知等。</p></li></ul><h2 id="Topic-Exchange（主题交换机）">Topic Exchange（主题交换机）</h2><ul class="lvl-0"><li class="lvl-2"><p>路由规则：消息的路由键与队列的绑定键模式匹配时，消息被路由到该队列。支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。</p></li><li class="lvl-2"><p>示例：如果队列绑定键为 <em>.orange.</em>，则路由键为 quick.orange.rabbit 的消息会被路由到该队列。</p></li><li class="lvl-2"><p>适用场景：模块化路由，如日志系统、事件驱动架构等。</p></li></ul><h2 id="Headers-Exchange（头部交换机）">Headers Exchange（头部交换机）</h2><ul class="lvl-0"><li class="lvl-2"><p>路由规则：消息的头部与队列的绑定头部匹配时，消息被路由到该队列。支持 x-match 参数（any 或 all）。即使配置了路由键也会忽略。</p></li><li class="lvl-2"><p>示例：如果队列绑定头部为 { “x-match”: “all”, “format”: “pdf”, “priority”: “high” }，则只有同时满足这两个条件的消息会被路由到该队列。</p></li><li class="lvl-2"><p>适用场景：多条件路由，如复杂过滤、动态路由等。</p></li></ul><h2 id="Local-Random-Exchange（本地随机交换机）">Local Random Exchange（本地随机交换机）</h2><ul class="lvl-0"><li class="lvl-2"><p>Local Random Exchange 是 RabbitMQ 4.0 引入的交换机类型，旨在优化<code>请求-响应</code>模式下的消息路由，特别适用于低延迟和高吞吐量的场景。通过结合独占队列使用，可以确保消息快速传递到本地消费者，减少网络延迟，提高系统性能。</p></li><li class="lvl-2"><p>路由规则：消息始终被路由到本地队列（位于同一节点上），如果有多个本地队列绑定，则随机选择一个进行投递。</p></li><li class="lvl-2"><p>示例：假设节点 A 上有两个绑定了 x-local-random 交换机的队列 Q1 和 Q2，发布的消息会随机路由到 Q1 或 Q2，但不会路由到其他节点的队列。</p></li><li class="lvl-2"><p>适用场景：请求-响应（RPC）模式下的低延迟通信，适合微服务架构中每个节点上都有消费者的场景。</p></li><li class="lvl-2"><p>在使用 Local Random Exchange 时，必须满足以下条件：</p><ul class="lvl-2"><li class="lvl-4">独占队列：消费者应声明独占队列，以确保队列仅绑定到当前节点。</li><li class="lvl-4">每个节点至少一个消费者：每个 RabbitMQ 节点上应至少有一个消费者，否则在该节点上发布的消息将被丢弃。</li><li class="lvl-4">交换机类型声明：使用 <code>x-local-random</code> 类型声明交换机。</li></ul></li></ul><h2 id="Exchange-与-Queue-绑定-Binding">Exchange 与 Queue 绑定(Binding)</h2><ul class="lvl-0"><li class="lvl-2"><p>创建好 Exchange 之后，需要将 Exchange 与 Queue 绑定，才能将消息发送到指定的队列。</p></li><li class="lvl-2"><p>Exchange 与 Queue 的绑定关系，即 Exchange 发送的消息，会根据路由键与队列的绑定键进行匹配，如果匹配成功，则将消息发送到对应的队列。</p></li><li class="lvl-2"><p>在 Exchange 页面点击 Exchange 的名称，进入 Exchange 详情页面，此处可以进行 Exchange 与 Queue 绑定配置<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/taKUjm.png" alt=""></p><blockquote><p>这里的<code>Arguments</code>用于设置 绑定 的其他参数，比如 <code>Headers Exchange</code> 需要设置 <code>x-match</code> 参数等。</p></blockquote></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RabbitMQ 版本为 4.1.4。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo&quot;&gt;Java Client 示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 之 Queue</title>
    <link href="https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/"/>
    <id>https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/</id>
    <published>2025-09-20T13:30:05.000Z</published>
    <updated>2025-09-28T07:30:09.100Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 RabbitMQ 的 Queue 的基本概念和用法。</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 RabbitMQ 版本为 4.1.4。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo">Java Client 示例</a></p></li></ul><span id="more"></span><h2 id="Queue-队列-是什么？">Queue(队列) 是什么？</h2><ul class="lvl-0"><li class="lvl-2"><p>在 RabbitMQ 中，<a href="https://www.rabbitmq.com/docs/queues">队列（Queue）</a> 是一种用于存储消息的 数据结构，消息会一直保存在队列中，直到被应用程序或服务消费为止。</p></li><li class="lvl-2"><p>生产者（Publisher） 把消息放进队列，消费者（Consumer） 从队列中取出消息。队列中的消息会按照 FIFO（先进先出）的顺序进行消费。</p></li><li class="lvl-2"><p>队列在生产者和消费者之间起到缓冲区的作用。生产者不需要知道消费者的存在，它们只需把消息发送到队列。消费者可以根据自身处理速度，按需消费消息。</p></li><li class="lvl-2"><p>RabbitMQ 目前 支持三种队列类型：</p></li></ul><table><thead><tr><th>队列类型</th><th>描述</th><th>特点</th><th>典型用途</th></tr></thead><tbody><tr><td><strong>Classic Queue（经典队列）</strong></td><td>最常用的队列类型，消息按 FIFO（先进先出）顺序存储和消费</td><td>支持持久化、优先级、TTL、死信等</td><td>大多数常规消息场景</td></tr><tr><td><strong>Quorum Queue（仲裁队列）</strong></td><td>基于 Raft 协议的队列，确保高可用和数据一致性</td><td>内置复制（副本数量可配置）、适合高可靠性场景，但吞吐量略低于经典队列</td><td>关键任务消息、高可靠性场景</td></tr><tr><td><strong>Stream Queue（流式队列）</strong></td><td>面向大量消息的高吞吐队列，支持消息按偏移量读取</td><td>类似 Kafka，可随机访问历史消息、顺序读取、可持久化大量消息</td><td>大数据流、日志处理、事件溯源</td></tr></tbody></table><h2 id="Classic-Queue-经典队列">Classic Queue(经典队列)</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://www.rabbitmq.com/docs/classic-queues">RabbitMQ 经典队列（原始队列类型）</a>是一种通用队列类型。实际上它是在 3.8.x 版本之前唯一的队列类型。</p></li><li class="lvl-2"><p>经典队列适用于数据安全不是优先事项的用例，因为存储在经典队列中的数据不会被复制。 经典队列使用非复制的 FIFO 队列实现。</p></li><li class="lvl-2"><p>经典队列不适合积累太多的消息，如果队列中积累的消息太多了，会严重影响客户端生产消息以及消费消息的性能。因此，经典队列主要用在数据量比较小，并且生产消息和消费消息的速度比较稳定的业务场景。比如内部系统之间的服务调用。</p></li><li class="lvl-2"><p>RabbitMQ 4.0 删除了对经典队列 <code>version1</code> 的支持，同时也不再支持将 经典队列 的消息在节点间复制。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MAdpRV.png" alt=""></p></li><li class="lvl-2"><p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p></li></ul><table><thead><tr><th>参数名称</th><th>配置参数名</th><th>数据类型</th><th>作用说明</th><th>备注 / 使用场景</th></tr></thead><tbody><tr><td><strong>Auto expire</strong></td><td><code>x-expires</code></td><td>整数（毫秒）</td><td>队列在 <strong>指定时间内无人使用（无消费者、无发布、无访问）</strong> 时自动删除</td><td>类似“队列空闲过期时间”，节省资源</td></tr><tr><td><strong>Message TTL</strong></td><td><code>x-message-ttl</code></td><td>整数（毫秒）</td><td>消息的 <strong>存活时间</strong>，超过时间后消息会被丢弃或发送到死信队列</td><td>用于限制消息时效性，如延迟消息或短期缓存</td></tr><tr><td><strong>Overflow behaviour</strong></td><td><code>x-overflow</code></td><td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td><td>当队列达到 <strong>最大长度</strong> 或 <strong>最大字节数</strong> 时的行为</td><td>- <code>drop-head</code>：丢弃最早的消息 <br> - <code>reject-publish</code>：拒绝新的消息</td></tr><tr><td><strong>Single active consumer</strong></td><td><code>x-single-active-consumer</code></td><td>布尔值（true/false）</td><td>是否启用 <strong>单活消费者模式</strong>，一次只允许一个消费者消费队列</td><td>用于严格顺序消费，保证某个消息不会被多个消费者同时处理</td></tr><tr><td><strong>Dead letter exchange (DLX)</strong></td><td><code>x-dead-letter-exchange</code></td><td>字符串</td><td>指定队列的 <strong>死信交换机</strong>，用于接收无法消费或过期的消息</td><td>常用于失败重试、消息补偿场景</td></tr><tr><td><strong>Dead letter routing key</strong></td><td><code>x-dead-letter-routing-key</code></td><td>字符串</td><td>消息转发到 DLX 时的 <strong>路由键</strong></td><td>可以灵活转发到不同队列</td></tr><tr><td><strong>Max length</strong></td><td><code>x-max-length</code></td><td>整数</td><td>队列中 <strong>最大消息条数</strong></td><td>超过时按照 Overflow behaviour 处理</td></tr><tr><td><strong>Max length bytes</strong></td><td><code>x-max-length-bytes</code></td><td>整数（字节）</td><td>队列中 <strong>消息总字节数上限</strong></td><td>超过时按照 Overflow behaviour 处理，适合大消息场景</td></tr><tr><td><strong>Maximum priority</strong></td><td><code>x-max-priority</code></td><td>整数</td><td>启用优先级队列时，队列可设置的 <strong>最大优先级值</strong></td><td>消息优先级范围是 0 到这个值，优先级高的消息先被消费</td></tr><tr><td><strong>Leader locator</strong></td><td><code>x-queue-leader-locator</code></td><td>字符串（<code>client-local</code>、<code>balanced</code>）</td><td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td><td><code>client-local</code>（默认）：选择客户端所在节点作为Leader <br> <code>balanced</code>：在节点间均衡Leader分布，用于 HA 队列优化</td></tr></tbody></table><h2 id="Quorum-Queue-仲裁队列">Quorum Queue(仲裁队列)</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://www.rabbitmq.com/docs/quorum-queues">仲裁队列（Quorum Queue）</a> 是 RabbitMQ 从3.8.0版本之后引入的一种现代队列类型，也是目前官方比较推荐的一种对列类型。未来有可能取代 经典队列 成为默认队列类型。</p></li><li class="lvl-2"><p>其基于 Raft 共识算法 实现 持久化、复制和高可用。它保证 数据安全性、可靠的主节点选举，即使在升级或集群波动期间也能保持高可用性。</p></li><li class="lvl-2"><p>仲裁队列支持 毒消息处理、至少一次死信投递 以及 AMQP 修改（AMQP.modified）的处理结果。</p></li><li class="lvl-2"><p>它适合 以数据安全为首要目标 的场景。与经典队列相比，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oQ8YiT.png" alt=""></p></li><li class="lvl-2"><p>仲裁队列（Quorum Queue）的 <code>Durability</code> 只能设置为 Durable(true)。<code>Auto delete</code> 只能为 No(false)。</p></li><li class="lvl-2"><p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p></li></ul><table><thead><tr><th>参数名称</th><th>配置参数名</th><th>数据类型</th><th>作用说明</th><th>备注 / 使用场景</th></tr></thead><tbody><tr><td><strong>Auto expire</strong></td><td><code>x-expires</code></td><td>整数（毫秒）</td><td>队列在指定时间内无人使用（无消费者、无发布、无访问）时自动删除</td><td>节省资源，队列空闲过期时间</td></tr><tr><td><strong>Message TTL</strong></td><td><code>x-message-ttl</code></td><td>整数（毫秒）</td><td>队列中消息的生存时间，超过时间后消息会被丢弃或转入死信队列</td><td>控制消息时效性</td></tr><tr><td><strong>Overflow behaviour</strong></td><td><code>x-overflow</code></td><td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td><td>当队列达到最大长度时的处理方式</td><td><code>drop-head</code>：丢弃最早消息，<code>reject-publish</code>：拒绝新消息</td></tr><tr><td><strong>Single active consumer</strong></td><td><code>x-single-active-consumer</code></td><td>布尔值（true/false）</td><td>是否启用单活消费者模式，一次只允许一个消费者消费队列</td><td>保证严格顺序消费</td></tr><tr><td><strong>Dead letter exchange (DLX)</strong></td><td><code>x-dead-letter-exchange</code></td><td>字符串</td><td>指定队列的死信交换机，用于接收无法消费或过期的消息</td><td>与 DLX 配合使用处理失败消息</td></tr><tr><td><strong>Dead letter routing key</strong></td><td><code>x-dead-letter-routing-key</code></td><td>字符串</td><td>消息转发到 DLX 时的路由键</td><td>灵活路由死信消息</td></tr><tr><td><strong>Max length</strong></td><td><code>x-max-length</code></td><td>整数</td><td>队列中最大消息条数</td><td>超过时按 Overflow behaviour 处理</td></tr><tr><td><strong>Max length bytes</strong></td><td><code>x-max-length-bytes</code></td><td>整数（字节）</td><td>队列消息总字节数上限</td><td>超过时按 Overflow behaviour 处理</td></tr><tr><td><strong>Delivery limit</strong></td><td><code>x-delivery-limit</code></td><td>整数</td><td>消息允许投递的最大次数，超过后变为死信</td><td>控制消息重试次数</td></tr><tr><td><strong>Initial cluster size</strong></td><td><code>x-quorum-initial-group-size</code></td><td>整数</td><td>队列在创建时需要的最小节点数</td><td>用于保证仲裁队列的高可用性</td></tr><tr><td><strong>Target cluster size</strong></td><td><code>x-quorum-target-group-size</code></td><td>整数</td><td>队列运行时的目标节点数</td><td>当集群节点变化时，仲裁队列会尝试调整副本数量</td></tr><tr><td><strong>Dead letter strategy</strong></td><td><code>x-dead-letter-strategy</code></td><td>字符串（<code>at-most-once</code>、<code>at-least-once</code>）</td><td>设置仲裁队列的死信处理策略</td><td>仅适用于 Quorum Queue。<br><code>at-most-once</code>（默认）：消息最多投递一次，可能丢失。<br><code>at-least-once</code>：确保消息至少投递一次，必须将 Overflow behaviour 设置为 <code>reject-publish</code>，否则回退到 <code>at-most-once</code>。</td></tr><tr><td><strong>Leader locator</strong></td><td><code>x-queue-leader-locator</code></td><td>字符串（<code>client-local</code>、<code>balanced</code>）</td><td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td><td><code>client-local</code>：选择客户端所在节点作为 Leader <br> <code>balanced</code>：在节点间均衡 Leader 分布</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>Quorum Queues 和 Classic Queues 的功能对比如下：</p></li></ul><table><thead><tr><th>Feature</th><th>中文含义</th><th>Classic queues</th><th>Quorum queues</th><th>说明</th></tr></thead><tbody><tr><td>Non-durable queues</td><td>非持久化队列</td><td>yes</td><td>no</td><td>Quorum queues 总是持久化，不支持非持久化</td></tr><tr><td>Message replication</td><td>消息复制</td><td>no</td><td>yes</td><td>Quorum queues 内置消息复制，Classic queues 需镜像策略</td></tr><tr><td>Exclusivity</td><td>独占队列</td><td>yes</td><td>no</td><td>Classic queues 支持独占队列，Quorum queues 不支持独占</td></tr><tr><td>Per message persistence</td><td>消息级持久化</td><td>per message</td><td>always</td><td>Quorum queues 消息总是持久化</td></tr><tr><td>Membership changes</td><td>节点成员变更</td><td>no</td><td>semi-automatic</td><td>Quorum queues 节点变化时半自动处理复制</td></tr><tr><td>Message TTL (Time-To-Live)</td><td>消息存活时间</td><td>yes</td><td>yes</td><td>两者都支持消息过期时间</td></tr><tr><td>Queue TTL</td><td>队列存活时间</td><td>yes</td><td>partially</td><td>Quorum queues 的 lease 不会因重新声明而续期</td></tr><tr><td>Queue length limits</td><td>队列长度限制</td><td>yes</td><td>yes</td><td>Quorum queues 支持长度限制，但 <code>x-overflow=reject-publish-dlx</code> 不支持</td></tr><tr><td>Keeps messages in memory</td><td>消息内存保存</td><td>see Classic Queues</td><td>never</td><td>Quorum queues 消息总是写入磁盘，不保留在内存</td></tr><tr><td>Message priority</td><td>消息优先级</td><td>yes</td><td>yes</td><td>支持消息优先级</td></tr><tr><td>Single Active Consumer</td><td>单活消费者</td><td>yes</td><td>yes</td><td>支持单活消费者</td></tr><tr><td>Consumer exclusivity</td><td>独占消费者</td><td>yes</td><td>no</td><td>Quorum queues 不支持独占消费者，需使用 Single Active Consumer</td></tr><tr><td>Consumer priority</td><td>消费者优先级</td><td>yes</td><td>yes</td><td>支持消费者优先级</td></tr><tr><td>Dead letter exchanges</td><td>死信交换机</td><td>yes</td><td>yes</td><td>支持死信交换机</td></tr><tr><td>Adheres to policies</td><td>遵循策略</td><td>yes</td><td>yes</td><td>支持策略，但 Quorum queues 的部分策略行为不同</td></tr><tr><td>Poison message handling</td><td>毒消息处理</td><td>no</td><td>yes</td><td>Quorum queues 支持毒消息处理</td></tr><tr><td>Server-named queues</td><td>服务器自动命名队列</td><td>yes</td><td>no</td><td>Quorum queues 不支持服务器自动命名队列</td></tr></tbody></table><h2 id="Stream-流">Stream(流)</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://www.rabbitmq.com/docs/streams">Stream</a> 是RabbitMQ自 3.9.0 版本开始引入的一种新的数据队列类型。这种队列类型的消息是持久化到磁盘并且具备分布式备份的，更适合于消费者多，读消息非常频繁的场景。</p></li><li class="lvl-2"><p>Stream 的核心是以append-only只添加的日志来记录消息，整体来说，就是消息将以append-only的方式持久化到日志文件中，然后通过调整每个消费者的消费进度offset，来实现消息的多次分发。</p></li><li class="lvl-2"><p>Stream 不支持死信交换机，不支持处理毒消息。</p></li><li class="lvl-2"><p>实际上 Stream 不属于队列，流（Streams） 是一种 持久化、可复制的数据结构，功能上类似队列：从生产者缓冲消息供消费者读取。但它与队列有两个重要区别：</p><ul class="lvl-2"><li class="lvl-4">存储模型 – 流是 追加日志（append-only log），消息可以 重复读取直到过期。</li><li class="lvl-4">消费模型 – 流提供 非破坏性消费语义（non-destructive consumer semantics），多个消费者可以多次读取同一条消息而不会删除它。</li></ul></li><li class="lvl-2"><p>Stream 始终是持久化和复制的，保证数据安全。消费者可以通过 RabbitMQ 客户端库 或 专用二进制协议插件 读取流，其中插件方式可以 访问所有流特性 并提供 最佳性能。合理的客户端连接策略有助于提升 吞吐量和效率。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/8KqZY9.png" alt=""></p></li><li class="lvl-2"><p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p></li></ul><table><thead><tr><th>参数名称</th><th>配置参数名</th><th>数据类型</th><th>作用说明</th><th>备注 / 使用场景</th></tr></thead><tbody><tr><td><strong>Max length bytes</strong></td><td><code>x-max-length-bytes</code></td><td>整数（字节）</td><td>流中允许存储的 <strong>最大数据总字节数</strong></td><td>超过时流将停止接收新消息，适合控制存储容量</td></tr><tr><td><strong>Max time retention</strong></td><td><code>x-max-age</code></td><td>字符串（时间单位，例如 <code>1h</code>, <code>30m</code>, <code>1d</code>）</td><td>设置流队列中消息的 <strong>最大保留时间</strong>，超过时间的消息会被删除</td><td>支持时间单位：Y=年, M=月, D=天, h=小时, m=分钟, s=秒。例如 <code>&quot;1h&quot;</code> 表示只保留最近 1 小时的消息，用于控制数据量和自动清理过期消息</td></tr><tr><td><strong>Max segment size in bytes</strong></td><td><code>x-stream-max-segment-size</code></td><td>整数（字节）</td><td>流分段存储时的 <strong>每个段的最大字节数</strong></td><td>控制单个文件段大小，有利于 I/O 性能和管理</td></tr><tr><td><strong>Filter size (per chunk) in bytes</strong></td><td><code>x-stream-filter-size-bytes</code></td><td>整数（字节）</td><td>流内部 <strong>过滤索引每块的大小</strong></td><td>用于加速消息定位和读取，影响内存使用和检索效率</td></tr><tr><td><strong>Initial cluster size</strong></td><td><code>x-initial-cluster-size</code></td><td>整数</td><td>流在创建时的 <strong>最小节点数</strong></td><td>保证流的复制和高可用性</td></tr><tr><td><strong>Leader locator</strong></td><td><code>x-queue-leader-locator</code></td><td>字符串（<code>client-local</code>、<code>balanced</code>）</td><td>设置在集群节点上声明流时，主节点（Leader）的选取规则</td><td><code>client-local</code>：客户端所在节点作为 Leader（默认）<br><code>balanced</code>：在节点间均衡 Leader 分布，用于优化 HA</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>Classic Queue vs Stream Queue Feature Matrix</p></li></ul><table><thead><tr><th>Feature</th><th>中文含义</th><th>Classic queues</th><th>Stream queues</th><th>说明</th></tr></thead><tbody><tr><td>Non-durable queues</td><td>非持久化队列</td><td>yes</td><td>no</td><td>Stream 队列总是持久化，不支持非持久化</td></tr><tr><td>Exclusivity</td><td>独占队列</td><td>yes</td><td>no</td><td>Classic 队列支持独占，Stream 队列不支持独占</td></tr><tr><td>Per message persistence</td><td>消息级持久化</td><td>per message</td><td>always</td><td>Stream 队列的消息总是持久化</td></tr><tr><td>Membership changes</td><td>节点成员变更</td><td>no</td><td>manual</td><td>Stream 队列节点变更需要手动管理</td></tr><tr><td>TTL</td><td>消息存活时间</td><td>yes</td><td>no (but see Retention)</td><td>Stream 队列没有消息 TTL，但可通过 Retention 控制过期</td></tr><tr><td>Queue length limits</td><td>队列长度限制</td><td>yes</td><td>no (but see Retention)</td><td>Stream 队列没有固定长度限制，通过 Retention 控制数据量</td></tr><tr><td>Keeps messages in memory</td><td>消息内存保存</td><td>see Classic Queues</td><td>never</td><td>Stream 队列消息不保存在内存中，只写入磁盘</td></tr><tr><td>Message priority</td><td>消息优先级</td><td>yes</td><td>no</td><td>Stream 队列不支持消息优先级</td></tr><tr><td>Consumer priority</td><td>消费者优先级</td><td>yes</td><td>no</td><td>Stream 队列不支持消费者优先级</td></tr><tr><td>Dead letter exchanges</td><td>死信交换机</td><td>yes</td><td>no</td><td>Stream 队列不支持死信交换机</td></tr><tr><td>Adheres to policies</td><td>遵循策略</td><td>yes</td><td>yes (see Retention)</td><td>Stream 队列支持策略，但主要通过 Retention 控制行为</td></tr><tr><td>Reacts to memory alarms</td><td>内存告警响应</td><td>yes</td><td>no (uses minimal RAM)</td><td>Stream 队列使用最小内存，不触发内存告警</td></tr><tr><td>Poison message handling</td><td>毒消息处理</td><td>no</td><td>no</td><td>Stream 队列不支持毒消息处理</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>我们可以激活<code>流插件</code>来使用流的特有功能</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rabbitmq-plugins <span class="built_in">enable</span> rabbitmq_stream rabbitmq_stream_management</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>激活<code>流插件</code>后，Stream队列的操作方式可以更高级，具体可以参考<a href="https://www.rabbitmq.com/tutorials/tutorial-two-java-stream">官方文档</a>，作者在<a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo/rabbitmq-stream">Java Client 示例</a>中也给出了示例代码。</p></li></ul><h3 id="超级流-Super-Streams">超级流(Super Streams)</h3><ul class="lvl-0"><li class="lvl-2"><p>超级流（Super streams） 是一种通过将一个大的流分区成更小的流来实现扩展的方式。它们与 单个消费者（Single Active Consumer） 集成，以在分区内保持消息顺序。超级流从 RabbitMQ 3.11 开始可用。</p></li><li class="lvl-2"><p>一个超级流是由多个普通流组成的逻辑流。它是一种通过 RabbitMQ Streams 来扩展发布和消费的方法：一个大型逻辑流被划分成多个分区流，将存储和流量分散到多个集群节点上。</p></li><li class="lvl-2"><p>超级流依然是一个逻辑实体：由于客户端库的智能化处理，应用程序会把它视为一个“大型”流。超级流的拓扑结构基于 AMQP 0.9.1 模型，也就是交换机（exchange）、队列（queue）和它们之间的绑定（binding）。</p></li><li class="lvl-2"><p>可以使用任何 AMQP 0.9.1 库或管理插件创建超级流的拓扑。它需要创建一个直连交换机（direct exchange）、分区流（partition streams），并将它们绑定在一起。</p></li><li class="lvl-2"><p>通过管理控制台创建超级流<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/j2G1HC.png" alt=""></p></li><li class="lvl-2"><p>也可以通过命令创建超级流，以下是如何用命令创建一个包含 3 个分区的超级流：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rabbitmq-streams add_super_stream [-p &lt;vhost&gt;] &lt;stream-name&gt; [--partitions &lt;number&gt;]</span></span><br><span class="line">rabbitmq-streams add_super_stream -p /vtest sq_3 --partitions 3</span><br></pre></td></tr></table></figure><blockquote><p>创建的Stream<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4py5OE.png" alt=""><br>创建的 Exchange，名称 sq_3<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/EwfTRM.png" alt=""><br>绑定关系<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/NErhQX.png" alt=""></p></blockquote><h2 id="队列类型扩展">队列类型扩展</h2><h3 id="懒队列">懒队列</h3><ul class="lvl-0"><li class="lvl-2"><p>从3.6.x版本到3.12.x版本，RabbitMQ提供了一种针对Classic Queue的优化配置，<code>lazy-mode</code>，<a href="https://www.rabbitmq.com/docs/lazy-queues">懒对列</a>。懒队列会尽可能早的将消息内容保存到硬盘当中，并且只有在用户请求到时，才临时从硬盘加载到RAM内存当中。</p></li><li class="lvl-2"><p>默认情况下，RabbitMQ接收到消息时，会保存到内存以便使用，同时把消息写到硬盘。但是，消息写入硬盘的过程中，是会阻塞队列的。RabbitMQ虽然针对写入硬盘速度做了很多算法优化，但是在长队列中，依然表现不是很理想，所以就有了懒队列的出现。</p></li><li class="lvl-2"><p>懒队列会尝试尽可能早的把消息写到硬盘中。这意味着在正常操作的大多数情况下，RAM中要保存的消息要少得多。当然，这是以增加磁盘IO为代价的。</p></li><li class="lvl-2"><p>懒队列适合消息量大且长期有堆积的队列，可以减少内存使用，加快消费速度。但是这是以大量消耗集群的网络及磁盘IO为代价的。</p></li><li class="lvl-2"><p>从3.12往后的版本中，RabbitMQ 不再支持“惰性”模式，因为 经典队列 当前的特性就类似于以前的 懒队列。</p></li></ul><h3 id="死信队列">死信队列</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://www.rabbitmq.com/docs/dlx">死信队列（Dead Letter Queue）</a>，新版中叫做 死信交换机（Dead Letter Exchange, DLX），是RabbitMQ对于未能正常消费的消息进行的一种补救机制，用于保存无法被正常处理的消息。当消息被消费者处理失败时，RabbitMQ会将消息发送到死信队列中，等待消费者处理。</p></li><li class="lvl-2"><p>死信队列也是一个普通的队列，同样可以在队列上声明消费者，继续对消息进行消费处理。</p></li><li class="lvl-2"><p>有以下几种情况，RabbitMQ会将一个正常消息转成死信</p><ul class="lvl-2"><li class="lvl-4">消息被拒绝（Message rejection）<ul class="lvl-4"><li class="lvl-6">由 AMQP 1.0 接收端使用 rejected 结果拒绝</li><li class="lvl-6">由 AMQP 0.9.1 消费者使用 basic.reject 或 basic.nack，并且参数 requeue=false</li></ul></li><li class="lvl-4">消息过期（Message expiration）<ul class="lvl-4"><li class="lvl-6">消息超过其配置的 TTL（生存时间） 后过期。</li></ul></li><li class="lvl-4">队列长度超限（Queue length exceeded）<ul class="lvl-4"><li class="lvl-6">队列中的消息数量或总字节数达到配置的最大限制后，被丢弃的消息会死信化。</li></ul></li><li class="lvl-4">投递次数超限（仅适用于仲裁队列 Quorum Queue）<ul class="lvl-4"><li class="lvl-6">消息的投递次数超过了仲裁队列中配置的 delivery-limit。</li></ul></li></ul></li><li class="lvl-2"><p>使用场景</p><ul class="lvl-2"><li class="lvl-4">你可以在队列上配置 死信交换机（DLX） 和 死信路由键（Dead Letter Routing Key）。</li><li class="lvl-4">当消息成为死信时，会被 重新发布到 DLX，这样你可以：<ul class="lvl-4"><li class="lvl-6">做错误日志记录</li><li class="lvl-6">进行失败消息重试</li><li class="lvl-6">用于监控和告警</li></ul></li></ul></li><li class="lvl-2"><p>死信交换机的配置方法（How Dead Lettering is Configured）</p><ul class="lvl-2"><li class="lvl-4">在 RabbitMQ 中，任何队列都可以通过 客户端 或者 策略（policies） 来配置 死信交换机（DLX）。</li><li class="lvl-4">配置时主要涉及两个核心参数：</li></ul></li></ul><table><thead><tr><th>配置参数名</th><th>说明</th></tr></thead><tbody><tr><td><strong>dead-letter-exchange</strong></td><td>指定用于接收死信消息的 <strong>死信交换机名称</strong></td></tr><tr><td><strong>dead-letter-routing-key</strong></td><td>指定死信消息重新发布时使用的 <strong>路由键（Routing Key）</strong></td></tr></tbody></table><blockquote><p>死信在转移到死信队列时，他的 routingkey 也会保存下来。但是如果配置了 <code>x-dead-letter-routing-key</code> 这个参数的话，routingkey 就会被替换为配置的这个值。</p></blockquote><ul class="lvl-0"><li class="lvl-2"><p>在创建队列时，我们可以通过为队列添加 <code>x-dead-letter-exchange</code> 和 <code>x-dead-letter-routing-key</code> 参数，来指定 死信交换机（DLX）和 死信路由键（Dead Letter Routing Key）。但是这样做很麻烦，每个队列都要单独配置，因此，我们可以使用 策略（policies） 来统一配置。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 仅指定死信交换机，这里交换机的名称是 my-dlx，交换机要提前创建好</span></span><br><span class="line">rabbitmqctl set_policy DLX <span class="string">&quot;.*&quot;</span> <span class="string">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br><span class="line"><span class="comment"># 同时指定 死信交换机 和 路由键</span></span><br><span class="line">rabbitmqctl set_policy DLX <span class="string">&quot;.*&quot;</span> <span class="string">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>参数说明：</p></li></ul><table><thead><tr><th>部分</th><th>含义</th></tr></thead><tbody><tr><td><code>rabbitmqctl</code></td><td>RabbitMQ 的命令行管理工具</td></tr><tr><td><code>set_policy</code></td><td>设置一个策略（Policy），用于动态配置交换机、队列或绑定的参数</td></tr><tr><td><code>DLX</code></td><td>策略的名称，用户自定义，例如这里叫 <code>DLX</code></td></tr><tr><td><code>&quot;.*&quot;</code></td><td>正则表达式，匹配对象的名称。<code>.*</code> 表示匹配 <strong>所有队列</strong>，也可以指定具体队列名，比如 <code>^my-queue$</code></td></tr><tr><td><code>&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;</code></td><td>策略内容，这里设置了死信交换机名称和路由键：<br> - <code>dead-letter-exchange</code>: 设置死信交换机名称为 <code>my-dlx</code><br> - <code>dead-letter-routing-key</code>: 设置路由键为 <code>my-routing-key</code></td></tr><tr><td><code>--apply-to queues</code></td><td>指定策略作用对象为 <strong>队列（queues）</strong>，而不是交换机（exchanges）或绑定（bindings）</td></tr><tr><td><code>--priority 7</code></td><td>策略的优先级，值越大优先级越高。多个策略作用在同一对象时，优先级高的会覆盖低的</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>执行这条命令后：</p><ul class="lvl-2"><li class="lvl-4">所有队列都会自动带上 <code>x-dead-letter-exchange=my-dlx</code> 和 <code>x-dead-letter-routing-key=my-routing-key</code> 配置。</li><li class="lvl-4">队列中被拒绝、过期、超长或超过投递次数的消息会被重新发布到 <code>my-dlx</code> 交换机，并使用 <code>my-routing-key</code> 作为路由键。</li></ul></li><li class="lvl-2"><p>消息被作为死信转移到死信队列后，会在Header当中增加⼀些消息。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x-first-death-queue：该消息首次成为死信时所在的队列名称</span><br><span class="line">x-first-death-reason：该消息首次被判定为死信的原因</span><br><span class="line">x-first-death-exchange：该消息在首次成为死信前被发布到的交换机名称</span><br><span class="line">x-last-death-queue：该消息最近一次成为死信时所在的队列名称</span><br><span class="line">x-last-death-reason：该消息最近一次被判定为死信的原因</span><br><span class="line">x-last-death-exchange：该消息在最近一次成为死信前被发布到的交换机名称</span><br></pre></td></tr></table></figure><h3 id="延迟队列">延迟队列</h3><ul class="lvl-0"><li class="lvl-2"><p>延迟队列（Delayed Message Queue）: 延迟队列是一种特殊类型的队列，用于延迟消息的投递。</p></li><li class="lvl-2"><p>RabbitMQ中，是不存在延迟队列的功能的，而通常如果要用到延迟队列，就会采用 <code>TTL</code> + <code>死信队列</code> 的方式来实现。</p></li><li class="lvl-2"><p>延迟队列的实现原理：</p><ul class="lvl-2"><li class="lvl-4">创建一个普通队列，并设置队列的 TTL（x-message-ttl）参数，以及指定一个死信队列(x-dead-letter-exchange)</li><li class="lvl-4">当消息的 TTL 到期时，消息会被自动从当前队列中删除，并进入死信队列。</li><li class="lvl-4">为死信队列创建一个消费者，并监听死信队列，处理延迟消息。</li></ul></li></ul><h3 id="优先级队列">优先级队列</h3><ul class="lvl-0"><li class="lvl-2"><p>优先级队列（Priority Queue）: RabbitMQ 支持为经典队列（classic queues）添加“优先级”功能。启用“优先级”功能的经典队列通常被称为“优先级队列”（priority queues）。</p></li><li class="lvl-2"><p>RabbitMQ 支持 1 到 255 之间的优先级值，但强烈建议使用 1 到 5 之间的值。需要注意的是，优先级值越高，会消耗更多的 CPU 和内存资源，因为 RabbitMQ 在内部需要为每个优先级（从 1 到最大配置值）维护一个子队列。</p></li><li class="lvl-2"><p>只有经典队列支持通过参数<code>x-max-priority</code>指定队列支持的最大优先级，且不支持 通过 策略（policies） 将经典队列声明为优先级队列。</p></li><li class="lvl-2"><p>发布消息时，可以通过参数 <code>priority</code> 指定消息的优先级。是的，消息也是可以设置参数的。</p></li><li class="lvl-2"><p>优先级队列如何与消费者协同工作</p><ul class="lvl-2"><li class="lvl-4">若消费者连接到一个 空队列，然后消息陆续被发布，那么这些消息可能 不会 在队列中等待（即刚发布就被消费者接收），此时优先级功能没有机会上场。优先级是在消息排队（ready 消息）状态时才能体现其作用。</li><li class="lvl-4">推荐在消费者端使用 basic.qos(prefetch) 设置（在 manual ack 模式下），以限制消费者同时处理的未确认消息数。这样能让优先级的分级效果更加明显，因为如果 prefetch 数量未满，高优先级消息可以先被取出。</li></ul></li><li class="lvl-2"><p>注意事项</p><ul class="lvl-2"><li class="lvl-4">未设置 <code>priority</code> 的消息 会被当作优先级 0 处理。若消息指定的优先级大于队列的最大值（x-max-priority），则该消息的优先级就是<code>x-max-priority</code>。</li><li class="lvl-4">TTL / 消息过期 (message expiration)：即使设置了 TTL，过期的消息只会在队列头被检查。这意味着如果一个低优先级的消息在前面但还没过期，而高优先级的消息在后面，低优先级的消息可能会阻塞队列头，导致高优先级的消息被延迟。</li><li class="lvl-4">队列最大长度限制 (max-length)：如果队列设置了最大长度，队列会从头部 (head) 丢弃消息以维持长度限制。这可能导致高优先级消息也被丢弃，从而违背直觉。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 RabbitMQ 的 Queue 的基本概念和用法。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RabbitMQ 版本为 4.1.4。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo&quot;&gt;Java Client 示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 的安装及使用</title>
    <link href="https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/"/>
    <id>https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/</id>
    <published>2025-09-18T13:30:05.000Z</published>
    <updated>2025-09-28T02:30:21.901Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 RabbitMQ 的安装与使用。</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 RabbitMQ 版本为 4.1.4。</p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo">Java Client 示例</a></p></li></ul><span id="more"></span><h2 id="RabbitMQ-简介">RabbitMQ 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 是一个开源的 消息队列中间件，基于 AMQP（Advanced Message Queuing Protocol，高级消息队列协议） 实现，用于在分布式系统中 解耦、缓冲和异步处理消息。</p></li><li class="lvl-2"><p>它的主要作用是让 <code>不同系统</code> 或 <code>应用</code> 之间可靠地传递消息，即使发送方或接收方暂时不可用，也能保证消息不丢失。</p></li><li class="lvl-2"><p>RabbitMQ 的核心特点</p></li></ul><table><thead><tr><th>核心特点</th><th>具体说明</th></tr></thead><tbody><tr><td><strong>可靠性</strong></td><td>- 支持消息确认（ACK）机制<br>- 消息持久化到磁盘<br>- 支持事务或确认模式，保证消息不会丢失</td></tr><tr><td><strong>灵活的路由</strong></td><td>- 通过 <strong>交换机（Exchange）</strong> 将消息路由到不同的 <strong>队列（Queue）</strong><br>- 支持多种路由策略：<br>  • direct：直连，按队列名路由<br>  • fanout：广播，所有队列都收到<br>  • topic：主题匹配，类似订阅模式<br>  • headers：按消息头匹配</td></tr><tr><td><strong>高性能</strong></td><td>- 内存队列快速处理消息<br>- 支持异步 IO 和 Erlang 的并发模型</td></tr><tr><td><strong>多语言支持</strong></td><td>- 客户端库丰富：Java、Python、Go、C#、Node.js 等<br>- 可在多种平台和框架中使用</td></tr><tr><td><strong>集群与高可用</strong></td><td>- 支持集群模式<br>- 队列可以镜像到多个节点，保证高可用</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 的核心概念</p></li></ul><table><thead><tr><th>概念</th><th>含义</th><th>作用范围</th><th>类比</th></tr></thead><tbody><tr><td><strong>Broker</strong></td><td>一个 <strong>RabbitMQ 服务实例</strong>，包含整个 AMQP 服务、管理插件、队列、交换机等资源</td><td>运行在一台服务器上，或集群中的一个节点</td><td>类似于数据库的 <strong>实例</strong></td></tr><tr><td><strong>Vhost</strong></td><td>Broker 内部的 <strong>逻辑分区</strong>，用于隔离不同的队列、交换机、绑定等资源</td><td>一个 Broker 可以有多个 vhost，每个 vhost 彼此隔离</td><td>类似于数据库实例里的 <strong>schema</strong>，实际使用中建议为每个业务配置一个独立的 vhost，并为每个vhost单独配置一个管理用户</td></tr></tbody></table><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td><strong>Producer</strong></td><td>消息生产者，发送消息到 RabbitMQ</td></tr><tr><td><strong>Queue</strong></td><td>队列，存储消息的地方</td></tr><tr><td><strong>Consumer</strong></td><td>消息消费者，从队列获取消息</td></tr><tr><td><strong>Exchange</strong></td><td>交换机，接收 Producer 的消息并根据规则路由到队列</td></tr><tr><td><strong>Binding</strong></td><td>绑定，定义 Exchange 与 Queue 的路由规则</td></tr><tr><td><strong>Message</strong></td><td>消息，RabbitMQ 传递的数据单元</td></tr><tr><td><strong>Connection</strong></td><td>连接，客户端与 RabbitMQ Broker 之间的 <strong>TCP 连接</strong>，是通信的物理通道</td></tr><tr><td><strong>Channel</strong></td><td>通道，Connection 内部的 <strong>逻辑连接</strong>，轻量级且多路复用，一个连接可开多个通道</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                        ┌─ Broker (RabbitMQ 实例)──────────┐</span><br><span class="line">                        │                                 │</span><br><span class="line">                        │    ┌───── Virtual Host ─────┐   │</span><br><span class="line">        Producer ─── TCP ──────&gt; Exchange ──&gt; Queue ────────&gt; TCP ── Consumer</span><br><span class="line">(Connection ──&gt; Channel)│    └────────────────────────┘   │</span><br><span class="line">                        │                                 │</span><br><span class="line">                        └─────────────────────────────────┘</span><br></pre></td></tr></table></figure><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qgdFHL.png" alt=""></p><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 的典型应用场景</p></li></ul><table><thead><tr><th>应用场景</th><th>说明</th></tr></thead><tbody><tr><td><strong>异步处理</strong></td><td>用户请求不直接处理，消息入队后由后台异步消费，例如邮件发送、图片处理</td></tr><tr><td><strong>削峰填谷</strong></td><td>缓冲高峰流量，平滑系统压力</td></tr><tr><td><strong>系统解耦</strong></td><td>不同服务之间不直接调用，降低耦合</td></tr><tr><td><strong>广播/通知</strong></td><td>发布/订阅模式，实现多服务同时收到消息</td></tr><tr><td><strong>日志收集</strong></td><td>统一接收、分发日志到不同处理系统</td></tr></tbody></table><h2 id="RabbitMQ-4-0-有哪些升级">RabbitMQ 4.0+ 有哪些升级</h2><ul class="lvl-0"><li class="lvl-2"><p>特性标志（Feature Flags）的优化与强制性要求</p></li></ul><ul class="lvl-0"><li class="lvl-3"><p>在升级到 4.0 之前，用户必须先升级到 3.13.x 版本并手动启用所有稳定的特性标志。</p></li><li class="lvl-3"><p>从 4.0+ 开始，如果集群中的所有节点都支持某个必需的特性标志，系统会在节点启动时自动启用该标志，无需人工干预。</p></li></ul><ul class="lvl-0"><li class="lvl-2"><p>AMQP 协议的增强</p></li></ul><ul class="lvl-0"><li class="lvl-3"><p>新增了对 AMQP 过滤表达式（AMQP Filter Expressions）Version 1.0 Working Draft 09 的支持。</p></li></ul><ul class="lvl-0"><li class="lvl-2"><p>MQTT 协议的改进</p></li></ul><ul class="lvl-0"><li class="lvl-3"><p>默认的 MQTT 最大包大小从之前的 256 MiB 降低到 16 MiB，同时仍允许用户通过配置项 mqtt.max_packet_size_authenticated 自定义该值</p></li></ul><ul class="lvl-0"><li class="lvl-2"><p>Classic队列的变化</p></li></ul><ul class="lvl-0"><li class="lvl-3"><p>删除了对 Classic队列 <code>version1</code> 的支持，默认就是 <code>version2</code></p></li><li class="lvl-3"><p>不再支持 Classic队列 的镜像功能，官方推荐使用 Quorum 队列 ，未来会将 Quorum 队列 作为默认队列。</p></li></ul><ul class="lvl-0"><li class="lvl-2"><p>集群状态下创建 Quorum 队列 和 Stream 队列 会自动升级为 复制队列（镜像）</p></li></ul><h2 id="RabbitMQ-单机安装">RabbitMQ 单机安装</h2><h3 id="安装Erlang">安装Erlang</h3><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ是基于Erlang语言开发的，所以安装RabbitMQ之前需要安装Erlang语言环境。需要注意的是RabbitMQ与Erlang语言之间是有版本对应关系的。参考官方文档<a href="https://www.rabbitmq.com/docs/which-erlang">Erlang Version Requirements</a></p></li><li class="lvl-2"><p>目前RabbitMQ最新版本是<code>4.1.4</code>，Erlang版本可以选择 <code>27.x</code>，<a href="https://github.com/rabbitmq/erlang-rpm/releases">GitHub下载地址</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 el9 的版本，对应 CentOS 9</span></span><br><span class="line">wget https://github.com/rabbitmq/erlang-rpm/releases/download/v27.3.4.3/erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line"><span class="built_in">sudo</span> rpm -ivh erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class="line"><span class="comment"># 查看安装的版本</span></span><br><span class="line">erl</span><br><span class="line"><span class="comment"># 输出类似于，这里 Erlang/OTP 27 就表示安装的是 27.x 版本</span></span><br><span class="line">Erlang/OTP 27 [erts-15.2.7.2] [<span class="built_in">source</span>] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:1] [jit:ns]</span><br><span class="line"></span><br><span class="line">Eshell V15.2.7.2 (press Ctrl+G to abort, <span class="built_in">type</span> <span class="built_in">help</span>(). <span class="keyword">for</span> <span class="built_in">help</span>)</span><br><span class="line">1&gt; q().  <span class="comment"># 退出命令，注意是括号后面还有一个点。输入 help(). 显示帮助信息</span></span><br><span class="line">ok</span><br></pre></td></tr></table></figure><h3 id="安装-RabbitMQ">安装 RabbitMQ</h3><ul class="lvl-0"><li class="lvl-2"><p>目前RabbitMQ最新版本是<code>4.1.4</code>，<a href="https://github.com/rabbitmq/rabbitmq-server/releases">GitHub下载地址</a>]</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载，noarch 表示架构无关，即 X86_64 和 ARM64 都可以</span></span><br><span class="line"><span class="comment"># 因为没有对应的 el9 的包，所以只能用 el8 的包了，实际使用中没有问题。</span></span><br><span class="line">wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v4.1.4/rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line"><span class="built_in">sudo</span> rpm -ivh rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class="line"><span class="comment"># 查看版本信息</span></span><br><span class="line">rabbitmq-diagnostics version <span class="comment"># 无需启动服务</span></span><br><span class="line"><span class="comment"># RabbitMQ 服务启动后方可正确输出</span></span><br><span class="line">rabbitmqctl version</span><br></pre></td></tr></table></figure><h3 id="RabbitMQ-启动与停止命令">RabbitMQ 启动与停止命令</h3><ul class="lvl-0"><li class="lvl-2"><p>Erlang VM 是 Erlang 语言运行环境，RabbitMQ 应用运行在 Erlang VM 下。</p></li><li class="lvl-2"><p>启动 RabbitMQ 服务(Erlang VM) + 应用</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl start rabbitmq-server</span><br><span class="line"><span class="comment"># 或者，--detached 后台运行，不加就是前台运行</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmq-server -detached</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单独启动 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmqctl start_app</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>停止 RabbitMQ 服务(Erlang VM) + 应用</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停止 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl stop rabbitmq-server</span><br><span class="line"><span class="comment"># 或者，单机模式 stop，集群模式 shutdown</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmqctl stop / shutdown</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单独停止 RabbitMQ 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmqctl stop_app</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查看RabbitMQ 服务状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl status rabbitmq-server</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmqctl status</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 在 CentOS 9 (RPM 安装) 的目录结构</p></li></ul><table><thead><tr><th>类型</th><th>目录路径</th><th>说明</th></tr></thead><tbody><tr><td>配置文件</td><td><code>/etc/rabbitmq</code></td><td><code>rabbitmq.conf</code>、<code>advanced.config</code> 等配置</td></tr><tr><td>日志文件</td><td><code>/var/log/rabbitmq</code></td><td>RabbitMQ 运行日志，默认存放在这里</td></tr><tr><td>数据目录</td><td><code>/var/lib/rabbitmq/mnesia</code></td><td>消息队列、元数据存储目录</td></tr><tr><td>Erlang Cookie</td><td><code>/var/lib/rabbitmq/.erlang.cookie</code></td><td>Erlang 节点间通信的 cookie 文件</td></tr><tr><td>可执行文件</td><td><code>/usr/lib/rabbitmq/bin</code></td><td><code>rabbitmq-server</code>、<code>rabbitmqctl</code> 等命令</td></tr><tr><td>启动脚本</td><td><code>/usr/lib/systemd/system/rabbitmq-server.service</code></td><td>systemd 管理 RabbitMQ 的启动脚本</td></tr><tr><td>插件目录</td><td><code>/usr/lib/rabbitmq/lib/rabbitmq_server-&lt;version&gt;/plugins</code></td><td>所有插件文件存放路径</td></tr></tbody></table><h3 id="激活Web管理控制台插件">激活Web管理控制台插件</h3><ul class="lvl-0"><li class="lvl-2"><p>对于 RabbitMQ 所有的操作基本都可以通过命令行完成，但是使用起来并不方便，这时我们可以激活 <code>rabbitmq_management</code> 插件，该插件提供了 Web 管理控制台，我们可以通过 Web 管理控制台来管理 RabbitMQ</p></li><li class="lvl-2"><p><a href="https://www.rabbitmq.com/docs/management">rabbitmq_management</a> 插件为 官方插件，默认已经安装，不需要下载，直接激活即可</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 激活插件</span></span><br><span class="line"><span class="built_in">sudo</span> rabbitmq-plugins <span class="built_in">enable</span> rabbitmq_management</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>该插件除了提供了 <code>Web 管理控制台</code> ，还提供 <code>基于 HTTP 的 API</code> 用于管理和监控 RabbitMQ 节点和集群，以及 <code>命令行工具 rabbitmqadmin</code>，这个后面会介绍。</p></li></ul><h4 id="设置远程访问帐号">设置远程访问帐号</h4><ul class="lvl-0"><li class="lvl-2"><p>插件激活后可以通过浏览器访问 <code>http://&lt;ip&gt;:15672</code>，rabbitmq_management 插件默认用户名和密码都是 <code>guest</code>，但是默认情况下其只能通过 <code>127.0.0.1</code> 访问，此时我们有两种方法可以解决</p></li></ul><h5 id="1-允许-guest-账号远程访问">1. 允许 <code>guest</code> 账号远程访问</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改 /etc/rabbitmq/rabbitmq.conf 文件</span></span><br><span class="line"><span class="comment"># 允许guest用户远程访问，`官方不推荐` 一直开启，建议开启后在 web 控制台中创建一个管理员账号，然后立刻关闭该配置</span></span><br><span class="line">loopback_users.guest = <span class="literal">false</span></span><br><span class="line"><span class="comment"># 默认的用户名和密码，注意这里 user 如果改成 admin，则上面的开启远程访问中的 guest 也要改成 admin</span></span><br><span class="line">default_user = guest</span><br><span class="line">default_pass = guest</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改完成后，重启 RabbitMQ 服务</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart rabbitmq-server</span><br></pre></td></tr></table></figure><h5 id="2-新创建一个可以远程访问的管理员账号">2. 新创建一个可以远程访问的管理员账号</h5><ul class="lvl-0"><li class="lvl-2"><p>创建管理员账号，比如这里 用户名为 <code>admin</code>，密码为 <code>rabbitmq</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> rabbitmqctl add_user admin rabbitmq</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>给管理员账号添加资源管理权限</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> rabbitmqctl set_permissions -p / admin <span class="string">&quot;.*&quot;</span> <span class="string">&quot;.*&quot;</span> <span class="string">&quot;.*&quot;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>部分</th><th>解释</th></tr></thead><tbody><tr><td><code>rabbitmqctl</code></td><td>RabbitMQ 的命令行管理工具，用于管理用户、权限、队列、交换机等。</td></tr><tr><td><code>set_permissions</code></td><td>设置指定用户在某个虚拟主机（vhost）下的权限。</td></tr><tr><td><code>-p /</code></td><td>指定虚拟主机（vhost）。这里的 <code>/</code> 是默认虚拟主机。</td></tr><tr><td><code>admin</code></td><td>用户名，这里是为 <code>admin</code> 用户设置权限。</td></tr><tr><td><code>&quot;.*&quot;</code>（配置权限）</td><td>第一个正则表达式，控制用户对资源配置的权限，比如创建交换机、队列、绑定等。<code>&quot;.*&quot;</code> 表示全部允许。</td></tr><tr><td><code>&quot;.*&quot;</code>（写权限）</td><td>第二个正则表达式，控制用户向哪些资源发送消息。<code>&quot;.*&quot;</code> 表示全部允许。</td></tr><tr><td><code>&quot;.*&quot;</code>（读权限）</td><td>第三个正则表达式，控制用户从哪些资源消费消息。<code>&quot;.*&quot;</code> 表示全部允许。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>设置admin账号为控制台管理员</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> rabbitmqctl set_user_tags admin administrator</span><br></pre></td></tr></table></figure><table><thead><tr><th>部分</th><th>解释</th></tr></thead><tbody><tr><td><code>rabbitmqctl</code></td><td>RabbitMQ 的命令行管理工具。</td></tr><tr><td><code>set_user_tags</code></td><td>用来为用户设置标签（tag），标签决定了用户在管理界面或 API 中的权限级别。</td></tr><tr><td><code>admin</code></td><td>用户名，这里是为 <code>admin</code> 用户设置标签。</td></tr><tr><td><code>administrator</code></td><td>标签名，表示给该用户赋予管理员权限。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>常见的用户标签</p></li></ul><table><thead><tr><th>标签</th><th>说明</th></tr></thead><tbody><tr><td><code>administrator</code></td><td>管理员，拥有最高权限，可通过 Web 管理界面、CLI、API 管理 RabbitMQ 所有内容</td></tr><tr><td><code>monitoring</code></td><td>监控用户，可查看所有监控信息，但不能修改配置</td></tr><tr><td><code>management</code></td><td>普通管理用户，可以登录管理界面，但权限受限</td></tr><tr><td><code>policymaker</code></td><td>策略管理用户，可以管理策略和参数，但不能管理其他用户</td></tr><tr><td>无标签</td><td>普通用户，只能收发消息，不能登录管理界面</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p><code>set_permissions</code> 与 <code>set_user_tags</code> 总结对比</p></li></ul><table><thead><tr><th>命令</th><th>控制范围</th><th>主要作用</th></tr></thead><tbody><tr><td><code>set_permissions</code></td><td>vhost 内的资源</td><td>发消息、收消息、创建队列、交换机</td></tr><tr><td><code>set_user_tags</code></td><td>管理界面、管理 API</td><td>用户管理、策略管理、集群管理</td></tr></tbody></table><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4lP2cD.png" alt=""></p><h3 id="启用所有稳定的-Feature-Flags">启用所有稳定的 Feature Flags</h3><ul class="lvl-0"><li class="lvl-2"><p>登录控制台后我们会看到一条告警信息，参考：<a href="https://www.rabbitmq.com/docs/feature-flags">Feature Flags</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">⚠ All stable feature flags must be enabled after completing an upgrade.</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>它的意思是：RabbitMQ 在新版本中引入了一些 Feature Flags（特性标志），这些特性标志用于控制一些新的功能或行为是否启用。升级 RabbitMQ 后，有些功能会处于 <code>未启用状态</code>，需要你手动开启，确保集群完全运行在最新的功能模式下。</p></li><li class="lvl-2"><p>背景：为什么有 Feature Flags？</p><ul class="lvl-2"><li class="lvl-4">向后兼容：RabbitMQ 升级时，可能引入了新的数据格式或内部机制，如果立即启用，旧版本节点可能无法理解。</li><li class="lvl-4">滚动升级支持：升级集群时，可以先升级节点，再统一启用功能，避免中途出问题。</li><li class="lvl-4">可控性：你可以选择在确认集群稳定后再启用新功能。</li></ul></li><li class="lvl-2"><p>查看当前 Feature Flags 状态</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqctl -q --formatter pretty_table list_feature_flags</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出会类似这样：</span></span><br><span class="line">┌──────────────────────────────────────┬──────────┐</span><br><span class="line">│ name                                 │ state    │</span><br><span class="line">├──────────────────────────────────────┼──────────┤</span><br><span class="line">│ classic_mirrored_queue_version       │ enabled  │</span><br><span class="line">├──────────────────────────────────────┼──────────┤</span><br><span class="line">│ classic_queue_type_delivery_support  │ enabled  │</span><br><span class="line">├──────────────────────────────────────┼──────────┤</span><br><span class="line">│ detailed_queues_endpoint             │ disabled │</span><br><span class="line">├──────────────────────────────────────┼──────────┤</span><br><span class="line">│ direct_exchange_routing_v2           │ enabled  │</span><br><span class="line">├──────────────────────────────────────┼──────────┤</span><br><span class="line"></span><br><span class="line">&gt; enabled：特性已启用</span><br><span class="line">&gt; disabled：特性未启用</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>可以输出 其它 格式，显示更详细的信息</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json</span></span><br><span class="line">rabbitmqctl -q --formatter json list_feature_flags name state provided_by desc doc_url | jq</span><br><span class="line"><span class="comment"># table</span></span><br><span class="line">rabbitmqctl -q --formatter pretty_table list_feature_flags name state provided_by desc doc_url</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启用所有已标记为 stable 的特性，建议升级下一个 RabbitMQ 版本 前一定要确保当前版本的 Feature Flags 都是启用的，避免升级后无法顺利启动服务。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqctl enable_feature_flag all</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>在控制台中也可以查看和开启这些 Feature Flags 的状态<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/VqNm1y.png" alt=""></p></li><li class="lvl-2"><p>这里要注意，<strong>Feature Flags 一旦开启就无法关闭。</strong></p></li></ul><h2 id="RabbitMQ-配置文件">RabbitMQ 配置文件</h2><ul class="lvl-0"><li class="lvl-2"><p>对于 RPM/YUM/DNF 安装的 RabbitMQ，配置文件默认路径是</p></li></ul><table><thead><tr><th>文件类型</th><th>默认位置</th><th>作用</th></tr></thead><tbody><tr><td>主配置文件（推荐）</td><td><code>/etc/rabbitmq/rabbitmq.conf</code></td><td>使用 <strong>INI 格式</strong>，主要配置都在这里</td></tr><tr><td>环境变量配置</td><td><code>/etc/rabbitmq/rabbitmq-env.conf</code></td><td>定义节点名、Cookie 位置、数据/日志目录等</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>安装后 <code>/etc/rabbitmq/</code> 目录可能是空的，你需要手动创建 <code>rabbitmq.conf</code>，详细的参数说明可以参看<a href="https://rabbitmq.com/configure.html">官网指南</a>，<a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbit/docs/rabbitmq.conf.example">rabbitmq.conf 示例</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/rabbitmq/rabbitmq.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 监听端口</span></span><br><span class="line">listeners.tcp.default = 5672</span><br><span class="line"><span class="comment"># 管理界面端口</span></span><br><span class="line">management.tcp.port = 15672</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmq-env.conf</code> 用来 定义节点名、Cookie 、数据/日志目录等的环境变量，RabbitMQ 启动时会自动读取该文件，以下是通过 RPM 安装的 RabbitMQ 的默认值</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/rabbitmq/rabbitmq-env.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点名称，默认使用主机短名(hostname -s)，例如 rabbit@myhost</span></span><br><span class="line">NODENAME=rabbit@&lt;hostname&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绑定的 IP 地址，留空表示监听所有地址，等价于 0.0.0.0</span></span><br><span class="line">NODE_IP_ADDRESS=</span><br><span class="line"></span><br><span class="line"><span class="comment"># AMQP 协议端口，默认 5672</span></span><br><span class="line">NODE_PORT=5672</span><br><span class="line"></span><br><span class="line"><span class="comment"># RabbitMQ 数据库存储目录</span></span><br><span class="line">MNESIA_BASE=/var/lib/rabbitmq/mnesia</span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志存放目录</span></span><br><span class="line">LOG_BASE=/var/log/rabbitmq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置文件路径，不带 .conf 后缀</span></span><br><span class="line">CONFIG_FILE=/etc/rabbitmq/rabbitmq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否使用长主机名，true/false (长主机名 hostname -f)</span></span><br><span class="line">USE_LONGNAME=<span class="literal">false</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>两个文件的作用</p></li></ul><table><thead><tr><th>文件</th><th>作用范围</th><th>典型参数</th><th>何时加载</th></tr></thead><tbody><tr><td><strong>rabbitmq-env.conf</strong></td><td>设置 RabbitMQ 启动时的 <strong>环境变量</strong></td><td>NODENAME, NODE_IP_ADDRESS, NODE_PORT, LOG_BASE, MNESIA_BASE</td><td>在启动 RabbitMQ 服务前由 <code>rabbitmq-env</code> 脚本读取</td></tr><tr><td><strong>rabbitmq.conf</strong></td><td>RabbitMQ <strong>运行时配置</strong>（内部参数、插件配置等）</td><td>listeners.tcp.default, log, cluster_formation 等</td><td>RabbitMQ 启动后由 Erlang VM 内部读取</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-4"><p><code>rabbitmq-env.conf</code> 决定 RabbitMQ 启动时的基本环境，比如节点名、数据目录、监听 IP 等，必须在启动前就确定。</p></li><li class="lvl-4"><p><code>rabbitmq.conf</code> 决定运行时的功能，比如端口监听、日志等级、集群配置等，可以动态修改，重启应用后生效。</p></li></ul><table><thead><tr><th><code>rabbitmq-env.conf</code> 变量</th><th><code>rabbitmq.conf</code> 对应配置</th><th>优先级</th><th>说明</th></tr></thead><tbody><tr><td>NODE_IP_ADDRESS</td><td><code>listeners.tcp.default = &lt;IP&gt;</code></td><td><code>rabbitmq.conf</code></td><td>只要在 <code>rabbitmq.conf</code> 里配置，就覆盖环境变量</td></tr><tr><td>NODE_PORT</td><td><code>listeners.tcp.default = &lt;Port&gt;</code></td><td><code>rabbitmq.conf</code></td><td>同上，IP 和端口可以一起配置</td></tr><tr><td>NODENAME</td><td><strong>无直接对应</strong></td><td><code>rabbitmq-env.conf</code></td><td>节点名只能通过 <code>rabbitmq-env.conf</code> 或环境变量设定</td></tr><tr><td>MNESIA_BASE</td><td><strong>无直接对应</strong></td><td><code>rabbitmq-env.conf</code></td><td>数据目录只能在启动前设定</td></tr><tr><td>LOG_BASE</td><td><code>log.dir = &lt;path&gt;</code></td><td><code>rabbitmq.conf</code></td><td>运行时配置覆盖环境变量</td></tr><tr><td>CONFIG_FILE</td><td><strong>无直接对应</strong></td><td><code>rabbitmq-env.conf</code></td><td>这个只决定加载哪个 <code>rabbitmq.conf</code> 文件</td></tr><tr><td>USE_LONGNAME</td><td><strong>无直接对应</strong></td><td><code>rabbitmq-env.conf</code></td><td>节点名是否使用长主机名只能启动前决定</td></tr></tbody></table><h2 id="RabbitMQ-环境变量">RabbitMQ 环境变量</h2><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmq-env.conf</code> 文件就是用来定义环境变量的，但要注意，<code>rabbitmq-env.conf</code> 文件中定义的变量 去掉了 <code>RABBITMQ_</code> 前缀，例如在环境中设置的变量名通常是 <code>RABBITMQ_NODENAME</code>，但在 <code>rabbitmq-env.conf</code> 中，设置变量时会去掉 <code>RABBITMQ_</code> 前缀，直接使用 <code>NODENAME</code>。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 rabbitmq-env.conf 中配置</span></span><br><span class="line">NODENAME=rabbit@localhost</span><br><span class="line">NODE_PORT=5672</span><br><span class="line">LOG_BASE=/var/log/rabbitmq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 而在环境中，你实际设置的变量是</span></span><br><span class="line"><span class="built_in">export</span> RABBITMQ_NODENAME=rabbit@localhost</span><br><span class="line"><span class="built_in">export</span> RABBITMQ_NODE_PORT=5672</span><br><span class="line"><span class="built_in">export</span> RABBITMQ_LOG_BASE=/var/log/rabbitmq</span><br></pre></td></tr></table></figure><table><thead><tr><th>环境变量名称</th><th>描述</th><th>Linux RPM 安装的默认值</th></tr></thead><tbody><tr><td><strong>RABBITMQ_BASE</strong></td><td>只针对 Windows 系统。该基目录包含 RabbitMQ 服务器的数据库和日志文件的子目录。</td><td>无（仅适用于 Windows）</td></tr><tr><td><strong>RABBITMQ_CONFIG_FILE</strong></td><td>配置文件的路径，没有 <code>.config</code> 扩展名。RabbitMQ 服务器使用该配置文件来配置组件。</td><td>默认配置文件路径：<code>/etc/rabbitmq/rabbitmq.conf</code></td></tr><tr><td><strong>RABBITMQ_GENERATED_CONFIG_DIR</strong></td><td>RabbitMQ 写入其生成的配置文件的目录。</td><td>默认生成路径：<code>/var/lib/rabbitmq/mnesia</code></td></tr><tr><td><strong>RABBITMQ_MNESIA_BASE</strong></td><td>RabbitMQ 服务器节点数据库、消息存储和集群状态文件的基目录，每个节点一个。通常会覆盖 <code>RABBITMQ_MNESIA_DIR</code>。</td><td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td></tr><tr><td><strong>RABBITMQ_MNESIA_DIR</strong></td><td>存储 RabbitMQ 节点数据的目录，包含模式数据库、消息存储、集群成员信息和其他持久节点状态。</td><td>默认值：<code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></td></tr><tr><td><strong>RABBITMQ_SCHEMA_DIR</strong></td><td>RabbitMQ 保存新格式配置文件使用的配置模式的目录。</td><td>默认值：<code>/etc/rabbitmq</code></td></tr><tr><td><strong>RABBITMQ_LOG_BASE</strong></td><td>该基目录包含 RabbitMQ 服务器的日志文件。</td><td>默认值：<code>/var/log/rabbitmq</code></td></tr><tr><td><strong>RABBITMQ_LOGS</strong></td><td>RabbitMQ 服务器的 Erlang 日志文件的路径。</td><td>默认值：<code>/var/log/rabbitmq/rabbitmq.log</code></td></tr><tr><td><strong>RABBITMQ_PLUGINS_DIR</strong></td><td>RabbitMQ 的插件目录。路径由特定操作系统的分隔符定义（Unix 使用 <code>:</code>，Windows 使用 <code>;</code>）。</td><td>默认值：<code>/usr/lib/rabbitmq/plugins</code></td></tr><tr><td><strong>RABBITMQ_PLUGINS_EXPAND_DIR</strong></td><td>用于展开启用的插件的工作目录。确保有效的 RabbitMQ 用户有足够权限读取和创建该目录中的文件。</td><td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td></tr><tr><td><strong>RABBITMQ_ENABLED_PLUGINS_FILE</strong></td><td>显式记录启用的插件的文件，启用或禁用插件时会重新创建该文件。确保有效的 RabbitMQ 用户有足够权限随时读取、写入和创建该文件。</td><td>默认值：<code>/var/lib/rabbitmq/.enabled_plugins</code></td></tr><tr><td><strong>RABBITMQ_PID_FILE</strong></td><td>用于 <code>rabbitmqctl</code> 的进程 ID 文件。</td><td>默认值：<code>/var/run/rabbitmq/rabbitmq.pid</code></td></tr></tbody></table><div class="warning"><p><em><strong>小贴士</strong></em></p><ul class="lvl-1"><li class="lvl-2">安装好 RabbitMQ 后，不要随便修改 <code>hostname</code>，因为默认情况下，RabbitMQ 的数据目录是基于 <code>hostname</code> 创建的，如果修改了 <code>hostname</code>，RabbitMQ 就会指向新的数据目录</li><li class="lvl-2">数据目录默认是 <code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></li><li class="lvl-2">如果修改了 <code>hostname</code>，但仍要使用原来的数据目录，可以设置 <code>RABBITMQ_MNESIA_DIR</code> 环境变量，指向原来的数据目录</li></ul></div><h2 id="RabbitMQ-相关命令">RabbitMQ 相关命令</h2><ul class="lvl-0"><li class="lvl-2"><p>日常使用中，基本都是通过 Web 管理界面操作，这里仅对命令进行简要介绍。</p></li></ul><table><thead><tr><th>命令</th><th>作用（简要）</th><th>常用示例（典型用法 + 中文说明）</th></tr></thead><tbody><tr><td><code>rabbitmq-defaults</code></td><td>定义/显示 RabbitMQ 安装默认目录和运行时前缀</td><td><code>编辑 sbin/rabbitmq-defaults 中 PREFIX/SYS_PREFIX</code>（修改默认目录到系统目录）</td></tr><tr><td><code>rabbitmq-diagnostics</code></td><td>健康检查 / 诊断工具，可用于监控</td><td><code>rabbitmq-diagnostics -q ping</code>（检查节点是否可达）<br><code>rabbitmq-diagnostics -q status</code>（查看节点状态）<br><code>rabbitmq-diagnostics -q check_running</code>（确认节点运行中）</td></tr><tr><td><code>rabbitmq-env</code></td><td><code>rabbitmq-env</code> 其实不是一个直接在命令行里单独使用的工具，而是 RabbitMQ 服务启动脚本 中用来加载 RabbitMQ 环境变量的脚本。</td><td>在 <code>/etc/rabbitmq/rabbitmq-env.conf</code> 中设置：<br><code>RABBITMQ_NODENAME=myrabbit</code>（设置节点名）<br>或用 <code>rabbitmq-env</code> 输出查看实际环境</td></tr><tr><td><code>rabbitmq-plugins</code></td><td>插件管理：列出/启用/禁用插件</td><td><code>rabbitmq-plugins list</code>（列出所有插件）<br><code>rabbitmq-plugins enable rabbitmq_management</code>（启用 Web 管理插件）<br><code>rabbitmq-plugins disable --offline plugin</code>（离线禁用插件）</td></tr><tr><td><code>rabbitmq-queues</code></td><td>队列副本管理：rebalance/grow/shrink</td><td><code>rabbitmq-queues rebalance all --vhost-pattern &quot;.*&quot; --queue-pattern &quot;.*&quot;</code>（重平衡所有队列副本）<br><code>rabbitmq-queues add_member --vhost / qname rabbit@node</code>（为队列增加节点副本）</td></tr><tr><td><code>rabbitmq-server</code></td><td>启动 RabbitMQ 节点（前台/后台）</td><td><code>rabbitmq-server</code>（前台启动）<br><code>rabbitmq-server -detached</code>（后台启动）</td></tr><tr><td><code>rabbitmq-upgrade</code></td><td>升级相关操作：drain/恢复等</td><td><code>rabbitmq-upgrade drain</code>（让节点进入维护模式，停止接收新连接）<br><code>rabbitmq-upgrade post_upgrade</code>（执行升级后收尾操作）<br><code>rabbitmq-upgrade revive</code>（恢复维护模式中的节点）</td></tr><tr><td><code>rabbitmqctl</code></td><td>最常用管理命令：用户、队列、集群管理</td><td><code>rabbitmqctl status</code>（查看节点状态）<br><code>rabbitmqctl list_queues</code>（列出所有队列）<br><code>rabbitmqctl add_user bob s3cr3t</code>（添加用户 bob，密码 s3cr3t）</td></tr><tr><td><code>rabbitmq-streams</code></td><td>管理 Streams（流式队列）</td><td><code>rabbitmq-streams stream_status --vhost / my-stream</code>（查看 my-stream 状态）<br><code>rabbitmq-streams add_replica --vhost / my-stream rabbit@node</code>（为 my-stream 增加副本节点）</td></tr></tbody></table><h3 id="最常用的命令-rabbitmqctl">最常用的命令 <code>rabbitmqctl</code></h3><h4 id="命令自动补全">命令自动补全</h4><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmqctl</code> 有一个 <code>autocomplete</code> 参数，可以自动完成命令参数，我们可以利用这个命令来实现命令自动补全</p></li><li class="lvl-2"><p><code>vim ~/.bashrc</code> 添加如下内容：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">_rabbitmqctl_completion</span></span>() &#123;</span><br><span class="line">    <span class="built_in">local</span> cur opts</span><br><span class="line">    cur=<span class="string">&quot;<span class="variable">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span>           <span class="comment"># 当前光标所在单词</span></span><br><span class="line">    opts=$(rabbitmqctl autocomplete <span class="string">&quot;<span class="variable">$cur</span>&quot;</span>)   <span class="comment"># 只传当前单词作为前缀</span></span><br><span class="line">    COMPREPLY=( $(compgen -W <span class="string">&quot;<span class="variable">$&#123;opts&#125;</span>&quot;</span> -- <span class="string">&quot;<span class="variable">$cur</span>&quot;</span>) )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">complete -F _rabbitmqctl_completion rabbitmqctl</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>实际上 RabbitMQ 的大部分命令都有 <code>autocomplete</code> 参数，都可以自动完成命令参数</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义通用补全函数</span></span><br><span class="line"><span class="function"><span class="title">_rabbitmq_completion</span></span>() &#123;</span><br><span class="line">    <span class="built_in">local</span> cur opts</span><br><span class="line">    cur=<span class="string">&quot;<span class="variable">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># 当前命令名，自动判断</span></span><br><span class="line">    <span class="built_in">local</span> cmd=<span class="string">&quot;<span class="variable">$&#123;COMP_WORDS[0]&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># 给对应命令传当前前缀</span></span><br><span class="line">    opts=$(<span class="variable">$cmd</span> autocomplete <span class="string">&quot;<span class="variable">$cur</span>&quot;</span> 2&gt;/dev/null)</span><br><span class="line">    COMPREPLY=( $(compgen -W <span class="string">&quot;<span class="variable">$&#123;opts&#125;</span>&quot;</span> -- <span class="string">&quot;<span class="variable">$cur</span>&quot;</span>) )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一次性绑定多个命令</span></span><br><span class="line">complete -F _rabbitmq_completion rabbitmqctl rabbitmq-plugins rabbitmq-diagnostics rabbitmq-queues rabbitmq-upgrade</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>测试</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使补全生效</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="comment"># tab 补全</span></span><br><span class="line">rabbitmqctl st&lt;TAB&gt;</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">start_app  status     stop       stop_app</span><br></pre></td></tr></table></figure><h4 id="常用命令参数">常用命令参数</h4><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmqctl help</code> 获取所有命令参数的简介</p></li><li class="lvl-2"><p><code>rabbitmqctl help &lt;command&gt;</code> 获取指定命令的帮助</p></li><li class="lvl-2"><p>日常使用中基本都是通过 <code>web 控制台</code> 完成，这里只做了解。</p></li></ul><h5 id="1-节点管理">1.节点管理</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>status</code></td><td>查看节点状态，包括运行状态、版本、内存、队列数量等</td><td><code>rabbitmqctl status</code></td></tr><tr><td><code>stop</code></td><td>停止 RabbitMQ 节点</td><td><code>rabbitmqctl stop</code></td></tr><tr><td><code>stop_app</code></td><td>停止 RabbitMQ 应用（保留节点运行）</td><td><code>rabbitmqctl stop_app</code></td></tr><tr><td><code>start_app</code></td><td>启动 RabbitMQ 应用</td><td><code>rabbitmqctl start_app</code></td></tr><tr><td><code>reset</code></td><td>重置 RabbitMQ 节点，删除所有队列和数据（慎用）</td><td><code>rabbitmqctl reset</code></td></tr><tr><td><code>force_reset</code></td><td>强制重置节点（即使在集群中也会重置）</td><td><code>rabbitmqctl force_reset</code></td></tr></tbody></table><h5 id="2-用户和权限管理">2. 用户和权限管理</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>list_users</code></td><td>列出所有用户</td><td><code>rabbitmqctl list_users</code></td></tr><tr><td><code>add_user &lt;user&gt; &lt;password&gt;</code></td><td>添加新用户</td><td><code>rabbitmqctl add_user alice mypassword</code></td></tr><tr><td><code>delete_user &lt;user&gt;</code></td><td>删除用户</td><td><code>rabbitmqctl delete_user alice</code></td></tr><tr><td><code>change_password &lt;user&gt; &lt;password&gt;</code></td><td>修改用户密码</td><td><code>rabbitmqctl change_password alice newpass</code></td></tr><tr><td><code>list_permissions &lt;user&gt;</code></td><td>查看某用户的权限</td><td><code>rabbitmqctl list_permissions alice</code></td></tr><tr><td><code>set_permissions -p &lt;vhost&gt; &lt;user&gt; &quot;&lt;conf&gt;&quot; &quot;&lt;write&gt;&quot; &quot;&lt;read&gt;&quot;</code></td><td>设置用户在虚拟主机的权限</td><td><code>rabbitmqctl set_permissions -p / alice &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</code></td></tr></tbody></table><h5 id="3-虚拟主机（vhost）管理">3. 虚拟主机（vhost）管理</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>list_vhosts</code></td><td>列出所有虚拟主机</td><td><code>rabbitmqctl list_vhosts</code></td></tr><tr><td><code>add_vhost &lt;vhost&gt;</code></td><td>添加虚拟主机</td><td><code>rabbitmqctl add_vhost my_vhost</code></td></tr><tr><td><code>delete_vhost &lt;vhost&gt;</code></td><td>删除虚拟主机</td><td><code>rabbitmqctl delete_vhost my_vhost</code></td></tr></tbody></table><h5 id="4-队列管理">4. 队列管理</h5><ul class="lvl-0"><li class="lvl-2"><p>队列可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看和删除队列</p></li></ul><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>list_queues</code></td><td>列出队列</td><td><code>rabbitmqctl list_queues</code></td></tr><tr><td><code>list_queues name messages consumers</code></td><td>列出队列及消息数、消费者数</td><td><code>rabbitmqctl list_queues name messages consumers</code></td></tr><tr><td><code>purge_queue &lt;queue&gt;</code></td><td>清空队列消息</td><td><code>rabbitmqctl purge_queue my_queue</code></td></tr><tr><td><code>delete_queue &lt;queue&gt;</code></td><td>删除队列</td><td><code>rabbitmqctl delete_queue my_queue</code></td></tr></tbody></table><h5 id="5-交换机和绑定">5. 交换机和绑定</h5><ul class="lvl-0"><li class="lvl-2"><p>交换机可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看</p></li></ul><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>list_exchanges</code></td><td>列出交换机</td><td><code>rabbitmqctl list_exchanges</code></td></tr><tr><td><code>list_bindings</code></td><td>列出绑定关系</td><td><code>rabbitmqctl list_bindings</code></td></tr></tbody></table><h5 id="6-集群管理">6. 集群管理</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>cluster_status</code></td><td>查看集群状态</td><td><code>rabbitmqctl cluster_status</code></td></tr><tr><td><code>join_cluster &lt;node&gt;</code></td><td>节点加入集群</td><td><code>rabbitmqctl join_cluster rabbit@node1</code></td></tr><tr><td><code>forget_cluster_node &lt;node&gt;</code></td><td>将节点从集群中移除</td><td><code>rabbitmqctl forget_cluster_node rabbit@node2</code></td></tr></tbody></table><h5 id="7-日志和调试">7. 日志和调试</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>report</code></td><td>输出节点诊断报告</td><td><code>rabbitmqctl report</code></td></tr><tr><td><code>eval &lt;expression&gt;</code></td><td>执行 Erlang 表达式</td><td><code>rabbitmqctl eval 'rabbit_mnesia:info().'</code></td></tr></tbody></table><h5 id="8-其他命令">8. 其他命令</h5><table><thead><tr><th>命令</th><th>功能</th><th>示例</th></tr></thead><tbody><tr><td><code>help</code></td><td>查看帮助命令</td><td><code>rabbitmqctl help</code></td></tr><tr><td><code>version</code></td><td>查看 RabbitMQ 版本</td><td><code>rabbitmqctl version</code></td></tr><tr><td><code>authenticate_user &lt;user&gt; &lt;password&gt;</code></td><td>验证用户密码</td><td><code>rabbitmqctl authenticate_user alice mypassword</code></td></tr></tbody></table><h2 id="RabbitMQ-HTTP-API">RabbitMQ HTTP API</h2><ul class="lvl-0"><li class="lvl-2"><p>RabbitMQ 的 HTTP API 是一个 基于 REST 的管理接口，主要用于对 RabbitMQ 的 资源管理和监控，它是 管理插件 <code>rabbitmq_management</code> 提供的功能。通过 HTTP API，你可以不用 <code>rabbitmqctl</code> 就能操作 RabbitMQ。</p></li><li class="lvl-2"><p>要使用 HTTP API，你需要在 RabbitMQ 节点上确保 <code>rabbitmq_management</code> 插件已经启动。前面我们介绍<code>web 管理控制台</code>时已经启动了该插件，所以你可以直接使用。</p></li><li class="lvl-2"><p>实际上 <code>Web管理控制台</code> 就是通过发送 AJAX 请求到 <code>/api/…</code> 接口来获取数据和执行操作。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/980Wwu.png" alt=""></p></li><li class="lvl-2"><p>这里有 HTTP API 的详细说明，本文不再赘述。</p></li></ul><h2 id="rabbitmqadmin">rabbitmqadmin</h2><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmqadmin</code> 是 管理插件 <code>rabbitmq_management</code> 提供的命令行工具，用于管理 RabbitMQ 的资源，如创建队列、交换机、绑定关系、查看队列、交换机、绑定关系等。</p></li><li class="lvl-2"><p><code>rabbitmqadmin</code> 是一个使用 <code>HTTP API</code> 的命令行工具，所以底层实际上是调用了 <code>HTTP API</code> 。</p></li><li class="lvl-2"><p><a href="https://github.com/rabbitmq/rabbitmqadmin-ng/releases">下载地址</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line"><span class="built_in">sudo</span> wget -O /usr/local/bin/rabbitmqadmin https://github.com/rabbitmq/rabbitmqadmin-ng/releases/download/v2.10.0/rabbitmqadmin-2.10.0-x86_64-unknown-linux-gnu</span><br><span class="line"><span class="comment"># 设置权限</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> +x /usr/local/bin/rabbitmqadmin</span><br><span class="line"><span class="comment"># 查看帮助</span></span><br><span class="line">rabbitmqadmin <span class="built_in">help</span></span><br><span class="line"><span class="comment"># 查看子命令帮助</span></span><br><span class="line">rabbitmqadmin <span class="built_in">help</span> &lt;<span class="built_in">command</span>&gt;</span><br><span class="line"><span class="comment">## 示例</span></span><br><span class="line"><span class="comment"># 查看 队列 帮助</span></span><br><span class="line">rabbitmqadmin <span class="built_in">help</span> queues</span><br><span class="line"><span class="comment"># 查看 队列声明 帮助，子子命令</span></span><br><span class="line">rabbitmqadmin <span class="built_in">help</span> queues <span class="built_in">declare</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p><code>rabbitmqadmin</code> 的功能非常强大，但是因为<code>HTTP API</code>故意没有公开某些操作，所以其不能替代 <code>rabbitmqctl</code> 或 <code>rabbitmq-plugins</code>等命令。</p></li><li class="lvl-2"><p>因为实际使用中很少直接通过命令行，所以这里只做简单介绍。上文提到了 <code>rabbitmqctl</code> 不支持声明(创建) 交换机和队列，这个通过 <code>rabbitmqadmin</code> 实现</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟主机</span></span><br><span class="line">rabbitmqadmin vhosts <span class="built_in">declare</span> --name <span class="string">&quot;my-vhost&quot;</span> --default-queue-type <span class="string">&quot;quorum&quot;</span> --description <span class="string">&quot;Used to test&quot;</span></span><br><span class="line"><span class="comment"># 声明队列</span></span><br><span class="line">rabbitmqadmin queues <span class="built_in">declare</span> --vhost <span class="string">&quot;my-vhost&quot;</span> --name <span class="string">&quot;target.classic.queue.name&quot;</span> --<span class="built_in">type</span> <span class="string">&quot;classic&quot;</span> --durable <span class="literal">true</span> --auto-delete <span class="literal">false</span></span><br><span class="line"><span class="comment"># 声明交换机</span></span><br><span class="line">rabbitmqadmin exchanges <span class="built_in">declare</span> --vhost <span class="string">&quot;my-vhost&quot;</span> --name <span class="string">&quot;target.direct.exchange.name&quot;</span> --<span class="built_in">type</span> <span class="string">&quot;direct&quot;</span> --durable <span class="literal">true</span> --auto-delete <span class="literal">false</span></span><br><span class="line"><span class="comment"># 绑定队列和交换机</span></span><br><span class="line">rabbitmqadmin bindings <span class="built_in">declare</span> --vhost <span class="string">&quot;my-vhost&quot;</span> --<span class="built_in">source</span> <span class="string">&quot;target.direct.exchange.name&quot;</span> --destination <span class="string">&quot;target.classic.queue.name&quot;</span> --destination-type <span class="string">&quot;queue&quot;</span> --routing-key <span class="string">&quot;target.routing.key&quot;</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>还有就是定期备份 RabbitMQ 的结构数据(不包括消息)</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导出</span></span><br><span class="line">abbitmqadmin definitions <span class="built_in">export</span> --file backup.json</span><br><span class="line"><span class="comment"># 导入</span></span><br><span class="line">rabbitmqadmin definitions import --file backup.json</span><br></pre></td></tr></table></figure><h2 id="RabbitMQ-需要开放哪些端口">RabbitMQ 需要开放哪些端口</h2><table><thead><tr><th>端口号</th><th>协议</th><th>用途说明</th><th>默认状态</th><th>安全建议</th></tr></thead><tbody><tr><td>5672</td><td>AMQP</td><td>主客户端连接端口</td><td>开放</td><td>必须开放，限制IP</td></tr><tr><td>5671</td><td>AMQP/SSL</td><td>TLS加密连接端口</td><td>关闭</td><td>如使用TLS则开放</td></tr><tr><td>15672</td><td>HTTP</td><td>管理界面端口</td><td>关闭</td><td>建议内网访问</td></tr><tr><td>15671</td><td>HTTPS</td><td>TLS管理界面端口</td><td>关闭</td><td>如使用HTTPS则开放</td></tr><tr><td>25672</td><td>Erlang Distribution</td><td>集群节点通信</td><td>开放</td><td>集群内部使用</td></tr><tr><td>35672-35682</td><td>Erlang Distribution</td><td>集群节点发现</td><td>开放</td><td>集群内部使用</td></tr><tr><td>5552</td><td>Stream Protocol</td><td>流协议端口,RabbitMQ 3.9+</td><td>关闭</td><td>使用流功能时开放</td></tr><tr><td>5551</td><td>Stream Protocol/SSL</td><td>流协议TLS端口,RabbitMQ 3.9+</td><td>关闭</td><td>如使用TLS则开放</td></tr><tr><td>61613</td><td>STOMP</td><td>STOMP协议支持端口</td><td>关闭</td><td>如使用STOMP协议则开放</td></tr><tr><td>61614</td><td>STOMP/SSL</td><td>STOMP TLS加密端口</td><td>关闭</td><td>如使用STOMP over TLS则开放</td></tr><tr><td>1883</td><td>MQTT</td><td>MQTT协议支持端口</td><td>关闭</td><td>如使用MQTT协议则开放</td></tr><tr><td>8883</td><td>MQTT/SSL</td><td>MQTT TLS加密端口</td><td>关闭</td><td>如使用MQTT over TLS则开放</td></tr><tr><td>15674</td><td>Web STOMP</td><td>WebSocket STOMP支持端口</td><td>关闭</td><td>如使用Web STOMP则开放</td></tr><tr><td>15675</td><td>Web MQTT</td><td>WebSocket MQTT支持端口</td><td>关闭</td><td>如使用Web MQTT则开放</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 RabbitMQ 的安装与使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 RabbitMQ 版本为 4.1.4。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo&quot;&gt;Java Client 示例&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/rabbitmq/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="rabbitmq" scheme="https://blog.hanqunfeng.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper 的安装及使用</title>
    <link href="https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/"/>
    <id>https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/</id>
    <published>2025-09-15T13:30:05.000Z</published>
    <updated>2025-10-11T06:39:24.904Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 CentOS9 中 Zookeeper 的安装与使用。</p></li><li class="lvl-2"><p><a href="https://zookeeper.apache.org">Zookeeper官网</a></p></li><li class="lvl-2"><p>本文使用的 Zookeeper 版本为 3.8.4。</p></li></ul><span id="more"></span><h2 id="Zookeeper-简介">Zookeeper 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper 是一个集中式服务，用于：</p></li></ul><table><thead><tr><th>场景</th><th>ZooKeeper 官方功能</th><th>主要节点类型</th><th>具体场景示例</th></tr></thead><tbody><tr><td>配置中心 (Config Center)</td><td>维护配置信息 (Configuration Management)</td><td>持久节点（Persistent）</td><td>把数据库连接信息、系统参数等放在 ZooKeeper 里，动态更新，像 Apollo、Spring Cloud Config 一样。</td></tr><tr><td>注册中心 (Service Registry)</td><td>提供命名服务 (Naming Service)</td><td>临时节点（Ephemeral）</td><td>服务实例启动时在 ZooKeeper 里注册自己的地址，客户端从 ZooKeeper 获取服务列表，类似于 Nacos、Eureka。</td></tr><tr><td>分布式锁 (Distributed Lock)</td><td>分布式同步 (Distributed Synchronization)</td><td>临时顺序节点（Ephemeral Sequential）</td><td>用临时顺序节点实现分布式锁，保证只有一个实例在执行关键任务，典型应用是分布式定时任务调度。</td></tr><tr><td>消息队列 (Message Queue)</td><td>集群管理服务 (Cluster Management)</td><td>持久/临时节点 + Watch 机制</td><td>通过 Watch 机制监听 ZNode 变化，节点间用数据变更当“信号”传递消息，早期 Kafka 用过这种方式。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。</p></li><li class="lvl-2"><p>不同于文件系统，每个节点都可以保存数据，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识，每个节点都有一个版本(version)，版本从0开始计数。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QgdBSR.png" alt=""></p></li></ul><h2 id="Zookeeper-安装">Zookeeper 安装</h2><ul class="lvl-0"><li class="lvl-2"><p>运行 Zookeeper 需要安装 JDK1.8+。我这里使用 <a href="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/">OpenJDK11</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /usr/local/jdk</span><br><span class="line"><span class="built_in">cd</span> /usr/local/jdk</span><br><span class="line"><span class="built_in">sudo</span> wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class="line"><span class="built_in">sudo</span> tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s jdk-11.0.28+6 jdk11</span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">vim /etc/profile <span class="comment"># 添加如下内容</span></span><br><span class="line">  <span class="built_in">export</span> JAVA_HOME=/usr/local/jdk/jdk11</span><br><span class="line">  <span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># 立即生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># 查看java版本</span></span><br><span class="line">java -version</span><br><span class="line">openjdk version <span class="string">&quot;11.0.28&quot;</span> 2025-07-15</span><br><span class="line">OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)</span><br><span class="line">OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="单机安装">单机安装</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://zookeeper.apache.org/releases.html">下载 Zookeeper</a>，目前最新的稳定版本为 <code>3.8.4</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class="line"><span class="comment"># 配置个软连接，方便以后升级</span></span><br><span class="line"><span class="built_in">ln</span> -s apache-zookeeper-3.8.4-bin zookeeper</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改配置文件</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> zookeeper/conf</span><br><span class="line"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br><span class="line"><span class="comment"># 建议修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改为指定的data目录</span></span><br><span class="line">vim zoo.cfg</span><br></pre></td></tr></table></figure><blockquote><p>zoo.cfg 参数说明</p></blockquote><table><thead><tr><th>配置项</th><th>说明</th><th>默认值</th><th>单位 / 备注</th></tr></thead><tbody><tr><td><strong>tickTime</strong></td><td>ZooKeeper 时间配置中的基本单位</td><td>2000</td><td>毫秒</td></tr><tr><td><strong>initLimit</strong></td><td>follower 初始化连接到 leader 的最大时长，单位为 tickTime 倍数</td><td>10</td><td>10 × tickTime = 20000 ms</td></tr><tr><td><strong>syncLimit</strong></td><td>follower 与 leader 数据同步的最大时长，单位为 tickTime 倍数</td><td>5</td><td>5 × tickTime = 10000 ms</td></tr><tr><td><strong>dataDir</strong></td><td>数据和日志存储目录（未指定 dataLogDir 时，日志也会保存在此目录）</td><td>/tmp/zookeeper</td><td>目录路径</td></tr><tr><td><strong>clientPort</strong></td><td>客户端连接 ZooKeeper 的端口号</td><td>2181</td><td>默认 2181</td></tr><tr><td><strong>maxClientCnxns</strong></td><td>单个客户端最大并发连接数</td><td>60</td><td>超过限制后新连接会被拒绝</td></tr><tr><td><strong>autopurge.snapRetainCount</strong></td><td>快照文件保留个数，超过数量的将会被清理</td><td>3</td><td>默认 3</td></tr><tr><td><strong>autopurge.purgeInterval</strong></td><td>清理任务执行间隔时间，单位小时，0 表示不自动清理</td><td>1</td><td>1 小时</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>启动 zookeeper</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> zookeeper</span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">bin/zkServer.sh start</span><br><span class="line"><span class="comment"># 指定配置文件</span></span><br><span class="line">bin/zkServer.sh start conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止</span></span><br><span class="line">bin/zkServer.sh stop</span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">bin/zkServer.sh status</span><br><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">./bin/zkServer.sh version</span><br></pre></td></tr></table></figure><h3 id="集群安装">集群安装</h3><h4 id="ZooKeeper-集群角色">ZooKeeper 集群角色</h4><h5 id="1-Leader（领导者）">1. Leader（领导者）</h5><ul class="lvl-0"><li class="lvl-2"><p><strong>职责：</strong></p><ul class="lvl-2"><li class="lvl-4">事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性；</li><li class="lvl-4">集群内部各个服务器的调度者；</li><li class="lvl-4">对于 <code>create</code>、<code>setData</code>、<code>delete</code> 等写操作请求，统一转发给 Leader 处理；</li><li class="lvl-4">Leader 负责决定编号、执行操作，这个过程称为 <strong>事务</strong>。</li></ul></li></ul><ul class="lvl-0"><li class="lvl-2"><p>三台虚拟机 zoo.cfg 文件末尾添加配置，启动时会自动选举出 Leader 角色，则其余就是 Follower 角色。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.1=10.250.0.229:2888:3888</span><br><span class="line">server.2=10.250.0.152:2888:3888</span><br><span class="line">server.3=10.250.0.36:2888:3888</span><br></pre></td></tr></table></figure><h5 id="2-Follower（跟随者）">2. Follower（跟随者）</h5><ul class="lvl-0"><li class="lvl-2"><p><strong>职责：</strong></p><ul class="lvl-2"><li class="lvl-4">处理客户端非事务（读操作）请求（可以直接响应）；</li><li class="lvl-4">转发事务请求给 Leader；</li><li class="lvl-4">参与集群 Leader 选举投票。</li></ul></li></ul><blockquote><p>leader节点可以处理读写请求，follower只可以处理读请求。follower在接到写请求时会把写请求转发给leader来处理。</p></blockquote><h5 id="3-Observer（观察者）">3. Observer（观察者）</h5><ul class="lvl-0"><li class="lvl-2"><p><strong>职责：</strong></p><ul class="lvl-2"><li class="lvl-4">对于非事务请求（读操作）可以独立处理；</li><li class="lvl-4">对于事务请求会转发给 Leader 处理；</li><li class="lvl-4">接收来自 Leader 的 <code>inform</code> 信息，更新本地存储；</li><li class="lvl-4">不参与提交和选举投票；</li><li class="lvl-4">通常用于 <strong>提升集群非事务处理能力</strong>，不影响集群事务处理性能。</li></ul></li></ul><ul class="lvl-0"><li class="lvl-2"><p>配置一个 ID 为 4 的观察者节点：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure><h4 id="集群搭建">集群搭建</h4><ul class="lvl-0"><li class="lvl-2"><p>环境准备：4台服务器，按照 <code>单机安装</code> 的方式准备好 Zookeeper 环境</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10.250.0.229</span><br><span class="line">10.250.0.152</span><br><span class="line">10.250.0.36</span><br><span class="line">10.250.0.56</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p><code>zoo.cfg</code> 文件末尾添加配置</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server.1=10.250.0.229:2888:3888</span><br><span class="line">server.2=10.250.0.152:2888:3888</span><br><span class="line">server.3=10.250.0.36:2888:3888</span><br><span class="line">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别在 <code>dataDir</code> 目录下创建 <code>myid</code> 文件，在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格）</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意 节点编号不能重复，而且要与 zoo.cfg 文件中的 server.id 一致</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; myid</span><br><span class="line"><span class="comment"># echo 2 &gt; myid</span></span><br><span class="line"><span class="comment"># echo 3 &gt; myid</span></span><br><span class="line"><span class="comment"># echo 4 &gt; myid</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>分别启动 Zookeeper 服务器</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分别启动4个节点的zookeeper server</span></span><br><span class="line">bin/zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态，可以看到节点角色类型</span></span><br><span class="line">bin/zkServer.sh status</span><br></pre></td></tr></table></figure><h4 id="集群最少节点要求和扩容规则">集群最少节点要求和扩容规则</h4><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper 使用 多数派（quorum）机制 来保证数据一致性</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.集群总节点数 N</span><br><span class="line">2.容忍的宕机节点数 F = (N-1)/2（向下取整）</span><br><span class="line">3.要保证集群可用，需要 大于 N/2 的节点存活</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>集群扩容规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.节点总数必须是奇数</span><br><span class="line">  奇数节点可以保证多数派投票机制正常</span><br><span class="line">  偶数节点不推荐，容错能力不增加（比如 4 台，仍然只容忍 1 台宕机）</span><br><span class="line"></span><br><span class="line">2.每次扩容建议 +2 节点</span><br><span class="line">  这样既保持奇数，又增加 quorum 容错能力</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>最少节点与容错能力表格</p></li></ul><table><thead><tr><th>集群总节点数 N</th><th>容忍宕机数 F</th><th>可用 quorum 节点数</th><th>备注</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>1</td><td>不推荐，无法容忍故障</td></tr><tr><td>2</td><td>0</td><td>2</td><td>不推荐，1 台宕机就不可用</td></tr><tr><td>3</td><td>1</td><td>2</td><td>最小可用生产集群</td></tr><tr><td>5</td><td>2</td><td>3</td><td>推荐生产集群规模</td></tr><tr><td>7</td><td>3</td><td>4</td><td>高可用大集群</td></tr><tr><td>9</td><td>4</td><td>5</td><td>更大集群，高容错</td></tr><tr><td>11</td><td>5</td><td>6</td><td>极高可用场景</td></tr></tbody></table><h2 id="ZooKeeper-默认端口说明">ZooKeeper 默认端口说明</h2><table><thead><tr><th>端口</th><th>用途</th><th>说明</th></tr></thead><tbody><tr><td>2181</td><td>客户端连接端口</td><td>客户端通过这个端口访问 ZooKeeper</td></tr><tr><td>2888</td><td>集群内部通信</td><td>follower 与 leader 之间同步数据</td></tr><tr><td>3888</td><td>leader 选举端口</td><td>集群选举 leader 使用</td></tr><tr><td>8080 (可选)</td><td>admin/metrics web端口</td><td>如果开启了 adminServer</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 永久开启端口</span></span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --permanent --add-port=2181/tcp</span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --permanent --add-port=2888/tcp</span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --permanent --add-port=3888/tcp</span><br><span class="line"><span class="comment"># 如果使用 adminServer</span></span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --permanent --add-port=8080/tcp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新加载防火墙配置</span></span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看是否开放成功</span></span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --list-all</span><br></pre></td></tr></table></figure><h2 id="客户端连接">客户端连接</h2><ul class="lvl-0"><li class="lvl-2"><p>命令行</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认连接 127.0.0.1:2181</span></span><br><span class="line">bin/zkCli.sh</span><br><span class="line"><span class="comment"># 指定 -server ip:port，如果是集群，则连接任意一个节点，ZooKeeper 会自动处理与 Leader/Follower 的交互</span></span><br><span class="line">bin/zkCli.sh -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure><blockquote><p>客户端命令简介：<a href="https://zookeeper.apache.org/doc/r3.8.4/zookeeperCLI.html">参考官网</a></p></blockquote><table><thead><tr><th>命令</th><th>语法示例</th><th>功能描述</th><th>常用参数及说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>help</strong></td><td><code>help</code></td><td>显示所有操作命令</td><td>无</td><td><code>help</code></td></tr><tr><td><strong>version</strong></td><td><code>version</code></td><td>查看客户端和服务器版本信息</td><td>无</td><td><code>version</code></td></tr><tr><td><strong>connect</strong></td><td><code>connect host:port</code></td><td>连接到指定 ZooKeeper 服务器</td><td><code>host:port</code>: 服务器地址</td><td><code>connect 127.0.0.1:2181</code></td></tr><tr><td><strong>close</strong></td><td><code>close</code></td><td>关闭当前会话 ,通过 <code>connect</code> 可重连</td><td>无</td><td><code>close</code></td></tr><tr><td><strong>quit</strong></td><td><code>quit</code></td><td>退出客户端</td><td>无</td><td><code>quit</code></td></tr><tr><td><strong>ls</strong></td><td><code>ls [-s] [-w] [-R] path</code></td><td>查看节点的子节点</td><td>- <code>-w</code>: 监听子节点变化<br>- <code>-s</code>: 显示节点状态信息<br>- <code>-R</code>: 递归查看</td><td><code>ls -s -w /zk_test</code></td></tr><tr><td><strong>getAllChildrenNumber</strong></td><td><code>getAllChildrenNumber path</code></td><td>获取某节点所有子节点的总数</td><td>无</td><td><code>getAllChildrenNumber /zk_test</code></td></tr><tr><td><strong>getEphemerals</strong></td><td><code>getEphemerals path</code></td><td>获取某路径下所有临时节点</td><td>无</td><td><code>getEphemerals /zk_test</code></td></tr><tr><td><strong>create</strong></td><td><code>create [-s] [-e] [-c] [-t ttl] path [data] [acl]</code></td><td>创建节点</td><td>- <code>-s</code>: 顺序节点<br>- <code>-e</code>: 临时节点<br>- <code>-c</code>: 容器节点<br>- <code>-t ttl</code>: TTL节点，单位毫秒</td><td><code>create -e /zk_test_ephemeral &quot;temp_data&quot;</code></td></tr><tr><td><strong>get</strong></td><td><code>get [-s] [-w] path</code></td><td>获取节点数据信息</td><td>- <code>-s</code>: 显示节点状态信息<br>- <code>-w</code>: 监听节点变化</td><td><code>get -s -w /zk_test</code></td></tr><tr><td><strong>set</strong></td><td><code>set [-s] [-v version] path data</code></td><td>设置节点数据</td><td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号</td><td><code>set /zk_test &quot;new_data&quot;</code></td></tr><tr><td><strong>stat</strong></td><td><code>stat [-w] path</code></td><td>查看节点状态信息</td><td>- <code>-w</code>: 监听节点变化</td><td><code>stat -w /zk_test</code></td></tr><tr><td><strong>sync</strong></td><td><code>sync path</code></td><td>同步指定节点数据</td><td>无</td><td><code>sync /zk_test</code></td></tr><tr><td><strong>delete</strong></td><td><code>delete [-v version] path</code></td><td>删除某一节点（无子节点）</td><td>- <code>-v</code>: 节点版本号</td><td><code>delete /zk_test</code></td></tr><tr><td><strong>deleteall</strong></td><td><code>deleteall path</code></td><td>递归删除某一节点及其子节点</td><td>无</td><td><code>deleteall /zk_test</code></td></tr><tr><td><strong>getAcl</strong></td><td><code>getAcl [-s] path</code></td><td>获取节点访问控制信息</td><td>- <code>-s</code>: 显示节点状态信息</td><td><code>getAcl /zk_test</code></td></tr><tr><td><strong>setAcl</strong></td><td><code>setAcl [-s] [-v version] [-R] path acl</code></td><td>设置节点访问控制列表</td><td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号<br>- <code>-R</code>: 递归设置</td><td><code>setAcl /zk_test world:anyone:r</code></td></tr><tr><td><strong>listquota</strong></td><td><code>listquota path</code></td><td>查看节点配额信息</td><td>无</td><td><code>listquota /zk_test</code></td></tr><tr><td><strong>setquota</strong></td><td><code>setquota [-n] [-b] val path</code></td><td>对节点增加限制</td><td>- <code>-n</code>: 子节点最大个数<br>- <code>-b</code>: 数据值最大长度，-1 表示无限制</td><td><code>setquota -n 5 /zk_test</code></td></tr><tr><td><strong>delquota</strong></td><td><code>delquota [-n                                    | -b] path</code></td><td>删除节点配额限制</td><td>- <code>-n</code>: 删除子节点数限制<br>- <code>-b</code>: 删除数据值大小限制</td><td><code>delquota -n /zk_test</code></td></tr><tr><td><strong>config</strong></td><td><code>config</code></td><td>查看服务器配置</td><td>无</td><td><code>config</code></td></tr><tr><td><strong>whoami</strong></td><td><code>whoami</code></td><td>查看当前会话身份</td><td>无</td><td><code>whoami</code></td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>GUI 工具</p></li></ul><table><thead><tr><th>名称</th><th>类型 / 运行方式</th><th>优点</th><th>注意事项</th></tr></thead><tbody><tr><td><strong>PrettyZoo</strong></td><td>桌面应用（JavaFX）(<a href="https://github.com/vran-dev/PrettyZoo" title="vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...">GitHub</a>)</td><td>支持 Mac/Windows/Linux，界面友好；支持节点创建/删除/更新/查询，ACL 管理，多 ZK 实例管理，SSH 隧道等功能。(<a href="https://github.com/vran-dev/PrettyZoo" title="vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...">GitHub</a>)</td><td>项目已经 archived，维护可能不活跃。最新版可能在兼容性或 Bug 修复方面不如活跃项目。也可能需要自己构建或调试。(<a href="https://github.com/vran-dev/PrettyZoo" title="vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...">GitHub</a>)</td></tr><tr><td><strong>ZooNavigator</strong></td><td>Web 界面 + 可 Docker 部署或本地启动(<a href="https://github.com/elkozmon/zoonavigator" title="elkozmon/zoonavigator: Web-based ZooKeeper UI">GitHub</a>)</td><td>功能丰富；支持多个 Zookeeper 版本（如 3.5.x ～ 3.9.x）；浏览 / 编辑 /搜索节点；导入导出配置；支持浏览器访问，无需本地 heavy GUI。(<a href="https://github.com/elkozmon/zoonavigator" title="elkozmon/zoonavigator: Web-based ZooKeeper UI">GitHub</a>)</td><td>因为 Web 应用，可能对浏览器安全策略与网络延迟敏感；需要部署自己版本或 Docker；如果要求本地脱机操作时，有些功能可能稍不如桌面应用。</td></tr><tr><td><strong>ZooKeeper Assistant</strong></td><td>桌面／管理员面板类型（支持监控界面等）(<a href="https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo" title="An exciting Apache ZooKeeper Desktop GUI">DEV Community</a>)</td><td>除了浏览节点树以外，还提供健康状态监控（延迟、请求数等）、不同数据格式支持（JSON/XML 等）、导入/导出节点数据、命令行操作集成。(<a href="https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo" title="An exciting Apache ZooKeeper Desktop GUI">DEV Community</a>)</td><td>有些功能可能在 Mac 上兼容性或视觉体验需要调试；具体版本支持情况要看最近更新。某些监控界面可能依赖于 ZK 的指标或插件。</td></tr></tbody></table><h2 id="Zookeeper-节点类型">Zookeeper 节点类型</h2><table><thead><tr><th>节点类型</th><th>生命周期说明</th><th>创建命令示例</th><th>特点说明</th></tr></thead><tbody><tr><td><strong>持久节点</strong> (Persistent)</td><td>节点一直存在，除非手动删除，即使客户端会话关闭，节点也不会消失</td><td><code>create /locks</code></td><td>适合存储配置信息、元数据等持久数据</td></tr><tr><td><strong>临时节点</strong> (Ephemeral)</td><td>客户端会话关闭（异常或超时）时，节点自动被删除</td><td><code>create -e /locks/DBLock</code></td><td>常用于分布式锁、临时会话数据</td></tr><tr><td><strong>有序节点</strong> (Sequential)</td><td>在持久或临时节点基础上，增加有序编号，ZooKeeper 自动在节点名后加递增序号</td><td><code>create -e -s /jobs/job</code></td><td>常用于分布式锁、队列等需要顺序的场景</td></tr><tr><td><strong>容器节点</strong> (Container)</td><td>V3.5.3+，当容器节点下的最后一个子节点被删除后，容器节点也会自动删除</td><td><code>create -c /work</code></td><td>适合分布式任务临时目录、动态数据目录</td></tr><tr><td><strong>TTL 节点</strong> (TTL)</td><td>在指定 TTL 时间内未修改且无子节点，节点会被自动删除（需开启 <code>extendedTypesEnabled=true</code> 配置）</td><td><code>create -t 3000 /ttl_node</code></td><td>适合临时缓存、临时状态数据，过期自动清理</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>注意</p><ul class="lvl-2"><li class="lvl-4">同一级节点 key 名称是唯一的</li><li class="lvl-4">创建节点时，必须要带上全路径</li></ul></li><li class="lvl-2"><p>节点状态信息</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 16] <span class="built_in">stat</span> /test</span><br><span class="line">cZxid = 0x100000002                   <span class="comment"># Znode创建的事务id</span></span><br><span class="line">ctime = Mon Sep 15 09:44:51 UTC 2025  <span class="comment"># 创建时间</span></span><br><span class="line">mZxid = 0x100000004                   <span class="comment"># 最后一次修改事务id</span></span><br><span class="line">mtime = Mon Sep 15 09:47:12 UTC 2025  <span class="comment"># 最后一次修改时间</span></span><br><span class="line">pZxid = 0x400000004                   <span class="comment"># 表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID（注意: 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）</span></span><br><span class="line">cversion = 1                          <span class="comment"># 子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。</span></span><br><span class="line">dataVersion = 1                       <span class="comment"># znode的数据版本号。每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据），可有效避免了数据更新时出现的先后顺序问题</span></span><br><span class="line">aclVersion = 0                        <span class="comment"># znode的ACL版本号。每次对节点进行ACL设置，aclVersion的值都会增加1</span></span><br><span class="line">ephemeralOwner = 0x0                  <span class="comment"># 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id。如果不是, ephemeralOwner值为0(持久节点)。</span></span><br><span class="line">dataLength = 3                        <span class="comment"># znode的数据长度</span></span><br><span class="line">numChildren = 1                       <span class="comment"># znode的子节点数量（只统计直接子节点的数量）</span></span><br></pre></td></tr></table></figure><h2 id="Zookeeper-监听机制">Zookeeper 监听机制</h2><ul class="lvl-0"><li class="lvl-2"><p>watch机制，顾名思义是一个监听机制。Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发生时才会触发监听，通知给客户端。</p></li><li class="lvl-2"><p>监听的对象是事件，支持的事件类型如下：</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- None: 连接建立事件</span><br><span class="line">- NodeCreated： 节点创建</span><br><span class="line">- NodeDeleted： 节点删除</span><br><span class="line">- NodeDataChanged：节点数据变化</span><br><span class="line">- NodeChildrenChanged：子节点列表变化</span><br><span class="line">- DataWatchRemoved：节点监听被移除</span><br><span class="line">- ChildWatchRemoved：子节点监听被移除</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>监听特性</p></li></ul><table><thead><tr><th>特性</th><th>说明</th></tr></thead><tbody><tr><td><strong>一次性触发</strong></td><td>Watch 是一次性的，一旦被触发就会被移除。再次使用时需要重新注册。</td></tr><tr><td><strong>客户端顺序回调</strong></td><td>Watch 回调是顺序串行执行的，客户端只有在回调完成后才能看到最新的数据状态。</td></tr><tr><td><strong>轻量级</strong></td><td>Watcher 回调逻辑不应过多，以免阻塞或影响其他 Watch 的执行。</td></tr><tr><td><strong>最小通信单位</strong></td><td><code>WatchEvent</code> 是最小的通信单位，只包含通知状态、事件类型和节点路径，不包含节点数据变化前后的具体内容。</td></tr><tr><td><strong>时效性</strong></td><td>Watcher 仅在当前 Session 完全失效时才无效。如果 Session 快速重连成功，Watcher 依然有效，可继续接收通知。</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>可以开启监听的命令</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#监听节点数据的变化</span></span><br><span class="line">get -w path</span><br><span class="line"><span class="built_in">stat</span> -w path</span><br><span class="line"></span><br><span class="line"><span class="comment">#监听子节点增减的变化</span></span><br><span class="line"><span class="built_in">ls</span> -w path</span><br></pre></td></tr></table></figure><h3 id="永久性-Watch">永久性 Watch</h3><ul class="lvl-0"><li class="lvl-2"><p>在被触发之后，仍然保留，可以继续监听ZNode上的变更，是Zookeeper 3.6.0版本新增的功能</p></li><li class="lvl-2"><p>创建监听</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">addWatch [-m mode] path</span><br><span class="line"></span><br><span class="line"><span class="comment"># mode:</span></span><br><span class="line"><span class="comment"># - PERSISTENT: 持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。</span></span><br><span class="line"><span class="comment"># - PERSISTENT_RECURSIVE: 持久化递归订阅(这个是默认值)，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性）</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除监听</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通一次性 Watch 不需要手动删除，触发后会自动移除；removewatches 主要用于持久 Watch（persistent watch）。</span></span><br><span class="line">removewatches path [-c|-d|-a] [-l]</span><br><span class="line"><span class="comment"># -c: 仅删除当前客户端的 Watch</span></span><br><span class="line"><span class="comment"># -d: 删除指定节点的所有 Watch(包括其他客户端注册的)</span></span><br><span class="line"><span class="comment"># -a: 删除所有节点的所有 Watch（包括其他客户端的 Watch），慎用！！！</span></span><br><span class="line"><span class="comment"># -l: 显示被删除的 Watch 列表</span></span><br></pre></td></tr></table></figure><h3 id="监听器应用场景">监听器应用场景</h3><table><thead><tr><th>类型</th><th>特点</th><th>应用场景举例</th><th>适合的节点类型</th></tr></thead><tbody><tr><td><strong>临时监听</strong>（一次性 Watch）</td><td>- 触发一次后自动移除<br>- 客户端需手动重新注册<br>- 轻量级，适合单次通知</td><td>1. <strong>配置中心</strong>：配置变化时通知客户端，客户端收到通知后重新拉取最新配置 <br> 2. <strong>分布式锁</strong>：节点删除（锁释放）后通知等待的客户端重新竞争锁 <br> 3. <strong>主从选举</strong>：主节点宕机后，其他节点收到通知重新选主</td><td><strong>持久节点</strong>（Persistent） <br><strong>临时节点</strong>（Ephemeral，用于锁和选主）</td></tr><tr><td><strong>永久监听</strong>（Persistent Watch）</td><td>- 注册后持续有效，直到客户端主动移除<br>- 支持子节点变化、数据变化的长期监听</td><td>1. <strong>服务发现</strong>：客户端长期监听服务节点变化，节点上线/下线时自动更新本地服务列表 <br> 2. <strong>监控告警</strong>：监控重要节点状态，节点数据变化或被删除时自动触发告警 <br> 3. <strong>分布式缓存</strong>：缓存节点变化时，通知客户端刷新缓存</td><td><strong>持久节点</strong>（Persistent）</td></tr></tbody></table><h2 id="ACL权限控制">ACL权限控制</h2><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper 默认情况下，所有节点的权限都是 <code>OPEN_ACL_UNSAFE</code> ，任何客户端都可以读写任意节点数据。</p></li><li class="lvl-2"><p>生产环境中，通常需要限制对节点的访问权限，即 <code>ACL</code> 权限控制。</p></li><li class="lvl-2"><p>ZooKeeper 里的 ACL（Access Control List，访问控制列表） 主要用于控制 谁可以对某个节点做什么操作，它是 ZooKeeper 提供的安全机制之一。</p></li></ul><h3 id="ACL-的作用">ACL 的作用</h3><ul class="lvl-0"><li class="lvl-2"><p>限制访问：只允许授权用户或客户端对指定节点进行读、写、删除等操作。</p></li><li class="lvl-2"><p>防止误操作：保护重要节点不被未授权的客户端修改或删除。</p></li><li class="lvl-2"><p>安全隔离：不同的应用或团队可以在同一 ZooKeeper 集群里安全共存。</p></li></ul><h3 id="ACL-的组成">ACL 的组成</h3><ul class="lvl-0"><li class="lvl-2"><p>zookeeper 的 acl 通过 <code>scheme:id:permissions</code> 来构成权限列表。</p><ul class="lvl-2"><li class="lvl-4">scheme：授权的模式，代表采用的某种权限机制，包括 world、auth、digest、ip、super 几种。</li><li class="lvl-4">id：授权对象，代表允许访问的用户。如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。</li><li class="lvl-4">permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限， 创建权限 create©、删除权限 delete(d)、读权限 read®、写权限 write(w)、管理权限admin(a)。</li></ul></li></ul><h3 id="常见的-scheme-类型">常见的 scheme 类型</h3><table><thead><tr><th>Scheme</th><th>说明</th><th>示例</th></tr></thead><tbody><tr><td><code>world</code></td><td>开放给所有用户，仅可设置为 <code>anyone</code> 代表所有客户端</td><td><code>world:anyone:r</code></td></tr><tr><td><code>auth</code></td><td>已通过 <code>addauth</code> 添加认证的客户端</td><td><code>auth:user1:rw</code></td></tr><tr><td><code>digest</code></td><td>用户名+密码认证（常用），<code>user:pwd</code> 需要加密存储</td><td><code>digest:user1:password:rw</code></td></tr><tr><td><code>ip</code></td><td>基于 IP 地址控制访问</td><td><code>ip:192.168.1.10:r</code></td></tr><tr><td><code>super</code></td><td>超级用户，拥有所有权限</td><td><code>super:admin:secret</code></td></tr></tbody></table><h3 id="权限类型">权限类型</h3><table><thead><tr><th>权限字符</th><th>权限名称</th><th>允许的操作/命令示例</th><th>说明</th></tr></thead><tbody><tr><td><strong><code>r</code></strong></td><td>读取(Read)</td><td><code>get /node</code> <br> <code>ls /node</code> <br> <code>getAcl /node</code></td><td>允许读取节点数据和子节点列表</td></tr><tr><td><strong><code>w</code></strong></td><td>写入(Write)</td><td><code>set /node data</code></td><td>允许修改节点数据</td></tr><tr><td><strong><code>c</code></strong></td><td>创建(Create)</td><td><code>create /node/sub &quot;data&quot;</code></td><td>允许在当前节点下创建子节点</td></tr><tr><td><strong><code>d</code></strong></td><td>删除(Delete)</td><td><code>delete /node/sub</code></td><td>允许删除当前节点的子节点</td></tr><tr><td><strong><code>a</code></strong></td><td>管理(Admin)</td><td><code>setAcl /node acl</code></td><td>允许修改 ACL 权限</td></tr></tbody></table><h3 id="典型应用场景">典型应用场景</h3><table><thead><tr><th>认证方式（scheme）</th><th>权限类型（permissions）</th><th>典型 ACL 配置示例</th><th>应用场景</th><th>特点说明</th></tr></thead><tbody><tr><td><strong>world</strong></td><td><code>r</code>（只读）</td><td><code>world:anyone:r</code></td><td>公共配置节点，所有客户端都可读取</td><td>简单、无认证，适合对安全性要求不高的只读场景</td></tr><tr><td><strong>auth</strong></td><td><code>r,w,c,d,a</code>（可组合）</td><td><code>auth:user:rwcd</code></td><td>内部应用共享节点，需客户端认证</td><td>需先 <code>addauth digest user1:password</code> 添加认证，适合多客户端共享</td></tr><tr><td><strong>digest</strong>（常用）</td><td><code>r,w,c,d,a</code>（可组合）</td><td><code>digest:user:secret:crwda</code></td><td>高安全节点，配置中心，分布式锁</td><td>用户名+密码认证，需加密存储密码，灵活安全</td></tr><tr><td><strong>ip</strong></td><td><code>r,w,c,d,a</code>（可组合）</td><td><code>ip:192.168.1.100:r</code></td><td>基于 IP 限制访问的场景</td><td>快速控制某些固定 IP 可访问，适合内部网络应用</td></tr></tbody></table><h3 id="ACL-相关命令">ACL 相关命令</h3><table><thead><tr><th>命令</th><th>语法</th><th>功能说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>getAcl</strong></td><td><code>getAcl path</code></td><td>读取指定节点的 ACL</td><td><code>getAcl /my_node</code></td></tr><tr><td><strong>setAcl</strong></td><td><code>setAcl path acl</code></td><td>设置指定节点的 ACL</td><td><code>setAcl /my_node world:anyone:crdwa</code></td></tr><tr><td><strong>create</strong></td><td><code>create path data [acl]</code></td><td>创建节点时指定 ACL</td><td><code>create /secure_node &quot;secret_data&quot; digest:user1:pwd:crwa</code></td></tr><tr><td><strong>addAuth</strong></td><td><code>addauth scheme auth</code></td><td>添加认证用户（类似登录）</td><td><code>addauth digest user1:password</code></td></tr><tr><td><strong>deleteAcl(不存在)</strong></td><td><code>setAcl path world:anyone:</code></td><td>删除节点 ACL（设为空或全开放）</td><td><code>setAcl /my_node world:anyone:</code></td></tr></tbody></table><h3 id="auth-与-digest-的区别"><code>auth</code> 与 <code>digest</code> 的区别</h3><ul class="lvl-0"><li class="lvl-2"><p>使用 <code>auth</code> 时，需先 <code>addauth digest user1:password</code> 添加认证，<code>setAcl</code> 时，使用 <code>auth:user1:rw</code>，这里是为已经登录的用户设置节点权限，所以不需要设置密码</p></li><li class="lvl-2"><p>使用 <code>digest</code> 时，无需进行登录认证，所以需要指定密码，即<code>setAcl</code> 时，使用 <code>digest:user1:password:rw</code></p></li><li class="lvl-2"><p><code>digest</code> 的密码是经过加密的，所以不能直接使用明文密码</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加密密码</span></span><br><span class="line"><span class="built_in">echo</span> -n user:123456 | openssl dgst -binary -sha1 | openssl <span class="built_in">base64</span></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">6DY5WhzOfGsWQ1XFuIyzxkpwdPo=</span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper客户端中设置权限</span></span><br><span class="line">setAcl /name digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:cdrwa</span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录时密码是明文</span></span><br><span class="line">addauth digest user:123456</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>无论使用 <code>digest</code> 还是 <code>auth</code>，在需要访问节点前，都需要先登录。</p></li></ul><h3 id="super-超级管理员"><code>super</code> 超级管理员</h3><ul class="lvl-0"><li class="lvl-2"><p>拥有全部节点的所有权限: <code>crwda</code></p></li><li class="lvl-2"><p>设置超级管理员</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加密密码，用户和密码可以随意设置</span></span><br><span class="line"><span class="built_in">echo</span> -n admin:123456 | openssl dgst -binary -sha1 | openssl <span class="built_in">base64</span></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 conf/zoo.cfg 文件并编辑，在文件中添加下面内容</span></span><br><span class="line">DigestAuthenticationProvider.superDigest=admin:0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>重新启动服务后登录客户端进行测试</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建节点并设置权限，这里将节点授权给用户user</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 10] create /testNode 666 digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:rw</span><br><span class="line">Created /testNode</span><br><span class="line"><span class="comment"># 查看节点内容被拒绝</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 11] get /testNode</span><br><span class="line">Insufficient permission : /testNode</span><br><span class="line"><span class="comment"># 登录super用户，验证超级用户是否有权限访问节点</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 12] addauth digest admin:123456</span><br><span class="line"><span class="comment"># 此时查看节点内容就可以了</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 13] get /testNode</span><br><span class="line">666</span><br></pre></td></tr></table></figure><h2 id="4字母命令">4字母命令</h2><h3 id="什么是-4-字母命令">什么是 <code>4 字母命令</code>?</h3><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper 提供了一组简短的 <code>4个字母的管理命令</code>(Four Letter Words Commands, 4lw)，可以通过 TCP 连接 ZooKeeper 端口（默认 2181）发送这些命令，快速查看或管理 ZooKeeper 状态。</p></li><li class="lvl-2"><p>常用的 <code>4字母命令</code></p></li></ul><table><thead><tr><th>命令</th><th>引入版本</th><th>功能描述</th><th>示例</th></tr></thead><tbody><tr><td><code>conf</code></td><td>3.3.0</td><td>打印服务相关配置的详细信息</td><td><code>echo conf | nc 127.0.0.1 2181</code></td></tr><tr><td><code>cons</code></td><td>3.3.0</td><td>列出所有连接到该服务器的客户端连接/会话详细信息，包括接收/发送的包数量、会话ID、操作延迟、最后操作执行时间等</td><td><code>echo cons | nc 127.0.0.1 2181</code></td></tr><tr><td><code>crst</code></td><td>3.3.0</td><td>重置所有连接的连接和会话统计信息</td><td><code>echo crst | nc 127.0.0.1 2181</code></td></tr><tr><td><code>dump</code></td><td>-</td><td>列出重要的会话和临时节点信息，仅在 Leader 节点上有效</td><td><code>echo dump | nc 127.0.0.1 2181</code></td></tr><tr><td><code>envi</code></td><td>-</td><td>打印服务环境的详细信息</td><td><code>echo envi | nc 127.0.0.1 2181</code></td></tr><tr><td><code>reqs</code></td><td>-</td><td>列出未经处理的请求</td><td><code>echo reqs | nc 127.0.0.1 2181</code></td></tr><tr><td><code>ruok</code></td><td>-</td><td>测试服务是否处于正常状态；正常返回 <code>imok</code></td><td><code>echo ruok | nc 127.0.0.1 2181</code></td></tr><tr><td><code>stat</code></td><td>-</td><td>输出关于性能和客户端连接的列表信息</td><td><code>echo stat | nc 127.0.0.1 2181</code></td></tr><tr><td><code>srst</code></td><td>-</td><td>重置服务器统计信息</td><td><code>echo srst | nc 127.0.0.1 2181</code></td></tr><tr><td><code>srvr</code></td><td>3.3.0</td><td>列出连接服务器的详细信息</td><td><code>echo srvr | nc 127.0.0.1 2181</code></td></tr><tr><td><code>wchs</code></td><td>3.3.0</td><td>列出服务器 Watch 的详细信息</td><td><code>echo wchs | nc 127.0.0.1 2181</code></td></tr><tr><td><code>wchc</code></td><td>3.3.0</td><td>通过会话列出服务器 Watch 的详细信息，输出与 Watch 相关的会话列表</td><td><code>echo wchc | nc 127.0.0.1 2181</code></td></tr><tr><td><code>wchp</code></td><td>3.3.0</td><td>通过路径列出服务器 Watch 的详细信息，输出与会话相关的路径</td><td><code>echo wchp | nc 127.0.0.1 2181</code></td></tr><tr><td><code>mntr</code></td><td>3.4.0</td><td>输出可用于检测集群健康状态的关键指标变量列表</td><td><code>echo mntr | nc 127.0.0.1 2181</code></td></tr></tbody></table><h3 id="开启-4字母命令">开启 <code>4字母命令</code></h3><ul class="lvl-0"><li class="lvl-2"><p>在 ZooKeeper 3.5.0 及之后的版本，4lw 命令默认是禁用的，必须在配置文件(zoo.cfg)中显式开启。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表示允许所有 4lw 命令都能用（风险最大）</span></span><br><span class="line">4lw.commands.whitelist=*</span><br><span class="line"><span class="comment"># 这样只允许执行 stat、conf、ruok 这几个命令。</span></span><br><span class="line">4lw.commands.whitelist=<span class="built_in">stat</span>,conf,ruok</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>使用方法</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果没有安装 nc，可以使用 yum 安装</span></span><br><span class="line">yum install nc -y</span><br><span class="line"><span class="comment"># 查看节点状态</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">stat</span> | nc 127.0.0.1 2181</span><br></pre></td></tr></table></figure><h2 id="Zookeeper-Java-Client">Zookeeper Java Client</h2><ul class="lvl-0"><li class="lvl-2"><p>项目示例：<a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/zookeeper-demo/">Github地址</a>，单元测试。</p></li></ul><h3 id="Zookeeper-官方Java客户端">Zookeeper 官方Java客户端</h3><ul class="lvl-0"><li class="lvl-2"><p>ZooKeeper官方的客户端API提供了基本的操作。例如，创建会话、创建节点、读取节点、更新数据、删除节点和检查节点是否存在等。不过，对于实际开发来说，ZooKeeper官方API有一些不足之处，具体如下：</p><ul class="lvl-2"><li class="lvl-4">ZooKeeper的Watcher监测是一次性的，每次触发之后都需要重新进行注册。</li><li class="lvl-4">会话超时之后没有实现重连机制。</li><li class="lvl-4">异常处理烦琐，ZooKeeper提供了很多异常，对于开发人员来说可能根本不知道应该如何处理这些抛出的异常。</li><li class="lvl-4">仅提供了简单的byte[]数组类型的接口，没有提供Java POJO级别的序列化数据处理接口。</li><li class="lvl-4">创建节点时如果抛出异常，需要自行检查节点是否存在。</li><li class="lvl-4">无法实现级联删除。</li><li class="lvl-4">总之，ZooKeeper官方API功能比较简单，在实际开发过程中比较笨重，一般不推荐使用。</li></ul></li><li class="lvl-2"><p>项目引入依赖时，最好保持与服务端版本一致，否则可能会有一些兼容性的问题</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- zookeeper client --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Zookeeper-第三方Java客户端-Curator">Zookeeper 第三方Java客户端 Curator</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://curator.apache.org/docs/about">Curator</a>是Netflix公司开源的一套ZooKeeper客户端框架，和ZkClient一样它解决了非常底层的细节开发工作，包括连接、重连、反复注册Watcher的问题以及NodeExistsException异常等。</p></li><li class="lvl-2"><p>Curator是Apache基金会的顶级项目之一，Curator具有更加完善的文档，另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。</p></li><li class="lvl-2"><p>Curator还为ZooKeeper客户端框架提供了一些比较普遍的、开箱即用的、分布式开发用的解决方案，例如Recipe、共享锁服务、Master选举机制和分布式计算器等，帮助开发者避免了“重复造轮子”的无效开发工作。</p></li><li class="lvl-2"><p>在实际的开发场景中，使用Curator客户端就足以应付日常的ZooKeeper集群操作的需求。</p></li><li class="lvl-2"><p>引入依赖说明：</p></li></ul><table><thead><tr><th>模块</th><th>依赖关系</th><th>功能定位</th><th>典型功能举例</th><th>常用场景</th></tr></thead><tbody><tr><td><strong>curator-client</strong></td><td>依赖 zookeeper</td><td>连接管理、重试策略、底层 API</td><td>连接会话管理、RetryPolicy</td><td>需要最轻量的 ZooKeeper 客户端</td></tr><tr><td><strong>curator-framework</strong></td><td>依赖 curator-client</td><td>高层 API 封装，简化 ZK 操作</td><td>创建节点、Watcher 管理、自动重连</td><td>通用 ZooKeeper 客户端开发</td></tr><tr><td><strong>curator-recipes</strong></td><td>依赖 curator-framework → curator-client</td><td>分布式模式现成实现</td><td>分布式锁、Leader 选举、队列、Barrier</td><td>直接用分布式工具，无需自己实现</td></tr></tbody></table><blockquote><p>使用建议</p></blockquote><ul class="lvl-0"><li class="lvl-4"><p>如果你只想轻量访问 ZooKeeper → <code>curator-client</code> 就够了，但几乎没人单独用。</p></li><li class="lvl-4"><p>如果你想方便操作 ZooKeeper API → <code>curator-framework</code>，大部分情况都适用。</p></li><li class="lvl-4"><p>如果你想用分布式锁、选举、Barrier → <code>curator-recipes</code>（它会自动引入前两个）。</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- zookeeper client --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--curator--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-recipes<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 CentOS9 中 Zookeeper 的安装与使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://zookeeper.apache.org&quot;&gt;Zookeeper官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文使用的 Zookeeper 版本为 3.8.4。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="zookeeper" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/zookeeper/"/>
    
    <category term="分布式" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="zookeeper" scheme="https://blog.hanqunfeng.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>ShardingSphere-Proxy5.5.2 DistSQL</title>
    <link href="https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/"/>
    <id>https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/</id>
    <published>2025-09-11T13:30:05.000Z</published>
    <updated>2025-09-15T02:14:23.413Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。</p></li><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/index_zh.html">ShardingSphere官网</a></p></li></ul><span id="more"></span><h2 id="DistSQL">DistSQL</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/">DistSQL</a>（Distributed SQL）是 Apache ShardingSphere 特有的操作语言。 它与标准 SQL 的使用方式完全一致，用于提供增量功能的 SQL 级别操作能力。</p></li><li class="lvl-2"><p>灵活的规则配置和资源管控能力是 Apache ShardingSphere 的特点之一。</p></li><li class="lvl-2"><p>在使用 4.x 及其之前版本时，开发者虽然可以像使用原生数据库一样操作数据，但却需要通过本地文件或注册中心配置资源和规则。然而，操作习惯变更，对于运维工程师并不友好。</p></li><li class="lvl-2"><p>从 5.x 版本开始，DistSQL（Distributed SQL）让用户可以像操作数据库一样操作 Apache ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的数据库产品。</p></li><li class="lvl-2"><p>DistSQL 细分为 RDL、RQL、RAL 和 RUL 四种类型。</p><ul class="lvl-2"><li class="lvl-4">RDL: Resource &amp; Rule Definition Language，负责资源和规则的创建、修改和删除。</li><li class="lvl-4">RQL: Resource &amp; Rule Query Language，负责资源和规则的查询和展现。</li><li class="lvl-4">RAL: Resource &amp; Rule Administration Language，负责强制路由、熔断、配置导入导出、数据迁移控制等管理功能。</li><li class="lvl-4">RUL: Resource &amp; Rule Utility Language，负责 SQL 解析、SQL 格式化、执行计划预览等功能。</li></ul></li><li class="lvl-2"><p>DistSQL 仅可以在 ShardingSphere-Proxy 中使用，不能在 ShardingSphere-JDBC 中使用。</p></li></ul><h2 id="示例准备">示例准备</h2><ul class="lvl-0"><li class="lvl-2"><p>具体的语法，官网介绍的很详细，这里基于 <a href="/2025/09/04/springboot3-shardingsphere-proxy/" title="SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 中的配置进行示例说明。</p></li><li class="lvl-2"><p>为了尽可能多的使用 DistSQL 语法，这里仅在 <code>global.yaml</code> 中配置如下内容:</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置为基于 zookeeper 集群模式，为了演示 DistSQL 语法，这里需要将配置持久化，使用 JDBC 的单机模式也可以</span></span><br><span class="line"><span class="attr">mode:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Cluster</span>                 <span class="comment"># 运行模式，默认是单机模式 Standalone</span></span><br><span class="line">  <span class="attr">repository:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">ZooKeeper</span>             <span class="comment"># 注册中心类型</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">governance_ds</span>  <span class="comment"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class="line">      <span class="attr">server-lists:</span> <span class="string">localhost:2181</span> <span class="comment"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class="line">      <span class="attr">retryIntervalMilliseconds:</span> <span class="number">500</span> <span class="comment"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class="line">      <span class="attr">timeToLiveSeconds:</span> <span class="number">60</span>     <span class="comment"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class="line">      <span class="attr">maxRetries:</span> <span class="number">3</span>             <span class="comment"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class="line">      <span class="attr">operationTimeoutMilliseconds:</span> <span class="number">500</span>  <span class="comment"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置用户和权限，因为 DistSQL 暂不支持 用户和权限管理，所以这里需要先配置用户和权限</span></span><br><span class="line"><span class="attr">authority:</span></span><br><span class="line">  <span class="attr">users:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">root@127.0.0.1</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">admin:</span> <span class="literal">true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">sharding@%</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">sharding</span></span><br><span class="line">  <span class="attr">privilege:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">DATABASE_PERMITTED</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">user-database-mappings:</span> <span class="string">root@127.0.0.1=*,sharding@%=sharding_db</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 ShardingSphere-Proxy 服务，并登录</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 ShardingSphere-Proxy</span></span><br><span class="line">./shardingsphere-proxy-bin/bin/start.sh</span><br><span class="line"><span class="comment"># 使用管理员登录</span></span><br><span class="line">mysql -h127.0.0.1 -uroot -proot -P3307</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前用户权限</span></span><br><span class="line">mysql&gt; SHOW AUTHORITY RULE;</span><br><span class="line">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class="line">| <span class="built_in">users</span>                      | provider           | props                                                                |</span><br><span class="line">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class="line">| root@127.0.0.1; sharding@% | DATABASE_PERMITTED | &#123;<span class="string">&quot;user-database-mappings&quot;</span>:<span class="string">&quot;root@127.0.0.1=*,sharding@%=sharding_db&quot;</span>&#125; |</span><br><span class="line">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.49 sec)</span><br></pre></td></tr></table></figure><h2 id="全局配置，即global-yaml中的配置">全局配置，即<code>global.yaml</code>中的配置</h2><ul class="lvl-0"><li class="lvl-2"><p>全局配置对所有逻辑数据库有效</p></li></ul><h3 id="属性配置">属性配置</h3><ul class="lvl-0"><li class="lvl-2"><p>配置文件中的配置</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">props:</span></span><br><span class="line">  <span class="attr">sql-show:</span> <span class="literal">true</span> <span class="comment"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br></pre></td></tr></table></figure><h4 id="DistSQL-语法">DistSQL 语法</h4><ul class="lvl-0"><li class="lvl-2"><p>设置属性，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/set-dist-vairable/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里要注意，属性名需要使用下划线格式</span></span><br><span class="line">SET DIST VARIABLE sql_show = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查看属性，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/show-dist-variable/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW DIST VARIABLES;</span><br><span class="line">+-----------------------------------------+-----------------+</span><br><span class="line">| variable_name                           | variable_value  |</span><br><span class="line">+-----------------------------------------+-----------------+</span><br><span class="line">| agent_plugins_enabled                   | <span class="literal">true</span>            |</span><br><span class="line">| cached_connections                      | 0               |</span><br><span class="line">| cdc_server_port                         | 33071           |</span><br><span class="line">| check_table_metadata_enabled            | <span class="literal">false</span>           |</span><br><span class="line">| kernel_executor_size                    | 0               |</span><br><span class="line">| load_table_metadata_batch_size          | 1000            |</span><br><span class="line">| max_connections_size_per_query          | 1               |</span><br><span class="line">| proxy_backend_query_fetch_size          | -1              |</span><br><span class="line">| proxy_default_port                      | 3307            |</span><br><span class="line">| proxy_frontend_database_protocol_type   |                 |</span><br><span class="line">| proxy_frontend_executor_size            | 0               |</span><br><span class="line">| proxy_frontend_flush_threshold          | 128             |</span><br><span class="line">| proxy_frontend_max_connections          | 0               |</span><br><span class="line">| proxy_frontend_ssl_cipher               |                 |</span><br><span class="line">| proxy_frontend_ssl_enabled              | <span class="literal">false</span>           |</span><br><span class="line">| proxy_frontend_ssl_version              | TLSv1.2,TLSv1.3 |</span><br><span class="line">| proxy_meta_data_collector_enabled       | <span class="literal">false</span>           |</span><br><span class="line">| proxy_netty_backlog                     | 1024            |</span><br><span class="line">| sql_show                                | <span class="literal">true</span>            |</span><br><span class="line">| sql_simple                              | <span class="literal">false</span>           |</span><br><span class="line">| system_log_level                        | INFO            |</span><br><span class="line">| system_schema_metadata_assembly_enabled | <span class="literal">true</span>            |</span><br><span class="line">+-----------------------------------------+-----------------+</span><br></pre></td></tr></table></figure><h3 id="分布式事务配置">分布式事务配置</h3><ul class="lvl-0"><li class="lvl-2"><p>配置文件中的配置</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">transaction:</span></span><br><span class="line">  <span class="attr">defaultType:</span> <span class="string">XA</span></span><br><span class="line">  <span class="attr">providerType:</span> <span class="string">Atomikos</span></span><br></pre></td></tr></table></figure><h4 id="DistSQL-语法-2">DistSQL 语法</h4><ul class="lvl-0"><li class="lvl-2"><p>查看事务规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/show-transaction-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW TRANSACTION RULE;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改事务规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/alter-transaction-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ALTER TRANSACTION RULE(</span><br><span class="line">  DEFAULT=<span class="string">&quot;XA&quot;</span>, TYPE(NAME=<span class="string">&quot;Atomikos&quot;</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="规则配置，即database-xxx-yaml中的配置">规则配置，即<code>database-xxx.yaml</code>中的配置</h2><ul class="lvl-0"><li class="lvl-2"><p>以下 DistSQL 仅可以在逻辑库中执行，所以需要先创建一个逻辑数据库</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE sharding_db;</span><br><span class="line">Query OK, 0 rows affected (0.03 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; use sharding_db;</span><br><span class="line">Database changed</span><br></pre></td></tr></table></figure><h3 id="数据源配置">数据源配置</h3><ul class="lvl-0"><li class="lvl-2"><p>在 DistSQL中，官方将数据源叫做<code>存储单元(STORAGE UNIT)</code></p></li><li class="lvl-2"><p>配置文件中的配置</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_0:</span> <span class="comment"># 逻辑数据源名称</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span>  <span class="comment"># 注意这里属性为 url</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">ds_1:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br></pre></td></tr></table></figure><h4 id="DistSQL-语法-3">DistSQL 语法</h4><ul class="lvl-0"><li class="lvl-2"><p>注册存储单元，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/register-storage-unit/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">REGISTER STORAGE UNIT ds_0 (</span><br><span class="line">    URL=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class="line">    USER=<span class="string">&quot;root&quot;</span>,</span><br><span class="line">    PASSWORD=<span class="string">&quot;newpwd&quot;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">REGISTER STORAGE UNIT ds_1 (</span><br><span class="line">    URL=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class="line">    USER=<span class="string">&quot;root&quot;</span>,</span><br><span class="line">    PASSWORD=<span class="string">&quot;newpwd&quot;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查询存储单元，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/storage-unit-query/show-storage-units/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW STORAGE UNITS FROM sharding_db \G;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改存储单元，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/alter-storage-unit/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ALTER STORAGE UNIT ds_1 (</span><br><span class="line">    URL=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class="line">    USER=<span class="string">&quot;root&quot;</span>,</span><br><span class="line">    PASSWORD=<span class="string">&quot;newpwd&quot;</span>,</span><br><span class="line">    PROPERTIES(<span class="string">&quot;maximumPoolSize&quot;</span>=10,<span class="string">&quot;idleTimeout&quot;</span>=30000)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>取消注册存储单元，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/unregister-storage-unit/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 无法移除已经被规则使用的存储单元</span></span><br><span class="line">UNREGISTER STORAGE UNIT ds_0;</span><br></pre></td></tr></table></figure><h3 id="单表配置">单表配置</h3><ul class="lvl-0"><li class="lvl-2"><p>配置文件中的配置</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SINGLE</span> <span class="comment"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="comment"># MySQL 风格</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ds_0.t_address</span> <span class="comment"># 加载指定单表</span></span><br></pre></td></tr></table></figure><h4 id="DistSQL-语法-4">DistSQL 语法</h4><ul class="lvl-0"><li class="lvl-2"><p>加载单表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/load-single-table/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查询单表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/single-table/show-single-table/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW SINGLE TABLES;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>卸载单表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/unload-single-table/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UNLOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure><h3 id="广播表配置">广播表配置</h3><ul class="lvl-0"><li class="lvl-2"><p>广播表，即所有数据源都包含的表，比如字典表</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!BROADCAST</span>  <span class="comment"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">dict</span>    <span class="comment"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br></pre></td></tr></table></figure><h4 id="DistSQL-语法-5">DistSQL 语法</h4><ul class="lvl-0"><li class="lvl-2"><p>创建广播表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/create-broadcast-table-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除广播表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/drop-broadcast-table-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查询广播表，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/broadcast-table/show-broadcast-table-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询当前逻辑库中具有广播规则的表</span></span><br><span class="line">SHOW BROADCAST TABLE RULES;</span><br><span class="line"><span class="comment"># 查询指定数据库中具有广播规则的表</span></span><br><span class="line">SHOW BROADCAST TABLE RULES FROM sharding_db;</span><br></pre></td></tr></table></figure><h3 id="分库分表配置">分库分表配置</h3><h4 id="单分片键，Long-类型">单分片键，Long 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">course:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class="comment"># 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">cid</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_inline</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">cid</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">course_inline:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span> <span class="comment"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 属性</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">course_$&#123;cid</span> <span class="string">%</span> <span class="number">2</span> <span class="string">+</span> <span class="number">1</span><span class="string">&#125;</span> <span class="comment"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class="line">          <span class="attr">allow-range-query-with-inline-sharding:</span> <span class="literal">true</span> <span class="comment"># 允许范围查询</span></span><br><span class="line">      <span class="attr">course_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span> <span class="comment"># 表示 ds_0, ds_1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-6">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建分片规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/create-sharding-table-rule/#1%E6%A0%87%E5%87%86%E5%88%86%E7%89%87%E8%A7%84%E5%88%99">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE SHARDING TABLE RULE course (</span><br><span class="line">  DATANODES(<span class="string">&quot;ds_<span class="variable">$&#123;0..1&#125;</span>.course_<span class="variable">$&#123;1..2&#125;</span>&quot;</span>),</span><br><span class="line">  DATABASE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;ds_<span class="variable">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class="line">  TABLE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=cid,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;course_<span class="variable">$&#123;cid % 2 + 1&#125;</span>&quot;</span>,<span class="string">&quot;allow-range-query-with-inline-sharding&quot;</span>=<span class="literal">true</span> )))),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=cid,TYPE(NAME=<span class="string">&quot;snowflake&quot;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h4 id="单分片键，String-类型">单分片键，String 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">t_user:</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span>  <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">id</span> <span class="comment"># 自增列名称，字符串类型</span></span><br><span class="line"><span class="comment">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">custom_snowflake_string</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">t_user_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span> <span class="comment"># 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算</span></span><br><span class="line">      <span class="attr">t_user_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span> <span class="comment"># 分表，t_user_0, t_user_1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式序列算法</span></span><br><span class="line">      <span class="attr">uuid:</span>    <span class="comment"># 定义名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">UUID</span> <span class="comment"># 字符串主键，String</span></span><br><span class="line">      <span class="attr">custom_snowflake_string:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CUSTOM_SNOWFLAKE_STRING</span> <span class="comment"># 自定义雪花算法，String，spi</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">workerId:</span> <span class="number">2</span></span><br><span class="line">          <span class="attr">datacenterId:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-7">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建分片规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE SHARDING TABLE RULE t_user (</span><br><span class="line">  DATANODES(<span class="string">&quot;ds_<span class="variable">$&#123;0..1&#125;</span>.t_user_<span class="variable">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class="line">  DATABASE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class="built_in">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;ds_<span class="variable">$&#123;Math.abs(id.hashCode()%2)&#125;</span>&quot;</span>)))),</span><br><span class="line">  TABLE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class="built_in">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;t_user_<span class="variable">$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span>&quot;</span>)))),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=<span class="built_in">id</span>,TYPE(NAME=<span class="string">&quot;CUSTOM_SNOWFLAKE_STRING&quot;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h4 id="多分片键，Long-类型">多分片键，Long 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">t_order_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order-complex-algorithm</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span>  <span class="comment"># 分片列名称,多个逗号分隔</span></span><br><span class="line"><span class="comment">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_item-class-based-algorithm_spi</span> <span class="comment"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">t_order_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order-complex-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">COMPLEX_INLINE</span> <span class="comment"># 基于行表达式的复合分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_order_complex_$&#123;(user_id</span> <span class="string">+</span> <span class="string">order_id</span> <span class="string">+</span> <span class="number">1</span><span class="string">)</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm_spi:</span> <span class="comment"># SPI</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">T_ORDER_ITEM_COMPLEX</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-8">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建分片规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE SHARDING TABLE RULE t_order_complex (</span><br><span class="line">  DATANODES(<span class="string">&quot;ds_<span class="variable">$&#123;0..1&#125;</span>.t_order_complex_<span class="variable">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class="line">  DATABASE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;ds_<span class="variable">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class="line">  TABLE_STRATEGY(TYPE=<span class="string">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;complex_inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;t_order_complex_<span class="variable">$&#123;(user_id + order_id + 1) % 2&#125;</span>&quot;</span>)))),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class="string">&quot;snowflake&quot;</span>))</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE SHARDING TABLE RULE t_order_item_complex (</span><br><span class="line">  DATANODES(<span class="string">&quot;ds_<span class="variable">$&#123;0..1&#125;</span>.t_order_item_complex_<span class="variable">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class="line">  DATABASE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;ds_<span class="variable">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class="line">  TABLE_STRATEGY(TYPE=<span class="string">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class="string">&quot;SNOWFLAKE&quot;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h4 id="自动分片规则">自动分片规则</h4><ul class="lvl-0"><li class="lvl-2"><p>上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">   <span class="comment"># 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致</span></span><br><span class="line">    <span class="attr">bindingTables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">t_order,t_order_item</span></span><br><span class="line">    <span class="attr">autoTables:</span> <span class="comment"># 自动分片规则配置</span></span><br><span class="line">      <span class="attr">t_order:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">mod_2:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MOD</span> <span class="comment"># 基于 MOD 的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">sharding-count:</span> <span class="number">2</span> <span class="comment"># 分片数量，即 对 2 进行取余</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-9">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建分片规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CREATE SHARDING TABLE RULE t_order (</span><br><span class="line">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class="line">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class="string">&quot;mod&quot;</span>,PROPERTIES(<span class="string">&quot;sharding-count&quot;</span>=<span class="string">&quot;2&quot;</span>)),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class="string">&quot;snowflake&quot;</span>))</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE SHARDING TABLE RULE t_order_item (</span><br><span class="line">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class="line">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class="string">&quot;mod&quot;</span>,PROPERTIES(<span class="string">&quot;sharding-count&quot;</span>=<span class="string">&quot;2&quot;</span>)),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class="string">&quot;snowflake&quot;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h4 id="其它分片操作语句">其它分片操作语句</h4><ul class="lvl-0"><li class="lvl-2"><p>查询分片规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/sharding/show-sharding-table-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前逻辑库下的所有分片规则</span></span><br><span class="line">SHOW SHARDING TABLE RULES \G;</span><br><span class="line"><span class="comment"># 查看指定逻辑库下的分片规则</span></span><br><span class="line">SHOW SHARDING TABLE RULES FROM sharding_db; \G;</span><br><span class="line"><span class="comment"># 查看指定分片规则</span></span><br><span class="line">SHOW SHARDING TABLE RULE t_user \G;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改分片规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/alter-sharding-table-rule/">官网文档</a>，与创建分片规则类似，将<code>CREATE</code>改为<code>ALTER</code>即可</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ALTER SHARDING TABLE RULE t_order_item_complex (</span><br><span class="line">  DATANODES(<span class="string">&quot;ds_<span class="variable">$&#123;0..1&#125;</span>.t_order_item_complex_<span class="variable">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class="line">  DATABASE_STRATEGY(TYPE=<span class="string">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;inline&quot;</span>,PROPERTIES(<span class="string">&quot;algorithm-expression&quot;</span>=<span class="string">&quot;ds_<span class="variable">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class="line">  TABLE_STRATEGY(TYPE=<span class="string">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class="string">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class="line">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class="string">&quot;SNOWFLAKE&quot;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除分片规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/drop-sharding-table-rule/">官网文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DROP SHARDING TABLE RULE t_order;</span><br><span class="line"><span class="comment"># 删除多个表</span></span><br><span class="line">DROP SHARDING TABLE RULE t_order,t_order_item;</span><br></pre></td></tr></table></figure><h3 id="数据加密规则">数据加密规则</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!ENCRYPT</span>    <span class="comment"># 数据加密配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 加密表名称</span></span><br><span class="line">        <span class="attr">columns:</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 加密列名称</span></span><br><span class="line">            <span class="attr">cipher:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">password</span> <span class="comment"># 密文列名称</span></span><br><span class="line">              <span class="attr">encryptorName:</span> <span class="string">aes_encryptor</span> <span class="comment"># 密文列加密算法名称</span></span><br><span class="line">    <span class="comment"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class="line">    <span class="attr">encryptors:</span></span><br><span class="line">      <span class="attr">aes_encryptor:</span> <span class="comment"># 加解密算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">AES</span> <span class="comment"># 加解密算法类型</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 加解密算法属性配置</span></span><br><span class="line">          <span class="attr">aes-key-value:</span> <span class="string">123456abc</span>     <span class="comment"># AES 使用的 KEY</span></span><br><span class="line">          <span class="attr">digest-algorithm-name:</span> <span class="string">SHA-1</span> <span class="comment"># AES KEY 的摘要算法</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-10">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建加密规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/encrypt/create-encrypt-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE ENCRYPT RULE t_user (</span><br><span class="line">COLUMNS(</span><br><span class="line">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class="string">&#x27;AES&#x27;</span>,PROPERTIES(<span class="string">&#x27;aes-key-value&#x27;</span>=<span class="string">&#x27;123456abc&#x27;</span>, <span class="string">&#x27;digest-algorithm-name&#x27;</span>=<span class="string">&#x27;SHA-1&#x27;</span>))))</span><br><span class="line">));</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改加密规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ALTER ENCRYPT RULE t_user (</span><br><span class="line">COLUMNS(</span><br><span class="line">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class="string">&#x27;AES&#x27;</span>,PROPERTIES(<span class="string">&#x27;aes-key-value&#x27;</span>=<span class="string">&#x27;123456abc&#x27;</span>, <span class="string">&#x27;digest-algorithm-name&#x27;</span>=<span class="string">&#x27;SHA-1&#x27;</span>))))</span><br><span class="line">));</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除加密规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP ENCRYPT RULE t_user;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查询加密规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/encrypt/show-encrypt-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询当前逻辑库中所有加密规则</span></span><br><span class="line">SHOW ENCRYPT RULES \G;</span><br><span class="line"><span class="comment"># 获取指定逻辑库中的加密规则</span></span><br><span class="line">SHOW ENCRYPT RULES FROM sharding_db \G;</span><br><span class="line"><span class="comment"># 获取指定逻辑表中的加密规则</span></span><br><span class="line">SHOW ENCRYPT RULE t_user \G;</span><br></pre></td></tr></table></figure><h3 id="数据脱敏规则">数据脱敏规则</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!MASK</span>  <span class="comment"># 数据脱敏配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 脱敏表名称</span></span><br><span class="line">        <span class="attr">columns:</span>  <span class="comment"># 脱敏列配置</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 脱敏列名称</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">md5_mask</span> <span class="comment"># 脱敏算法名称</span></span><br><span class="line">          <span class="attr">email:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">mask_before_special_chars_mask</span></span><br><span class="line">          <span class="attr">telephone:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">keep_first_n_last_m_mask</span></span><br><span class="line">          <span class="attr">name:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">my_mask</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">maskAlgorithms:</span> <span class="comment"># 脱敏算法配置</span></span><br><span class="line">      <span class="attr">md5_mask:</span> <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span>  <span class="comment"># 脱敏算法类型，md5加密后展示</span></span><br><span class="line">      <span class="attr">mask_before_special_chars_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MASK_BEFORE_SPECIAL_CHARS</span> <span class="comment"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">special-chars:</span> <span class="string">&#x27;@&#x27;</span>  <span class="comment"># 遇到 @ 之前的部分做脱敏</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span>   <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">keep_first_n_last_m_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">KEEP_FIRST_N_LAST_M</span> <span class="comment"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">first-n:</span> <span class="number">3</span>     <span class="comment"># 保留前 3 位</span></span><br><span class="line">          <span class="attr">last-m:</span> <span class="number">4</span>      <span class="comment"># 保留后 4 位</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span> <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">my_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MY_CUSTOM_MASK</span>  <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&quot;#&quot;</span></span><br></pre></td></tr></table></figure><h5 id="DistSQL-语法-11">DistSQL 语法</h5><ul class="lvl-0"><li class="lvl-2"><p>创建脱敏规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/mask/create-mask-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE MASK RULE t_user (</span><br><span class="line">  COLUMNS(</span><br><span class="line">    (NAME=password, TYPE(NAME=<span class="string">&#x27;MD5&#x27;</span>)),</span><br><span class="line">    (NAME=email, TYPE(NAME=<span class="string">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class="string">&quot;special-chars&quot;</span>=<span class="string">&quot;@&quot;</span>,  <span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;*&quot;</span>))),</span><br><span class="line">    (NAME=telephone, TYPE(NAME=<span class="string">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class="string">&quot;first-n&quot;</span>=3, <span class="string">&quot;last-m&quot;</span>=4, <span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;*&quot;</span>))),</span><br><span class="line">    (NAME=`name`, TYPE(NAME=<span class="string">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;#&quot;</span>)))</span><br><span class="line">  )</span><br><span class="line">);</span><br><span class="line"><span class="comment"># 这里注意 name 是关键字，所以需要用 `` 包起来</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>修改脱敏规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ALTER MASK RULE t_user (</span><br><span class="line">  COLUMNS(</span><br><span class="line">    (NAME=password, TYPE(NAME=<span class="string">&#x27;MD5&#x27;</span>)),</span><br><span class="line">    (NAME=email, TYPE(NAME=<span class="string">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class="string">&quot;special-chars&quot;</span>=<span class="string">&quot;@&quot;</span>,  <span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;*&quot;</span>))),</span><br><span class="line">    (NAME=telephone, TYPE(NAME=<span class="string">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class="string">&quot;first-n&quot;</span>=3, <span class="string">&quot;last-m&quot;</span>=4, <span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;*&quot;</span>))),</span><br><span class="line">    (NAME=`name`, TYPE(NAME=<span class="string">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class="string">&quot;replace-char&quot;</span>=<span class="string">&quot;#&quot;</span>)))</span><br><span class="line">  )</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>删除脱敏规则</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP MASK RULE t_user;</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>查询脱敏规则，<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/mask/show-mask-rule/">官方文档</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询当前逻辑库中所有脱敏规则</span></span><br><span class="line">SHOW MASK RULES;</span><br><span class="line"><span class="comment"># 仅查询指定逻辑库中的脱敏规则</span></span><br><span class="line">SHOW MASK RULES FROM sharding_db;</span><br><span class="line"><span class="comment"># 查询指定规则</span></span><br><span class="line">mysql&gt; SHOW MASK RULE t_user;</span><br><span class="line">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class="line">| table  | column    | algorithm_type            | algorithm_props                                 |</span><br><span class="line">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class="line">| t_user | password  | MD5                       |                                                 |</span><br><span class="line">| t_user | email     | MASK_BEFORE_SPECIAL_CHARS | &#123;<span class="string">&quot;replace-char&quot;</span>:<span class="string">&quot;*&quot;</span>,<span class="string">&quot;special-chars&quot;</span>:<span class="string">&quot;@&quot;</span>&#125;        |</span><br><span class="line">| t_user | telephone | KEEP_FIRST_N_LAST_M       | &#123;<span class="string">&quot;first-n&quot;</span>:<span class="string">&quot;3&quot;</span>,<span class="string">&quot;last-m&quot;</span>:<span class="string">&quot;4&quot;</span>,<span class="string">&quot;replace-char&quot;</span>:<span class="string">&quot;*&quot;</span>&#125; |</span><br><span class="line">| t_user | name      | MY_CUSTOM_MASK            | &#123;<span class="string">&quot;replace-char&quot;</span>:<span class="string">&quot;#&quot;</span>&#125;                            |</span><br><span class="line">+--------+-----------+---------------------------+-------------------------------------------------+</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/index_zh.html&quot;&gt;ShardingSphere官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/sharding-sphere/"/>
    
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/tags/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/tags/sharding-sphere/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot3 + ShardingSphere-Proxy5.5.2 运行模式</title>
    <link href="https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/"/>
    <id>https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/</id>
    <published>2025-09-10T13:30:05.000Z</published>
    <updated>2025-09-15T06:26:28.238Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。</p></li><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/index_zh.html">ShardingSphere官网</a></p></li><li class="lvl-2"><p>本文在 <a href="/2025/09/04/springboot3-shardingsphere-proxy/" title="SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 的基础上进行修改。</p></li></ul><span id="more"></span><h2 id="运行模式说明">运行模式说明</h2><ul class="lvl-0"><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/document/5.5.2/cn/dev-manual/mode/">运行模式</a></p></li><li class="lvl-2"><p>ShardingSphere-Proxy 运行模式分为两种：单机模式(Standalone) 和 集群模式(Cluster)。</p></li><li class="lvl-2"><p>运行模式就是指定将<code>元数据</code>(认证、数据源、分片规则等等)持久化的存储方式。</p></li><li class="lvl-2"><p>默认运行模式为单机模式，使用<code>H2</code>的内存方式。</p></li></ul><h2 id="单机模式-Standalone">单机模式(Standalone)</h2><ul class="lvl-0"><li class="lvl-2"><p>单机模式能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知。 通过某一实例更新元数据之后，会导致其他实例由于获取不到最新的元数据而产生不一致的错误。</p></li><li class="lvl-2"><p>适用于工程师在本地搭建 Apache ShardingSphere 环境。</p></li><li class="lvl-2"><p>单机模式目前仅支持一种：JDBC，即数据库持久化。以下为默认值(<code>JDBCRepositoryPropertyKey</code>)。</p></li></ul><table><thead><tr><th>名称</th><th>数据类型</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>provider</td><td>String</td><td>元数据存储类型，可选值为 <code>H2</code>、<code>MySQL</code> 、<code>EmbeddedDerby</code>、<code>DerbyNetworkServer</code>、<code>HSQLDB</code></td><td>H2</td></tr><tr><td>jdbc_url</td><td>String</td><td>JDBC URL</td><td><code>jdbc:h2:mem:config;DB_CLOSE_DELAY=0;DATABASE_TO_UPPER=false;MODE=MYSQL</code></td></tr><tr><td>username</td><td>String</td><td>账号</td><td>sa</td></tr><tr><td>password</td><td>String</td><td>密码</td><td>空（无默认值）</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>这里以 Mysql 存储元数据为例，相关属性参考<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#jdbc-%E6%8C%81%E4%B9%85%E5%8C%96">官网说明</a></p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mode:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Standalone</span></span><br><span class="line">  <span class="attr">repository:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">JDBC</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">provider:</span> <span class="string">MySQL</span></span><br><span class="line">      <span class="attr">jdbc_url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">newpwd</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>此时需要将 mysql 的驱动 jar 包 添加到 <code>ext-lib</code> 目录下</p></li><li class="lvl-2"><p>启动 ShardingSphere Proxy 成功后会自动在上面的数据库中创建一张表，并将配置文件的中的元数据存储进去</p></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `repository` (</span><br><span class="line">  `id` <span class="type">varchar</span>(<span class="number">36</span>) <span class="keyword">COLLATE</span> utf8mb4_bin <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `key` text <span class="keyword">COLLATE</span> utf8mb4_bin,</span><br><span class="line">  `<span class="keyword">value</span>` text <span class="keyword">COLLATE</span> utf8mb4_bin,</span><br><span class="line">  `parent` text <span class="keyword">COLLATE</span> utf8mb4_bin,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 <span class="keyword">COLLATE</span><span class="operator">=</span>utf8mb4_bin;</span><br></pre></td></tr></table></figure><h3 id="重点说明">重点说明</h3><ul class="lvl-0"><li class="lvl-2"><p>当数据库中不存在该表时，会自动创建该表，并将配置文件的元数据插入该表中。</p></li><li class="lvl-2"><p>当数据库中已存在该表时，会读取该表中的数据并将其加载到内存，而不会读取配置文件中的元数据。即此时配置文件中的元数据不会生效。</p></li><li class="lvl-2"><p>若此时想修改配置规则，有三种方法：</p><ul class="lvl-2"><li class="lvl-4">1.删除该表，修改配置文件后重新启动Proxy，此时会重新创建该表并加载配置文件中的元数据。</li><li class="lvl-4">2.手工修改数据表中的元数据，但修改后需要重新启动Proxy才会加载新的元数据。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li><li class="lvl-4">3.<code>[推荐]</code>登录逻辑数据库后，使用 <a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/">DistSQL</a> 动态修改配置，修改后的配置会被保存在该表中，并立即生效，无需重启Proxy。</li></ul></li><li class="lvl-2"><p>开发和测试环境可以直接使用默认的 H2 内存数据库，生产环境可以使用 MySQL等数据库对元数据进行持久化保存或者使用下面的集群模式。</p></li></ul><h2 id="集群模式-Cluster">集群模式(Cluster)</h2><ul class="lvl-0"><li class="lvl-2"><p>集群模式提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调的能力。 它能够提供计算能力水平扩展和高可用等分布式系统必备的能力，集群环境需要通过独立部署的注册中心来存储元数据和协调节点状态。</p></li><li class="lvl-2"><p>在生产环境建议使用集群模式。</p></li><li class="lvl-2"><p>这里以 zookeeper 集群模式为例，相关属性参考<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#zookeeper-%E6%8C%81%E4%B9%85%E5%8C%96">官网说明</a></p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mode:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Cluster</span>                 <span class="comment"># 运行模式，默认是单机模式 Standalone</span></span><br><span class="line">  <span class="attr">repository:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">ZooKeeper</span>             <span class="comment"># 注册中心类型，当前版本仅支持 ZooKeeper 和 etcd</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">governance_ds</span>  <span class="comment"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class="line">      <span class="attr">server-lists:</span> <span class="string">localhost:2181</span> <span class="comment"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class="line">      <span class="attr">retryIntervalMilliseconds:</span> <span class="number">500</span> <span class="comment"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class="line">      <span class="attr">timeToLiveSeconds:</span> <span class="number">60</span>     <span class="comment"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class="line">      <span class="attr">maxRetries:</span> <span class="number">3</span>             <span class="comment"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class="line">      <span class="attr">operationTimeoutMilliseconds:</span> <span class="number">500</span>  <span class="comment"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br></pre></td></tr></table></figure><h3 id="重点说明-2">重点说明</h3><ul class="lvl-0"><li class="lvl-2"><p>不要手工修改 Zookeeper 集群中的 namespace 下的配置信息!</p></li><li class="lvl-2"><p>既然是集群，就需要多个 ShardingSphere-Proxy 实例。 当第一个 ShardingSphere-Proxy 实例 启动后，其它相同配置的 ShardingSphere-Proxy 实例仅需要一个 <code>global.yaml</code> 全局配置文件即可，并仅需在其中配置上面的<code>运行模式</code>信息，而不需要再配置其它配置，比如认证、数据源、分片规则等信息，这些信息会通过 Zookeeper 集群中的 namespace 获取并保存到本地内存中。</p></li><li class="lvl-2"><p>每个 ShardingSphere-Proxy 实例启动时，都会自动将自己注册到 Zookeeper 集群中指定的 namespace 下，并自动获取该 namespace 下的配置信息。</p></li><li class="lvl-2"><p>当 Zookeeper 集群中不存在指定的 namespace 时，此时第一次启动 ShardingSphere-Proxy 会自动在 Zookeeper 中创建 namespace，并写入配置文件中的配置信息到 Zookeeper 中。</p></li><li class="lvl-2"><p>当 Zookeeper 集群中已存在指定的 namespace 时，此时再启动 ShardingSphere-Proxy 会自动从 Zookeeper 中读取 namespace 下的配置信息，并将其加载到内存中，不会再读取本地配置文件中的配置信息。</p></li><li class="lvl-2"><p>当 Zookeeper 集群中已存在指定的 namespace 时，根据上面的规则，此时修改本地的配置文件中的分片规则后重启ShardingSphere-Proxy 并不会生效。</p><ul class="lvl-2"><li class="lvl-4">此时有三种方法：<ul class="lvl-4"><li class="lvl-6"><ol><li class="lvl-9">删除 Zookeeper 集群中指定的 namespace，然后重启 ShardingSphere-Proxy。这种方法有个弊端，即会导致连接到相同 ZooKeeper 集群的 namespace 的其它 ShardingSphere-Proxy 实例数据丢失(完全不可用)，也需要重启才能重新获取到数据。</li></ol></li><li class="lvl-6"><ol start="2"><li class="lvl-9">手工修改 Zookeeper 集群中指定的 namespace 下的分片规则，修改后会立即同步到所有 ShardingSphere-Proxy 实例。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li></ol></li><li class="lvl-6"><ol start="3"><li class="lvl-9"><code>[推荐]</code>登录逻辑数据库后，使用 <a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/">DistSQL</a> 动态修改配置，此时会自动同步到所有 ShardingSphere-Proxy 实例。所以，灵活掌握 <code>DistSQL</code> 是维护 ShardingSphere-Proxy 集群的关键。</li></ol></li></ul></li></ul></li><li class="lvl-2"><p>多个 ShardingSphere-Proxy 实例 可以通过负载均衡器，比如 Nginx，将请求路由到不同的 ShardingSphere-Proxy 实例。比如：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">stream&#123;</span><br><span class="line">    upstream shardingsphere_proxy&#123;</span><br><span class="line">        server  10.10.21.35:3307;</span><br><span class="line">        server  10.10.21.36:3307;</span><br><span class="line">    &#125;</span><br><span class="line">    server&#123;</span><br><span class="line">        listen 3310;</span><br><span class="line">        proxy_connect_timeout 20s;</span><br><span class="line">        proxy_timeout 5m;</span><br><span class="line">        proxy_pass shardingsphere_proxy;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="与-Spring-Boot3-整合">与 Spring Boot3 整合</h2><ul class="lvl-0"><li class="lvl-2"><p>无论是 <code>单机模式</code> 还是 <code>集群模式</code>，其目的都是将 <code>配置</code> 保存到独立的 <code>配置中心(数据库 或 Zookeeper)</code>中，并让其它 <code>ShardingSphere-Proxy</code> 实例从该配置中心中读取配置信息。</p></li><li class="lvl-2"><p>前文我们介绍过 <code>Spring Boot3</code> + <code>ShardingSphere-Proxy</code> 就相当于是集成普通的MySql数据库，而 <code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code> 就需要单独在本地配置各种规则。</p></li><li class="lvl-2"><p>实际上 <code>ShardingSphere-JDBC</code> 也可以从 <code>配置中心</code> 中读取配置信息，这样我们就不需要在本地配置任何规则了，我们仅需要在 <code>sharding.yaml</code> 中配置好<code>运行模式</code>，并配置好 <code>databaseName</code> 的名称即可。注意，此时配置中心的的事务不能是 <code>XA</code>，因为<code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code>目前不支持 <code>XA</code> 事务。</p></li><li class="lvl-2"><p>此时，springboot项目启动后会拉取<code>配置中心</code>中的配置信息并将其保存到本地内存，本地配置文件中的其它配置信息会被忽略。<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/G3kESF.png" alt=""></p></li></ul><h3 id="单机模式">单机模式</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-03">代码示例</a></p></li><li class="lvl-2"><p>通过 DistSQL 改规则后，必须重启应用才能生效</p></li><li class="lvl-2"><p>sharding.yaml</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mode:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Standalone</span></span><br><span class="line">  <span class="attr">repository:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">JDBC</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">provider:</span> <span class="string">MySQL</span></span><br><span class="line">      <span class="attr">jdbc_url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"><span class="comment"># 数据库名称，默认值：logic_db</span></span><br><span class="line"><span class="attr">databaseName:</span> <span class="string">sharding_db</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>Maven 依赖</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.hanqf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>algorithm-swapper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="集群模式">集群模式</h3><ul class="lvl-0"><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-04">代码示例</a></p></li><li class="lvl-2"><p>通过 DistSQL 改规则后，立即推送到所有实例，无需重启应用。</p></li><li class="lvl-2"><p>sharding.yaml，注意这里一定要配置 <code>databaseName</code></p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 开启集群模式</span></span><br><span class="line"><span class="attr">mode:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Cluster</span>                 <span class="comment"># 运行模式，默认是单机模式 Standalone</span></span><br><span class="line">  <span class="attr">repository:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">ZooKeeper</span>             <span class="comment"># 注册中心类型</span></span><br><span class="line">    <span class="attr">props:</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">governance_ds</span>  <span class="comment"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class="line">      <span class="attr">server-lists:</span> <span class="string">localhost:2181</span> <span class="comment"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class="line">      <span class="attr">retryIntervalMilliseconds:</span> <span class="number">500</span> <span class="comment"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class="line">      <span class="attr">timeToLiveSeconds:</span> <span class="number">60</span>     <span class="comment"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class="line">      <span class="attr">maxRetries:</span> <span class="number">3</span>             <span class="comment"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class="line">      <span class="attr">operationTimeoutMilliseconds:</span> <span class="number">500</span>  <span class="comment"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class="line"><span class="comment"># 数据库名称，默认值：logic_db</span></span><br><span class="line"><span class="attr">databaseName:</span> <span class="string">sharding_db</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>Maven 依赖，注意要加上 <code>shardingsphere-cluster-mode-repository-zookeeper</code> 的依赖</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.hanqf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>algorithm-swapper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- shardingsphere-cluster-mode-repository-zookeeper --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-cluster-mode-repository-zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="如何选择">如何选择</h3><ul class="lvl-0"><li class="lvl-2"><p>当我使用<code>springboot3+shardingSphere-JDBC5.5.2</code>时，我应该使用本地<code>配置文件</code>的方式还是使用<code>配置中心</code>（比如：zookeeper）的方式呢？</p></li></ul><table><thead><tr><th>方式</th><th>部署复杂度</th><th>配置动态更新</th><th>多实例共享配置</th><th>热更新支持</th><th>适用环境</th></tr></thead><tbody><tr><td>本地配置文件</td><td>简单</td><td>不支持</td><td>不支持</td><td>否</td><td>开发/测试/小型项目</td></tr><tr><td>配置中心（ZooKeeper/etcd）</td><td>略高</td><td>支持</td><td>支持</td><td>是</td><td>生产/分布式环境</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>注意</p><ul class="lvl-2"><li class="lvl-4">DistSQL 目前确实只支持在 ShardingSphere-Proxy 上执行，并且 Proxy 只支持 MySQL 和 PostgreSQL 协议。</li><li class="lvl-4">如果你在 Spring Boot + ShardingSphere-JDBC 里用 其它数据库（比如 SQL Server、Oracle、DB2 等），就无法直接通过 DistSQL 去动态改配置。</li><li class="lvl-4">此时你可以选择通过 Zookeeper 的客户端直接修改或配置规则，也可以不选择 <code>配置中心</code> 的方式，直接使用 <code>本地配置文件</code>。</li></ul></li></ul><h2 id="什么时候需要分库分表">什么时候需要分库分表</h2><ul class="lvl-0"><li class="lvl-2"><p>分库分表的主要目的是 <strong>解决数据量大带来的性能、可用性和可扩展性问题</strong>。通常需要考虑的几个关键指标：</p></li></ul><h3 id="1-数据量指标">1. 数据量指标</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>单表数据量过大</strong>：一般来说，单表数据量在 <strong>千万级</strong> 以上时，查询、写入和索引的性能会明显下降。</p></li><li class="lvl-2"><p>例如：一个订单表一天有上百万条数据，一年下来可能有上亿条，单表性能会成为瓶颈。</p></li></ul><h3 id="2-访问量指标">2. 访问量指标</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>高并发写入或查询</strong>：数据库连接、事务锁、IO 等资源会成为瓶颈。</p></li><li class="lvl-2"><p>如果你的系统每天有上千万的请求，数据库可能无法承受。</p></li></ul><h3 id="3-业务隔离需求">3. 业务隔离需求</h3><ul class="lvl-0"><li class="lvl-2"><p>不同业务的数据分离，避免单个业务影响整个数据库的稳定性。</p></li><li class="lvl-2"><p>例如：电商系统中的订单和日志数据，日志量非常大，和订单分开存储更合理。</p></li></ul><h3 id="4-运营与成本因素">4. 运营与成本因素</h3><ul class="lvl-0"><li class="lvl-2"><p>分库分表后，可以分布到多个数据库实例上，支持 <strong>水平扩展</strong>，而不必依赖昂贵的单机数据库。</p></li></ul><h2 id="使用-ShardingSphere-可能带来的问题">使用 ShardingSphere 可能带来的问题</h2><ul class="lvl-0"><li class="lvl-2"><p>使用 <strong>ShardingSphere</strong> 可以方便地解决分库分表问题，但在实际生产中，它会带来一些新的复杂性和潜在问题，主要体现在性能、运维、功能限制等方面。</p></li></ul><h3 id="1-性能与延迟">1. 性能与延迟</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>跨库 JOIN 性能差</strong><br>分库分表后，跨库的 <code>JOIN</code> 查询会在各个分片上分别执行，然后在 ShardingSphere 层合并结果，性能明显下降。</p><ul class="lvl-2"><li class="lvl-4">例如：订单表在多个库，查询订单 + 用户信息时必须跨库 JOIN，执行效率比单库低很多。</li></ul></li><li class="lvl-2"><p><strong>分页查询慢</strong><br>分库分表后，如果要全局排序 + 分页，需要所有分片查出数据再合并，代价非常大。</p><ul class="lvl-2"><li class="lvl-4">解决方式：使用分片键范围分页，或引入 ElasticSearch/ClickHouse 做搜索和统计。</li></ul></li><li class="lvl-2"><p><strong>广播表压力</strong><br>配置了广播表（每个库一份完整数据）后，更新需要同步所有库，写入性能下降。</p></li></ul><h3 id="2-SQL-兼容性限制">2. SQL 兼容性限制</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>复杂 SQL 支持不完整</strong><br>ShardingSphere 对某些复杂 SQL（如子查询、窗口函数）支持有限，可能报错或性能极差。</p></li><li class="lvl-2"><p><strong>存储过程、触发器受限</strong><br>分库分表后，存储过程、触发器在分片数据库执行可能不一致，维护成本高。</p></li></ul><h3 id="3-分布式事务问题">3. 分布式事务问题</h3><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere 支持 <strong>XA 分布式事务</strong>，但性能不如单机事务，出现网络抖动时可能会卡住。</p></li><li class="lvl-2"><p>如果业务需要强一致性，必须结合可靠消息或 TCC、SAGA 等分布式事务模式，架构会更复杂。</p></li></ul><h3 id="4-运维与管理复杂度">4. 运维与管理复杂度</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>分片规则变更困难</strong><br>例如，最初按 <code>user_id % 2</code> 分成两个库，后续想增加到 4 个库，需要迁移数据，非常麻烦。</p></li><li class="lvl-2"><p><strong>监控与调优</strong><br>ShardingSphere 增加了中间层，SQL 路由、执行计划、数据节点状态都需要额外的监控工具支持。</p></li></ul><h3 id="5-成本与学习曲线">5. 成本与学习曲线</h3><ul class="lvl-0"><li class="lvl-2"><p>配置相对复杂：分片规则、读写分离、分布式事务、弹性扩容都需要仔细设计。</p></li><li class="lvl-2"><p>学习曲线较陡：开发和运维人员必须了解 ShardingSphere 的工作机制，否则定位问题很困难。</p></li></ul><h3 id="6-高可用与扩展问题">6. 高可用与扩展问题</h3><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere-JDBC 是应用内库，无法独立扩展，需要依赖应用扩容。</p></li><li class="lvl-2"><p>ShardingSphere-Proxy 支持集群，但需要自己搭建高可用架构，涉及负载均衡、故障切换等问题。</p></li></ul><h2 id="其它技术方案：分布式数据库">其它技术方案：分布式数据库</h2><ul class="lvl-0"><li class="lvl-2"><p>开源产品: 核心功能完全开源，企业版提供额外商业特性</p></li></ul><table><thead><tr><th>数据库</th><th>架构类型</th><th>SQL 兼容性</th><th>分布式事务支持</th><th>数据存储模型</th><th>主要特点</th><th>典型应用场景</th></tr></thead><tbody><tr><td><strong><a href="https://www.pingcap.com/">TiDB</a></strong></td><td>分布式 HTAP</td><td>MySQL 协议兼容</td><td>支持（Percolator 模型）</td><td>行存 + 列存混合</td><td>开源、云原生、强一致性、弹性扩展</td><td>在线事务处理 + 实时分析</td></tr><tr><td><strong><a href="https://en.oceanbase.com/">OceanBase</a></strong></td><td>分布式关系型数据库</td><td>MySQL/Oracle 兼容</td><td>支持（两阶段提交）</td><td>行存</td><td>高性能、金融级事务、阿里蚂蚁金服核心系统使用</td><td>金融、电商、核心交易系统</td></tr><tr><td><strong><a href="https://www.cockroachlabs.com/">CockroachDB</a></strong></td><td>分布式 NewSQL</td><td>PostgreSQL 兼容</td><td>支持（分布式事务）</td><td>行存</td><td>类 Spanner 架构，全球分布，强一致性</td><td>全球化分布式应用</td></tr><tr><td><strong><a href="https://www.citusdata.com/">Citus</a> (PostgreSQL)</strong></td><td>PostgreSQL 扩展</td><td>PostgreSQL 兼容</td><td>部分支持（基于逻辑分片）</td><td>行存</td><td>基于 PostgreSQL 的分布式扩展，支持大规模 OLAP</td><td>大数据实时分析、BI 场景</td></tr><tr><td><strong><a href="https://vitess.io/">Vitess</a></strong></td><td>分布式中间件 + 存储</td><td>MySQL 协议兼容</td><td>弱事务（最终一致性）</td><td>行存</td><td>YouTube 开源，K8s 友好，分库分表自动化</td><td>大规模 Web 应用，在线服务</td></tr><tr><td><strong><a href="https://www.yugabyte.com/">YugabyteDB</a></strong></td><td>分布式 SQL + NoSQL</td><td>PostgreSQL 兼容</td><td>支持（两阶段提交）</td><td>行存 + 列存混合</td><td>融合 NewSQL 和 NoSQL，强一致性，跨区域部署</td><td>金融级事务 + 分析混合场景</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>商业产品</p></li></ul><table><thead><tr><th>数据库</th><th>架构类型</th><th>SQL 兼容性</th><th>分布式事务支持</th><th>数据存储模型</th><th>主要特点</th><th>典型应用场景</th></tr></thead><tbody><tr><td><strong><a href="https://www.alibabacloud.com/product/polardb">PolarDB</a></strong></td><td>云原生分布式数据库</td><td>MySQL/PostgreSQL 兼容</td><td>支持（云端分布式事务）</td><td>行存</td><td>阿里云产品，弹性扩容，存储计算分离</td><td>云上企业数据库解决方案</td></tr><tr><td><strong><a href="https://www.huaweicloud.com/product/gaussdb.html">GaussDB</a></strong></td><td>分布式关系型数据库</td><td>MySQL/Oracle 兼容</td><td>支持（分布式事务）</td><td>行存 + 列存混合</td><td>华为推出，分布式 HTAP，云原生架构</td><td>企业级 OLTP + OLAP 混合负载</td></tr><tr><td><strong><a href="https://cloud.google.com/spanner">Spanner</a></strong></td><td>全球分布式数据库</td><td>类 SQL</td><td>支持（TrueTime 协议）</td><td>行存</td><td>Google 云产品，全球分布式强一致事务</td><td>全球化分布式事务，金融场景</td></tr><tr><td><strong><a href="https://aws.amazon.com/rds/aurora/">Amazon Aurora</a></strong></td><td>云原生分布式关系型数据库</td><td>MySQL/PostgreSQL 兼容</td><td>支持（单实例事务，多 AZ 高可用）</td><td>行存</td><td>AWS 托管，自动扩展存储，多可用区高可用</td><td>OLTP、企业级业务</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/index_zh.html&quot;&gt;ShardingSphere官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文在 &lt;a href=&quot;/2025/09/04/springboot3-shardingsphere-proxy/&quot; title=&quot;SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表&quot;&gt;SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表&lt;/a&gt; 的基础上进行修改。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/sharding-sphere/"/>
    
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/tags/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/tags/sharding-sphere/"/>
    
  </entry>
  
  <entry>
    <title>Maven 私服 Nexus 升级实录</title>
    <link href="https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/"/>
    <id>https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/</id>
    <published>2025-09-08T13:30:05.000Z</published>
    <updated>2025-09-15T06:26:27.872Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 Mavne 私服 Nexus 升级的全过程，从 <code>3.29.2-02</code> 升级到 <code>3.83.2-01</code></p></li><li class="lvl-2"><p><a href="https://help.sonatype.com/en/sonatype-nexus-repository.html">Nexus官网</a></p></li><li class="lvl-2"><p><a href="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/">OpenJdk下载地址</a></p></li><li class="lvl-2"><p><a href="https://help.sonatype.com/en/sonatype-nexus-repository-system-requirements.html">Nexus系统配置要求</a></p></li></ul><span id="more"></span><h2 id="升级过程说明">升级过程说明</h2><ul class="lvl-0"><li class="lvl-2"><p>Nexus 从 <code>3.71.x</code> 开始，不再支持 <code>OrientDB</code>，后续版本仅支持 <code>H2</code> 和 <code>PostgreSQL</code> ，根据<a href="https://help.sonatype.com/en/upgrading-to-nexus-repository-3-71-0-and-beyond.html">官网说明</a>，<code>3.70.x</code> 以下的版本需要将 Nexus 先升级到 <code>3.70.x</code> 的最新版本，然后使用官方提供的数据库迁移工具，将数据库迁移到 <code>H2</code> 后，再升级到 <code>3.71.x</code> 以后的版本</p></li></ul><h2 id="从-3-29-2-02-升级到-nexus-3-70-4-02">从 <code>3.29.2-02</code> 升级到 <code>nexus-3.70.4-02</code></h2><h3 id="安装-OpenJDK">安装 <code>OpenJDK</code></h3><ul class="lvl-0"><li class="lvl-2"><p>需要先安装好 <code>OpenJDK</code>，原因是<code>Nexus的数据库迁移工具</code>仅支持 <code>OpenJDK</code>，不支持 <code>Oracle JDK</code>，我这里选择安装 <code>OpenJDK11</code></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line">curl -O https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class="line">tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/jdk-11.0.28+6/bin/java /usr/bin/java</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk-11.0.28+6</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h3 id="安装-nexus-3-70-x">安装 <code>nexus-3.70.x</code></h3><ul class="lvl-0"><li class="lvl-2"><p>目前官网发布的<code>nexus-3.70.x</code>的最新版本为 <code>nexus-3.70.4-02</code>，<a href="https://help.sonatype.com/en/orientdb-downloads.html">下载页面</a>，其对应的数据库迁移工具也可以从该页面下载。</p></li><li class="lvl-2"><p>这里我们选择 <a href="https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz">Java 11 的版本</a>，升级安装与第一次安装方式一样。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到 nexus 用户，原 nexus-3.29.2-02 就安装在 该用户的 `home` 目录下</span></span><br><span class="line">su - nexus</span><br><span class="line"><span class="comment"># 关闭 原 nexus 服务，关于如何将 Nexus 配置为系统服务，可以参考：https://help.sonatype.com/en/run-as-a-service.html</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl stop nexus</span><br><span class="line"><span class="comment">#~/nexus3/bin/nexus stop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要科学上网</span></span><br><span class="line">curl -O https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class="line">tar -zxvf nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class="line"><span class="built_in">rm</span> -f ~/nexus3</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/nexus-3.70.4-02 ~/nexus3</span><br><span class="line"><span class="comment"># 启动 nexus</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl start nexus</span><br><span class="line"><span class="comment"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure><h3 id="迁移数据到-H2">迁移数据到 H2</h3><ul class="lvl-0"><li class="lvl-2"><p>下载数据库迁移工具</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> ~/backup</span><br><span class="line"><span class="built_in">cd</span> ~/backup</span><br><span class="line"><span class="comment"># 与 nexus 版本一致</span></span><br><span class="line">curl -O https://download.sonatype.com/nexus/nxrm3-migrator/nexus-db-migrator-3.70.4-02.jar</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>登录 Nexus 导出数据: 设置 -&gt; System -&gt; Tasks -&gt; Create task -&gt; Admin - Export databases for backup<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MS26e5.png" alt=""></p></li><li class="lvl-2"><p>任务创建后点击<code>Run</code>，即可在 <code>/home/nexus/backup</code> 目录下看到备份文件</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ll /home/nexus/backup</span><br><span class="line">-rw-rw-r-- 1 nexus nexus   121066 Sep  8 07:25 analytics-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class="line">-rw-rw-r-- 1 nexus nexus 19349428 Sep  8 07:25 component-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class="line">-rw-rw-r-- 1 nexus nexus   266208 Sep  8 07:25 config-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class="line">-rw-r--r-- 1 nexus nexus 56809625 Sep  8 06:41 nexus-db-migrator-3.70.4-02.jar</span><br><span class="line">-rw-rw-r-- 1 nexus nexus   132802 Sep  8 07:25 security-2025-09-08-07-25-57-3.70.4-02.bak</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>使用迁移工具生成H2数据库文件，官网参考资料: <a href="https://help.sonatype.com/en/migrating-to-a-new-database.html#migrating-from-orientdb-to-h2">Migrating From OrientDB to H2</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始迁移前需要先关闭 nexus 服务</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl stop nexus</span><br><span class="line"><span class="comment"># ~/nexus3/bin/nexus stop</span></span><br><span class="line"><span class="comment"># 进入备份目录</span></span><br><span class="line"><span class="built_in">cd</span> /home/nexus/backup</span><br><span class="line"><span class="comment"># 这里要使用 OpenJDK 11 运行，根据需要适当调整内存参数</span></span><br><span class="line">java -Xmx2G -Xms2G -XX:+UseG1GC -jar nexus-db-migrator-3.70.4-02.jar --migration_type=h2</span><br><span class="line"><span class="comment"># 运行后会提示你迁移数据库前需要先关闭 nexus 服务，我们输入 y 继续</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>运行成功后会生成 <code>nexus.mv.db</code>，将其移动到 <code>/home/nexus/sonatype-work/nexus3/db/</code> 目录下</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> nexus.mv.db /home/nexus/sonatype-work/nexus3/db/</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>编辑<code>/home/nexus/sonatype-work/nexus3/etc/nexus.properties</code> 文件，添加如下内容</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># enable db h2</span></span><br><span class="line">nexus.datastore.enabled=<span class="literal">true</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>启动 nexus，此时我们就完成了 从 <code>3.29.2-02</code> 到 <code>nexus-3.70.4-02</code> 的升级</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start nexus</span><br><span class="line"><span class="comment"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure><h2 id="从-nexus-3-70-4-02-升级到-nexus-3-83-2-01">从 <code>nexus-3.70.4-02</code> 升级到 <code>nexus-3.83.2-01</code></h2><ul class="lvl-0"><li class="lvl-2"><p>这个升级就比较简单了，和我们此前的升级方式是一样的，下载解压后替换安装目录即可，这里要注意，从<code>nexus-3.71.0+</code>开始仅支持<code>jdk17</code>，所以需要提前安装好<code>jdk17</code>，另外从<code>nexus-3.78.0</code>开始，Nexus 内置了<code>openjdk17</code>，所以不需要再额外安装jdk。</p></li><li class="lvl-2"><p><code>nexus-3.83.2-01</code> 是目前的最新版，<a href="https://help.sonatype.com/en/download.html">最新版下载页面</a>，<a href="https://help.sonatype.com/en/download-archives---repository-manager-3.html">历史版本下载页面地址</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭 Nexus 服务</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl stop nexus</span><br><span class="line"><span class="comment"># ~/nexus3/bin/nexus stop</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">curl -O https://download.sonatype.com/nexus/3/nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class="line">tar -zxvf nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class="line"><span class="built_in">rm</span> -f nexus3</span><br><span class="line"><span class="built_in">ln</span> -s nexus-3.83.2-01 nexus3</span><br><span class="line"><span class="comment"># 启动 Nexus，nexus-3.83.2-01 自带 openjdk17，所以不需要单独安装 openjdk</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl start nexus</span><br><span class="line"><span class="comment"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure><p><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/rgLwWf.png" alt=""><br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/mdWh22.png" alt="" width="1400" height="1000"><br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/56aOWz.png" alt=""></p>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 Mavne 私服 Nexus 升级的全过程，从 &lt;code&gt;3.29.2-02&lt;/code&gt; 升级到 &lt;code&gt;3.83.2-01&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://help.sonatype.com/en/sonatype-nexus-repository.html&quot;&gt;Nexus官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://mirrors.tuna.tsinghua.edu.cn/Adoptium/&quot;&gt;OpenJdk下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://help.sonatype.com/en/sonatype-nexus-repository-system-requirements.html&quot;&gt;Nexus系统配置要求&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="maven" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/maven/"/>
    
    <category term="nexus" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/maven/nexus/"/>
    
    
    <category term="mavne" scheme="https://blog.hanqunfeng.com/tags/mavne/"/>
    
    <category term="nexus" scheme="https://blog.hanqunfeng.com/tags/nexus/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</title>
    <link href="https://blog.hanqunfeng.com/2025/09/04/springboot3-shardingsphere-proxy/"/>
    <id>https://blog.hanqunfeng.com/2025/09/04/springboot3-shardingsphere-proxy/</id>
    <published>2025-09-04T13:30:05.000Z</published>
    <updated>2025-09-15T06:26:28.249Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 分库分表的使用。</p></li><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/index_zh.html">ShardingSphere官网</a></p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy">本文项目代码Github地址</a></p></li><li class="lvl-2"><p>本文将 <a href="/2025/09/01/springboot3-shardingsphere/" title="SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表">SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表</a> 修改为 <code>ShardingSphere-Proxy</code> 的模式</p></li></ul><span id="more"></span><h2 id="ShardingSphere-Proxy-简介">ShardingSphere-Proxy 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere-Proxy 定位为透明化的数据库代理端，通过实现数据库二进制协议，对异构语言提供支持。 目前提供 MySQL 和 PostgreSQL 协议，透明化数据库操作，对 DBA 更加友好。</p><ul class="lvl-2"><li class="lvl-4">向应用程序完全透明，可直接当做 MySQL/PostgreSQL 使用；</li><li class="lvl-4">兼容 MariaDB 等基于 MySQL 协议的数据库，以及 openGauss 等基于 PostgreSQL 协议的数据库；</li><li class="lvl-4">适用于任何兼容 MySQL/PostgreSQL 协议的的客户端，如：MySQL Command Client, MySQL Workbench, Navicat 等。</li></ul></li><li class="lvl-2"><p>ShardingSphere-Proxy 独立部署架构图<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/AMn2pu.png" alt=""></p></li><li class="lvl-2"><p>ShardingSphere-Proxy 与 ShardingSphere-JDBC 的特性比较</p></li></ul><table><thead><tr><th>特性</th><th>ShardingSphere-JDBC</th><th>ShardingSphere-Proxy</th></tr></thead><tbody><tr><td><strong>数据库支持</strong></td><td>任意数据库</td><td>MySQL / PostgreSQL</td></tr><tr><td><strong>连接消耗数</strong></td><td>高</td><td>低</td></tr><tr><td><strong>异构语言支持</strong></td><td>仅支持 Java</td><td>支持任意语言</td></tr><tr><td><strong>性能</strong></td><td>损耗低</td><td>损耗略高</td></tr><tr><td><strong>无中心化</strong></td><td>是</td><td>否</td></tr><tr><td><strong>静态入口</strong></td><td>无</td><td>有</td></tr></tbody></table><h2 id="部署-ShardingSphere-Proxy">部署 ShardingSphere-Proxy</h2><ul class="lvl-0"><li class="lvl-2"><p>运行 ShardingSphere-Proxy 要求 JDK 1.8+</p></li><li class="lvl-2"><p>下载 <a href="https://shardingsphere.apache.org/document/current/cn/downloads/">ShardingSphere-Proxy5.5.2</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.apache.org/dyn/closer.lua/shardingsphere/5.5.2/apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/</span><br></pre></td></tr></table></figure><h2 id="配置-ShardingSphere-Proxy">配置 ShardingSphere-Proxy</h2><ul class="lvl-0"><li class="lvl-2"><p><code>conf/global.yaml</code>: 全局配置，所谓全局，就是对所有逻辑库都生效的配置</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/authority/</span></span><br><span class="line"><span class="attr">authority:</span></span><br><span class="line"> <span class="attr">users:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">root@127.0.0.1</span> <span class="comment"># 格式：用户名@IP</span></span><br><span class="line">     <span class="attr">password:</span> <span class="string">root</span></span><br><span class="line">     <span class="attr">admin:</span> <span class="literal">true</span>          <span class="comment"># 是否是管理员</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">sharding@%</span>     <span class="comment"># 所有IP都可以访问</span></span><br><span class="line">     <span class="attr">password:</span> <span class="string">sharding</span></span><br><span class="line"> <span class="attr">privilege:</span></span><br><span class="line">   <span class="attr">type:</span> <span class="string">DATABASE_PERMITTED</span> <span class="comment"># 权限类型</span></span><br><span class="line">   <span class="attr">props:</span></span><br><span class="line">      <span class="attr">user-database-mappings:</span> <span class="string">root@127.0.0.1=*,sharding@%=sharding_db</span> <span class="comment"># 用户权限映射，*表示所有数据库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启XA事务，如果是 springboot项目，只需要在方法上加上 @Transactional 注解即可开启事务(从 MySQL 5.7 开始就全面支持 XA 分布式事务)</span></span><br><span class="line"><span class="comment"># https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/</span></span><br><span class="line"><span class="attr">transaction:</span>  <span class="comment"># 配置事务</span></span><br><span class="line">  <span class="attr">defaultType:</span> <span class="string">XA</span>        <span class="comment"># 事务类型，默认 LOCAL</span></span><br><span class="line">  <span class="attr">providerType:</span> <span class="string">Atomikos</span> <span class="comment"># 事务管理器具体实现，默认就是 Atomikos</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/props/</span></span><br><span class="line"><span class="attr">props:</span></span><br><span class="line">  <span class="attr">sql-show:</span> <span class="literal">true</span> <span class="comment"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class="line">  <span class="attr">check-table-metadata-enabled:</span> <span class="literal">false</span> <span class="comment"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p><code>conf/database-my.yaml</code>: 自定义分配规则配置</p></li></ul><blockquote><p>注意:<br>1.名称必须以 <code>database-</code>开头，实际上<code>conf</code>目录下有很多示例，我们可以根据需要进行配置<br>2.<code>global.yaml</code>中的配置项不能配置到 <code>database-my.yaml</code>中</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据库名称，默认值：logic_db</span></span><br><span class="line"><span class="attr">databaseName:</span> <span class="string">sharding_db</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/</span></span><br><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_0:</span> <span class="comment"># 逻辑数据源名称</span></span><br><span class="line">    <span class="comment"># dataSourceClassName: com.zaxxer.hikari.HikariDataSource # 不要指定</span></span><br><span class="line">    <span class="comment"># driverClassName: com.mysql.cj.jdbc.Driver               # 不要指定</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span>  <span class="comment"># 注意这里属性为 url</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">ds_1:</span></span><br><span class="line">    <span class="comment"># dataSourceClassName: com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line">    <span class="comment"># driverClassName: com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下规则与前文中的 shardingsphere-jdbc 中的 rules 相同</span></span><br><span class="line"><span class="comment"># 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="comment"># 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致</span></span><br><span class="line">    <span class="attr">bindingTables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">t_order,t_order_item</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">course:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">cid</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_inline</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">cid</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order-complex-algorithm</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span>  <span class="comment"># 分片列名称,多个逗号分隔</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_item-class-based-algorithm_spi</span> <span class="comment"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">      <span class="attr">t_user:</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span>  <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">id</span> <span class="comment"># 自增列名称，字符串类型</span></span><br><span class="line">          <span class="comment">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">custom_snowflake_string</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#       t_address:      # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明</span></span><br><span class="line">    <span class="comment">#         actualDataNodes: ds_0.t_address # 实际数据节点</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">autoTables:</span> <span class="comment"># 自动分片规则配置</span></span><br><span class="line">      <span class="attr">t_order:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/</span></span><br><span class="line">      <span class="attr">course_inline:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span> <span class="comment"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 属性</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">course_$&#123;cid</span> <span class="string">%</span> <span class="number">2</span> <span class="string">+</span> <span class="number">1</span><span class="string">&#125;</span> <span class="comment"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class="line">          <span class="attr">allow-range-query-with-inline-sharding:</span> <span class="literal">true</span> <span class="comment"># 允许范围查询</span></span><br><span class="line">      <span class="attr">course_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span> <span class="comment"># 表示 ds_0, ds_1</span></span><br><span class="line">      <span class="attr">mod_2:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MOD</span> <span class="comment"># 基于 MOD 的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">sharding-count:</span> <span class="number">2</span> <span class="comment"># 分片数量，即 对 2 进行取余</span></span><br><span class="line">      <span class="attr">t_order_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order-complex-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">COMPLEX_INLINE</span> <span class="comment"># 基于行表达式的复合分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_order_complex_$&#123;(user_id</span> <span class="string">+</span> <span class="string">order_id</span> <span class="string">+</span> <span class="number">1</span><span class="string">)</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm_spi:</span> <span class="comment"># SPI</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">T_ORDER_ITEM_COMPLEX</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line">      <span class="attr">t_user_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span></span><br><span class="line">      <span class="attr">t_user_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br><span class="line">      <span class="attr">uuid:</span> <span class="comment"># 定义名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">UUID</span> <span class="comment"># 字符串主键，String</span></span><br><span class="line">      <span class="attr">custom_snowflake_string:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CUSTOM_SNOWFLAKE_STRING</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">workerId:</span> <span class="number">2</span></span><br><span class="line">          <span class="attr">datacenterId:</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!BROADCAST</span>  <span class="comment"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">dict</span>    <span class="comment"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!ENCRYPT</span>    <span class="comment"># 数据加密配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span> <span class="comment"># 加密表名称</span></span><br><span class="line">        <span class="attr">columns:</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 加密列名称</span></span><br><span class="line">            <span class="attr">cipher:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">password</span> <span class="comment"># 密文列名称</span></span><br><span class="line">              <span class="attr">encryptorName:</span> <span class="string">aes_encryptor</span> <span class="comment"># 密文列加密算法名称</span></span><br><span class="line">    <span class="comment"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class="line">    <span class="attr">encryptors:</span></span><br><span class="line">      <span class="attr">aes_encryptor:</span> <span class="comment"># 加解密算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">AES</span> <span class="comment"># 加解密算法类型</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 加解密算法属性配置</span></span><br><span class="line">          <span class="attr">aes-key-value:</span> <span class="string">123456abc</span>     <span class="comment"># AES 使用的 KEY</span></span><br><span class="line">          <span class="attr">digest-algorithm-name:</span> <span class="string">SHA-1</span> <span class="comment"># AES KEY 的摘要算法</span></span><br><span class="line">      <span class="attr">md5_encryptor:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">salt:</span> <span class="number">123456</span>  <span class="comment"># 盐值（可选）</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!MASK</span>  <span class="comment"># 数据脱敏配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span> <span class="comment"># 脱敏表名称</span></span><br><span class="line">        <span class="attr">columns:</span> <span class="comment"># 脱敏列配置</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 脱敏列名称</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">md5_mask</span> <span class="comment"># 脱敏算法名称</span></span><br><span class="line">          <span class="attr">email:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">mask_before_special_chars_mask</span></span><br><span class="line">          <span class="attr">telephone:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">keep_first_n_last_m_mask</span></span><br><span class="line">          <span class="attr">name:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">my_mask</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">maskAlgorithms:</span> <span class="comment"># 脱敏算法配置</span></span><br><span class="line">      <span class="attr">md5_mask:</span> <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span>  <span class="comment"># 脱敏算法类型，md5加密后展示</span></span><br><span class="line">      <span class="attr">mask_before_special_chars_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MASK_BEFORE_SPECIAL_CHARS</span> <span class="comment"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">special-chars:</span> <span class="string">&#x27;@&#x27;</span>  <span class="comment"># 遇到 @ 之前的部分做脱敏</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span>   <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">keep_first_n_last_m_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">KEEP_FIRST_N_LAST_M</span> <span class="comment"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">first-n:</span> <span class="number">3</span>     <span class="comment"># 保留前 3 位</span></span><br><span class="line">          <span class="attr">last-m:</span> <span class="number">4</span>      <span class="comment"># 保留后 4 位</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span> <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">my_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MY_CUSTOM_MASK</span>  <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&quot;#&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SINGLE</span> <span class="comment"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="comment"># MySQL 风格</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ds_0.t_address</span> <span class="comment"># 加载指定单表</span></span><br><span class="line"><span class="comment">#       - ds_1.* # 加载指定数据源中的全部单表</span></span><br><span class="line"><span class="comment">#       - &quot;*.*&quot; # 加载全部单表</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>上面的<code>rules</code>中使用的是<code>mysql</code>数据库，所以我们需要引入<code>mysql</code>数据库的依赖</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/</span><br><span class="line"><span class="built_in">mkdir</span> ext-lib</span><br><span class="line"><span class="built_in">cd</span> ext-lib</span><br><span class="line">wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.11/mysql-connector-java-8.0.11.jar</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>同时<code>rules</code>中包含一些自定义的算法，我们也需要将这些算法作为依赖进行引入，将这些算法类打成<code>jar</code>，然后也拷贝到<code>ext-lib</code>目录下，我已经将其发布到了github上，实际上和前文中的 <code>shardingsphere-jdbc</code> 项目中将算法配置为 <code>spi</code> 的方式是一致的。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 只克隆仓库的基本信息，不下载所有文件</span></span><br><span class="line">git <span class="built_in">clone</span> --filter=blob:none --sparse https://github.com/hanqunfeng/springbootchapter.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 进入仓库目录</span></span><br><span class="line"><span class="built_in">cd</span> springbootchapter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 设置只检出你需要的目录</span></span><br><span class="line">git sparse-checkout <span class="built_in">set</span> springboot3-demo/shardingsphere-demo/algorithm-swapper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 编译打包</span></span><br><span class="line"><span class="built_in">cd</span> springboot3-demo/shardingsphere-demo/algorithm-swapper</span><br><span class="line">mvn clean package -DskipTests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 将打好的包复制到 shardingsphere-proxy 的 ext-lib 目录下</span></span><br><span class="line"><span class="built_in">cp</span> target/algorithm-swapper-1.0.0.jar <span class="variable">$shardingsphere</span>-proxy$/ext-lib</span><br></pre></td></tr></table></figure><h2 id="启动与关闭-ShardingSphere-Proxy">启动与关闭 ShardingSphere Proxy</h2><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere Proxy 要求 JDK 1.8 或以上版本</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$shardingsphere</span>-proxy$/bin</span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">./start.sh</span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">./stop.sh</span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>参数说明</p></li></ul><table><thead><tr><th>参数</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td><code>-a</code></td><td>绑定地址，可以是 IPv4、IPv6 或主机名，多个地址用逗号分隔。</td><td><code>0.0.0.0</code></td></tr><tr><td><code>-p</code></td><td>绑定端口号，可以在 <code>global.yaml</code> 中修改。<code>-p</code> 优先级更高</td><td><code>3307</code></td></tr><tr><td><code>-c</code></td><td>ShardingSphere-Proxy 配置目录路径。</td><td><code>conf</code></td></tr><tr><td><code>-f</code></td><td>强制启动 ShardingSphere-Proxy。</td><td>无</td></tr><tr><td><code>-g</code></td><td>如果在 <code>agent</code> 目录下部署了 <code>shardingsphere-agent</code>，启用 agent 功能。</td><td>无</td></tr><tr><td><code>-s</code></td><td>指定用于连接的 socket 文件路径。</td><td>无</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere-Proxy 启动命令速查表</p></li></ul><table><thead><tr><th>场景</th><th>命令示例</th><th>说明</th></tr></thead><tbody><tr><td><strong>默认启动</strong></td><td><code>./start.sh</code></td><td>默认端口 <code>3307</code>，配置目录 <code>conf</code></td></tr><tr><td><strong>指定端口和配置目录</strong></td><td><code>./start.sh 3308 /opt/shardingsphere-proxy/conf</code></td><td>简写模式，指定端口和配置目录</td></tr><tr><td><strong>参数形式启动</strong></td><td><code>./start.sh -p 3308 -c /opt/shardingsphere-proxy/conf</code></td><td>与上面等效，但更明确</td></tr><tr><td><strong>指定监听地址</strong></td><td><code>./start.sh -a 192.168.1.100 -p 3307 -c conf</code></td><td>指定单个 IP 地址</td></tr><tr><td><strong>指定多个监听地址</strong></td><td><code>./start.sh -a 192.168.1.100,127.0.0.1 -p 3307 -c conf</code></td><td>多个地址用逗号分隔</td></tr><tr><td><strong>强制启动</strong></td><td><code>./start.sh -p 3307 -c conf -f</code></td><td>遇到残留 PID 文件时使用</td></tr><tr><td><strong>启用 agent</strong></td><td><code>./start.sh -p 3307 -c conf -g</code></td><td>启动 ShardingSphere-Agent</td></tr><tr><td><strong>使用 Unix Socket</strong></td><td><code>./start.sh -p 3307 -c conf -s /tmp/sharding-proxy.sock</code></td><td>通过 Socket 文件进行连接</td></tr><tr><td><strong>多选项组合</strong></td><td><code>./start.sh -a 127.0.0.1 -p 3310 -c /opt/proxy/conf -f -g -s /tmp/proxy.sock</code></td><td>一次性指定多个选项</td></tr></tbody></table><h2 id="项目连接-ShardingSphere-Proxy-时，就像连接普通的-mysql-服务一样">项目连接 ShardingSphere-Proxy 时，就像连接普通的 mysql 服务一样</h2><ul class="lvl-0"><li class="lvl-2"><p>示例项目：<a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy">https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy</a></p></li></ul><h2 id="后记">后记</h2><ul class="lvl-0"><li class="lvl-2"><p>在 <code>ShardingSphere-JDBC</code> 和 <code>ShardingSphere-Proxy</code> 中，存在部分 MySQL(其它数据库也类似) 的 SQL 语法或功能目前还不完全支持的情况。<code>ShardingSphere</code> 在做 SQL 路由、改写、执行时，必须能解析 SQL 并理解其语义，但并不是 MySQL 的 100% 完全代理。因此，有些复杂或特定场景下的 SQL 可能无法被正确解析或执行。</p></li><li class="lvl-2"><p>支持良好的 SQL 语法</p><ul class="lvl-2"><li class="lvl-4">基础 DML<br>SELECT、INSERT、UPDATE、DELETE<br>基本的条件查询、排序、分页、分组、聚合函数（如 COUNT、SUM、AVG）</li><li class="lvl-4">DCL<br>基本的事务语句：BEGIN、COMMIT、ROLLBACK</li><li class="lvl-4">DDL<br>部分表结构管理语句：CREATE TABLE、ALTER TABLE、DROP TABLE</li><li class="lvl-4">函数支持<br>大部分常用的 MySQL 内置函数，如字符串、数学、日期函数</li></ul></li></ul><h3 id="在-ShardingSphere-MySQL-下建议避免或谨慎使用的-SQL-清单">在 ShardingSphere + MySQL 下建议避免或谨慎使用的 SQL 清单</h3><ul class="lvl-0"><li class="lvl-2"><ol><li class="lvl-5">跨分片复杂查询</li></ol></li></ul><table><thead><tr><th>SQL 场景</th><th>原因</th><th>建议处理方式</th></tr></thead><tbody><tr><td>多表复杂 JOIN（特别是跨分片）</td><td>需要跨库数据聚合，性能差，可能报错</td><td>使用广播表/绑定表，或在应用层完成</td></tr><tr><td>跨分片子查询</td><td>SQL 路由困难，可能不支持</td><td>尽量改成单表查询或分步查询</td></tr><tr><td>跨分片的 GROUP BY / ORDER BY</td><td>在 Proxy 层聚合，性能很差</td><td>尽量避免，或控制数据量</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><ol start="2"><li class="lvl-5">DDL 相关</li></ol></li></ul><table><thead><tr><th>SQL 场景</th><th>原因</th><th>建议处理方式</th></tr></thead><tbody><tr><td><code>ALTER TABLE</code> 复杂变更</td><td>需在所有分片执行，可能执行失败</td><td>手动在每个分片库执行</td></tr><tr><td><code>CREATE TRIGGER</code>、<code>PROCEDURE</code></td><td>Proxy 不解析这些语法，直接透传不安全</td><td>尽量在单库手动创建</td></tr><tr><td><code>CREATE FUNCTION</code></td><td>同上</td><td>单库执行或应用层替代</td></tr><tr><td><code>FULLTEXT INDEX</code>、<code>SPATIAL INDEX</code></td><td>分片环境下无法自动维护索引</td><td>单库手动维护或避免使用</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><ol start="3"><li class="lvl-5">文件导入导出</li></ol></li></ul><table><thead><tr><th>SQL 场景</th><th>原因</th><th>建议处理方式</th></tr></thead><tbody><tr><td><code>LOAD DATA INFILE</code></td><td>Proxy 不支持文件系统直接访问</td><td>在分片库手动执行或通过应用导入</td></tr><tr><td><code>SELECT ... INTO OUTFILE</code></td><td>同上</td><td>应用层处理导出</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><ol start="4"><li class="lvl-5">MySQL 特有功能</li></ol></li></ul><table><thead><tr><th>功能</th><th>支持情况</th><th>建议</th></tr></thead><tbody><tr><td>MySQL 8.0 公共表表达式（CTE）</td><td>部分支持</td><td>避免跨分片使用</td></tr><tr><td>窗口函数（<code>OVER() PARTITION BY</code>）</td><td>部分支持</td><td>避免跨分片大数据量使用</td></tr><tr><td>JSON 函数</td><td>基本支持</td><td>单表场景可用，跨分片需谨慎</td></tr></tbody></table><ul class="lvl-0"><li class="lvl-2"><p>分布式事务</p></li></ul><table><thead><tr><th>场景</th><th>问题原因</th><th>建议处理方式</th></tr></thead><tbody><tr><td>跨分片原生事务</td><td>MySQL 原生事务不支持跨库</td><td>使用 ShardingSphere XA / BASE</td></tr><tr><td>大事务 + 分布式事务</td><td>性能开销大</td><td>尽量控制事务范围</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 分库分表的使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/index_zh.html&quot;&gt;ShardingSphere官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy&quot;&gt;本文项目代码Github地址&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文将 &lt;a href=&quot;/2025/09/01/springboot3-shardingsphere/&quot; title=&quot;SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表&quot;&gt;SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表&lt;/a&gt; 修改为 &lt;code&gt;ShardingSphere-Proxy&lt;/code&gt; 的模式&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/sharding-sphere/"/>
    
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/tags/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/tags/sharding-sphere/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表</title>
    <link href="https://blog.hanqunfeng.com/2025/09/01/springboot3-shardingsphere/"/>
    <id>https://blog.hanqunfeng.com/2025/09/01/springboot3-shardingsphere/</id>
    <published>2025-09-01T13:30:05.000Z</published>
    <updated>2025-09-15T06:26:28.263Z</updated>
    
    <content type="html"><![CDATA[<!-- **加粗** *斜体* ***加粗并斜体*** ~~删除线~~ ==突出显示== `突出显示(推荐)` ++下划线++ ~下标~ ^上标^ 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference. 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600) +++ **点击折叠** 这是被隐藏的内容 +++::: tips success warning danger这里是容器内的内容:::% note info % success warning danger这里是容器内的内容% endnote %引用本地其它文章连接{} 大括号开始% post_link 文件名称(不包含.md) %大括号结束 --><h2 id="摘要">摘要</h2><ul class="lvl-0"><li class="lvl-2"><p>本文介绍 SpringBoot3.5.5 + ShardingSphere-JDBC5.5.2 分库分表的使用。</p></li><li class="lvl-2"><p><a href="https://shardingsphere.apache.org/index_zh.html">ShardingSphere官网</a></p></li><li class="lvl-2"><p><a href="https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-01">本文项目代码Github地址</a></p></li></ul><span id="more"></span><h2 id="ShardingSphere-JDBC-简介">ShardingSphere-JDBC 简介</h2><ul class="lvl-0"><li class="lvl-2"><p>ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。</p><ul class="lvl-2"><li class="lvl-4">适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC；</li><li class="lvl-4">支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, HikariCP 等；</li><li class="lvl-4">支持任意实现 JDBC 规范的数据库，目前支持 MySQL，PostgreSQL，Oracle，SQLServer 以及任何可使用 JDBC 访问的数据库。</li></ul></li><li class="lvl-2"><p>ShardingSphere-JDBC 独立部署架构图<br><img src="https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/RgXClY.png" alt=""></p></li></ul><h2 id="maven依赖">maven依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 本项目 基于 mysql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="application-yml">application.yml</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">driver-class-name:</span> <span class="string">org.apache.shardingsphere.driver.ShardingSphereDriver</span></span><br><span class="line">    <span class="comment"># 指向类路径下的 sharding.yaml（也可 absolute path / file: / http: 等，见官方说明）</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:shardingsphere:classpath:sharding.yaml</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>也可以不在 <code>application.yml</code> 中配置，而是通过 <code>@Configuration</code> 创建 <code>@Bean</code>，这样就可以配置多数据源了。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataSourceConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean(name = &quot;shardingDataSource&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> DataSource <span class="title function_">shardingDataSource</span><span class="params">()</span> <span class="keyword">throws</span> SQLException, IOException &#123;</span><br><span class="line">        <span class="comment">// ShardingSphere 提供的工厂方法，根据配置构建 DataSource</span></span><br><span class="line">        <span class="keyword">try</span> (<span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> getClass().getClassLoader().getResourceAsStream(<span class="string">&quot;sharding.yaml&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (inputStream == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Cannot find sharding.yaml in classpath&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">byte</span>[] yamlBytes = inputStream.readAllBytes();</span><br><span class="line">            <span class="keyword">return</span> YamlShardingSphereDataSourceFactory.createDataSource(yamlBytes);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="sharding-yaml">sharding.yaml</h2><ul class="lvl-0"><li class="lvl-2"><p>完整配置，下文会介绍部分配置</p></li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/</span></span><br><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_0:</span> <span class="comment"># 逻辑数据源名称</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">jdbcUrl:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">ds_1:</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">jdbcUrl:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="comment"># 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致</span></span><br><span class="line">    <span class="attr">bindingTables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">t_order,t_order_item</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">course:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">cid</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_inline</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">cid</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order-complex-algorithm</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span>  <span class="comment"># 分片列名称,多个逗号分隔</span></span><br><span class="line"><span class="comment">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_item-class-based-algorithm_spi</span> <span class="comment"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">      <span class="attr">t_user:</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span>  <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">id</span> <span class="comment"># 自增列名称，字符串类型</span></span><br><span class="line"><span class="comment">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">custom_snowflake_string</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#       t_address:      # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明</span></span><br><span class="line"><span class="comment">#         actualDataNodes: ds_0.t_address # 实际数据节点</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">autoTables:</span> <span class="comment"># 自动分片规则配置</span></span><br><span class="line">      <span class="attr">t_order:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/</span></span><br><span class="line">      <span class="attr">course_inline:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span> <span class="comment"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 属性</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">course_$&#123;cid</span> <span class="string">%</span> <span class="number">2</span> <span class="string">+</span> <span class="number">1</span><span class="string">&#125;</span> <span class="comment"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class="line">          <span class="attr">allow-range-query-with-inline-sharding:</span> <span class="literal">true</span> <span class="comment"># 允许范围查询</span></span><br><span class="line">      <span class="attr">course_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span> <span class="comment"># 表示 ds_0, ds_1</span></span><br><span class="line">      <span class="attr">mod_2:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MOD</span> <span class="comment"># 基于 MOD 的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">sharding-count:</span> <span class="number">2</span> <span class="comment"># 分片数量，即 对 2 进行取余</span></span><br><span class="line">      <span class="attr">t_order_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order-complex-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">COMPLEX_INLINE</span> <span class="comment"># 基于行表达式的复合分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_order_complex_$&#123;(user_id</span> <span class="string">+</span> <span class="string">order_id</span> <span class="string">+</span> <span class="number">1</span><span class="string">)</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CLASS_BASED</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">strategy:</span> <span class="string">COMPLEX</span> <span class="comment"># 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略</span></span><br><span class="line">          <span class="attr">algorithmClassName:</span> <span class="string">com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm</span> <span class="comment"># 指定算法类</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm_spi:</span> <span class="comment"># SPI</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">T_ORDER_ITEM_COMPLEX</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line">      <span class="attr">t_user_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span></span><br><span class="line">      <span class="attr">t_user_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br><span class="line">      <span class="attr">uuid:</span>    <span class="comment"># 定义名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">UUID</span> <span class="comment"># 字符串主键，String</span></span><br><span class="line">      <span class="attr">custom_snowflake_string:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CUSTOM_SNOWFLAKE_STRING</span>  <span class="comment"># 自定义雪花算法，String</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">workerId:</span> <span class="number">2</span></span><br><span class="line">          <span class="attr">datacenterId:</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!BROADCAST</span>  <span class="comment"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">dict</span>    <span class="comment"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!ENCRYPT</span>    <span class="comment"># 数据加密配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 加密表名称</span></span><br><span class="line">        <span class="attr">columns:</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 加密列名称</span></span><br><span class="line">            <span class="attr">cipher:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">password</span> <span class="comment"># 密文列名称</span></span><br><span class="line">              <span class="attr">encryptorName:</span> <span class="string">aes_encryptor</span> <span class="comment"># 密文列加密算法名称</span></span><br><span class="line">    <span class="comment"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class="line">    <span class="attr">encryptors:</span></span><br><span class="line">      <span class="attr">aes_encryptor:</span> <span class="comment"># 加解密算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">AES</span> <span class="comment"># 加解密算法类型</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 加解密算法属性配置</span></span><br><span class="line">          <span class="attr">aes-key-value:</span> <span class="string">123456abc</span>     <span class="comment"># AES 使用的 KEY</span></span><br><span class="line">          <span class="attr">digest-algorithm-name:</span> <span class="string">SHA-1</span> <span class="comment"># AES KEY 的摘要算法</span></span><br><span class="line">      <span class="attr">md5_encryptor:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">salt:</span> <span class="number">123456</span>  <span class="comment"># 盐值（可选）</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!MASK</span>  <span class="comment"># 数据脱敏配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 脱敏表名称</span></span><br><span class="line">        <span class="attr">columns:</span>  <span class="comment"># 脱敏列配置</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 脱敏列名称</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">md5_mask</span> <span class="comment"># 脱敏算法名称</span></span><br><span class="line">          <span class="attr">email:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">mask_before_special_chars_mask</span></span><br><span class="line">          <span class="attr">telephone:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">keep_first_n_last_m_mask</span></span><br><span class="line">          <span class="attr">name:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">my_mask</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">maskAlgorithms:</span> <span class="comment"># 脱敏算法配置</span></span><br><span class="line">      <span class="attr">md5_mask:</span> <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span>  <span class="comment"># 脱敏算法类型，md5加密后展示</span></span><br><span class="line">      <span class="attr">mask_before_special_chars_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MASK_BEFORE_SPECIAL_CHARS</span> <span class="comment"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">special-chars:</span> <span class="string">&#x27;@&#x27;</span>  <span class="comment"># 遇到 @ 之前的部分做脱敏</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span>   <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">keep_first_n_last_m_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">KEEP_FIRST_N_LAST_M</span> <span class="comment"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">first-n:</span> <span class="number">3</span>     <span class="comment"># 保留前 3 位</span></span><br><span class="line">          <span class="attr">last-m:</span> <span class="number">4</span>      <span class="comment"># 保留后 4 位</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span> <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">my_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MY_CUSTOM_MASK</span>  <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&quot;#&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SINGLE</span> <span class="comment"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="comment"># MySQL 风格</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ds_0.t_address</span> <span class="comment"># 加载指定单表</span></span><br><span class="line"><span class="comment">#       - ds_1.* # 加载指定数据源中的全部单表</span></span><br><span class="line"><span class="comment">#       - &quot;*.*&quot; # 加载全部单表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/</span></span><br><span class="line"><span class="attr">props:</span></span><br><span class="line">  <span class="attr">sql-show:</span> <span class="literal">true</span> <span class="comment"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class="line">  <span class="attr">check-table-metadata-enabled:</span> <span class="literal">false</span> <span class="comment"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure><h3 id="数据源配置">数据源配置</h3><ul class="lvl-0"><li class="lvl-2"><p>hikari + mysql</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_0:</span> <span class="comment"># 逻辑数据源名称</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">jdbcUrl:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">ds_1:</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">jdbcUrl:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>druid + mysql</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_1:</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line">    <span class="comment"># Druid 特有配置</span></span><br><span class="line">    <span class="attr">initialSize:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">minIdle:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">maxActive:</span> <span class="number">20</span></span><br><span class="line">    <span class="attr">maxWait:</span> <span class="number">60000</span></span><br><span class="line">    <span class="attr">testWhileIdle:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">validationQuery:</span> <span class="string">SELECT</span> <span class="number">1</span> <span class="string">FROM</span> <span class="string">DUAL</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>druid + mysql + p6spy</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSources:</span></span><br><span class="line">  <span class="attr">ds_0:</span> <span class="comment"># 逻辑数据源名称</span></span><br><span class="line">    <span class="attr">dataSourceClassName:</span> <span class="string">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class="line">    <span class="attr">driverClassName:</span> <span class="string">com.p6spy.engine.spy.P6SpyDriver</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:p6spy:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">newpwd</span></span><br><span class="line">    <span class="comment"># Druid 特有配置</span></span><br><span class="line">    <span class="attr">initialSize:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">minIdle:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">maxActive:</span> <span class="number">20</span></span><br><span class="line">    <span class="attr">maxWait:</span> <span class="number">60000</span></span><br><span class="line">    <span class="attr">testWhileIdle:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">validationQuery:</span> <span class="string">SELECT</span> <span class="number">1</span> <span class="string">FROM</span> <span class="string">DUAL</span></span><br></pre></td></tr></table></figure><h3 id="分库分表配置">分库分表配置</h3><h4 id="单分片键，Long-类型">单分片键，Long 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">course:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class="comment"># 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">cid</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">course_inline</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">cid</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">course_inline:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span> <span class="comment"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 属性</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">course_$&#123;cid</span> <span class="string">%</span> <span class="number">2</span> <span class="string">+</span> <span class="number">1</span><span class="string">&#125;</span> <span class="comment"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class="line">          <span class="attr">allow-range-query-with-inline-sharding:</span> <span class="literal">true</span> <span class="comment"># 允许范围查询</span></span><br><span class="line">      <span class="attr">course_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span> <span class="comment"># 表示 ds_0, ds_1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>这里分库与分表采用了不同的字段，分库使用 user_id，分表使用 cid</p></li><li class="lvl-2"><p>allow-range-query-with-inline-sharding: true ，这里设置为允许范围查询，默认值是 false，不允许 between 查询</p></li></ul><h4 id="单分片键，String-类型">单分片键，String 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">t_user:</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">standard:</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">id</span>  <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_user_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">id</span> <span class="comment"># 自增列名称，字符串类型</span></span><br><span class="line"><span class="comment">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">custom_snowflake_string</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">t_user_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span> <span class="comment"># 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算</span></span><br><span class="line">      <span class="attr">t_user_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span> <span class="comment"># 分表，t_user_0, t_user_1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式序列算法</span></span><br><span class="line">      <span class="attr">uuid:</span>    <span class="comment"># 定义名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">UUID</span> <span class="comment"># 字符串主键，String</span></span><br><span class="line">      <span class="attr">custom_snowflake_string:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CUSTOM_SNOWFLAKE_STRING</span> <span class="comment"># 自定义雪花算法，String，spi</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">workerId:</span> <span class="number">2</span></span><br><span class="line">          <span class="attr">datacenterId:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>这里分库与分表采用了相同的字段，即主键id，因其为字符串类型，所以需要使用 hashCode() 获取数字，再进行运算</p></li><li class="lvl-2"><p>主键获取规则使用的自定义的雪花算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.infra.algorithm.keygen.core.KeyGenerateAlgorithm</code>，这里注意，从 <code>5.5.3</code> 开始会更换为 <code>org.apache.shardingsphere.infra.algorithm.keygen.spi.KeyGenerateAlgorithm</code></p></li></ul><h4 id="多分片键，Long-类型">多分片键，Long 类型</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">    <span class="attr">tables:</span> <span class="comment"># 手工分片规则配置</span></span><br><span class="line">      <span class="attr">t_order_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order-complex-algorithm</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item_complex:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataNodes:</span> <span class="string">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class="comment"># 实际数据节点</span></span><br><span class="line">        <span class="attr">databaseStrategy:</span> <span class="comment"># 分库策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_db_inline</span> <span class="comment"># 分片算法名称</span></span><br><span class="line">        <span class="attr">tableStrategy:</span> <span class="comment"># 分表策略</span></span><br><span class="line">          <span class="attr">complex:</span> <span class="comment"># 用于多分片键的复杂分片场景</span></span><br><span class="line">            <span class="attr">shardingColumns:</span> <span class="string">user_id,order_id</span>  <span class="comment"># 分片列名称,多个逗号分隔</span></span><br><span class="line"><span class="comment">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">t_order_item-class-based-algorithm_spi</span> <span class="comment"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">t_order_db_inline:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">INLINE</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">ds_$&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order-complex-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">COMPLEX_INLINE</span> <span class="comment"># 基于行表达式的复合分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">algorithm-expression:</span> <span class="string">t_order_complex_$&#123;(user_id</span> <span class="string">+</span> <span class="string">order_id</span> <span class="string">+</span> <span class="number">1</span><span class="string">)</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">CLASS_BASED</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">strategy:</span> <span class="string">COMPLEX</span> <span class="comment"># 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略</span></span><br><span class="line">          <span class="attr">algorithmClassName:</span> <span class="string">com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm</span> <span class="comment"># 指定算法类</span></span><br><span class="line">      <span class="attr">t_order_item-class-based-algorithm_spi:</span> <span class="comment"># SPI</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">T_ORDER_ITEM_COMPLEX</span> <span class="comment"># 基于自定义类的分片算法</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>多个分片键，<code>t_order_complex</code>表使用了内置的<code>COMPLEX_INLINE</code>算法，而<code>t_order_item_complex</code>表使用了自定义的的分片算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.sharding.spi.ShardingAlgorithm</code></p></li></ul><h4 id="自动分片规则">自动分片规则</h4><ul class="lvl-0"><li class="lvl-2"><p>上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SHARDING</span> <span class="comment"># 分片规则配置</span></span><br><span class="line">   <span class="comment"># 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致</span></span><br><span class="line">    <span class="attr">bindingTables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">t_order,t_order_item</span></span><br><span class="line">    <span class="attr">autoTables:</span> <span class="comment"># 自动分片规则配置</span></span><br><span class="line">      <span class="attr">t_order:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">order_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line">      <span class="attr">t_order_item:</span> <span class="comment"># 逻辑表名称</span></span><br><span class="line">        <span class="attr">actualDataSources:</span> <span class="string">ds_$&#123;0..1&#125;</span> <span class="comment"># 数据源名称</span></span><br><span class="line">        <span class="attr">shardingStrategy:</span> <span class="comment"># 切分策略</span></span><br><span class="line">          <span class="attr">standard:</span> <span class="comment"># 用于单分片键的标准分片场景</span></span><br><span class="line">            <span class="attr">shardingColumn:</span> <span class="string">user_id</span> <span class="comment"># 分片列名称</span></span><br><span class="line">            <span class="attr">shardingAlgorithmName:</span> <span class="string">mod_2</span> <span class="comment"># 自动分片算法名称</span></span><br><span class="line">        <span class="attr">keyGenerateStrategy:</span> <span class="comment"># 分布式序列策略</span></span><br><span class="line">          <span class="attr">column:</span> <span class="string">item_id</span> <span class="comment"># 自增列名称</span></span><br><span class="line">          <span class="attr">keyGeneratorName:</span> <span class="string">snowflake</span> <span class="comment"># 分布式序列算法名称</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">shardingAlgorithms:</span> <span class="comment"># 分片算法</span></span><br><span class="line">      <span class="attr">mod_2:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MOD</span> <span class="comment"># 基于 MOD 的分片算法</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">sharding-count:</span> <span class="number">2</span> <span class="comment"># 分片数量，即 对 2 进行取余</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">keyGenerators:</span> <span class="comment"># 分布式主键生成器</span></span><br><span class="line">      <span class="attr">snowflake:</span> <span class="comment"># 定义名称，在上面引用</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">SNOWFLAKE</span> <span class="comment"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>自动分片规则需要声明数据库，但不需要声明表分配规则，其根据分片算法自动确定具体的数据表。</p></li><li class="lvl-2"><p>同时这里还配置了<code>bindingTables</code>，用来指定其分片路由一致。</p></li></ul><h3 id="广播表配置">广播表配置</h3><ul class="lvl-0"><li class="lvl-2"><p>广播表，即所有数据源都包含的表，比如字典表</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!BROADCAST</span>  <span class="comment"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">dict</span>    <span class="comment"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br></pre></td></tr></table></figure><h3 id="数据加密规则">数据加密规则</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!ENCRYPT</span>    <span class="comment"># 数据加密配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 加密表名称</span></span><br><span class="line">        <span class="attr">columns:</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 加密列名称</span></span><br><span class="line">            <span class="attr">cipher:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">password</span> <span class="comment"># 密文列名称</span></span><br><span class="line">              <span class="attr">encryptorName:</span> <span class="string">aes_encryptor</span> <span class="comment"># 密文列加密算法名称</span></span><br><span class="line">    <span class="comment"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class="line">    <span class="attr">encryptors:</span></span><br><span class="line">      <span class="attr">aes_encryptor:</span> <span class="comment"># 加解密算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">AES</span> <span class="comment"># 加解密算法类型</span></span><br><span class="line">        <span class="attr">props:</span> <span class="comment"># 加解密算法属性配置</span></span><br><span class="line">          <span class="attr">aes-key-value:</span> <span class="string">123456abc</span>     <span class="comment"># AES 使用的 KEY</span></span><br><span class="line">          <span class="attr">digest-algorithm-name:</span> <span class="string">SHA-1</span> <span class="comment"># AES KEY 的摘要算法</span></span><br><span class="line">      <span class="attr">md5_encryptor:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">salt:</span> <span class="number">123456</span>  <span class="comment"># 盐值（可选）</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>配置加密字段规则后，新增数据时，会自动对加密字段加密后存储，查询时也会加密后进行比较查询。</p></li></ul><h3 id="数据脱敏规则">数据脱敏规则</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!MASK</span>  <span class="comment"># 数据脱敏配置</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="attr">t_user:</span>  <span class="comment"># 脱敏表名称</span></span><br><span class="line">        <span class="attr">columns:</span>  <span class="comment"># 脱敏列配置</span></span><br><span class="line">          <span class="attr">password:</span> <span class="comment"># 脱敏列名称</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">md5_mask</span> <span class="comment"># 脱敏算法名称</span></span><br><span class="line">          <span class="attr">email:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">mask_before_special_chars_mask</span></span><br><span class="line">          <span class="attr">telephone:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">keep_first_n_last_m_mask</span></span><br><span class="line">          <span class="attr">name:</span></span><br><span class="line">            <span class="attr">maskAlgorithm:</span> <span class="string">my_mask</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">maskAlgorithms:</span> <span class="comment"># 脱敏算法配置</span></span><br><span class="line">      <span class="attr">md5_mask:</span> <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MD5</span>  <span class="comment"># 脱敏算法类型，md5加密后展示</span></span><br><span class="line">      <span class="attr">mask_before_special_chars_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MASK_BEFORE_SPECIAL_CHARS</span> <span class="comment"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">special-chars:</span> <span class="string">&#x27;@&#x27;</span>  <span class="comment"># 遇到 @ 之前的部分做脱敏</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span>   <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">keep_first_n_last_m_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">KEEP_FIRST_N_LAST_M</span> <span class="comment"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">first-n:</span> <span class="number">3</span>     <span class="comment"># 保留前 3 位</span></span><br><span class="line">          <span class="attr">last-m:</span> <span class="number">4</span>      <span class="comment"># 保留后 4 位</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&#x27;*&#x27;</span> <span class="comment"># 脱敏字符用 * 代替</span></span><br><span class="line">      <span class="attr">my_mask:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">MY_CUSTOM_MASK</span>  <span class="comment"># 自定义脱敏算法名称</span></span><br><span class="line">        <span class="attr">props:</span></span><br><span class="line">          <span class="attr">replace-char:</span> <span class="string">&quot;#&quot;</span></span><br></pre></td></tr></table></figure><ul class="lvl-0"><li class="lvl-2"><p>被脱敏的字段在查询时会进行脱敏展示。</p></li><li class="lvl-2"><p>这里还自定义了脱敏算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.mask.spi.MaskAlgorithm</code></p></li></ul><h3 id="单表规则">单表规则</h3><ul class="lvl-0"><li class="lvl-2"><p>即不需要进行分库分表的表</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="type">!SINGLE</span> <span class="comment"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class="line">    <span class="attr">tables:</span></span><br><span class="line">      <span class="comment"># MySQL 风格</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ds_0.t_address</span> <span class="comment"># 加载指定单表</span></span><br></pre></td></tr></table></figure><h3 id="属性配置">属性配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/</span></span><br><span class="line"><span class="attr">props:</span></span><br><span class="line">  <span class="attr">sql-show:</span> <span class="literal">true</span> <span class="comment"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class="line">  <span class="attr">check-table-metadata-enabled:</span> <span class="literal">false</span> <span class="comment"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure><h3 id="事务配置">事务配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/</span></span><br><span class="line"><span class="attr">transaction:</span></span><br><span class="line">  <span class="attr">defaultType:</span> <span class="string">LOCAL</span> <span class="comment"># 默认事务类型就是 LOCAL</span></span><br></pre></td></tr></table></figure><h2 id="后记">后记</h2><ul class="lvl-0"><li class="lvl-2"><p>springboot3 集成 shardingsphere-JDBC5.5.2 与 springboot2 不同，不再提供 <code>springboot-starter-shardingsphere</code>，相关配置也采用了独立的配置文件。</p></li><li class="lvl-2"><p>代码中包含两个库中使用到的数据库脚本，<code>shardingsphere-demo/shardingsphere-demo-01/sql</code></p></li><li class="lvl-2"><p>具体使用效果可以通过项目中提供的单元测试类进行验证。</p></li><li class="lvl-2"><p>springboot3 集成 shardingsphere-JDBC5.5.2 目前<a href="https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/jdbc-driver/spring-boot/">尚不支持 <code>XA</code> 分布式事务</a>，这是因为从 <code>Spring Boot 3.x</code> 开始，就全面迁移到了 <code>Jakarta EE 9+</code>，也就是说，所有 <code>javax.*</code> 的类都迁移到 <code>jakarta.*</code> 命名空间(事务、JPA、Servlet 等 API 都受影响)，而 <code>ShardingSphere 5.5</code> 中的 XA 事务主要依赖 <code>Atomikos</code> 或 <code>Narayana</code> 等第三方分布式事务管理器，这些库目前大部分还是基于 <code>javax.transaction.*</code> 的 API。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--
 **加粗**
 *斜体*
 ***加粗并斜体***
 ~~删除线~~
 ==突出显示==
 `突出显示(推荐)`
 ++下划线++
 ~下标~
 ^上标^
 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.
 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)

 +++ **点击折叠**
 这是被隐藏的内容
 +++

::: tips success warning danger
这里是容器内的内容
:::

% note info % success warning danger
这里是容器内的内容
% endnote %

引用本地其它文章连接{}
 大括号开始% post_link 文件名称(不包含.md) %大括号结束
 --&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;ul class=&quot;lvl-0&quot;&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;本文介绍 SpringBoot3.5.5 + ShardingSphere-JDBC5.5.2 分库分表的使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/index_zh.html&quot;&gt;ShardingSphere官网&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;lvl-2&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-01&quot;&gt;本文项目代码Github地址&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="技术" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/categories/%E6%8A%80%E6%9C%AF/springboot/sharding-sphere/"/>
    
    
    <category term="springboot" scheme="https://blog.hanqunfeng.com/tags/springboot/"/>
    
    <category term="sharding-sphere" scheme="https://blog.hanqunfeng.com/tags/sharding-sphere/"/>
    
  </entry>
  
</feed>
