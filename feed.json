{"version":"https://jsonfeed.org/version/1","name":"飘逸峰的博客","home_page_url":"https://blog.hanqunfeng.com","feed_url":"https://blog.hanqunfeng.com/feed.json","author":{"name":"飘逸峰"},"items":[{"id":"https://blog.hanqunfeng.com/2025/10/31/rocketmq-08-acl2.0/","url":"https://blog.hanqunfeng.com/2025/10/31/rocketmq-08-acl2.0/","title":"RocketMQ ACL 2.0","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ ACL 2.0 的使用方法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"ACL-2-0-简介\">ACL 2.0 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 <a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a> 中没有找到关于 ACL 2.0 的介绍，但是有介绍 ACL 1.0 的使用方法: <a href=\"https://rocketmq.apache.org/zh/docs/bestPractice/03access\">https://rocketmq.apache.org/zh/docs/bestPractice/03access</a>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在阿里云上找到一篇参考资料：<a href=\"https://developer.aliyun.com/article/1569146\">Apache RocketMQ ACL 2.0 全新升级</a></p>\n</li>\n</ul>\n<h2 id=\"配置步骤\">配置步骤</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文在 <a href=\"/2025/10/23/rocketmq-01-install/\" title=\"RocketMQ 的安装及使用\">RocketMQ 的安装及使用</a> 中 集群 安装完成之后，开始配置 ACL 2.0。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在所有 Broker 的配置文件<code>broker.conf</code>中增加认证与授权配置:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># broker.conf</span></span><br><span class=\"line\"><span class=\"comment\"># 认证配置</span></span><br><span class=\"line\">authenticationEnabled = <span class=\"literal\">true</span></span><br><span class=\"line\">authenticationProvider = org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProvider</span><br><span class=\"line\">initAuthenticationUser = &#123;<span class=\"string\">&quot;username&quot;</span>:<span class=\"string\">&quot;mqadmin&quot;</span>,<span class=\"string\">&quot;password&quot;</span>:<span class=\"string\">&quot;1234567&quot;</span>&#125;</span><br><span class=\"line\">innerClientAuthenticationCredentials = &#123;<span class=\"string\">&quot;accessKey&quot;</span>:<span class=\"string\">&quot;mqadmin&quot;</span>,<span class=\"string\">&quot;secretKey&quot;</span>:<span class=\"string\">&quot;1234567&quot;</span>&#125;</span><br><span class=\"line\">authenticationMetadataProvider = org.apache.rocketmq.auth.authentication.provider.LocalAuthenticationMetadataProvider</span><br><span class=\"line\"><span class=\"comment\"># 授权配置</span></span><br><span class=\"line\">authorizationEnabled = <span class=\"literal\">true</span></span><br><span class=\"line\">authorizationProvider = org.apache.rocketmq.auth.authorization.provider.DefaultAuthorizationProvider</span><br><span class=\"line\">authorizationMetadataProvider = org.apache.rocketmq.auth.authorization.provider.LocalAuthorizationMetadataProvider</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数定义</th>\n<th style=\"text-align:left\">参数名称</th>\n<th style=\"text-align:left\">参数描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>authenticationEnabled</strong></td>\n<td style=\"text-align:left\">是否打开认证开关</td>\n<td style=\"text-align:left\">用于判断认证是否打开。<br>可选值：<br>• <code>true</code> – 是<br>• <code>false</code> – 否</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>authenticationProvider</strong></td>\n<td style=\"text-align:left\">认证方式提供者</td>\n<td style=\"text-align:left\">用于提供请求访问时的认证方式。<br>可选值：<br>• <code>org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProvider</code> – 默认的认证方式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>initAuthenticationUser</strong></td>\n<td style=\"text-align:left\">系统初始化用户</td>\n<td style=\"text-align:left\">用于系统初始化时自动创建的用户账号。<br>示例：<br><code>&#123;&quot;username&quot;:&quot;rocketmq&quot;,&quot;password&quot;:&quot;12345678&quot;&#125;</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>innerClientAuthenticationCredentials</strong></td>\n<td style=\"text-align:left\">组件间认证用户</td>\n<td style=\"text-align:left\">用于设置集群内组件之间的访问凭证。<br>示例：<br><code>&#123;&quot;accessKey&quot;:&quot;rocketmq&quot;,&quot;secretKey&quot;:&quot;12345678&quot;&#125;</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>authenticationMetadataProvider</strong></td>\n<td style=\"text-align:left\">认证元数据提供者</td>\n<td style=\"text-align:left\">用于提供认证相关的元数据（如用户）。<br>可选值：<br>• <code>org.apache.rocketmq.auth.authentication.provider.LocalAuthenticationMetadataProvider</code> – 本地认证元数据提供者<br>• <code>org.apache.rocketmq.proxy.auth.ProxyAuthenticationMetadataProvider</code> – Proxy认证元数据提供者</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>authenticationStrategy</strong></td>\n<td style=\"text-align:left\">认证策略</td>\n<td style=\"text-align:left\">用于指定请求访问时的认证策略。<br>可选值：<br>• <code>org.apache.rocketmq.auth.authentication.strategy.StatelessAuthenticationStrategy</code> – 每次请求认证策略<br>• <code>org.apache.rocketmq.auth.authentication.strategy.StatefulAuthenticationStrategy</code> – 首次请求认证策略</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重启启动所有 Broker</p>\n</li>\n</ul>\n<h2 id=\"命令行管理用户\">命令行管理用户</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 <code>conf/tools.yml</code> 配置正确的账号密码，否则无法执行 <code>mqadmin</code> 命令。</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\"><span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"用户管理\">用户管理</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">接口定义</th>\n<th style=\"text-align:left\">接口名称</th>\n<th style=\"text-align:left\">接口参数</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>createUser</strong></td>\n<td style=\"text-align:left\">创建用户</td>\n<td style=\"text-align:left\">-n namesrv 地址<br>-b broker 地址<br>-c 集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-u 用户名称<br>-p 用户密码<br>-t 用户类型（Super、Normal）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>updateUser</strong></td>\n<td style=\"text-align:left\">更新用户</td>\n<td style=\"text-align:left\">-n namesrv 地址<br>-b broker 地址<br>-c 集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-u 用户名称<br>-p 用户密码<br>-t 用户类型（Super、Normal）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>deleteUser</strong></td>\n<td style=\"text-align:left\">删除用户</td>\n<td style=\"text-align:left\">-b broker 地址<br>-c 集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-u 用户名称</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>getUser</strong></td>\n<td style=\"text-align:left\">查询用户详情</td>\n<td style=\"text-align:left\">-n namesrv 地址<br>-b broker 地址<br>-c 集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-u 用户名称</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>listUser</strong></td>\n<td style=\"text-align:left\">查询用户列表</td>\n<td style=\"text-align:left\">-n namesrv 地址<br>-b broker 地址<br>-c 集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-u 用户名称<br>-f 过滤条件（支持用户名称模糊查询，可选）</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建用户</span></span><br><span class=\"line\">sh bin/mqadmin createUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p rocketmq</span><br><span class=\"line\"><span class=\"comment\"># 创建用户，指定用户类型</span></span><br><span class=\"line\">sh bin/mqadmin createUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p rocketmq -t Super</span><br><span class=\"line\"><span class=\"comment\"># 更新用户</span></span><br><span class=\"line\">sh bin/mqadmin updateUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p 12345678</span><br><span class=\"line\"><span class=\"comment\"># 删除用户</span></span><br><span class=\"line\">sh bin/mqadmin deleteUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq</span><br><span class=\"line\"><span class=\"comment\"># 查询用户详情</span></span><br><span class=\"line\">sh bin/mqadmin getUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq</span><br><span class=\"line\"><span class=\"comment\"># 查询用户列表</span></span><br><span class=\"line\">sh bin/mqadmin listUser -n 127.0.0.1:9876 -c DefaultCluster</span><br><span class=\"line\"><span class=\"comment\"># 查询用户列表，带过滤条件</span></span><br><span class=\"line\">sh bin/mqadmin listUser -n 127.0.0.1:9876 -c DefaultCluster -f mq</span><br></pre></td></tr></table></figure>\n<h3 id=\"权限管理\">权限管理</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>管理员(Super)拥有所以资源的访问权限，普通用户(Normal)则只有对应资源类型的访问权限。以下是为普通用户设置权限的命令。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">命令名称</th>\n<th style=\"text-align:left\">操作定义</th>\n<th style=\"text-align:left\">命令参数及解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong><code>createAcl</code></strong></td>\n<td style=\"text-align:left\">创建授权</td>\n<td style=\"text-align:left\">-n <strong>127.0.0.1:9876</strong>：NameServer 地址（多个以 <code>;</code> 分隔）<br>-b broker 地址<br>-c <strong>DefaultCluster</strong>：集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-s <strong>User:rocketmq</strong>：授权的用户（<code>User:rocketmq</code> 表示给用户 <code>rocketmq</code> 授权）<br>-r <strong>Topic:*,Group:</strong>：资源类型与名称，<code>*</code> 表示所有 Topic 和 Group<br>-a <strong>Pub,Sub</strong>：授权操作类型，<code>Pub</code> 表示发布权限，<code>Sub</code> 表示订阅权限<br>-i <strong>192.168.1.0/24</strong>：授权的 IP 地址范围<br>-d <strong>Allow</strong>：授权类型，<code>Allow</code> 允许，<code>Deny</code> 拒绝</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong><code>updateAcl</code></strong></td>\n<td style=\"text-align:left\">更新授权</td>\n<td style=\"text-align:left\">-n <strong>127.0.0.1:9876</strong>：NameServer 地址<br>-b broker 地址<br>-c <strong>DefaultCluster</strong>：集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-s <strong>User:rocketmq</strong>：授权的用户<br>-r <strong>Topic:*,Group:</strong>：资源类型与名称<br>-a <strong>Pub,Sub</strong>：授权操作类型<br>-i <strong>192.168.1.0/24</strong>：IP 地址范围<br>-d <strong>Deny</strong>：授权类型，更新为 <code>Deny</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong><code>deleteAcl</code></strong></td>\n<td style=\"text-align:left\">删除授权</td>\n<td style=\"text-align:left\">-n <strong>127.0.0.1:9876</strong>：NameServer 地址<br>-b broker 地址<br>-c <strong>DefaultCluster</strong>：集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-s <strong>User:rocketmq</strong>：授权的用户<br>-r <strong>Topic:</strong>：指定删除某个资源（如 Topic）授权</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong><code>listAcl</code></strong></td>\n<td style=\"text-align:left\">查询授权列表</td>\n<td style=\"text-align:left\">-n <strong>127.0.0.1:9876</strong>：NameServer 地址<br>-b broker 地址<br>-c <strong>DefaultCluster</strong>：集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-s <strong>User:rocketmq</strong>：授权的用户<br>-r <strong>Topic:</strong>：指定资源类型（如 Topic）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong><code>getAcl</code></strong></td>\n<td style=\"text-align:left\">查询授权详情</td>\n<td style=\"text-align:left\">-n <strong>127.0.0.1:9876</strong>：NameServer 地址<br>-b broker 地址<br>-c <strong>DefaultCluster</strong>：集群名称<br><strong>注：</strong><code>-b</code> 和 <code>-c</code> 参数二选一<br>-s <strong>User:rocketmq</strong>：授权的用户</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建授权</span></span><br><span class=\"line\">sh bin/mqadmin createAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*,Group:* -a Pub,Sub -i 192.168.1.0/24 -d Allow</span><br><span class=\"line\"><span class=\"comment\"># 更新授权</span></span><br><span class=\"line\">sh bin/mqadmin updateAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*,Group:* -a Pub,Sub -i 192.168.1.0/24 -d Deny</span><br><span class=\"line\"><span class=\"comment\"># 删除授权</span></span><br><span class=\"line\">sh bin/mqadmin deleteAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq</span><br><span class=\"line\"><span class=\"comment\"># 删除授权，指定资源</span></span><br><span class=\"line\">sh bin/mqadmin deleteAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*</span><br><span class=\"line\"><span class=\"comment\"># 查询授权列表</span></span><br><span class=\"line\">sh bin/mqadmin listAcl -n 127.0.0.1:9876 -c DefaultCluster</span><br><span class=\"line\"><span class=\"comment\"># 查询授权列表，带过滤条件</span></span><br><span class=\"line\">sh bin/mqadmin listAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*</span><br><span class=\"line\"><span class=\"comment\"># 查询授权详情</span></span><br><span class=\"line\">sh bin/mqadmin getAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq</span><br></pre></td></tr></table></figure>\n<h2 id=\"Dashboard-配置\">Dashboard 配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时在 Dashboard 中配置好认证信息并重启，即可正常访问RocketMQ集群，并且支持在web端配置ACL认证信息。</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># vim run/application.yaml # 按需替换配置</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">rocketmq:</span></span><br><span class=\"line\">  <span class=\"attr\">config:</span></span><br><span class=\"line\">    <span class=\"attr\">namesrvAddrs:</span>                <span class=\"comment\"># 填写NameServer地址列表</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.175</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.188</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.131</span><span class=\"string\">:9876</span></span><br><span class=\"line\">    <span class=\"attr\">dataPath:</span> <span class=\"string\">/usr/local/soft/rocketmq/data/dashboard</span> <span class=\"comment\"># Dashboard文件目录，登录用户配置文件所在目录</span></span><br><span class=\"line\">    <span class=\"attr\">loginRequired:</span> <span class=\"literal\">true</span>  <span class=\"comment\"># 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件</span></span><br><span class=\"line\">    <span class=\"comment\"># 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey</span></span><br><span class=\"line\">    <span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\">    <span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Proxy-配置\">Proxy 配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Broker 开启 ACL 2.0 认证后，即使在代码中添加了ACL认证信息的情况下，<a href=\"https://github.com/apache/rocketmq-clients/tree/master/java/client/src/main/java/org/apache/rocketmq/client/java/example\">新版客户端(rocketmq-client-java)</a>通过<code>Proxy</code>发送或订阅消息依旧会失败，<a href=\"https://github.com/apache/rocketmq/tree/develop/example\">原客户端(rocketmq-client)</a>通过<code>Nameserver</code>发送或订阅消息正常，尚不知道该如何完美解决。</p>\n</li>\n<li class=\"lvl-2\">\n<p>按照这篇文章<a href=\"https://developer.aliyun.com/article/1569146\">Apache RocketMQ ACL 2.0 全新升级</a>的介绍，在所有 Proxy 的配置文件<code>rmq-proxy.json</code>中增加认证与授权配置依旧没有解决该问题。</p>\n</li>\n</ul>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authenticationEnabled&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authenticationProvider&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProvider&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authenticationMetadataProvider&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;org.apache.rocketmq.proxy.auth.ProxyAuthenticationMetadataProvider&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;innerClientAuthenticationCredentials&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;&#123;\\&quot;accessKey\\&quot;:\\&quot;mqadmin\\&quot;, \\&quot;secretKey\\&quot;:\\&quot;1234567\\&quot;&#125;&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authorizationEnabled&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authorizationProvider&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;org.apache.rocketmq.auth.authorization.provider.DefaultAuthorizationProvider&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;authorizationMetadataProvider&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;org.apache.rocketmq.proxy.auth.ProxyAuthorizationMetadataProvider&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>异常信息如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Caused by: org.apache.rocketmq.client.java.exception.UnauthorizedException: [request-id=1b2af952-38d9-4201-bd10-055e442c6b59, response-code=40100] Authentication failed. Please verify the credentials and try again.</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>之后通过这篇文章 <a href=\"https://blog.zcw159357.com/article/1/2025-03-15-0048.html\">rocketmq部署踩坑(二) acl配置</a> 的介绍，需要在 <code>rmq-proxy.json</code> 中增加如下配置：</p>\n</li>\n</ul>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">&quot;enableAclRpcHookForClusterMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置完成后，重启 Proxy，生产者发送消息果然没问题了，消费者启动也不会报错，但是就是接收不到任何消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>之后通过这篇文章 <a href=\"https://blog.csdn.net/icebamboo2015/article/details/152118732\">关于RocketMq5.3.3开启ACL2.0通过proxy8081端口只能发消息，不能收消息问题简单处理</a> 的说明，将所有 <code>broker.conf</code> 中 <code>authorizationEnabled</code> 配置改为 <code>false</code>，重启 Broker，问题解决。</p>\n</li>\n</ul>\n<h2 id=\"后记\">后记</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>笔者感觉当前 RocketMQ 的 ACL 2.0 认证机制还存在一些bug，就连官网也没有提供的文档说明，暂时先玩玩吧。</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RocketMQ ACL 2.0 的使用方法。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。 ACL 2.0 简介 在 RocketMQ官网 中没有找到关于 ACL 2.0 的介绍，但是有介绍 ACL 1.0 的使用方法: https://rocketmq.apache.org/zh/docs/bestPractice/03access。 在阿里云上找到一篇参考资料：Apache RocketMQ ACL 2.0 全新升级 配置步骤 本文在 RocketMQ 的安装及使用 中 集群 安装完成之后，开始配置 ACL 2.0。 在所有 Broker 的配置文件broker.conf中增加认证与授权配置: 1234567891011# broker.conf# 认证配置authenticationEnabled = trueauthenticationProvider = org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProviderinitAuthenticationUser = &#123;&quot;username&quot;:&quot;mqadmin&quot;,&quot;password&quot;:&quot;1234567&quot;&#125;innerClientAuthenticationCredentials = &#123;&quot;accessKey&quot;:&quot;mqadmin&quot;,&quot;secretKey&quot;:&quot;1234567&quot;&#125;authenticationMetadataProvider = org.apache.rocketmq.auth.authentication.provider.LocalAuthenticationMetadataProvider# 授权配置authorizationEnabled = trueauthorizationProvider = org.apache.rocketmq.auth.authorization.provider.DefaultAuthorizationProviderauthorizationMetadataProvider = org.apache.rocketmq.auth.authorization.provider.LocalAuthorizationMetadataProvider 参数定义 参数名称 参数描述 authenticationEnabled 是否打开认证开关 用于判断认证是否打开。可选值：• true – 是• false – 否 authenticationProvider 认证方式提供者 用于提供请求访问时的认证方式。可选值：• org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProvider – 默认的认证方式 initAuthenticationUser 系统初始化用户 用于系统初始化时自动创建的用户账号。示例：&#123;&quot;username&quot;:&quot;rocketmq&quot;,&quot;password&quot;:&quot;12345678&quot;&#125; innerClientAuthenticationCredentials 组件间认证用户 用于设置集群内组件之间的访问凭证。示例：&#123;&quot;accessKey&quot;:&quot;rocketmq&quot;,&quot;secretKey&quot;:&quot;12345678&quot;&#125; authenticationMetadataProvider 认证元数据提供者 用于提供认证相关的元数据（如用户）。可选值：• org.apache.rocketmq.auth.authentication.provider.LocalAuthenticationMetadataProvider – 本地认证元数据提供者• org.apache.rocketmq.proxy.auth.ProxyAuthenticationMetadataProvider – Proxy认证元数据提供者 authenticationStrategy 认证策略 用于指定请求访问时的认证策略。可选值：• org.apache.rocketmq.auth.authentication.strategy.StatelessAuthenticationStrategy – 每次请求认证策略• org.apache.rocketmq.auth.authentication.strategy.StatefulAuthenticationStrategy – 首次请求认证策略 重启启动所有 Broker 命令行管理用户 如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 conf/tools.yml 配置正确的账号密码，否则无法执行 mqadmin 命令。 12accessKey: mqadminsecretKey: 1234567 用户管理 接口定义 接口名称 接口参数 createUser 创建用户 -n namesrv 地址-b broker 地址-c 集群名称注：-b 和 -c 参数二选一-u 用户名称-p 用户密码-t 用户类型（Super、Normal） updateUser 更新用户 -n namesrv 地址-b broker 地址-c 集群名称注：-b 和 -c 参数二选一-u 用户名称-p 用户密码-t 用户类型（Super、Normal） deleteUser 删除用户 -b broker 地址-c 集群名称注：-b 和 -c 参数二选一-u 用户名称 getUser 查询用户详情 -n namesrv 地址-b broker 地址-c 集群名称注：-b 和 -c 参数二选一-u 用户名称 listUser 查询用户列表 -n namesrv 地址-b broker 地址-c 集群名称注：-b 和 -c 参数二选一-u 用户名称-f 过滤条件（支持用户名称模糊查询，可选） 示例 1234567891011121314# 创建用户sh bin/mqadmin createUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p rocketmq# 创建用户，指定用户类型sh bin/mqadmin createUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p rocketmq -t Super# 更新用户sh bin/mqadmin updateUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq -p 12345678# 删除用户sh bin/mqadmin deleteUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq# 查询用户详情sh bin/mqadmin getUser -n 127.0.0.1:9876 -c DefaultCluster -u rocketmq# 查询用户列表sh bin/mqadmin listUser -n 127.0.0.1:9876 -c DefaultCluster# 查询用户列表，带过滤条件sh bin/mqadmin listUser -n 127.0.0.1:9876 -c DefaultCluster -f mq 权限管理 管理员(Super)拥有所以资源的访问权限，普通用户(Normal)则只有对应资源类型的访问权限。以下是为普通用户设置权限的命令。 命令名称 操作定义 命令参数及解释 createAcl 创建授权 -n 127.0.0.1:9876：NameServer 地址（多个以 ; 分隔）-b broker 地址-c DefaultCluster：集群名称注：-b 和 -c 参数二选一-s User:rocketmq：授权的用户（User:rocketmq 表示给用户 rocketmq 授权）-r Topic:*,Group:：资源类型与名称，* 表示所有 Topic 和 Group-a Pub,Sub：授权操作类型，Pub 表示发布权限，Sub 表示订阅权限-i 192.168.1.0/24：授权的 IP 地址范围-d Allow：授权类型，Allow 允许，Deny 拒绝 updateAcl 更新授权 -n 127.0.0.1:9876：NameServer 地址-b broker 地址-c DefaultCluster：集群名称注：-b 和 -c 参数二选一-s User:rocketmq：授权的用户-r Topic:*,Group:：资源类型与名称-a Pub,Sub：授权操作类型-i 192.168.1.0/24：IP 地址范围-d Deny：授权类型，更新为 Deny deleteAcl 删除授权 -n 127.0.0.1:9876：NameServer 地址-b broker 地址-c DefaultCluster：集群名称注：-b 和 -c 参数二选一-s User:rocketmq：授权的用户-r Topic:：指定删除某个资源（如 Topic）授权 listAcl 查询授权列表 -n 127.0.0.1:9876：NameServer 地址-b broker 地址-c DefaultCluster：集群名称注：-b 和 -c 参数二选一-s User:rocketmq：授权的用户-r Topic:：指定资源类型（如 Topic） getAcl 查询授权详情 -n 127.0.0.1:9876：NameServer 地址-b broker 地址-c DefaultCluster：集群名称注：-b 和 -c 参数二选一-s User:rocketmq：授权的用户 示例 1234567891011121314# 创建授权sh bin/mqadmin createAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*,Group:* -a Pub,Sub -i 192.168.1.0/24 -d Allow# 更新授权sh bin/mqadmin updateAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*,Group:* -a Pub,Sub -i 192.168.1.0/24 -d Deny# 删除授权sh bin/mqadmin deleteAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq# 删除授权，指定资源sh bin/mqadmin deleteAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*# 查询授权列表sh bin/mqadmin listAcl -n 127.0.0.1:9876 -c DefaultCluster# 查询授权列表，带过滤条件sh bin/mqadmin listAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq -r Topic:*# 查询授权详情sh bin/mqadmin getAcl -n 127.0.0.1:9876 -c DefaultCluster -s User:rocketmq Dashboard 配置 此时在 Dashboard 中配置好认证信息并重启，即可正常访问RocketMQ集群，并且支持在web端配置ACL认证信息。 12345678910111213# vim run/application.yaml # 按需替换配置rocketmq: config: namesrvAddrs: # 填写NameServer地址列表 - 10.250.0.175:9876 - 10.250.0.188:9876 - 10.250.0.131:9876 dataPath: /usr/local/soft/rocketmq/data/dashboard # Dashboard文件目录，登录用户配置文件所在目录 loginRequired: true # 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件 # 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey accessKey: mqadmin secretKey: 1234567 Proxy 配置 Broker 开启 ACL 2.0 认证后，即使在代码中添加了ACL认证信息的情况下，新版客户端(rocketmq-client-java)通过Proxy发送或订阅消息依旧会失败，原客户端(rocketmq-client)通过Nameserver发送或订阅消息正常，尚不知道该如何完美解决。 按照这篇文章Apache RocketMQ ACL 2.0 全新升级的介绍，在所有 Proxy 的配置文件rmq-proxy.json中增加认证与授权配置依旧没有解决该问题。 123456789&#123; &quot;authenticationEnabled&quot;: true, &quot;authenticationProvider&quot;: &quot;org.apache.rocketmq.auth.authentication.provider.DefaultAuthenticationProvider&quot;, &quot;authenticationMetadataProvider&quot;: &quot;org.apache.rocketmq.proxy.auth.ProxyAuthenticationMetadataProvider&quot;, &quot;innerClientAuthenticationCredentials&quot;: &quot;&#123;\\&quot;accessKey\\&quot;:\\&quot;mqadmin\\&quot;, \\&quot;secretKey\\&quot;:\\&quot;1234567\\&quot;&#125;&quot;, &quot;authorizationEnabled&quot;: true, &quot;authorizationProvider&quot;: &quot;org.apache.rocketmq.auth.authorization.provider.DefaultAuthorizationProvider&quot;, &quot;authorizationMetadataProvider&quot;: &quot;org.apache.rocketmq.proxy.auth.ProxyAuthorizationMetadataProvider&quot;&#125; 异常信息如下： 1Caused by: org.apache.rocketmq.client.java.exception.UnauthorizedException: [request-id=1b2af952-38d9-4201-bd10-055e442c6b59, response-code=40100] Authentication failed. Please verify the credentials and try again. 之后通过这篇文章 rocketmq部署踩坑(二) acl配置 的介绍，需要在 rmq-proxy.json 中增加如下配置： 1&quot;enableAclRpcHookForClusterMode&quot;: true 配置完成后，重启 Proxy，生产者发送消息果然没问题了，消费者启动也不会报错，但是就是接收不到任何消息。 之后通过这篇文章 关于RocketMq5.3.3开启ACL2.0通过proxy8081端口只能发消息，不能收消息问题简单处理 的说明，将所有 broker.conf 中 authorizationEnabled 配置改为 false，重启 Broker，问题解决。 后记 笔者感觉当前 RocketMQ 的 ACL 2.0 认证机制还存在一些bug，就连官网也没有提供的文档说明，暂时先玩玩吧。","summary":"摘要 本文介绍 RocketMQ ACL 2.0 的使用方法。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。","date_published":"2025-10-31T13:40:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/29/rocketmq-08-acl1.0/","url":"https://blog.hanqunfeng.com/2025/10/29/rocketmq-08-acl1.0/","title":"RocketMQ ACL 1.0","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ ACL 1.0 的使用方法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"ACL-1-0-简介\">ACL 1.0 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ACL控制在增强集群访问控制安全性的同时也会带来部署流程和运维管理的复杂度。</p>\n</li>\n<li class=\"lvl-2\">\n<p>一般仅建议在网络环境不安全、业务数据敏感、多部门租户混用的场景下使用。如果生产集群本身是私有集群不会被外部部门租户访问，可以不开启。</p>\n</li>\n</ul>\n<h2 id=\"ACL-1-0-使用方法\">ACL 1.0 使用方法</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文在 <a href=\"/2025/10/23/rocketmq-01-install/\" title=\"RocketMQ 的安装及使用\">RocketMQ 的安装及使用</a> 中 集群 安装完成之后，开始配置 ACL 1.0。</p>\n</li>\n<li class=\"lvl-2\">\n<p>首先需要在 Broker 节点开启 ACL 权限，在 <code>broker.conf</code> 文件中添加如下配置，并重启 Broker</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aclEnable=<span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>权限配置文件为 <code>conf/plain_acl.yml</code>，这个文件不需要修改，后面会介绍如何通过命令行进行配置，默认的内容如下：</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 全局白名单，支持的格式：*;192.168.*.*;192.168.0.1</span></span><br><span class=\"line\"><span class=\"comment\"># 白名单内的 IP 都可以访问，无需配置帐号</span></span><br><span class=\"line\"><span class=\"attr\">globalWhiteRemoteAddresses:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"number\">10.10</span><span class=\"number\">.103</span><span class=\"string\">.*</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"number\">192.168</span><span class=\"number\">.0</span><span class=\"string\">.*</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 全局白名单外的IP,需要账号访问</span></span><br><span class=\"line\"><span class=\"comment\"># 账号配置，数组形式</span></span><br><span class=\"line\"><span class=\"attr\">accounts:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">accessKey:</span> <span class=\"string\">RocketMQ</span> <span class=\"comment\"># 用户名</span></span><br><span class=\"line\">    <span class=\"attr\">secretKey:</span> <span class=\"number\">12345678</span> <span class=\"comment\"># 密码</span></span><br><span class=\"line\">    <span class=\"attr\">whiteRemoteAddress:</span> <span class=\"comment\"># 当前帐号的白名单</span></span><br><span class=\"line\">    <span class=\"attr\">admin:</span> <span class=\"literal\">false</span>        <span class=\"comment\"># 是否是管理员</span></span><br><span class=\"line\">    <span class=\"attr\">defaultTopicPerm:</span> <span class=\"string\">DENY</span> <span class=\"comment\"># 当前用户对未在 topicPerms 中显式声明的 Topic 的默认权限:DENY;PUB;SUB;PUB|SUB</span></span><br><span class=\"line\">    <span class=\"attr\">defaultGroupPerm:</span> <span class=\"string\">SUB</span>  <span class=\"comment\"># 当前用户对未在 groupPerms 中显式声明的 Consumer Group 的默认权限:DENY;PUB;SUB;PUB|SUB</span></span><br><span class=\"line\">    <span class=\"attr\">topicPerms:</span>            <span class=\"comment\"># 特定的 topic 权限</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">topicA=DENY</span>        <span class=\"comment\"># topicName=perm</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">topicB=PUB|SUB</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">topicC=SUB</span></span><br><span class=\"line\">    <span class=\"attr\">groupPerms:</span>            <span class=\"comment\"># 特定的 ConsumerGroup 权限</span></span><br><span class=\"line\">      <span class=\"comment\"># the group should convert to retry topic</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">groupA=DENY</span>        <span class=\"comment\"># groupName=perm</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">groupB=PUB|SUB</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">groupC=SUB</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">accessKey:</span> <span class=\"string\">rocketmq2</span></span><br><span class=\"line\">    <span class=\"attr\">secretKey:</span> <span class=\"number\">12345678</span></span><br><span class=\"line\">    <span class=\"attr\">whiteRemoteAddress:</span> <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"string\">.*</span></span><br><span class=\"line\">    <span class=\"comment\"># if it is admin, it could access all resources</span></span><br><span class=\"line\">    <span class=\"attr\">admin:</span> <span class=\"literal\">true</span>         <span class=\"comment\"># 是否是管理员,true 表示管理员,管理员可以访问所有资源</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>权限定义</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">权限值</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>DENY</strong></td>\n<td style=\"text-align:left\">拒绝</td>\n<td style=\"text-align:left\">禁止对该 Topic 的任何操作（无论是发送还是订阅）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>ANY</strong></td>\n<td style=\"text-align:left\">任意权限</td>\n<td style=\"text-align:left\">具有发布（PUB）和订阅（SUB）双重权限</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>PUB</strong></td>\n<td style=\"text-align:left\">发送权限</td>\n<td style=\"text-align:left\">允许生产者向该 Topic 发送消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>SUB</strong></td>\n<td style=\"text-align:left\">订阅权限</td>\n<td style=\"text-align:left\">允许消费者订阅并消费该 Topic 的消息</td>\n</tr>\n</tbody>\n</table>\n<div class=\"tips\">\n<p><em><strong>defaultGroupPerm: SUB</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">表示：默认允许该用户以任意消费者组身份参与消费（不限制 group），但前提是该消费者对目标 Topic 也必须拥有 SUB 权限。</li>\n</ul>\n</div>\n<h3 id=\"命令行配置-ACL\">命令行配置 ACL</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 <code>conf/tools.yml</code> 配置正确的账号密码，否则无法执行 <code>mqadmin</code> 命令。</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\"><span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>以下命令执行后会自动修改 <code>conf/plain_acl.yml</code> 文件</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>添加白名单</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin updateGlobalWhiteAddr \\</span><br><span class=\"line\">    -n 127.0.0.1:9876 \\</span><br><span class=\"line\">    -c DefaultCluster \\</span><br><span class=\"line\">    -g 10.250.0.*,10.252.*.*,10.20.0.31</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">是否必填</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\">二选一必填</td>\n<td style=\"text-align:left\">指定要更新白名单的 <strong>Broker 地址</strong></td>\n<td style=\"text-align:left\"><code>127.0.0.1:10911</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\">二选一必填</td>\n<td style=\"text-align:left\">指定要更新白名单的 <strong>Cluster 名称</strong>，集群内所有 Broker 都会被更新</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-g</code></td>\n<td style=\"text-align:left\">✅ 必填</td>\n<td style=\"text-align:left\">要设置的全局白名单地址列表，支持通配符</td>\n<td style=\"text-align:left\"><code>&quot;10.10.103.*,192.168.0.*&quot;</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">NameServer 地址</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-p</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">指定 ACL 配置文件路径（Broker 端对应的配置文件路径）</td>\n<td style=\"text-align:left\"><code>/home/rocketmq/conf/plain_acl.yml</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\">否</td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:left\">—</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建或更新用户，accessKey 和 secretKey 的长度必须大于 6 位</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建管理员</span></span><br><span class=\"line\">sh bin/mqadmin updateAclConfig \\</span><br><span class=\"line\">    -n 127.0.0.1:9876 \\</span><br><span class=\"line\">    -c DefaultCluster \\</span><br><span class=\"line\">    -a mqadmin \\</span><br><span class=\"line\">    -s 1234567 \\</span><br><span class=\"line\">    -m <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建普通用户</span></span><br><span class=\"line\">sh bin/mqadmin updateAclConfig \\</span><br><span class=\"line\">  -c DefaultCluster \\</span><br><span class=\"line\">  -a rocketmq_user \\</span><br><span class=\"line\">  -s 12345678 \\</span><br><span class=\"line\">  -i <span class=\"string\">&quot;PUB|SUB&quot;</span> \\</span><br><span class=\"line\">  -u SUB \\</span><br><span class=\"line\">  -t <span class=\"string\">&quot;topicA=PUB|SUB,topicB=DENY&quot;</span> \\</span><br><span class=\"line\">  -g <span class=\"string\">&quot;groupA=SUB,groupB=DENY&quot;</span> \\</span><br><span class=\"line\">  -w <span class=\"string\">&quot;192.168.0.*&quot;</span> \\</span><br><span class=\"line\">  -n 127.0.0.1:9876</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">是否必填</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">示例</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-a</code></td>\n<td style=\"text-align:left\">✅ 必填</td>\n<td style=\"text-align:left\">用户名（accessKey）</td>\n<td style=\"text-align:left\"><code>rocketmq_user</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-s</code></td>\n<td style=\"text-align:left\">✅ 必填</td>\n<td style=\"text-align:left\">密码（secretKey）</td>\n<td style=\"text-align:left\"><code>12345678</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\">二选一</td>\n<td style=\"text-align:left\">指定目标 Broker 地址</td>\n<td style=\"text-align:left\"><code>127.0.0.1:10911</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\">二选一</td>\n<td style=\"text-align:left\">指定目标集群名称，集群中所有 Broker 都会被更新</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-g</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">指定 Group 权限列表</td>\n<td style=\"text-align:left\"><code>groupA=SUB,groupB=DENY</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-t</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">指定 Topic 权限列表</td>\n<td style=\"text-align:left\">`topicA=PUB</td>\n<td>SUB,topicB=DENY`</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-u</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">设置默认 Group 权限</td>\n<td style=\"text-align:left\"><code>SUB</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-i</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">设置默认 Topic 权限</td>\n<td style=\"text-align:left\"><code>DENY</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-w</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">设置 IP 白名单</td>\n<td style=\"text-align:left\"><code>&quot;10.10.10.*,192.168.1.*&quot;</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-m</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">是否设置为管理员账号</td>\n<td style=\"text-align:left\"><code>true</code> 或 <code>false</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">指定 NameServer 地址</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\">否</td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:left\">—</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除用户</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin deleteAccessConfig \\</span><br><span class=\"line\">    -n 127.0.0.1:9876 \\</span><br><span class=\"line\">    -c DefaultCluster \\</span><br><span class=\"line\">    -a mqadmin</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">是否必填</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-a</code></td>\n<td style=\"text-align:left\">✅ 必填</td>\n<td style=\"text-align:left\">要删除的用户名（accessKey）</td>\n<td style=\"text-align:left\"><code>rocketmq_user</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\">二选一</td>\n<td style=\"text-align:left\">指定目标 Broker 地址</td>\n<td style=\"text-align:left\"><code>127.0.0.1:10911</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\">二选一</td>\n<td style=\"text-align:left\">指定目标集群名称（删除整个集群上的该账号）</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\">指定 NameServer 地址</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\">否</td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:left\">—</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Dashboard-配置\">Dashboard 配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时在 Dashboard 中配置好认证信息并重启，即可正常访问RocketMQ集群，但是并不支持在web端配置ACL认证信息。</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># vim run/application.yaml # 按需替换配置</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">rocketmq:</span></span><br><span class=\"line\">  <span class=\"attr\">config:</span></span><br><span class=\"line\">    <span class=\"attr\">namesrvAddrs:</span>                <span class=\"comment\"># 填写NameServer地址列表</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.175</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.188</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.131</span><span class=\"string\">:9876</span></span><br><span class=\"line\">    <span class=\"attr\">dataPath:</span> <span class=\"string\">/usr/local/soft/rocketmq/data/dashboard</span> <span class=\"comment\"># Dashboard文件目录，登录用户配置文件所在目录</span></span><br><span class=\"line\">    <span class=\"attr\">loginRequired:</span> <span class=\"literal\">true</span>  <span class=\"comment\"># 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件</span></span><br><span class=\"line\">    <span class=\"comment\"># 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey</span></span><br><span class=\"line\">    <span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\">    <span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"Proxy-配置\">Proxy 配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Broker 开启 ACL 1.0 认证后，即使在代码中添加了ACL认证信息的情况下，<a href=\"https://github.com/apache/rocketmq-clients/tree/master/java/client/src/main/java/org/apache/rocketmq/client/java/example\">新版客户端(rocketmq-client-java)</a>通过<code>Proxy</code>发送或订阅消息依旧会失败，<a href=\"https://github.com/apache/rocketmq/tree/develop/example\">原客户端(rocketmq-client)</a>通过<code>Nameserver</code>发送或订阅消息正常，尚不知道该如何完美解决。</p>\n</li>\n</ul>\n<h3 id=\"目前有两种没什么意义的解决方法：\">目前有两种没什么意义的解决方法：</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol>\n<li class=\"lvl-5\">将 Proxy IP 添加到白名单，因为客户端连接Proxy后，所有的请求都是由Proxy转发，所以将Proxy IP添加到白名单即可免于认证，该方法无需重启即可生效</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin updateGlobalWhiteAddr \\</span><br><span class=\"line\">    -n 127.0.0.1:9876 \\</span><br><span class=\"line\">    -c DefaultCluster \\</span><br><span class=\"line\">    -g 10.250.0.*</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol start=\"2\">\n<li class=\"lvl-5\">为 Proxy 开启 <code>enableAclRpcHookForClusterMode</code></li>\n</ol>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">修改<code>conf/rmq-proxy.json</code>文件，添加<code>enableAclRpcHookForClusterMode</code>参数</li>\n</ul>\n  <figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">&quot;enableAclRpcHookForClusterMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">修改<code>conf/tools.yml</code>文件，配置帐号信息：</li>\n</ul>\n  <figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\"><span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">重新启动Proxy即可</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>两种方法，客户端代码都不需要进行修改，甚至不需要添加ACL认证信息</p>\n</li>\n<li class=\"lvl-2\">\n<p>但这样做没啥意义，proxy也可以配置acl，但是没搞懂如何配置</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RocketMQ ACL 1.0 的使用方法。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。 ACL 1.0 简介 ACL控制在增强集群访问控制安全性的同时也会带来部署流程和运维管理的复杂度。 一般仅建议在网络环境不安全、业务数据敏感、多部门租户混用的场景下使用。如果生产集群本身是私有集群不会被外部部门租户访问，可以不开启。 ACL 1.0 使用方法 本文在 RocketMQ 的安装及使用 中 集群 安装完成之后，开始配置 ACL 1.0。 首先需要在 Broker 节点开启 ACL 权限，在 broker.conf 文件中添加如下配置，并重启 Broker 1aclEnable=true 权限配置文件为 conf/plain_acl.yml，这个文件不需要修改，后面会介绍如何通过命令行进行配置，默认的内容如下： 123456789101112131415161718192021222324252627282930# 全局白名单，支持的格式：*;192.168.*.*;192.168.0.1# 白名单内的 IP 都可以访问，无需配置帐号globalWhiteRemoteAddresses: - 10.10.103.* - 192.168.0.*# 全局白名单外的IP,需要账号访问# 账号配置，数组形式accounts: - accessKey: RocketMQ # 用户名 secretKey: 12345678 # 密码 whiteRemoteAddress: # 当前帐号的白名单 admin: false # 是否是管理员 defaultTopicPerm: DENY # 当前用户对未在 topicPerms 中显式声明的 Topic 的默认权限:DENY;PUB;SUB;PUB|SUB defaultGroupPerm: SUB # 当前用户对未在 groupPerms 中显式声明的 Consumer Group 的默认权限:DENY;PUB;SUB;PUB|SUB topicPerms: # 特定的 topic 权限 - topicA=DENY # topicName=perm - topicB=PUB|SUB - topicC=SUB groupPerms: # 特定的 ConsumerGroup 权限 # the group should convert to retry topic - groupA=DENY # groupName=perm - groupB=PUB|SUB - groupC=SUB - accessKey: rocketmq2 secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # if it is admin, it could access all resources admin: true # 是否是管理员,true 表示管理员,管理员可以访问所有资源 权限定义 权限值 含义 说明 DENY 拒绝 禁止对该 Topic 的任何操作（无论是发送还是订阅） ANY 任意权限 具有发布（PUB）和订阅（SUB）双重权限 PUB 发送权限 允许生产者向该 Topic 发送消息 SUB 订阅权限 允许消费者订阅并消费该 Topic 的消息 defaultGroupPerm: SUB 表示：默认允许该用户以任意消费者组身份参与消费（不限制 group），但前提是该消费者对目标 Topic 也必须拥有 SUB 权限。 命令行配置 ACL 如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 conf/tools.yml 配置正确的账号密码，否则无法执行 mqadmin 命令。 12accessKey: mqadminsecretKey: 1234567 以下命令执行后会自动修改 conf/plain_acl.yml 文件 添加白名单 1234sh bin/mqadmin updateGlobalWhiteAddr \\ -n 127.0.0.1:9876 \\ -c DefaultCluster \\ -g 10.250.0.*,10.252.*.*,10.20.0.31 参数 是否必填 含义 示例 -b 二选一必填 指定要更新白名单的 Broker 地址 127.0.0.1:10911 -c 二选一必填 指定要更新白名单的 Cluster 名称，集群内所有 Broker 都会被更新 DefaultCluster -g ✅ 必填 要设置的全局白名单地址列表，支持通配符 &quot;10.10.103.*,192.168.0.*&quot; -n 可选 NameServer 地址 127.0.0.1:9876 -p 可选 指定 ACL 配置文件路径（Broker 端对应的配置文件路径） /home/rocketmq/conf/plain_acl.yml -h 否 打印帮助信息 — 创建或更新用户，accessKey 和 secretKey 的长度必须大于 6 位 1234567891011121314151617181920# 创建管理员sh bin/mqadmin updateAclConfig \\ -n 127.0.0.1:9876 \\ -c DefaultCluster \\ -a mqadmin \\ -s 1234567 \\ -m true# 创建普通用户sh bin/mqadmin updateAclConfig \\ -c DefaultCluster \\ -a rocketmq_user \\ -s 12345678 \\ -i &quot;PUB|SUB&quot; \\ -u SUB \\ -t &quot;topicA=PUB|SUB,topicB=DENY&quot; \\ -g &quot;groupA=SUB,groupB=DENY&quot; \\ -w &quot;192.168.0.*&quot; \\ -n 127.0.0.1:9876 参数 是否必填 含义 示例 -a ✅ 必填 用户名（accessKey） rocketmq_user -s ✅ 必填 密码（secretKey） 12345678 -b 二选一 指定目标 Broker 地址 127.0.0.1:10911 -c 二选一 指定目标集群名称，集群中所有 Broker 都会被更新 DefaultCluster -g 可选 指定 Group 权限列表 groupA=SUB,groupB=DENY -t 可选 指定 Topic 权限列表 `topicA=PUB SUB,topicB=DENY` -u 可选 设置默认 Group 权限 SUB -i 可选 设置默认 Topic 权限 DENY -w 可选 设置 IP 白名单 &quot;10.10.10.*,192.168.1.*&quot; -m 可选 是否设置为管理员账号 true 或 false -n 可选 指定 NameServer 地址 127.0.0.1:9876 -h 否 打印帮助信息 — 删除用户 1234sh bin/mqadmin deleteAccessConfig \\ -n 127.0.0.1:9876 \\ -c DefaultCluster \\ -a mqadmin 参数 是否必填 含义 示例 -a ✅ 必填 要删除的用户名（accessKey） rocketmq_user -b 二选一 指定目标 Broker 地址 127.0.0.1:10911 -c 二选一 指定目标集群名称（删除整个集群上的该账号） DefaultCluster -n 可选 指定 NameServer 地址 127.0.0.1:9876 -h 否 打印帮助信息 — Dashboard 配置 此时在 Dashboard 中配置好认证信息并重启，即可正常访问RocketMQ集群，但是并不支持在web端配置ACL认证信息。 1234567891011121314# vim run/application.yaml # 按需替换配置rocketmq: config: namesrvAddrs: # 填写NameServer地址列表 - 10.250.0.175:9876 - 10.250.0.188:9876 - 10.250.0.131:9876 dataPath: /usr/local/soft/rocketmq/data/dashboard # Dashboard文件目录，登录用户配置文件所在目录 loginRequired: true # 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件 # 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey accessKey: mqadmin secretKey: 1234567 Proxy 配置 Broker 开启 ACL 1.0 认证后，即使在代码中添加了ACL认证信息的情况下，新版客户端(rocketmq-client-java)通过Proxy发送或订阅消息依旧会失败，原客户端(rocketmq-client)通过Nameserver发送或订阅消息正常，尚不知道该如何完美解决。 目前有两种没什么意义的解决方法： 将 Proxy IP 添加到白名单，因为客户端连接Proxy后，所有的请求都是由Proxy转发，所以将Proxy IP添加到白名单即可免于认证，该方法无需重启即可生效 1234sh bin/mqadmin updateGlobalWhiteAddr \\ -n 127.0.0.1:9876 \\ -c DefaultCluster \\ -g 10.250.0.* 为 Proxy 开启 enableAclRpcHookForClusterMode 修改conf/rmq-proxy.json文件，添加enableAclRpcHookForClusterMode参数 1&quot;enableAclRpcHookForClusterMode&quot;: true 修改conf/tools.yml文件，配置帐号信息： 12accessKey: mqadminsecretKey: 1234567 重新启动Proxy即可 两种方法，客户端代码都不需要进行修改，甚至不需要添加ACL认证信息 但这样做没啥意义，proxy也可以配置acl，但是没搞懂如何配置","summary":"摘要 本文介绍 RocketMQ ACL 1.0 的使用方法。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ 从 5.3.0 起引入安全性更高的 ACL 2.0，5.3.2 是最后一个还支持 ACL 1.0 的版本，5.3.3 移除了 ACL 1.0，官方建议所有使用 Apache RocketMQ ACL 的用户迁移到 ACL 2.0。","date_published":"2025-10-29T13:40:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-07-admin-tool/","url":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-07-admin-tool/","title":"RocketMQ Admin Tool","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ Admin Tool 的常用命令。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RocketMQ-Admin-Tool-简介\">RocketMQ Admin Tool 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/02admintool\">RocketMQ Admin Tool</a> 是 RocketMQ 的一个命令行工具，用于管理 RocketMQ 的集群。</p>\n</li>\n</ul>\n<h2 id=\"Topic-相关命令\">Topic 相关命令</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建或更新 Topic</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">全称</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">可选值 / 格式</th>\n<th style=\"text-align:left\">是否必填</th>\n<th style=\"text-align:left\">示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-t</code></td>\n<td style=\"text-align:left\"><code>--topic</code></td>\n<td style=\"text-align:left\">主题名称</td>\n<td style=\"text-align:left\">字符串</td>\n<td style=\"text-align:left\">✅ 必填</td>\n<td style=\"text-align:left\"><code>-t MyTopic</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\"><code>--brokerAddr</code></td>\n<td style=\"text-align:left\">指定创建 Topic 的 Broker 地址（与 <code>-c</code> 二选一）</td>\n<td style=\"text-align:left\"><code>ip:port</code></td>\n<td style=\"text-align:left\">✅ 必填（与 <code>-c</code> 二选一）</td>\n<td style=\"text-align:left\"><code>-b 192.168.1.10:10911</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\"><code>--clusterName</code></td>\n<td style=\"text-align:left\">指定创建 Topic 的集群名（与 <code>-b</code> 二选一）</td>\n<td style=\"text-align:left\">字符串</td>\n<td style=\"text-align:left\">✅ 必填（与 <code>-b</code> 二选一）</td>\n<td style=\"text-align:left\"><code>-c DefaultCluster</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\"><code>--namesrvAddr</code></td>\n<td style=\"text-align:left\">NameServer 地址列表</td>\n<td style=\"text-align:left\">多个地址用 <code>;</code> 分隔</td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-n 192.168.1.1:9876;192.168.1.2:9876</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-r</code></td>\n<td style=\"text-align:left\"><code>--readQueueNums</code></td>\n<td style=\"text-align:left\">读队列数量，默认为8，始终保持 r == w</td>\n<td style=\"text-align:left\">整数</td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-r 4</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-w</code></td>\n<td style=\"text-align:left\"><code>--writeQueueNums</code></td>\n<td style=\"text-align:left\">写队列数量，默认为8，始终保持 r == w</td>\n<td style=\"text-align:left\">整数</td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-w 4</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-p</code></td>\n<td style=\"text-align:left\"><code>--perm</code></td>\n<td style=\"text-align:left\">Topic 权限，默认为6</td>\n<td style=\"text-align:left\">2：写（W）<br>4：读（R）<br>6：读写（RW）</td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-p 6</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-o</code></td>\n<td style=\"text-align:left\"><code>--order</code></td>\n<td style=\"text-align:left\">是否顺序 Topic，兼容4.x版本，5.x版本使用 -a “+message.type=FIFO”</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-o false</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-u</code></td>\n<td style=\"text-align:left\"><code>--unit</code></td>\n<td style=\"text-align:left\">是否为单元（Unit）Topic（用于多租户隔离）</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-u false</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-s</code></td>\n<td style=\"text-align:left\"><code>--hasUnitSub</code></td>\n<td style=\"text-align:left\">是否有 Unit 订阅</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-s false</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-a</code></td>\n<td style=\"text-align:left\"><code>--attributes</code></td>\n<td style=\"text-align:left\">额外属性设置，用 <code>+</code> 表示添加、<code>-</code> 表示删除</td>\n<td style=\"text-align:left\">例：<code>+a=b,+c=d,-e</code></td>\n<td style=\"text-align:left\">可选</td>\n<td style=\"text-align:left\"><code>-a &quot;+message.type=NORMAL&quot;</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\"><code>--help</code></td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:left\">无</td>\n<td style=\"text-align:left\">否</td>\n<td style=\"text-align:left\"><code>-h</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 Topic，此时 Topic 类型为 UNSPECIFIED，集群下所有 Broker 都会创建该 Topic</span></span><br><span class=\"line\">sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster</span><br><span class=\"line\"><span class=\"comment\"># 仅在指定的 Broker 中创建 Topic，注意只能在 Master 节点上创建</span></span><br><span class=\"line\">sh bin/mqadmin updateTopic  -n 127.0.0.1:9876 -b 10.250.0.31:10911 -t newTopic</span><br><span class=\"line\"><span class=\"comment\"># 创建 Topic，并指定 Topic 类型为 NORMAL，支持的消息类型：UNSPECIFIED, TRANSACTION, FIFO, MIXED, DELAY, NORMAL</span></span><br><span class=\"line\">sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -a <span class=\"string\">&quot;+message.type=NORMAL&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 创建 Topic，并指定 Topic 类型为 FIFO，同时指定读写队列数量都为 4</span></span><br><span class=\"line\">sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -r 4 -w 4 -a <span class=\"string\">&quot;+message.type=FIFO&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 指定权限，默认为 6：读写</span></span><br><span class=\"line\">sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -p 6</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看与删除 Topic</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看所有 Topic，此时只打印 topic 列表</span></span><br><span class=\"line\">sh bin/mqadmin topicList -n 127.0.0.1:9876</span><br><span class=\"line\"><span class=\"comment\"># 查看所有 Topic，-c 参数表示同时打印 Cluster Name 和 Consumer Group</span></span><br><span class=\"line\">sh bin/mqadmin topicList -n 127.0.0.1:9876 -c</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 删除 Topic，删除指定集群下的指定Topic</span></span><br><span class=\"line\">sh bin/mqadmin deleteTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>其它 Topic 命令</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看 Topic 路由信息</span></span><br><span class=\"line\">sh bin/mqadmin topicRoute -n 127.0.0.1:9876 -t newTopic</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"string\">&quot;brokerDatas&quot;</span>:[</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerAddrs&quot;</span>:&#123;0:<span class=\"string\">&quot;10.250.0.188:11011&quot;</span>,1:<span class=\"string\">&quot;10.250.0.31:10911&quot;</span></span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerName&quot;</span>:<span class=\"string\">&quot;broker-b&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;cluster&quot;</span>:<span class=\"string\">&quot;DefaultCluster&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;enableActingMaster&quot;</span>:<span class=\"literal\">false</span></span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerAddrs&quot;</span>:&#123;0:<span class=\"string\">&quot;10.250.0.31:11011&quot;</span>,1:<span class=\"string\">&quot;10.250.0.188:10911&quot;</span></span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerName&quot;</span>:<span class=\"string\">&quot;broker-a&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;cluster&quot;</span>:<span class=\"string\">&quot;DefaultCluster&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;enableActingMaster&quot;</span>:<span class=\"literal\">false</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t],</span><br><span class=\"line\">\t<span class=\"string\">&quot;filterServerTable&quot;</span>:&#123;&#125;,</span><br><span class=\"line\">\t<span class=\"string\">&quot;queueDatas&quot;</span>:[</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerName&quot;</span>:<span class=\"string\">&quot;broker-b&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;perm&quot;</span>:6,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;readQueueNums&quot;</span>:8,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;topicSysFlag&quot;</span>:0,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;writeQueueNums&quot;</span>:8</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;brokerName&quot;</span>:<span class=\"string\">&quot;broker-a&quot;</span>,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;perm&quot;</span>:6,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;readQueueNums&quot;</span>:8,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;topicSysFlag&quot;</span>:0,</span><br><span class=\"line\">\t\t\t<span class=\"string\">&quot;writeQueueNums&quot;</span>:8</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 Topic 消息队列offset</span></span><br><span class=\"line\">sh bin/mqadmin topicStatus -n 127.0.0.1:9876 -t newTopic</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\"><span class=\"comment\">#Broker Name                      #QID  #Min Offset           #Max Offset             #Last Updated</span></span><br><span class=\"line\">broker-a                          0     0                     3                       2025-10-27 03:08:43,112</span><br><span class=\"line\">broker-a                          1     0                     4                       2025-10-27 06:13:21,968</span><br><span class=\"line\">broker-a                          2     0                     2                       2025-10-27 06:13:34,685</span><br><span class=\"line\">broker-a                          3     0                     2                       2025-10-26 05:44:17,222</span><br><span class=\"line\">broker-a                          4     0                     1                       2025-10-26 05:44:45,513</span><br><span class=\"line\">broker-a                          5     0                     1                       2025-10-26 06:13:10,541</span><br><span class=\"line\">broker-a                          6     0                     2                       2025-10-26 02:58:34,393</span><br><span class=\"line\">broker-a                          7     0                     1                       2025-10-25 12:42:41,189</span><br><span class=\"line\">broker-b                          0     0                     1                       2025-10-25 14:01:24,836</span><br><span class=\"line\">broker-b                          1     0                     2                       2025-10-26 06:14:24,411</span><br><span class=\"line\">broker-b                          2     0                     0</span><br><span class=\"line\">broker-b                          3     0                     0</span><br><span class=\"line\">broker-b                          4     0                     0</span><br><span class=\"line\">broker-b                          5     0                     1                       2025-10-25 12:30:57,672</span><br><span class=\"line\">broker-b                          6     0                     1                       2025-10-26 06:19:47,051</span><br><span class=\"line\">broker-b                          7     0                     1                       2025-10-26 06:14:49,216</span><br></pre></td></tr></table></figure>\n<h2 id=\"集群相关命令\">集群相关命令</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看集群信息，集群、BrokerName、BrokerId、TPS等信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 集群信息</span></span><br><span class=\"line\">sh bin/mqadmin clusterList -n 127.0.0.1:9876 -c DefaultCluster</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class=\"line\">DefaultCluster          broker-a                0     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               2.60(0,0ms|0,0ms)  1-0(0.0w, 0.0, 0.0)               0  67.03         0.3300          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-a                1     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  67.03         0.3200         <span class=\"literal\">false</span></span><br><span class=\"line\">DefaultCluster          broker-b                0     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.80(0,0ms|0,0ms)  1-0(0.0w, 0.0, 0.0)               0  67.17         0.3200          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-b                1     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  1-0(0.0w, 0.0, 0.0)               0  67.17         0.3300         <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\">## Broker 统计信息</span></span><br><span class=\"line\"><span class=\"comment\">#BID: BrokerId，0 表示 Master，&gt;0 表示 Slave</span></span><br><span class=\"line\"><span class=\"comment\">#InTPS(LOAD): 生产者写入 TPS 与负载， 0.00(0,0ms): 每秒入站消息数(队列数，平均耗时)</span></span><br><span class=\"line\"><span class=\"comment\">#OutTPS(LOAD): 消费者拉取 TPS 与负载，2.60(0,0ms|0,0ms): 每秒出站消息数(队列数，平均耗时|平均延时)</span></span><br><span class=\"line\"><span class=\"comment\">#Timer(Progress): Broker 的消息处理进度，格式如 1-0(0.0w, 0.0, 0.0)：前面是定时轮次进度，括号内是写入等待等统计</span></span><br><span class=\"line\"><span class=\"comment\">#PCWait(ms): 表示 Broker 写入 PageCache 的平均等待时间，数值越低越好</span></span><br><span class=\"line\"><span class=\"comment\">#Hour: 表示 Broker 已运行的时长</span></span><br><span class=\"line\"><span class=\"comment\">#SPACE: 磁盘空间使用比例，小数形式，例如 0.3300 表示使用了 33.0%</span></span><br><span class=\"line\"><span class=\"comment\">#ACTIVATED: true 表示当前 Master 正在工作；false 表示从节点或备用 Master</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看集群统计信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin clusterList -n 127.0.0.1:9876 -c DefaultCluster -m</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name     #Broker Name                       #InTotalYest  #OutTotalYest  #InTotalToday #OutTotalToday</span></span><br><span class=\"line\">DefaultCluster    broker-a                                      0              0              0              0</span><br><span class=\"line\">DefaultCluster    broker-a                                      0              0              0              0</span><br><span class=\"line\">DefaultCluster    broker-b                                      0            369              0              0</span><br><span class=\"line\">DefaultCluster    broker-b                                      0              0              0              0</span><br><span class=\"line\"><span class=\"comment\">## Broker 统计信息</span></span><br><span class=\"line\"><span class=\"comment\">#InTotalYest：昨日入站消息总量，该 Broker 在昨天接收（生产者写入）的消息总数</span></span><br><span class=\"line\"><span class=\"comment\">#OutTotalYest：昨日出站消息总量，该 Broker 在昨天发送（消费者消费）的消息总数</span></span><br><span class=\"line\"><span class=\"comment\">#InTotalToday：今日入站消息总量，该 Broker 在今天接收（生产者写入）的消息总数</span></span><br><span class=\"line\"><span class=\"comment\">#OutTotalToday：今日出站消息总量，该 Broker 在今天发送（消费者消费）的消息总数</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"消息相关\">消息相关</h2>\n<h3 id=\"发送消息\">发送消息</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">全写</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:center\">是否必填</th>\n<th style=\"text-align:left\">示例值</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-t</code></td>\n<td style=\"text-align:left\"><code>--topic</code></td>\n<td style=\"text-align:left\">消息要发送的 Topic 名称</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">必须指定目标 Topic</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-p</code></td>\n<td style=\"text-align:left\"><code>--body</code></td>\n<td style=\"text-align:left\">消息体内容（UTF-8 字符串）</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>&quot;Hello RocketMQ&quot;</code></td>\n<td style=\"text-align:left\">实际消息内容</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\"><code>--namesrvAddr</code></td>\n<td style=\"text-align:left\">NameServer 地址</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td style=\"text-align:left\">不指定则用默认配置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\"><code>--broker</code></td>\n<td style=\"text-align:left\">指定发送到哪个 broker</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>broker-a</code></td>\n<td style=\"text-align:left\">一般用于测试 Broker 状态</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-i</code></td>\n<td style=\"text-align:left\"><code>--qid</code></td>\n<td style=\"text-align:left\">指定发送到的队列 ID</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>2</code></td>\n<td style=\"text-align:left\">一般不需要设置，RocketMQ 会自动选择</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\"><code>--tags</code></td>\n<td style=\"text-align:left\">消息的标签（tag）</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>testTag</code></td>\n<td style=\"text-align:left\">用于消息过滤</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-k</code></td>\n<td style=\"text-align:left\"><code>--key</code></td>\n<td style=\"text-align:left\">消息的业务键（key）</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>order123</code></td>\n<td style=\"text-align:left\">可用于追踪消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-m</code></td>\n<td style=\"text-align:left\"><code>--msgTraceEnable</code></td>\n<td style=\"text-align:left\">是否开启消息轨迹</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code></td>\n<td style=\"text-align:left\">默认 <code>false</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\"><code>--help</code></td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\">无</td>\n<td style=\"text-align:left\">显示命令参数说明</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 发送消息</span></span><br><span class=\"line\">sh bin/mqadmin sendMessage -n 127.0.0.1:9876 -t TestTopic -p <span class=\"string\">&quot;Hello RocketMQ&quot;</span></span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\"><span class=\"comment\">#Broker Name                      #QID  #Send Result            #MsgId</span></span><br><span class=\"line\">broker-b                          2     SEND_OK                 0AFA00AFCF171EB44E468CC7D5EE0000</span><br><span class=\"line\"><span class=\"comment\">## 输出解释</span></span><br><span class=\"line\"><span class=\"comment\">#Broker Name: Broker 名称</span></span><br><span class=\"line\"><span class=\"comment\">#QID: 队列 ID</span></span><br><span class=\"line\"><span class=\"comment\">#Send Result: 发送结果，SEND_OK 表示成功</span></span><br><span class=\"line\"><span class=\"comment\">#MsgId: 消息 ID</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定 tags、key</span></span><br><span class=\"line\">sh bin/mqadmin sendMessage -n 127.0.0.1:9876 -t TestTopic -p <span class=\"string\">&quot;Hello RocketMQ&quot;</span> -c testTag -k order123</span><br></pre></td></tr></table></figure>\n<h3 id=\"消费消息\">消费消息</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">全写</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:center\">是否必填</th>\n<th style=\"text-align:left\">示例值</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-t</code></td>\n<td style=\"text-align:left\"><code>--topic</code></td>\n<td style=\"text-align:left\">目标 Topic 名称</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">必填</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\"><code>--namesrvAddr</code></td>\n<td style=\"text-align:left\">NameServer 地址</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td style=\"text-align:left\">建议填写以避免默认配置不生效</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-g</code></td>\n<td style=\"text-align:left\"><code>--consumerGroup</code></td>\n<td style=\"text-align:left\">消费组名称</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>TestGroup</code></td>\n<td style=\"text-align:left\">可指定消费组（影响消费位点）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\"><code>--brokerName</code></td>\n<td style=\"text-align:left\">Broker 名称</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>broker-a</code></td>\n<td style=\"text-align:left\">指定从哪个 broker 拉取消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-i</code></td>\n<td style=\"text-align:left\"><code>--queueId</code></td>\n<td style=\"text-align:left\">队列 ID</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">默认从 0 号队列开始</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-o</code></td>\n<td style=\"text-align:left\"><code>--offset</code></td>\n<td style=\"text-align:left\">队列起始偏移量（offset）</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">指定从哪个位置开始消费</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\"><code>--MessageNumber</code></td>\n<td style=\"text-align:left\">消费消息数量</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>10</code></td>\n<td style=\"text-align:left\">默认通常为 1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-s</code></td>\n<td style=\"text-align:left\"><code>--beginTimestamp</code></td>\n<td style=\"text-align:left\">起始时间</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>2025-10-28#10:00:00:000</code></td>\n<td style=\"text-align:left\">格式或时间戳均可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-e</code></td>\n<td style=\"text-align:left\"><code>--endTimestamp</code></td>\n<td style=\"text-align:left\">结束时间</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>2025-10-28#12:00:00:000</code></td>\n<td style=\"text-align:left\">与 <code>-s</code> 一起使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\"><code>--help</code></td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\">无</td>\n<td style=\"text-align:left\">显示命令参数说明</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认从队列 0 开始消费，拉取全部消息</span></span><br><span class=\"line\">sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic</span><br><span class=\"line\"><span class=\"comment\"># 拉取指定条数的消息，-c 指定拉取条数</span></span><br><span class=\"line\">sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -c 10</span><br><span class=\"line\"><span class=\"comment\"># 指定偏移量，此时必须同时指定 brokerName、queueId、offset</span></span><br><span class=\"line\">sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -b broker-b -i 2 -o 3</span><br><span class=\"line\"><span class=\"comment\"># 指定消费者组</span></span><br><span class=\"line\">sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -g TestGroup</span><br><span class=\"line\"><span class=\"comment\"># 指定时间范围</span></span><br><span class=\"line\">sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -s 2025-10-28#00:00:00:000 -e 2025-10-28#08:00:00:000</span><br></pre></td></tr></table></figure>\n<h4 id=\"消费结果\">消费结果</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Consume ok</span><br><span class=\"line\">MSGID: 0AFA00AFCF171EB44E468CC7D5EE0000</span><br><span class=\"line\">MessageExt [brokerName=broker-b, queueId=2, storeSize=228, queueOffset=0, sysFlag=0,</span><br><span class=\"line\">  bornTimestamp=1761638706671, bornHost=/10.250.0.175:41362,</span><br><span class=\"line\">  storeTimestamp=1761638706691, storeHost=/10.250.0.188:11011,</span><br><span class=\"line\">  msgId=0AFA00BC00002B0300000000000CA1E9, commitLogOffset=827881,</span><br><span class=\"line\">  bodyCRC=1774740973, reconsumeTimes=0, preparedTransactionOffset=0,</span><br><span class=\"line\">  toString()=Message&#123;topic=<span class=\"string\">&#x27;TestTopic&#x27;</span>, flag=0,</span><br><span class=\"line\">    properties=&#123;MSG_REGION=DefaultRegion, UNIQ_KEY=0AFA00AFCF171EB44E468CC7D5EE0000,</span><br><span class=\"line\">      CLUSTER=DefaultCluster, MIN_OFFSET=0, WAIT=<span class=\"literal\">true</span>, TRACE_ON=<span class=\"literal\">true</span>, MAX_OFFSET=1&#125;,</span><br><span class=\"line\">    body=[72, 101, 108, 108, 111, 32, 82, 111, 99, 107, 101, 116, 77, 81],</span><br><span class=\"line\">    transactionId=<span class=\"string\">&#x27;null&#x27;</span>&#125;]</span><br><span class=\"line\">BODY: Hello RocketMQ</span><br><span class=\"line\"></span><br><span class=\"line\">MessageQueue [topic=TestTopic, brokerName=broker-b, queueId=2] <span class=\"built_in\">print</span> msg finished. status=NO_NEW_MSG, offset=1</span><br><span class=\"line\">The older -1 message of the 2 queue will be provided</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>📘 字段解析表格</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">字段</th>\n<th style=\"text-align:left\">示例值</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>MSGID</strong></td>\n<td style=\"text-align:left\"><code>0AFA00AFCF171EB44E468CC7D5EE0000</code></td>\n<td style=\"text-align:left\">消息唯一标识（客户端生成）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>brokerName</strong></td>\n<td style=\"text-align:left\"><code>broker-b</code></td>\n<td style=\"text-align:left\">消息存储在哪个 Broker 上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>queueId</strong></td>\n<td style=\"text-align:left\"><code>2</code></td>\n<td style=\"text-align:left\">存储的队列编号（TestTopic 有多个队列时的第 3 个）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>queueOffset</strong></td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">队列中的偏移量（从 0 开始）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storeSize</strong></td>\n<td style=\"text-align:left\"><code>228</code></td>\n<td style=\"text-align:left\">消息在磁盘中的存储字节大小</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>sysFlag</strong></td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">消息系统标志位（内部用途）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>bornTimestamp</strong></td>\n<td style=\"text-align:left\"><code>1761638706671</code></td>\n<td style=\"text-align:left\">消息在生产者端创建的时间（毫秒）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>bornHost</strong></td>\n<td style=\"text-align:left\"><code>/10.250.0.175:41362</code></td>\n<td style=\"text-align:left\">生产者客户端的 IP 和端口</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storeTimestamp</strong></td>\n<td style=\"text-align:left\"><code>1761638706691</code></td>\n<td style=\"text-align:left\">消息被 Broker 存储的时间（毫秒）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storeHost</strong></td>\n<td style=\"text-align:left\"><code>/10.250.0.188:11011</code></td>\n<td style=\"text-align:left\">Broker 的存储节点地址</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>msgId</strong></td>\n<td style=\"text-align:left\"><code>0AFA00BC00002B0300000000000CA1E9</code></td>\n<td style=\"text-align:left\">消息在 Broker 存储系统生成的唯一 ID</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>commitLogOffset</strong></td>\n<td style=\"text-align:left\"><code>827881</code></td>\n<td style=\"text-align:left\">消息在 commitLog 文件中的偏移量</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>bodyCRC</strong></td>\n<td style=\"text-align:left\"><code>1774740973</code></td>\n<td style=\"text-align:left\">消息体的 CRC 校验码（用于校验数据一致性）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>reconsumeTimes</strong></td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">被重新消费的次数（0 表示第一次消费）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>preparedTransactionOffset</strong></td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">如果是事务消息，这里会记录预提交偏移量；普通消息为 0</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>topic</strong></td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">消息所属主题</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>properties</strong></td>\n<td style=\"text-align:left\"><code>&#123;MSG_REGION=DefaultRegion, UNIQ_KEY=..., ...&#125;</code></td>\n<td style=\"text-align:left\">消息属性，包括系统属性与用户属性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>body</strong></td>\n<td style=\"text-align:left\"><code>[72, 101, 108, 108, 111, 32, 82, 111, 99, 107, 101, 116, 77, 81]</code></td>\n<td style=\"text-align:left\">消息体的字节数组</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>BODY（解码后）</strong></td>\n<td style=\"text-align:left\"><code>Hello RocketMQ</code></td>\n<td style=\"text-align:left\">实际消息内容（UTF-8 字符串）</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>⚙️ 消息状态说明</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">输出信息</th>\n<th style=\"text-align:left\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>Consume ok</code></td>\n<td style=\"text-align:left\">表示成功从 Broker 拉取消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>status=NO_NEW_MSG</code></td>\n<td style=\"text-align:left\">当前队列（queueId=2）中已经没有比 offset=1 更新的消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>offset=1</code></td>\n<td style=\"text-align:left\">当前队列消费到 offset=1（下次消费从此开始）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>The older -1 message of the 2 queue will be provided</code></td>\n<td style=\"text-align:left\">这是一句提示语，意思是：队列中没有更早的消息（offset=-1 表示无历史消息）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"查询消息\">查询消息</h3>\n<h4 id=\"根据消息-ID-查询消息-queryMsgById\">根据消息 ID 查询消息(queryMsgById)</h4>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">全写</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:center\">是否必填</th>\n<th style=\"text-align:left\">示例值</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-i</code></td>\n<td style=\"text-align:left\"><code>--msgId</code></td>\n<td style=\"text-align:left\">要查询的消息 ID</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>0AFA00AFCF171EB44E468CC7D5EE0000</code></td>\n<td style=\"text-align:left\">必填，用于精确定位消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-t</code></td>\n<td style=\"text-align:left\"><code>--topic</code></td>\n<td style=\"text-align:left\">目标 Topic 名称</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">必填</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\"><code>--namesrvAddr</code></td>\n<td style=\"text-align:left\">NameServer 地址</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td style=\"text-align:left\">建议明确指定</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\"><code>--cluster</code></td>\n<td style=\"text-align:left\">集群名称或 LMQ 父 Topic</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td style=\"text-align:left\">在多集群场景下使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-g</code></td>\n<td style=\"text-align:left\"><code>--consumerGroup</code></td>\n<td style=\"text-align:left\">消费组名称</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>TestGroup</code></td>\n<td style=\"text-align:left\">当用于消费者关联查询时可指定</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-d</code></td>\n<td style=\"text-align:left\"><code>--clientId</code></td>\n<td style=\"text-align:left\">消费者客户端 ID</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>192.168.0.1@12345</code></td>\n<td style=\"text-align:left\">辅助定位消费实例</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-f</code></td>\n<td style=\"text-align:left\"><code>--bodyFormat</code></td>\n<td style=\"text-align:left\">消息体输出格式</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>UTF-8</code> / <code>HEX</code> / <code>BASE64</code></td>\n<td style=\"text-align:left\">默认 UTF-8</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-s</code></td>\n<td style=\"text-align:left\"><code>--sendMessage</code></td>\n<td style=\"text-align:left\">是否重新发送消息</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code></td>\n<td style=\"text-align:left\">调试时可使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-u</code></td>\n<td style=\"text-align:left\"><code>--unitName</code></td>\n<td style=\"text-align:left\">单元名（多单元部署时使用）</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>unit01</code></td>\n<td style=\"text-align:left\">一般场景可忽略</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\"><code>--help</code></td>\n<td style=\"text-align:left\">打印帮助信息</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\">无</td>\n<td style=\"text-align:left\">显示命令说明</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin queryMsgById -n 127.0.0.1:9876 -t TestTopic -i 0AFA00AFCF171EB44E468CC7D5EE0000 -f UTF-8</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">OffsetID:            0AFA00BC00002B0300000000000CA1E9</span><br><span class=\"line\">Topic:               TestTopic</span><br><span class=\"line\">Tags:                [null]</span><br><span class=\"line\">Keys:                [null]</span><br><span class=\"line\">Queue ID:            2</span><br><span class=\"line\">Queue Offset:        0</span><br><span class=\"line\">CommitLog Offset:    827881</span><br><span class=\"line\">Reconsume Times:     0</span><br><span class=\"line\">Born Timestamp:      2025-10-28 08:05:06,671</span><br><span class=\"line\">Store Timestamp:     2025-10-28 08:05:06,691</span><br><span class=\"line\">Born Host:           10.250.0.175:41362</span><br><span class=\"line\">Store Host:          10.250.0.188:11011</span><br><span class=\"line\">System Flag:         0</span><br><span class=\"line\">Properties:          &#123;MSG_REGION=DefaultRegion, UNIQ_KEY=0AFA00AFCF171EB44E468CC7D5EE0000, CLUSTER=DefaultCluster, WAIT=<span class=\"literal\">true</span>, TRACE_ON=<span class=\"literal\">true</span>&#125;</span><br><span class=\"line\">Message Body Path:   /tmp/rocketmq/msgbodys/0AFA00AFCF171EB44E468CC7D5EE0000</span><br><span class=\"line\">Message Body:        Hello RocketMQ</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>输出字段详解</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">字段名</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">示例</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>OffsetID</strong></td>\n<td style=\"text-align:left\">消息在 CommitLog 中的偏移标识（内部定位使用）</td>\n<td style=\"text-align:left\"><code>0AFA00BC00002B0300000000000CA1E9</code></td>\n<td style=\"text-align:left\">可用于 broker 内部追踪定位消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Topic</strong></td>\n<td style=\"text-align:left\">主题名称</td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">消息所属的主题</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Tags</strong></td>\n<td style=\"text-align:left\">消息标签</td>\n<td style=\"text-align:left\"><code>[null]</code></td>\n<td style=\"text-align:left\">若生产消息时未设置 tag，则为 null</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Keys</strong></td>\n<td style=\"text-align:left\">消息键</td>\n<td style=\"text-align:left\"><code>[null]</code></td>\n<td style=\"text-align:left\">通常可用于业务层索引查询</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Queue ID</strong></td>\n<td style=\"text-align:left\">消息所在的队列编号</td>\n<td style=\"text-align:left\"><code>2</code></td>\n<td style=\"text-align:left\">对应 topic 的第 3 个队列（从 0 开始）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Queue Offset</strong></td>\n<td style=\"text-align:left\">队列偏移量</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">表示是该队列的第一条消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>CommitLog Offset</strong></td>\n<td style=\"text-align:left\">消息在 commitlog 文件中的偏移量</td>\n<td style=\"text-align:left\"><code>827881</code></td>\n<td style=\"text-align:left\">broker 存储层位置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Reconsume Times</strong></td>\n<td style=\"text-align:left\">被重新消费的次数</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">表示未重试消费过</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Born Timestamp</strong></td>\n<td style=\"text-align:left\">消息生成时间</td>\n<td style=\"text-align:left\"><code>2025-10-28 08:05:06,671</code></td>\n<td style=\"text-align:left\">生产者发送消息的时间</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Store Timestamp</strong></td>\n<td style=\"text-align:left\">消息存储时间</td>\n<td style=\"text-align:left\"><code>2025-10-28 08:05:06,691</code></td>\n<td style=\"text-align:left\">broker 写入消息的时间（通常相差几毫秒）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Born Host</strong></td>\n<td style=\"text-align:left\">生产者客户端 IP:端口</td>\n<td style=\"text-align:left\"><code>10.250.0.175:41362</code></td>\n<td style=\"text-align:left\">生产者所在机器</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Store Host</strong></td>\n<td style=\"text-align:left\">broker 存储该消息的地址</td>\n<td style=\"text-align:left\"><code>10.250.0.188:11011</code></td>\n<td style=\"text-align:left\">对应的 broker 服务端</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>System Flag</strong></td>\n<td style=\"text-align:left\">系统标志位</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">内部使用（标识压缩/事务等）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Properties</strong></td>\n<td style=\"text-align:left\">消息属性</td>\n<td style=\"text-align:left\"><code>&#123;MSG_REGION=DefaultRegion, UNIQ_KEY=..., CLUSTER=DefaultCluster, WAIT=true, TRACE_ON=true&#125;</code></td>\n<td style=\"text-align:left\">包含 RocketMQ 自动附加的元数据</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Message Body Path</strong></td>\n<td style=\"text-align:left\">消息体在本地保存的文件路径</td>\n<td style=\"text-align:left\"><code>/tmp/rocketmq/msgbodys/0AFA00AFCF171EB44E468CC7D5EE0000</code></td>\n<td style=\"text-align:left\">RocketMQ CLI 将消息体内容（字节数组）写入文件以供查看</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Message Body</strong></td>\n<td style=\"text-align:left\">消息内容</td>\n<td style=\"text-align:left\"><code>Hello RocketMQ</code></td>\n<td style=\"text-align:left\">消息内容</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"根据消息-Key-查询消息-queryMsgByKey\">根据消息 Key 查询消息(queryMsgByKey)</h4>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:center\">必填</th>\n<th style=\"text-align:left\">示例</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-t, --topic</code></td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>TestTopic</code></td>\n<td style=\"text-align:left\">要查询的主题名称</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-k, --msgKey</code></td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>order_10001</code></td>\n<td style=\"text-align:left\">发送消息时设置的业务 Key</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n, --namesrvAddr</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td style=\"text-align:left\">NameServer 地址</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c, --cluster</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td style=\"text-align:left\">指定集群名称（可选）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b, --beginTimestamp</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>1730083200000</code></td>\n<td style=\"text-align:left\">查询起始时间戳（ms）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-e, --endTimestamp</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>1730173200000</code></td>\n<td style=\"text-align:left\">查询结束时间戳（ms）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-m, --maxNum</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>64</code></td>\n<td style=\"text-align:left\">返回的最大消息数，默认 64</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h, --help</code></td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\">-</td>\n<td style=\"text-align:left\">打印帮助信息</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin queryMsgByKey -n 127.0.0.1:9876 -t TestTopic -k order123</span><br><span class=\"line\"><span class=\"comment\">## 查询结果</span></span><br><span class=\"line\"><span class=\"comment\">#Message ID                                        #QID                                  #Offset</span></span><br><span class=\"line\">0AFA00AFCF781EB44E468CC902A30000                      7                                        1</span><br></pre></td></tr></table></figure>\n<h2 id=\"消费者\">消费者</h2>\n<h4 id=\"创建或更新消费者订阅组-updateSubGroup\">创建或更新消费者订阅组(updateSubGroup)</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>消费者订阅组 就是 消费者组，其主要作用是调整消费者消费，例如：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">消费顺序（顺序/并发）</li>\n<li class=\"lvl-6\">广播模式</li>\n<li class=\"lvl-6\">消费使能</li>\n<li class=\"lvl-6\">消费重试策略</li>\n<li class=\"lvl-6\">延迟消费队列等</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">全写</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:center\">是否必填</th>\n<th style=\"text-align:left\">示例值</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>-g</code></td>\n<td style=\"text-align:left\"><code>--groupName</code></td>\n<td style=\"text-align:left\">消费者组名称</td>\n<td style=\"text-align:center\">✅</td>\n<td style=\"text-align:left\"><code>TestConsumerGroup</code></td>\n<td style=\"text-align:left\">必填</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-n</code></td>\n<td style=\"text-align:left\"><code>--namesrvAddr</code></td>\n<td style=\"text-align:left\">NameServer 地址</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>127.0.0.1:9876</code></td>\n<td style=\"text-align:left\">建议明确指定</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-b</code></td>\n<td style=\"text-align:left\"><code>--brokerAddr</code></td>\n<td style=\"text-align:left\">指定 Broker 地址</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>10.250.0.188:10911</code></td>\n<td style=\"text-align:left\">仅对单 Broker 更新</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-c</code></td>\n<td style=\"text-align:left\"><code>--clusterName</code></td>\n<td style=\"text-align:left\">指定 Cluster 名称</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td style=\"text-align:left\">对整个集群更新</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-d</code></td>\n<td style=\"text-align:left\"><code>--consumeBroadcastEnable</code></td>\n<td style=\"text-align:left\">是否广播消费</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">true 表示广播，false 表示集群模式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-o</code></td>\n<td style=\"text-align:left\"><code>--consumeMessageOrderly</code></td>\n<td style=\"text-align:left\">是否顺序消费</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">顺序消费只在同队列中生效</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-i</code></td>\n<td style=\"text-align:left\"><code>--brokerId</code></td>\n<td style=\"text-align:left\">从哪个 Broker 获取订阅信息</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">内部用途，通常不用设置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-m</code></td>\n<td style=\"text-align:left\"><code>--consumeFromMinEnable</code></td>\n<td style=\"text-align:left\">是否从最小 offset 消费</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">新组首次消费时生效</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-p</code></td>\n<td style=\"text-align:left\"><code>--groupRetryPolicy</code></td>\n<td style=\"text-align:left\">消费组重试策略 JSON</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>&#123;&quot;type&quot;:&quot;EXPONENTIAL&quot;,&quot;exponentialRetryPolicy&quot;:&#123;&quot;initial&quot;:5000,&quot;max&quot;:7200000,&quot;multiplier&quot;:2&#125;&#125;</code></td>\n<td style=\"text-align:left\">可以自定义重试间隔</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-q</code></td>\n<td style=\"text-align:left\"><code>--retryQueueNums</code></td>\n<td style=\"text-align:left\">重试队列数量</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>1</code> ~ <code>16</code></td>\n<td style=\"text-align:left\">默认为 1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-r</code></td>\n<td style=\"text-align:left\"><code>--retryMaxTimes</code></td>\n<td style=\"text-align:left\">最大重试次数</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>16</code></td>\n<td style=\"text-align:left\">默认 16 次</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-s</code></td>\n<td style=\"text-align:left\"><code>--consumeEnable</code></td>\n<td style=\"text-align:left\">是否使能消费</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">false 表示暂停消费</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-w</code></td>\n<td style=\"text-align:left\"><code>--whichBrokerWhenConsumeSlowly</code></td>\n<td style=\"text-align:left\">慢消费选择 Broker ID</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>0</code></td>\n<td style=\"text-align:left\">内部使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-a</code></td>\n<td style=\"text-align:left\"><code>--notifyConsumerIdsChanged</code></td>\n<td style=\"text-align:left\">通知 ConsumerId 改变</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>true</code> / <code>false</code></td>\n<td style=\"text-align:left\">可触发消费者刷新订阅信息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>--attributes</code></td>\n<td style=\"text-align:left\"><code>--attributes</code></td>\n<td style=\"text-align:left\">其他自定义属性</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\"><code>attr1=val1,attr2=val2</code></td>\n<td style=\"text-align:left\">可设置自定义配置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>-h</code></td>\n<td style=\"text-align:left\"><code>--help</code></td>\n<td style=\"text-align:left\">打印帮助</td>\n<td style=\"text-align:center\">❌</td>\n<td style=\"text-align:left\">-</td>\n<td style=\"text-align:left\">显示命令帮助</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建普通消费者组</span></span><br><span class=\"line\">sh bin/mqadmin updateSubGroup -c DefaultCluster -g NormalGroup -n 127.0.0.1:9876</span><br><span class=\"line\"><span class=\"comment\"># 创建顺序消费组</span></span><br><span class=\"line\">sh bin/mqadmin updateSubGroup -c DefaultCluster -g FIFOGroup -n 127.0.0.1:9876 -o <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建广播消费组</span></span><br><span class=\"line\">sh bin/mqadmin updateSubGroup -c DefaultCluster -g BroadcastGroup -n 127.0.0.1:9876 -d <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建自定义属性的消费者组，这里配置了重试策略</span></span><br><span class=\"line\">sh bin/mqadmin updateSubGroup -n 127.0.0.1:9876 -g TestConsumerGroup -c DefaultCluster -d <span class=\"literal\">true</span> -o <span class=\"literal\">true</span> -m <span class=\"literal\">true</span> -p <span class=\"string\">&#x27;&#123;&quot;type&quot;:&quot;EXPONENTIAL&quot;,&quot;exponentialRetryPolicy&quot;:&#123;&quot;initial&quot;:5000,&quot;max&quot;:7200000,&quot;multiplier&quot;:2&#125;&#125;&#x27;</span> -q 1 -r 16 -s <span class=\"literal\">true</span> -w 0 -a <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"删除消费者订阅组-deleteSubGroup\">删除消费者订阅组(deleteSubGroup)</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin deleteSubGroup -n 127.0.0.1:9876 -g TestConsumerGroup -c DefaultCluster</span><br></pre></td></tr></table></figure>\n<h2 id=\"重要说明\">重要说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 <code>conf/tools.yml</code> 配置正确的账号密码，否则无法执行 <code>mqadmin</code> 命令。</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">accessKey:</span> <span class=\"string\">mqadmin</span></span><br><span class=\"line\"><span class=\"attr\">secretKey:</span> <span class=\"number\">1234567</span></span><br></pre></td></tr></table></figure>","content_text":"摘要 本文介绍 RocketMQ Admin Tool 的常用命令。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ Admin Tool 简介 RocketMQ Admin Tool 是 RocketMQ 的一个命令行工具，用于管理 RocketMQ 的集群。 Topic 相关命令 创建或更新 Topic 参数 全称 说明 可选值 / 格式 是否必填 示例 -t --topic 主题名称 字符串 ✅ 必填 -t MyTopic -b --brokerAddr 指定创建 Topic 的 Broker 地址（与 -c 二选一） ip:port ✅ 必填（与 -c 二选一） -b 192.168.1.10:10911 -c --clusterName 指定创建 Topic 的集群名（与 -b 二选一） 字符串 ✅ 必填（与 -b 二选一） -c DefaultCluster -n --namesrvAddr NameServer 地址列表 多个地址用 ; 分隔 可选 -n 192.168.1.1:9876;192.168.1.2:9876 -r --readQueueNums 读队列数量，默认为8，始终保持 r == w 整数 可选 -r 4 -w --writeQueueNums 写队列数量，默认为8，始终保持 r == w 整数 可选 -w 4 -p --perm Topic 权限，默认为6 2：写（W）4：读（R）6：读写（RW） 可选 -p 6 -o --order 是否顺序 Topic，兼容4.x版本，5.x版本使用 -a “+message.type=FIFO” true / false 可选 -o false -u --unit 是否为单元（Unit）Topic（用于多租户隔离） true / false 可选 -u false -s --hasUnitSub 是否有 Unit 订阅 true / false 可选 -s false -a --attributes 额外属性设置，用 + 表示添加、- 表示删除 例：+a=b,+c=d,-e 可选 -a &quot;+message.type=NORMAL&quot; -h --help 打印帮助信息 无 否 -h 示例 12345678910# 创建 Topic，此时 Topic 类型为 UNSPECIFIED，集群下所有 Broker 都会创建该 Topicsh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster# 仅在指定的 Broker 中创建 Topic，注意只能在 Master 节点上创建sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -b 10.250.0.31:10911 -t newTopic# 创建 Topic，并指定 Topic 类型为 NORMAL，支持的消息类型：UNSPECIFIED, TRANSACTION, FIFO, MIXED, DELAY, NORMALsh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -a &quot;+message.type=NORMAL&quot;# 创建 Topic，并指定 Topic 类型为 FIFO，同时指定读写队列数量都为 4sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -r 4 -w 4 -a &quot;+message.type=FIFO&quot;# 指定权限，默认为 6：读写sh bin/mqadmin updateTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster -p 6 查看与删除 Topic 1234567# 查看所有 Topic，此时只打印 topic 列表sh bin/mqadmin topicList -n 127.0.0.1:9876# 查看所有 Topic，-c 参数表示同时打印 Cluster Name 和 Consumer Groupsh bin/mqadmin topicList -n 127.0.0.1:9876 -c# 删除 Topic，删除指定集群下的指定Topicsh bin/mqadmin deleteTopic -n 127.0.0.1:9876 -t newTopic -c DefaultCluster 其它 Topic 命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 查看 Topic 路由信息sh bin/mqadmin topicRoute -n 127.0.0.1:9876 -t newTopic## 输出&#123; &quot;brokerDatas&quot;:[ &#123; &quot;brokerAddrs&quot;:&#123;0:&quot;10.250.0.188:11011&quot;,1:&quot;10.250.0.31:10911&quot; &#125;, &quot;brokerName&quot;:&quot;broker-b&quot;, &quot;cluster&quot;:&quot;DefaultCluster&quot;, &quot;enableActingMaster&quot;:false &#125;, &#123; &quot;brokerAddrs&quot;:&#123;0:&quot;10.250.0.31:11011&quot;,1:&quot;10.250.0.188:10911&quot; &#125;, &quot;brokerName&quot;:&quot;broker-a&quot;, &quot;cluster&quot;:&quot;DefaultCluster&quot;, &quot;enableActingMaster&quot;:false &#125; ], &quot;filterServerTable&quot;:&#123;&#125;, &quot;queueDatas&quot;:[ &#123; &quot;brokerName&quot;:&quot;broker-b&quot;, &quot;perm&quot;:6, &quot;readQueueNums&quot;:8, &quot;topicSysFlag&quot;:0, &quot;writeQueueNums&quot;:8 &#125;, &#123; &quot;brokerName&quot;:&quot;broker-a&quot;, &quot;perm&quot;:6, &quot;readQueueNums&quot;:8, &quot;topicSysFlag&quot;:0, &quot;writeQueueNums&quot;:8 &#125; ]&#125;# 查看 Topic 消息队列offsetsh bin/mqadmin topicStatus -n 127.0.0.1:9876 -t newTopic## 输出#Broker Name #QID #Min Offset #Max Offset #Last Updatedbroker-a 0 0 3 2025-10-27 03:08:43,112broker-a 1 0 4 2025-10-27 06:13:21,968broker-a 2 0 2 2025-10-27 06:13:34,685broker-a 3 0 2 2025-10-26 05:44:17,222broker-a 4 0 1 2025-10-26 05:44:45,513broker-a 5 0 1 2025-10-26 06:13:10,541broker-a 6 0 2 2025-10-26 02:58:34,393broker-a 7 0 1 2025-10-25 12:42:41,189broker-b 0 0 1 2025-10-25 14:01:24,836broker-b 1 0 2 2025-10-26 06:14:24,411broker-b 2 0 0broker-b 3 0 0broker-b 4 0 0broker-b 5 0 1 2025-10-25 12:30:57,672broker-b 6 0 1 2025-10-26 06:19:47,051broker-b 7 0 1 2025-10-26 06:14:49,216 集群相关命令 查看集群信息，集群、BrokerName、BrokerId、TPS等信息 123456789101112131415161718# 集群信息sh bin/mqadmin clusterList -n 127.0.0.1:9876 -c DefaultCluster## 输出#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #Timer(Progress) #PCWait(ms) #Hour #SPACE #ACTIVATEDDefaultCluster broker-a 0 10.250.0.31:11011 V5_3_2 0.00(0,0ms) 2.60(0,0ms|0,0ms) 1-0(0.0w, 0.0, 0.0) 0 67.03 0.3300 trueDefaultCluster broker-a 1 10.250.0.188:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 67.03 0.3200 falseDefaultCluster broker-b 0 10.250.0.188:11011 V5_3_2 0.00(0,0ms) 0.80(0,0ms|0,0ms) 1-0(0.0w, 0.0, 0.0) 0 67.17 0.3200 trueDefaultCluster broker-b 1 10.250.0.31:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 1-0(0.0w, 0.0, 0.0) 0 67.17 0.3300 false## Broker 统计信息#BID: BrokerId，0 表示 Master，&gt;0 表示 Slave#InTPS(LOAD): 生产者写入 TPS 与负载， 0.00(0,0ms): 每秒入站消息数(队列数，平均耗时)#OutTPS(LOAD): 消费者拉取 TPS 与负载，2.60(0,0ms|0,0ms): 每秒出站消息数(队列数，平均耗时|平均延时)#Timer(Progress): Broker 的消息处理进度，格式如 1-0(0.0w, 0.0, 0.0)：前面是定时轮次进度，括号内是写入等待等统计#PCWait(ms): 表示 Broker 写入 PageCache 的平均等待时间，数值越低越好#Hour: 表示 Broker 已运行的时长#SPACE: 磁盘空间使用比例，小数形式，例如 0.3300 表示使用了 33.0%#ACTIVATED: true 表示当前 Master 正在工作；false 表示从节点或备用 Master 查看集群统计信息 123456789101112sh bin/mqadmin clusterList -n 127.0.0.1:9876 -c DefaultCluster -m## 输出#Cluster Name #Broker Name #InTotalYest #OutTotalYest #InTotalToday #OutTotalTodayDefaultCluster broker-a 0 0 0 0DefaultCluster broker-a 0 0 0 0DefaultCluster broker-b 0 369 0 0DefaultCluster broker-b 0 0 0 0## Broker 统计信息#InTotalYest：昨日入站消息总量，该 Broker 在昨天接收（生产者写入）的消息总数#OutTotalYest：昨日出站消息总量，该 Broker 在昨天发送（消费者消费）的消息总数#InTotalToday：今日入站消息总量，该 Broker 在今天接收（生产者写入）的消息总数#OutTotalToday：今日出站消息总量，该 Broker 在今天发送（消费者消费）的消息总数 消息相关 发送消息 参数 全写 说明 是否必填 示例值 备注 -t --topic 消息要发送的 Topic 名称 ✅ TestTopic 必须指定目标 Topic -p --body 消息体内容（UTF-8 字符串） ✅ &quot;Hello RocketMQ&quot; 实际消息内容 -n --namesrvAddr NameServer 地址 ❌ 127.0.0.1:9876 不指定则用默认配置 -b --broker 指定发送到哪个 broker ❌ broker-a 一般用于测试 Broker 状态 -i --qid 指定发送到的队列 ID ❌ 2 一般不需要设置，RocketMQ 会自动选择 -c --tags 消息的标签（tag） ❌ testTag 用于消息过滤 -k --key 消息的业务键（key） ❌ order123 可用于追踪消息 -m --msgTraceEnable 是否开启消息轨迹 ❌ true 默认 false -h --help 打印帮助信息 ❌ 无 显示命令参数说明 示例 1234567891011121314# 发送消息sh bin/mqadmin sendMessage -n 127.0.0.1:9876 -t TestTopic -p &quot;Hello RocketMQ&quot;## 输出#Broker Name #QID #Send Result #MsgIdbroker-b 2 SEND_OK 0AFA00AFCF171EB44E468CC7D5EE0000## 输出解释#Broker Name: Broker 名称#QID: 队列 ID#Send Result: 发送结果，SEND_OK 表示成功#MsgId: 消息 ID# 指定 tags、keysh bin/mqadmin sendMessage -n 127.0.0.1:9876 -t TestTopic -p &quot;Hello RocketMQ&quot; -c testTag -k order123 消费消息 参数 全写 说明 是否必填 示例值 备注 -t --topic 目标 Topic 名称 ✅ TestTopic 必填 -n --namesrvAddr NameServer 地址 ❌ 127.0.0.1:9876 建议填写以避免默认配置不生效 -g --consumerGroup 消费组名称 ❌ TestGroup 可指定消费组（影响消费位点） -b --brokerName Broker 名称 ❌ broker-a 指定从哪个 broker 拉取消息 -i --queueId 队列 ID ❌ 0 默认从 0 号队列开始 -o --offset 队列起始偏移量（offset） ❌ 0 指定从哪个位置开始消费 -c --MessageNumber 消费消息数量 ❌ 10 默认通常为 1 -s --beginTimestamp 起始时间 ❌ 2025-10-28#10:00:00:000 格式或时间戳均可 -e --endTimestamp 结束时间 ❌ 2025-10-28#12:00:00:000 与 -s 一起使用 -h --help 打印帮助信息 ❌ 无 显示命令参数说明 示例 12345678910# 默认从队列 0 开始消费，拉取全部消息sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic# 拉取指定条数的消息，-c 指定拉取条数sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -c 10# 指定偏移量，此时必须同时指定 brokerName、queueId、offsetsh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -b broker-b -i 2 -o 3# 指定消费者组sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -g TestGroup# 指定时间范围sh bin/mqadmin consumeMessage -n 127.0.0.1:9876 -t TestTopic -s 2025-10-28#00:00:00:000 -e 2025-10-28#08:00:00:000 消费结果 12345678910111213141516Consume okMSGID: 0AFA00AFCF171EB44E468CC7D5EE0000MessageExt [brokerName=broker-b, queueId=2, storeSize=228, queueOffset=0, sysFlag=0, bornTimestamp=1761638706671, bornHost=/10.250.0.175:41362, storeTimestamp=1761638706691, storeHost=/10.250.0.188:11011, msgId=0AFA00BC00002B0300000000000CA1E9, commitLogOffset=827881, bodyCRC=1774740973, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message&#123;topic=&#x27;TestTopic&#x27;, flag=0, properties=&#123;MSG_REGION=DefaultRegion, UNIQ_KEY=0AFA00AFCF171EB44E468CC7D5EE0000, CLUSTER=DefaultCluster, MIN_OFFSET=0, WAIT=true, TRACE_ON=true, MAX_OFFSET=1&#125;, body=[72, 101, 108, 108, 111, 32, 82, 111, 99, 107, 101, 116, 77, 81], transactionId=&#x27;null&#x27;&#125;]BODY: Hello RocketMQMessageQueue [topic=TestTopic, brokerName=broker-b, queueId=2] print msg finished. status=NO_NEW_MSG, offset=1The older -1 message of the 2 queue will be provided 📘 字段解析表格 字段 示例值 说明 MSGID 0AFA00AFCF171EB44E468CC7D5EE0000 消息唯一标识（客户端生成） brokerName broker-b 消息存储在哪个 Broker 上 queueId 2 存储的队列编号（TestTopic 有多个队列时的第 3 个） queueOffset 0 队列中的偏移量（从 0 开始） storeSize 228 消息在磁盘中的存储字节大小 sysFlag 0 消息系统标志位（内部用途） bornTimestamp 1761638706671 消息在生产者端创建的时间（毫秒） bornHost /10.250.0.175:41362 生产者客户端的 IP 和端口 storeTimestamp 1761638706691 消息被 Broker 存储的时间（毫秒） storeHost /10.250.0.188:11011 Broker 的存储节点地址 msgId 0AFA00BC00002B0300000000000CA1E9 消息在 Broker 存储系统生成的唯一 ID commitLogOffset 827881 消息在 commitLog 文件中的偏移量 bodyCRC 1774740973 消息体的 CRC 校验码（用于校验数据一致性） reconsumeTimes 0 被重新消费的次数（0 表示第一次消费） preparedTransactionOffset 0 如果是事务消息，这里会记录预提交偏移量；普通消息为 0 topic TestTopic 消息所属主题 properties &#123;MSG_REGION=DefaultRegion, UNIQ_KEY=..., ...&#125; 消息属性，包括系统属性与用户属性 body [72, 101, 108, 108, 111, 32, 82, 111, 99, 107, 101, 116, 77, 81] 消息体的字节数组 BODY（解码后） Hello RocketMQ 实际消息内容（UTF-8 字符串） ⚙️ 消息状态说明 输出信息 含义 Consume ok 表示成功从 Broker 拉取消息 status=NO_NEW_MSG 当前队列（queueId=2）中已经没有比 offset=1 更新的消息 offset=1 当前队列消费到 offset=1（下次消费从此开始） The older -1 message of the 2 queue will be provided 这是一句提示语，意思是：队列中没有更早的消息（offset=-1 表示无历史消息） 查询消息 根据消息 ID 查询消息(queryMsgById) 参数 全写 说明 是否必填 示例值 备注 -i --msgId 要查询的消息 ID ✅ 0AFA00AFCF171EB44E468CC7D5EE0000 必填，用于精确定位消息 -t --topic 目标 Topic 名称 ✅ TestTopic 必填 -n --namesrvAddr NameServer 地址 ❌ 127.0.0.1:9876 建议明确指定 -c --cluster 集群名称或 LMQ 父 Topic ❌ DefaultCluster 在多集群场景下使用 -g --consumerGroup 消费组名称 ❌ TestGroup 当用于消费者关联查询时可指定 -d --clientId 消费者客户端 ID ❌ 192.168.0.1@12345 辅助定位消费实例 -f --bodyFormat 消息体输出格式 ❌ UTF-8 / HEX / BASE64 默认 UTF-8 -s --sendMessage 是否重新发送消息 ❌ true 调试时可使用 -u --unitName 单元名（多单元部署时使用） ❌ unit01 一般场景可忽略 -h --help 打印帮助信息 ❌ 无 显示命令说明 示例 123456789101112131415161718sh bin/mqadmin queryMsgById -n 127.0.0.1:9876 -t TestTopic -i 0AFA00AFCF171EB44E468CC7D5EE0000 -f UTF-8## 输出OffsetID: 0AFA00BC00002B0300000000000CA1E9Topic: TestTopicTags: [null]Keys: [null]Queue ID: 2Queue Offset: 0CommitLog Offset: 827881Reconsume Times: 0Born Timestamp: 2025-10-28 08:05:06,671Store Timestamp: 2025-10-28 08:05:06,691Born Host: 10.250.0.175:41362Store Host: 10.250.0.188:11011System Flag: 0Properties: &#123;MSG_REGION=DefaultRegion, UNIQ_KEY=0AFA00AFCF171EB44E468CC7D5EE0000, CLUSTER=DefaultCluster, WAIT=true, TRACE_ON=true&#125;Message Body Path: /tmp/rocketmq/msgbodys/0AFA00AFCF171EB44E468CC7D5EE0000Message Body: Hello RocketMQ 输出字段详解 字段名 含义 示例 说明 OffsetID 消息在 CommitLog 中的偏移标识（内部定位使用） 0AFA00BC00002B0300000000000CA1E9 可用于 broker 内部追踪定位消息 Topic 主题名称 TestTopic 消息所属的主题 Tags 消息标签 [null] 若生产消息时未设置 tag，则为 null Keys 消息键 [null] 通常可用于业务层索引查询 Queue ID 消息所在的队列编号 2 对应 topic 的第 3 个队列（从 0 开始） Queue Offset 队列偏移量 0 表示是该队列的第一条消息 CommitLog Offset 消息在 commitlog 文件中的偏移量 827881 broker 存储层位置 Reconsume Times 被重新消费的次数 0 表示未重试消费过 Born Timestamp 消息生成时间 2025-10-28 08:05:06,671 生产者发送消息的时间 Store Timestamp 消息存储时间 2025-10-28 08:05:06,691 broker 写入消息的时间（通常相差几毫秒） Born Host 生产者客户端 IP:端口 10.250.0.175:41362 生产者所在机器 Store Host broker 存储该消息的地址 10.250.0.188:11011 对应的 broker 服务端 System Flag 系统标志位 0 内部使用（标识压缩/事务等） Properties 消息属性 &#123;MSG_REGION=DefaultRegion, UNIQ_KEY=..., CLUSTER=DefaultCluster, WAIT=true, TRACE_ON=true&#125; 包含 RocketMQ 自动附加的元数据 Message Body Path 消息体在本地保存的文件路径 /tmp/rocketmq/msgbodys/0AFA00AFCF171EB44E468CC7D5EE0000 RocketMQ CLI 将消息体内容（字节数组）写入文件以供查看 Message Body 消息内容 Hello RocketMQ 消息内容 根据消息 Key 查询消息(queryMsgByKey) 参数 必填 示例 说明 -t, --topic ✅ TestTopic 要查询的主题名称 -k, --msgKey ✅ order_10001 发送消息时设置的业务 Key -n, --namesrvAddr ❌ 127.0.0.1:9876 NameServer 地址 -c, --cluster ❌ DefaultCluster 指定集群名称（可选） -b, --beginTimestamp ❌ 1730083200000 查询起始时间戳（ms） -e, --endTimestamp ❌ 1730173200000 查询结束时间戳（ms） -m, --maxNum ❌ 64 返回的最大消息数，默认 64 -h, --help ❌ - 打印帮助信息 示例 1234sh bin/mqadmin queryMsgByKey -n 127.0.0.1:9876 -t TestTopic -k order123## 查询结果#Message ID #QID #Offset0AFA00AFCF781EB44E468CC902A30000 7 1 消费者 创建或更新消费者订阅组(updateSubGroup) 消费者订阅组 就是 消费者组，其主要作用是调整消费者消费，例如： 消费顺序（顺序/并发） 广播模式 消费使能 消费重试策略 延迟消费队列等 参数 全写 说明 是否必填 示例值 备注 -g --groupName 消费者组名称 ✅ TestConsumerGroup 必填 -n --namesrvAddr NameServer 地址 ❌ 127.0.0.1:9876 建议明确指定 -b --brokerAddr 指定 Broker 地址 ❌ 10.250.0.188:10911 仅对单 Broker 更新 -c --clusterName 指定 Cluster 名称 ❌ DefaultCluster 对整个集群更新 -d --consumeBroadcastEnable 是否广播消费 ❌ true / false true 表示广播，false 表示集群模式 -o --consumeMessageOrderly 是否顺序消费 ❌ true / false 顺序消费只在同队列中生效 -i --brokerId 从哪个 Broker 获取订阅信息 ❌ 0 内部用途，通常不用设置 -m --consumeFromMinEnable 是否从最小 offset 消费 ❌ true / false 新组首次消费时生效 -p --groupRetryPolicy 消费组重试策略 JSON ❌ &#123;&quot;type&quot;:&quot;EXPONENTIAL&quot;,&quot;exponentialRetryPolicy&quot;:&#123;&quot;initial&quot;:5000,&quot;max&quot;:7200000,&quot;multiplier&quot;:2&#125;&#125; 可以自定义重试间隔 -q --retryQueueNums 重试队列数量 ❌ 1 ~ 16 默认为 1 -r --retryMaxTimes 最大重试次数 ❌ 16 默认 16 次 -s --consumeEnable 是否使能消费 ❌ true / false false 表示暂停消费 -w --whichBrokerWhenConsumeSlowly 慢消费选择 Broker ID ❌ 0 内部使用 -a --notifyConsumerIdsChanged 通知 ConsumerId 改变 ❌ true / false 可触发消费者刷新订阅信息 --attributes --attributes 其他自定义属性 ❌ attr1=val1,attr2=val2 可设置自定义配置 -h --help 打印帮助 ❌ - 显示命令帮助 示例 12345678910# 创建普通消费者组sh bin/mqadmin updateSubGroup -c DefaultCluster -g NormalGroup -n 127.0.0.1:9876# 创建顺序消费组sh bin/mqadmin updateSubGroup -c DefaultCluster -g FIFOGroup -n 127.0.0.1:9876 -o true# 创建广播消费组sh bin/mqadmin updateSubGroup -c DefaultCluster -g BroadcastGroup -n 127.0.0.1:9876 -d true# 创建自定义属性的消费者组，这里配置了重试策略sh bin/mqadmin updateSubGroup -n 127.0.0.1:9876 -g TestConsumerGroup -c DefaultCluster -d true -o true -m true -p &#x27;&#123;&quot;type&quot;:&quot;EXPONENTIAL&quot;,&quot;exponentialRetryPolicy&quot;:&#123;&quot;initial&quot;:5000,&quot;max&quot;:7200000,&quot;multiplier&quot;:2&#125;&#125;&#x27; -q 1 -r 16 -s true -w 0 -a true 删除消费者订阅组(deleteSubGroup) 1sh bin/mqadmin deleteSubGroup -n 127.0.0.1:9876 -g TestConsumerGroup -c DefaultCluster 重要说明 如果 RocketMQ 开启了 ACL，无论是 ACL 1.0 还是 ACL 2.0，都需要在 conf/tools.yml 配置正确的账号密码，否则无法执行 mqadmin 命令。 12accessKey: mqadminsecretKey: 1234567","summary":"摘要 本文介绍 RocketMQ Admin Tool 的常用命令。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-28T13:40:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-06-proxy-config/","url":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-06-proxy-config/","title":"RocketMQ Proxy 的配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ Proxy 的配置项。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"配置项项目源码简介\">配置项项目源码简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当前版本尚不支持通过命令行查看 Proxy 的配置项，但是在启动Proxy的日志中可以看到当前生效的配置项。</p>\n</li>\n<li class=\"lvl-2\">\n<p>另外在源码 <code>rocketmq-all-5.3.2-source-release/proxy</code> 的启动类 <code>org.apache.rocketmq.proxy.ProxyStartup</code>中 可以看到其启动时会初始化如下配置项的类</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.proxy.config.ProxyConfig</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项说明\">配置项说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Proxy 配置参数说明与优化建议，这里要注意，Proxy的配置文件是 JSON 格式</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">分类</th>\n<th style=\"text-align:left\">参数名</th>\n<th style=\"text-align:left\">默认值</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">优化建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>基础信息</strong></td>\n<td style=\"text-align:left\"><code>rocketMQClusterName</code></td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td style=\"text-align:left\">Broker 集群名称（Proxy 用于关联 RocketMQ 集群）</td>\n<td style=\"text-align:left\">若有多个集群，应唯一命名</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>proxyClusterName</code></td>\n<td style=\"text-align:left\"><code>DefaultCluster</code></td>\n<td style=\"text-align:left\">Proxy 所属集群名称（与 brokerClusterName 可不同）</td>\n<td style=\"text-align:left\">✅建议独立命名，区分 Proxy 集群</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>proxyName</code></td>\n<td style=\"text-align:left\">主机名（例：<code>ip-10-250-0-175...</code>）</td>\n<td style=\"text-align:left\">Proxy 实例名称，用于唯一标识</td>\n<td style=\"text-align:left\">✅建议设置唯一名称</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>localServeAddr</code></td>\n<td style=\"text-align:left\">本地 IP</td>\n<td style=\"text-align:left\">Proxy 本地服务地址（Remoting 通信使用）</td>\n<td style=\"text-align:left\">✅建议显式指定 IP</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Namesrv</strong></td>\n<td style=\"text-align:left\"><code>namesrvAddr</code></td>\n<td style=\"text-align:left\">多个地址（分号分隔）</td>\n<td style=\"text-align:left\">NameServer 地址，Proxy 通过它同步路由</td>\n<td style=\"text-align:left\">✅推荐配置为可访问的内网地址</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>namesrvDomain</code></td>\n<td style=\"text-align:left\">空</td>\n<td style=\"text-align:left\">NameServer 域名（可用于动态解析）</td>\n<td style=\"text-align:left\">可选，DNS 方式时使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>namesrvDomainSubgroup</code></td>\n<td style=\"text-align:left\">空</td>\n<td style=\"text-align:left\">子域分组（多集群域名发现用）</td>\n<td style=\"text-align:left\">一般可忽略</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>TLS 配置</strong></td>\n<td style=\"text-align:left\"><code>tlsTestModeEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">测试模式下跳过验证（仅用于本地测试）</td>\n<td style=\"text-align:left\">❗生产应设为 false</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>tlsKeyPath</code></td>\n<td style=\"text-align:left\"><code>/conf/tls/rocketmq.key</code></td>\n<td style=\"text-align:left\">TLS 私钥路径</td>\n<td style=\"text-align:left\">✅根据证书路径调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>tlsCertPath</code></td>\n<td style=\"text-align:left\"><code>/conf/tls/rocketmq.crt</code></td>\n<td style=\"text-align:left\">TLS 证书路径</td>\n<td style=\"text-align:left\">✅根据证书路径调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>gRPC 基础</strong></td>\n<td style=\"text-align:left\"><code>proxyMode</code></td>\n<td style=\"text-align:left\"><code>CLUSTER</code></td>\n<td style=\"text-align:left\">Proxy 模式：CLUSTER / LOCAL / REMOTING</td>\n<td style=\"text-align:left\">✅生产推荐 CLUSTER</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcServerPort</code></td>\n<td style=\"text-align:left\">8081</td>\n<td style=\"text-align:left\">gRPC 服务端监听端口</td>\n<td style=\"text-align:left\">若冲突可修改</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcShutdownTimeSeconds</code></td>\n<td style=\"text-align:left\">30</td>\n<td style=\"text-align:left\">优雅关闭等待时间</td>\n<td style=\"text-align:left\">可适当调大</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableGrpcEpoll</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">启用 Linux epoll I/O 模型</td>\n<td style=\"text-align:left\">✅Linux 建议开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcMaxInboundMessageSize</code></td>\n<td style=\"text-align:left\">136314880 (~130MB)</td>\n<td style=\"text-align:left\">最大入站消息大小</td>\n<td style=\"text-align:left\">根据消息大小调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>消息限制</strong></td>\n<td style=\"text-align:left\"><code>maxMessageSize</code></td>\n<td style=\"text-align:left\">4194304 (4MB)</td>\n<td style=\"text-align:left\">最大消息体大小</td>\n<td style=\"text-align:left\">✅应与 Broker 一致</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableMessageBodyEmptyCheck</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">校验消息体是否为空</td>\n<td style=\"text-align:left\">保持默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxUserPropertySize</code></td>\n<td style=\"text-align:left\">16384 (16KB)</td>\n<td style=\"text-align:left\">用户属性最大长度</td>\n<td style=\"text-align:left\">根据业务复杂度调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>userPropertyMaxNum</code></td>\n<td style=\"text-align:left\">128</td>\n<td style=\"text-align:left\">单条消息最大属性数量</td>\n<td style=\"text-align:left\">可适当调低防止性能损耗</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxMessageGroupSize</code></td>\n<td style=\"text-align:left\">64</td>\n<td style=\"text-align:left\">最大消息组大小（批量 pop 使用）</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>消息可见性与延迟</strong></td>\n<td style=\"text-align:left\"><code>defaultInvisibleTimeMills</code></td>\n<td style=\"text-align:left\">60000 (60s)</td>\n<td style=\"text-align:left\">pop 消息默认不可见时间</td>\n<td style=\"text-align:left\">✅高并发时可调低</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxInvisibleTimeMills</code></td>\n<td style=\"text-align:left\">43200000 (12h)</td>\n<td style=\"text-align:left\">最大不可见时长</td>\n<td style=\"text-align:left\">✅可根据业务降低</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxDelayTimeMills</code></td>\n<td style=\"text-align:left\">86400000 (1d)</td>\n<td style=\"text-align:left\">最大延迟时间</td>\n<td style=\"text-align:left\">与 Broker 保持一致</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>useDelayLevel</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否使用延迟等级模式</td>\n<td style=\"text-align:left\">若 Broker 启用等级延迟则开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>messageDelayLevel</code></td>\n<td style=\"text-align:left\"><code>&quot;1s 5s 10s ... 2h&quot;</code></td>\n<td style=\"text-align:left\">延迟等级配置表</td>\n<td style=\"text-align:left\">✅需与 broker.conf 对齐</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>线程池（gRPC 模块）</strong></td>\n<td style=\"text-align:left\"><code>grpcBossLoopNum</code></td>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">Netty boss 线程</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcWorkerLoopNum</code></td>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">gRPC worker 线程</td>\n<td style=\"text-align:left\">✅CPU&gt;4 时可调高至核数</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcThreadPoolNums</code></td>\n<td style=\"text-align:left\">20</td>\n<td style=\"text-align:left\">gRPC 业务线程数</td>\n<td style=\"text-align:left\">✅建议 ≈ CPU 核数×2</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>grpcThreadPoolQueueCapacity</code></td>\n<td style=\"text-align:left\">100000</td>\n<td style=\"text-align:left\">队列容量</td>\n<td style=\"text-align:left\">⚠️建议 ≤20000，防 OOM</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>线程池（内部模块）</strong></td>\n<td style=\"text-align:left\"><code>producerProcessorThreadPoolNums</code></td>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">生产者处理线程</td>\n<td style=\"text-align:left\">✅可根据QPS调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>consumerProcessorThreadPoolNums</code></td>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">消费者处理线程</td>\n<td style=\"text-align:left\">同上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>topicRouteServiceThreadPoolNums</code></td>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">路由服务线程</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>renewThreadPoolNums</code></td>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">自动续期线程</td>\n<td style=\"text-align:left\">高并发时可调大</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>缓存配置</strong></td>\n<td style=\"text-align:left\"><code>topicRouteServiceCacheExpiredSeconds</code></td>\n<td style=\"text-align:left\">300</td>\n<td style=\"text-align:left\">路由缓存有效期</td>\n<td style=\"text-align:left\">✅可适当调大</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>topicConfigCacheExpiredSeconds</code></td>\n<td style=\"text-align:left\">300</td>\n<td style=\"text-align:left\">Topic 配置缓存有效期</td>\n<td style=\"text-align:left\">同上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>subscriptionGroupConfigCacheExpiredSeconds</code></td>\n<td style=\"text-align:left\">300</td>\n<td style=\"text-align:left\">订阅组缓存有效期</td>\n<td style=\"text-align:left\">同上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>aclCacheExpiredSeconds</code></td>\n<td style=\"text-align:left\">300</td>\n<td style=\"text-align:left\">ACL 缓存有效期</td>\n<td style=\"text-align:left\">✅同上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>事务与心跳</strong></td>\n<td style=\"text-align:left\"><code>transactionHeartbeatThreadPoolNums</code></td>\n<td style=\"text-align:left\">20</td>\n<td style=\"text-align:left\">事务心跳线程数</td>\n<td style=\"text-align:left\">✅根据事务量调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transactionHeartbeatPeriodSecond</code></td>\n<td style=\"text-align:left\">20</td>\n<td style=\"text-align:left\">事务心跳周期</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transactionDataExpireMillis</code></td>\n<td style=\"text-align:left\">30000</td>\n<td style=\"text-align:left\">事务数据过期时间</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>指标与监控</strong></td>\n<td style=\"text-align:left\"><code>metricsExporterType</code></td>\n<td style=\"text-align:left\">DISABLE</td>\n<td style=\"text-align:left\">指标导出方式：DISABLE / PROM / GRPC / LOG</td>\n<td style=\"text-align:left\">✅建议启用 PROM</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsPromExporterPort</code></td>\n<td style=\"text-align:left\">5557</td>\n<td style=\"text-align:left\">Prometheus 导出端口</td>\n<td style=\"text-align:left\">✅建议暴露监控</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsInDelta</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否按增量导出指标</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Remoting 模式</strong></td>\n<td style=\"text-align:left\"><code>enableRemotingLocalProxyGrpc</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">启用本地 Proxy gRPC 转发</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>remotingListenPort</code></td>\n<td style=\"text-align:left\">8080</td>\n<td style=\"text-align:left\">Remoting 通信端口</td>\n<td style=\"text-align:left\">若冲突修改</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>sendLatencyEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">启用发送延迟探测（LoadBalance 优化）</td>\n<td style=\"text-align:left\">✅建议开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>startDetectorEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">启用启动探测功能</td>\n<td style=\"text-align:left\">可选，测试阶段使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>可观测性</strong></td>\n<td style=\"text-align:left\"><code>traceOn</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">启用链路追踪</td>\n<td style=\"text-align:left\">✅建议开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enablePrintJstack</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">打印线程堆栈（用于诊断）</td>\n<td style=\"text-align:left\">✅可延长周期减少日志</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>综合优化建议</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">方向</th>\n<th style=\"text-align:left\">建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>性能调优</strong></td>\n<td style=\"text-align:left\">启用 <code>enableGrpcEpoll=true</code>；合理配置线程池（如减少队列长度）；设置合适的 <code>grpcThreadPoolNums</code>。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>可靠性</strong></td>\n<td style=\"text-align:left\">开启 <code>traceOn</code> 与 <code>sendLatencyEnable</code> 监控；使用 Prometheus 指标导出。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>安全性</strong></td>\n<td style=\"text-align:left\">禁用 <code>tlsTestModeEnable</code>，使用真实 TLS 证书。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>资源管理</strong></td>\n<td style=\"text-align:left\">限制缓存数量（如 topic/user/acl）和线程队列容量，防止内存膨胀。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>可维护性</strong></td>\n<td style=\"text-align:left\">使用独立的 <code>proxyClusterName</code>，并在配置文件 <code>rmq-proxy.json</code> 中明确各项端口和路径。</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 RocketMQ Proxy 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 配置项项目源码简介 当前版本尚不支持通过命令行查看 Proxy 的配置项，但是在启动Proxy的日志中可以看到当前生效的配置项。 另外在源码 rocketmq-all-5.3.2-source-release/proxy 的启动类 org.apache.rocketmq.proxy.ProxyStartup中 可以看到其启动时会初始化如下配置项的类 1org.apache.rocketmq.proxy.config.ProxyConfig 配置项说明 Proxy 配置参数说明与优化建议，这里要注意，Proxy的配置文件是 JSON 格式 分类 参数名 默认值 说明 优化建议 基础信息 rocketMQClusterName DefaultCluster Broker 集群名称（Proxy 用于关联 RocketMQ 集群） 若有多个集群，应唯一命名 proxyClusterName DefaultCluster Proxy 所属集群名称（与 brokerClusterName 可不同） ✅建议独立命名，区分 Proxy 集群 proxyName 主机名（例：ip-10-250-0-175...） Proxy 实例名称，用于唯一标识 ✅建议设置唯一名称 localServeAddr 本地 IP Proxy 本地服务地址（Remoting 通信使用） ✅建议显式指定 IP Namesrv namesrvAddr 多个地址（分号分隔） NameServer 地址，Proxy 通过它同步路由 ✅推荐配置为可访问的内网地址 namesrvDomain 空 NameServer 域名（可用于动态解析） 可选，DNS 方式时使用 namesrvDomainSubgroup 空 子域分组（多集群域名发现用） 一般可忽略 TLS 配置 tlsTestModeEnable true 测试模式下跳过验证（仅用于本地测试） ❗生产应设为 false tlsKeyPath /conf/tls/rocketmq.key TLS 私钥路径 ✅根据证书路径调整 tlsCertPath /conf/tls/rocketmq.crt TLS 证书路径 ✅根据证书路径调整 gRPC 基础 proxyMode CLUSTER Proxy 模式：CLUSTER / LOCAL / REMOTING ✅生产推荐 CLUSTER grpcServerPort 8081 gRPC 服务端监听端口 若冲突可修改 grpcShutdownTimeSeconds 30 优雅关闭等待时间 可适当调大 enableGrpcEpoll false 启用 Linux epoll I/O 模型 ✅Linux 建议开启 grpcMaxInboundMessageSize 136314880 (~130MB) 最大入站消息大小 根据消息大小调整 消息限制 maxMessageSize 4194304 (4MB) 最大消息体大小 ✅应与 Broker 一致 enableMessageBodyEmptyCheck true 校验消息体是否为空 保持默认即可 maxUserPropertySize 16384 (16KB) 用户属性最大长度 根据业务复杂度调整 userPropertyMaxNum 128 单条消息最大属性数量 可适当调低防止性能损耗 maxMessageGroupSize 64 最大消息组大小（批量 pop 使用） 默认即可 消息可见性与延迟 defaultInvisibleTimeMills 60000 (60s) pop 消息默认不可见时间 ✅高并发时可调低 maxInvisibleTimeMills 43200000 (12h) 最大不可见时长 ✅可根据业务降低 maxDelayTimeMills 86400000 (1d) 最大延迟时间 与 Broker 保持一致 useDelayLevel false 是否使用延迟等级模式 若 Broker 启用等级延迟则开启 messageDelayLevel &quot;1s 5s 10s ... 2h&quot; 延迟等级配置表 ✅需与 broker.conf 对齐 线程池（gRPC 模块） grpcBossLoopNum 1 Netty boss 线程 默认即可 grpcWorkerLoopNum 4 gRPC worker 线程 ✅CPU&gt;4 时可调高至核数 grpcThreadPoolNums 20 gRPC 业务线程数 ✅建议 ≈ CPU 核数×2 grpcThreadPoolQueueCapacity 100000 队列容量 ⚠️建议 ≤20000，防 OOM 线程池（内部模块） producerProcessorThreadPoolNums 2 生产者处理线程 ✅可根据QPS调整 consumerProcessorThreadPoolNums 2 消费者处理线程 同上 topicRouteServiceThreadPoolNums 2 路由服务线程 默认即可 renewThreadPoolNums 2 自动续期线程 高并发时可调大 缓存配置 topicRouteServiceCacheExpiredSeconds 300 路由缓存有效期 ✅可适当调大 topicConfigCacheExpiredSeconds 300 Topic 配置缓存有效期 同上 subscriptionGroupConfigCacheExpiredSeconds 300 订阅组缓存有效期 同上 aclCacheExpiredSeconds 300 ACL 缓存有效期 ✅同上 事务与心跳 transactionHeartbeatThreadPoolNums 20 事务心跳线程数 ✅根据事务量调整 transactionHeartbeatPeriodSecond 20 事务心跳周期 默认即可 transactionDataExpireMillis 30000 事务数据过期时间 默认即可 指标与监控 metricsExporterType DISABLE 指标导出方式：DISABLE / PROM / GRPC / LOG ✅建议启用 PROM metricsPromExporterPort 5557 Prometheus 导出端口 ✅建议暴露监控 metricsInDelta false 是否按增量导出指标 默认即可 Remoting 模式 enableRemotingLocalProxyGrpc true 启用本地 Proxy gRPC 转发 默认即可 remotingListenPort 8080 Remoting 通信端口 若冲突修改 sendLatencyEnable false 启用发送延迟探测（LoadBalance 优化） ✅建议开启 startDetectorEnable false 启用启动探测功能 可选，测试阶段使用 可观测性 traceOn false 启用链路追踪 ✅建议开启 enablePrintJstack true 打印线程堆栈（用于诊断） ✅可延长周期减少日志 综合优化建议 方向 建议 性能调优 启用 enableGrpcEpoll=true；合理配置线程池（如减少队列长度）；设置合适的 grpcThreadPoolNums。 可靠性 开启 traceOn 与 sendLatencyEnable 监控；使用 Prometheus 指标导出。 安全性 禁用 tlsTestModeEnable，使用真实 TLS 证书。 资源管理 限制缓存数量（如 topic/user/acl）和线程队列容量，防止内存膨胀。 可维护性 使用独立的 proxyClusterName，并在配置文件 rmq-proxy.json 中明确各项端口和路径。","summary":"摘要 本文介绍 RocketMQ Proxy 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-28T13:33:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-05-controller-config/","url":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-05-controller-config/","title":"RocketMQ Controller 的配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ Controller 的配置项。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"查看-Controller-配置项\">查看 Controller 配置项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看全部默认配置项</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看全部默认配置项</span></span><br><span class=\"line\">sh bin/mqcontroller -p</span><br><span class=\"line\"><span class=\"comment\"># 查看加载了指定配置文件后的全部配置项</span></span><br><span class=\"line\">sh bin/mqcontroller -p -c conf/broker.conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项项目源码简介\">配置项项目源码简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在源码 <code>rocketmq-all-5.3.2-source-release/controller</code> 的启动类 <code>org.apache.rocketmq.controller.ControllerStartup</code>中 可以看到其启动时会初始化如下配置项的类</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">ControllerConfig</span> <span class=\"variable\">controllerConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">ControllerConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">JraftConfig</span> <span class=\"variable\">jraftConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">JraftConfig</span>();</span><br><span class=\"line\">controllerConfig.setJraftConfig(jraftConfig);</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">NettyServerConfig</span> <span class=\"variable\">nettyServerConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">NettyServerConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">NettyClientConfig</span> <span class=\"variable\">nettyClientConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">NettyClientConfig</span>();</span><br><span class=\"line\">nettyServerConfig.setListenPort(<span class=\"number\">19876</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项说明\">配置项说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Controller 配置参数说明与优化建议</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">分类</th>\n<th style=\"text-align:left\">参数名</th>\n<th style=\"text-align:left\">默认值</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">优化 / 建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>基础信息</strong></td>\n<td style=\"text-align:left\"><code>rocketmqHome</code></td>\n<td style=\"text-align:left\">/usr/local/soft/rocketmq/rocketmq5</td>\n<td style=\"text-align:left\">RocketMQ 根路径</td>\n<td style=\"text-align:left\">保持默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>configStorePath</code></td>\n<td style=\"text-align:left\">/root/controller/controller.properties</td>\n<td style=\"text-align:left\">Controller 配置文件路径</td>\n<td style=\"text-align:left\">✅ 改为 <code>/data/rocketmq/controller/controller.properties</code>，避免使用 <code>/root</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>controllerType</code></td>\n<td style=\"text-align:left\">DLedger</td>\n<td style=\"text-align:left\">Controller 类型（DLedger / STANDALONE）</td>\n<td style=\"text-align:left\">✅ 建议使用 DLedger（高可用）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>controllerStorePath</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">Controller 元数据存储路径</td>\n<td style=\"text-align:left\">✅ 建议 <code>/data/rocketmq/controller/store</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>DLedger 选举配置</strong></td>\n<td style=\"text-align:left\"><code>controllerDLegerGroup</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">Controller 集群组名</td>\n<td style=\"text-align:left\">✅ 必填，例如：<code>controllerGroup01</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>controllerDLegerPeers</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">集群节点列表，格式：<code>n0-10.0.0.1:19876;n1-10.0.0.2:19876;n2-10.0.0.3:19876</code></td>\n<td style=\"text-align:left\">✅ 必填（3 节点推荐）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>controllerDLegerSelfId</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">当前节点 ID，如 <code>n0</code></td>\n<td style=\"text-align:left\">✅ 必填</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>mappedFileSize</code></td>\n<td style=\"text-align:left\">1073741824</td>\n<td style=\"text-align:left\">DLedger 存储文件大小 (1GB)</td>\n<td style=\"text-align:left\">可保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>electMasterMaxRetryCount</code></td>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">Master 选举最大重试次数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableElectUncleanMaster</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否允许选举非同步 Master</td>\n<td style=\"text-align:left\">✅ 建议保持 false（避免数据丢失）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Broker 管理</strong></td>\n<td style=\"text-align:left\"><code>scanNotActiveBrokerInterval</code></td>\n<td style=\"text-align:left\">5000</td>\n<td style=\"text-align:left\">扫描不活跃 Broker 的间隔(ms)</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>scanInactiveMasterInterval</code></td>\n<td style=\"text-align:left\">5000</td>\n<td style=\"text-align:left\">检测失活 Master 间隔(ms)</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>notifyBrokerRoleChanged</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否通知 Broker 角色变更</td>\n<td style=\"text-align:left\">✅ 建议开启（保持同步）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>isProcessReadEvent</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否处理读事件</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>线程与性能</strong></td>\n<td style=\"text-align:left\"><code>controllerThreadPoolNums</code></td>\n<td style=\"text-align:left\">16</td>\n<td style=\"text-align:left\">控制线程池大小</td>\n<td style=\"text-align:left\">可调至 8–32 视规模而定</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>controllerRequestThreadPoolQueueCapacity</code></td>\n<td style=\"text-align:left\">50000</td>\n<td style=\"text-align:left\">控制线程池队列容量</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Metrics 监控</strong></td>\n<td style=\"text-align:left\"><code>metricsExporterType</code></td>\n<td style=\"text-align:left\">DISABLE</td>\n<td style=\"text-align:left\">指标输出方式（DISABLE / PROM / GRPC / LOG）</td>\n<td style=\"text-align:left\">✅ 建议设为 <code>PROM</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsPromExporterPort</code></td>\n<td style=\"text-align:left\">5557</td>\n<td style=\"text-align:left\">Prometheus 端口</td>\n<td style=\"text-align:left\">✅ 若启用监控，可用默认 5557</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsPromExporterHost</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">Prometheus 绑定主机</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricLoggingExporterIntervalInMills</code></td>\n<td style=\"text-align:left\">10000</td>\n<td style=\"text-align:left\">日志输出指标间隔</td>\n<td style=\"text-align:left\">可调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsGrpcExporterTarget</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">gRPC 监控目标</td>\n<td style=\"text-align:left\">可忽略</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>metricsInDelta</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否以增量输出指标</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>JRaft 配置（底层一致性协议）</strong></td>\n<td style=\"text-align:left\"><code>jRaftGroupId</code></td>\n<td style=\"text-align:left\">jRaft-Controller</td>\n<td style=\"text-align:left\">Raft 组名</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftServerId</code></td>\n<td style=\"text-align:left\">localhost:9880</td>\n<td style=\"text-align:left\">当前节点 ID</td>\n<td style=\"text-align:left\">✅ 修改为实际 IP，例如 <code>10.0.0.1:9880</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftInitConf</code></td>\n<td style=\"text-align:left\">localhost:9880,localhost:9881,localhost:9882</td>\n<td style=\"text-align:left\">集群配置</td>\n<td style=\"text-align:left\">✅ 修改为实际节点 IP</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftControllerRPCAddr</code></td>\n<td style=\"text-align:left\">localhost:9770,localhost:9771,localhost:9772</td>\n<td style=\"text-align:left\">Controller RPC 地址</td>\n<td style=\"text-align:left\">✅ 修改为实际节点 IP</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftElectionTimeoutMs</code></td>\n<td style=\"text-align:left\">1000</td>\n<td style=\"text-align:left\">选举超时（ms）</td>\n<td style=\"text-align:left\">默认即可（过低可能频繁选举）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftScanWaitTimeoutMs</code></td>\n<td style=\"text-align:left\">1000</td>\n<td style=\"text-align:left\">扫描等待超时</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>jRaftSnapshotIntervalSecs</code></td>\n<td style=\"text-align:left\">3600</td>\n<td style=\"text-align:left\">快照间隔时间（秒）</td>\n<td style=\"text-align:left\">✅ 可设为 600（10分钟）加快日志压缩</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>网络配置</strong></td>\n<td style=\"text-align:left\"><code>bindAddress</code></td>\n<td style=\"text-align:left\">0.0.0.0</td>\n<td style=\"text-align:left\">绑定监听地址</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>listenPort</code></td>\n<td style=\"text-align:left\">19876</td>\n<td style=\"text-align:left\">Controller 服务端口</td>\n<td style=\"text-align:left\">✅ 确保未冲突</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>serverWorkerThreads</code></td>\n<td style=\"text-align:left\">8</td>\n<td style=\"text-align:left\">Netty 工作线程</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>serverSelectorThreads</code></td>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">Selector 线程数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>serverSocketBacklog</code></td>\n<td style=\"text-align:left\">1024</td>\n<td style=\"text-align:left\">Socket backlog 队列</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>useEpollNativeSelector</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否使用 Epoll</td>\n<td style=\"text-align:left\">✅ Linux 环境建议 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableShutdownGracefully</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">优雅停机</td>\n<td style=\"text-align:left\">✅ 建议 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>客户端通信</strong></td>\n<td style=\"text-align:left\"><code>clientWorkerThreads</code></td>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">客户端工作线程</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>clientAsyncSemaphoreValue</code></td>\n<td style=\"text-align:left\">65535</td>\n<td style=\"text-align:left\">异步请求信号量</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>clientCloseSocketIfTimeout</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">连接超时关闭</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>connectTimeoutMillis</code></td>\n<td style=\"text-align:left\">3000</td>\n<td style=\"text-align:left\">连接超时</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>useTLS</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 TLS</td>\n<td style=\"text-align:left\">✅ 若生产环境有安全要求，建议启用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>其他</strong></td>\n<td style=\"text-align:left\"><code>configBlackList</code></td>\n<td style=\"text-align:left\">configBlackList;configStorePath</td>\n<td style=\"text-align:left\">配置黑名单项</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxReconnectIntervalTimeSeconds</code></td>\n<td style=\"text-align:left\">60</td>\n<td style=\"text-align:left\">最大重连间隔</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableReconnectForGoAway</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否为 GOAWAY 连接启用重连</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>推荐重点优化的关键项</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">项目</th>\n<th style=\"text-align:left\">推荐值</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>controllerType</code></td>\n<td style=\"text-align:left\">DLedger</td>\n<td style=\"text-align:left\">高可用模式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>controllerDLegerGroup</code></td>\n<td style=\"text-align:left\">controllerGroup01</td>\n<td style=\"text-align:left\">集群分组名</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>controllerDLegerPeers</code></td>\n<td style=\"text-align:left\"><code>n0-10.0.0.1:19876;n1-10.0.0.2:19876;n2-10.0.0.3:19876</code></td>\n<td style=\"text-align:left\">三节点推荐</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>controllerDLegerSelfId</code></td>\n<td style=\"text-align:left\">n0 / n1 / n2</td>\n<td style=\"text-align:left\">对应节点 ID</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>enableElectUncleanMaster</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">防止脏主选举</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>notifyBrokerRoleChanged</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">保持集群一致性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>metricsExporterType</code></td>\n<td style=\"text-align:left\">PROM</td>\n<td style=\"text-align:left\">便于 Prometheus 监控</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>metricsPromExporterPort</code></td>\n<td style=\"text-align:left\">5557</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>useEpollNativeSelector</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">Linux 性能优化</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>enableShutdownGracefully</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">优雅停机</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>controllerStorePath</code></td>\n<td style=\"text-align:left\">/data/rocketmq/controller/store</td>\n<td style=\"text-align:left\">避免使用 <code>/root</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>jRaftSnapshotIntervalSecs</code></td>\n<td style=\"text-align:left\">600</td>\n<td style=\"text-align:left\">提高快照频率</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 RocketMQ Controller 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 查看 Controller 配置项 查看全部默认配置项 1234# 查看全部默认配置项sh bin/mqcontroller -p# 查看加载了指定配置文件后的全部配置项sh bin/mqcontroller -p -c conf/broker.conf 配置项项目源码简介 在源码 rocketmq-all-5.3.2-source-release/controller 的启动类 org.apache.rocketmq.controller.ControllerStartup中 可以看到其启动时会初始化如下配置项的类 123456final ControllerConfig controllerConfig = new ControllerConfig();final JraftConfig jraftConfig = new JraftConfig();controllerConfig.setJraftConfig(jraftConfig);final NettyServerConfig nettyServerConfig = new NettyServerConfig();final NettyClientConfig nettyClientConfig = new NettyClientConfig();nettyServerConfig.setListenPort(19876); 配置项说明 Controller 配置参数说明与优化建议 分类 参数名 默认值 说明 优化 / 建议 基础信息 rocketmqHome /usr/local/soft/rocketmq/rocketmq5 RocketMQ 根路径 保持默认即可 configStorePath /root/controller/controller.properties Controller 配置文件路径 ✅ 改为 /data/rocketmq/controller/controller.properties，避免使用 /root controllerType DLedger Controller 类型（DLedger / STANDALONE） ✅ 建议使用 DLedger（高可用） controllerStorePath (空) Controller 元数据存储路径 ✅ 建议 /data/rocketmq/controller/store DLedger 选举配置 controllerDLegerGroup (空) Controller 集群组名 ✅ 必填，例如：controllerGroup01 controllerDLegerPeers (空) 集群节点列表，格式：n0-10.0.0.1:19876;n1-10.0.0.2:19876;n2-10.0.0.3:19876 ✅ 必填（3 节点推荐） controllerDLegerSelfId (空) 当前节点 ID，如 n0 ✅ 必填 mappedFileSize 1073741824 DLedger 存储文件大小 (1GB) 可保持默认 electMasterMaxRetryCount 3 Master 选举最大重试次数 默认即可 enableElectUncleanMaster false 是否允许选举非同步 Master ✅ 建议保持 false（避免数据丢失） Broker 管理 scanNotActiveBrokerInterval 5000 扫描不活跃 Broker 的间隔(ms) 默认即可 scanInactiveMasterInterval 5000 检测失活 Master 间隔(ms) 默认即可 notifyBrokerRoleChanged true 是否通知 Broker 角色变更 ✅ 建议开启（保持同步） isProcessReadEvent false 是否处理读事件 默认即可 线程与性能 controllerThreadPoolNums 16 控制线程池大小 可调至 8–32 视规模而定 controllerRequestThreadPoolQueueCapacity 50000 控制线程池队列容量 默认即可 Metrics 监控 metricsExporterType DISABLE 指标输出方式（DISABLE / PROM / GRPC / LOG） ✅ 建议设为 PROM metricsPromExporterPort 5557 Prometheus 端口 ✅ 若启用监控，可用默认 5557 metricsPromExporterHost (空) Prometheus 绑定主机 默认即可 metricLoggingExporterIntervalInMills 10000 日志输出指标间隔 可调整 metricsGrpcExporterTarget (空) gRPC 监控目标 可忽略 metricsInDelta false 是否以增量输出指标 默认即可 JRaft 配置（底层一致性协议） jRaftGroupId jRaft-Controller Raft 组名 默认即可 jRaftServerId localhost:9880 当前节点 ID ✅ 修改为实际 IP，例如 10.0.0.1:9880 jRaftInitConf localhost:9880,localhost:9881,localhost:9882 集群配置 ✅ 修改为实际节点 IP jRaftControllerRPCAddr localhost:9770,localhost:9771,localhost:9772 Controller RPC 地址 ✅ 修改为实际节点 IP jRaftElectionTimeoutMs 1000 选举超时（ms） 默认即可（过低可能频繁选举） jRaftScanWaitTimeoutMs 1000 扫描等待超时 默认即可 jRaftSnapshotIntervalSecs 3600 快照间隔时间（秒） ✅ 可设为 600（10分钟）加快日志压缩 网络配置 bindAddress 0.0.0.0 绑定监听地址 默认即可 listenPort 19876 Controller 服务端口 ✅ 确保未冲突 serverWorkerThreads 8 Netty 工作线程 默认即可 serverSelectorThreads 3 Selector 线程数 默认即可 serverSocketBacklog 1024 Socket backlog 队列 默认即可 useEpollNativeSelector false 是否使用 Epoll ✅ Linux 环境建议 true enableShutdownGracefully false 优雅停机 ✅ 建议 true 客户端通信 clientWorkerThreads 4 客户端工作线程 默认即可 clientAsyncSemaphoreValue 65535 异步请求信号量 默认即可 clientCloseSocketIfTimeout true 连接超时关闭 默认即可 connectTimeoutMillis 3000 连接超时 默认即可 useTLS false 是否启用 TLS ✅ 若生产环境有安全要求，建议启用 其他 configBlackList configBlackList;configStorePath 配置黑名单项 默认即可 maxReconnectIntervalTimeSeconds 60 最大重连间隔 默认即可 enableReconnectForGoAway true 是否为 GOAWAY 连接启用重连 默认即可 推荐重点优化的关键项 项目 推荐值 说明 controllerType DLedger 高可用模式 controllerDLegerGroup controllerGroup01 集群分组名 controllerDLegerPeers n0-10.0.0.1:19876;n1-10.0.0.2:19876;n2-10.0.0.3:19876 三节点推荐 controllerDLegerSelfId n0 / n1 / n2 对应节点 ID enableElectUncleanMaster false 防止脏主选举 notifyBrokerRoleChanged true 保持集群一致性 metricsExporterType PROM 便于 Prometheus 监控 metricsPromExporterPort 5557 默认即可 useEpollNativeSelector true Linux 性能优化 enableShutdownGracefully true 优雅停机 controllerStorePath /data/rocketmq/controller/store 避免使用 /root jRaftSnapshotIntervalSecs 600 提高快照频率","summary":"摘要 本文介绍 RocketMQ Controller 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-28T13:32:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-04-broker-config/","url":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-04-broker-config/","title":"RocketMQ Broker 的配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ Broker 的配置项。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"查看-Broker-配置项\">查看 Broker 配置项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看全部默认配置项</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看全部默认配置项</span></span><br><span class=\"line\">sh bin/mqbroker -p</span><br><span class=\"line\"><span class=\"comment\"># 查看加载了指定配置文件后的全部配置项</span></span><br><span class=\"line\">sh bin/mqbroker -p -c conf/broker.conf</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看重要的配置项</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看重要的默认配置项</span></span><br><span class=\"line\">sh bin/mqbroker -m</span><br><span class=\"line\"><span class=\"comment\"># 查看加载了指定配置文件后的重要配置项</span></span><br><span class=\"line\">sh bin/mqbroker -m -c conf/broker.conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项项目源码简介\">配置项项目源码简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在源码 <code>rocketmq-all-5.3.2-source-release/broker</code> 的启动类 <code>org.apache.rocketmq.broker.BrokerStartup</code>中 可以看到其启动时会初始化如下配置项的类</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">BrokerConfig</span> <span class=\"variable\">brokerConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">BrokerConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">NettyServerConfig</span> <span class=\"variable\">nettyServerConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">NettyServerConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">NettyClientConfig</span> <span class=\"variable\">nettyClientConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">NettyClientConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">MessageStoreConfig</span> <span class=\"variable\">messageStoreConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">MessageStoreConfig</span>();</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"type\">AuthConfig</span> <span class=\"variable\">authConfig</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">AuthConfig</span>();</span><br><span class=\"line\">nettyServerConfig.setListenPort(<span class=\"number\">10911</span>);</span><br><span class=\"line\">messageStoreConfig.setHaListenPort(<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项说明\">配置项说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Broker的全部配置项非常多，这里仅列出了重要的配置项。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">分类</th>\n<th style=\"text-align:left\">参数名</th>\n<th style=\"text-align:left\">默认值</th>\n<th style=\"text-align:left\">参数说明</th>\n<th style=\"text-align:left\">优化 / 建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>基础配置</strong></td>\n<td style=\"text-align:left\"><code>namesrvAddr</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">NameServer 地址列表（多个用 <code>;</code> 分隔）</td>\n<td style=\"text-align:left\">✅ <strong>必须设置</strong>，否则 broker 无法注册到 nameserver。例：<code>namesrvAddr=10.250.0.10:9876;10.250.0.11:9876</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>listenPort</code></td>\n<td style=\"text-align:left\">6888</td>\n<td style=\"text-align:left\">Broker 监听客户端连接的端口</td>\n<td style=\"text-align:left\">✅ 建议保持默认或显式设置为 10911（经典端口）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>brokerIP1</code></td>\n<td style=\"text-align:left\">10.250.0.188</td>\n<td style=\"text-align:left\">Broker 对外通信 IP</td>\n<td style=\"text-align:left\">✅ 在多网卡环境务必指定公网/内网 IP</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>recoverConcurrently</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否并发恢复 CommitLog</td>\n<td style=\"text-align:left\">默认即可（高安全性）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Topic &amp; 订阅</strong></td>\n<td style=\"text-align:left\"><code>autoCreateTopicEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否允许自动创建 Topic</td>\n<td style=\"text-align:left\">✅ 生产建议设为 <strong>false</strong>，防止误创建</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>autoCreateSubscriptionGroup</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否自动创建订阅组</td>\n<td style=\"text-align:left\">✅ 同上，建议 <strong>false</strong></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>msgTraceTopicName</code></td>\n<td style=\"text-align:left\">RMQ_SYS_TRACE_TOPIC</td>\n<td style=\"text-align:left\">消息轨迹主题名</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>traceTopicEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否开启消息轨迹功能</td>\n<td style=\"text-align:left\">✅ 建议设为 <strong>true</strong> 以便问题排查</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>事务消息</strong></td>\n<td style=\"text-align:left\"><code>rejectTransactionMessage</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否拒绝事务消息</td>\n<td style=\"text-align:left\">若不使用事务可设为 true 减少负担</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transactionTimeOut</code></td>\n<td style=\"text-align:left\">6000</td>\n<td style=\"text-align:left\">事务超时时间（ms）</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transactionCheckMax</code></td>\n<td style=\"text-align:left\">15</td>\n<td style=\"text-align:left\">事务最大回查次数</td>\n<td style=\"text-align:left\">可调高（20）提高可靠性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transactionCheckInterval</code></td>\n<td style=\"text-align:left\">30000</td>\n<td style=\"text-align:left\">事务回查间隔（ms）</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>访问控制</strong></td>\n<td style=\"text-align:left\"><code>aclEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 ACL 权限验证</td>\n<td style=\"text-align:left\">✅ 生产环境 <strong>必须 true</strong></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>存储路径</strong></td>\n<td style=\"text-align:left\"><code>storePathRootDir</code></td>\n<td style=\"text-align:left\">/root/store</td>\n<td style=\"text-align:left\">消息存储根目录</td>\n<td style=\"text-align:left\">✅ 改为 <code>/data/rocketmq/store</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>storePathCommitLog</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">CommitLog 存储路径</td>\n<td style=\"text-align:left\">若为空则使用上面的根目录</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>storePathDLedgerCommitLog</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">DLedger 模式存储路径</td>\n<td style=\"text-align:left\">DLedger 模式才需要</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>storePathEpochFile</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">epoch 文件路径</td>\n<td style=\"text-align:left\">Controller 模式使用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>storePathBrokerIdentity</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">Broker 身份文件路径</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>disappearTimeAfterStart</code></td>\n<td style=\"text-align:left\">-1</td>\n<td style=\"text-align:left\">Broker 启动后失效等待时间</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>storeType</code></td>\n<td style=\"text-align:left\">default</td>\n<td style=\"text-align:left\">存储类型（default / dledger）</td>\n<td style=\"text-align:left\">✅ 多副本部署建议 dledger</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>刷盘与写入</strong></td>\n<td style=\"text-align:left\"><code>flushIntervalCommitLog</code></td>\n<td style=\"text-align:left\">500</td>\n<td style=\"text-align:left\">异步 flush 周期（ms）</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>commitIntervalCommitLog</code></td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">commit 间隔</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>flushCommitLogTimed</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否定时 flush</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>文件清理</strong></td>\n<td style=\"text-align:left\"><code>deleteWhen</code></td>\n<td style=\"text-align:left\">04</td>\n<td style=\"text-align:left\">删除过期文件时间点</td>\n<td style=\"text-align:left\">每天凌晨 4 点</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>fileReservedTime</code></td>\n<td style=\"text-align:left\">72</td>\n<td style=\"text-align:left\">文件保留时间（小时）</td>\n<td style=\"text-align:left\">✅ 可改为 48 减少磁盘压力</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>deleteFileBatchMax</code></td>\n<td style=\"text-align:left\">10</td>\n<td style=\"text-align:left\">删除文件批量数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>消息访问性能</strong></td>\n<td style=\"text-align:left\"><code>maxTransferBytesOnMessageInMemory</code></td>\n<td style=\"text-align:left\">262144</td>\n<td style=\"text-align:left\">内存消息读取最大字节</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxTransferCountOnMessageInMemory</code></td>\n<td style=\"text-align:left\">32</td>\n<td style=\"text-align:left\">内存消息读取最大条数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxTransferBytesOnMessageInDisk</code></td>\n<td style=\"text-align:left\">65536</td>\n<td style=\"text-align:left\">磁盘消息读取最大字节</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>maxTransferCountOnMessageInDisk</code></td>\n<td style=\"text-align:left\">8</td>\n<td style=\"text-align:left\">磁盘消息读取最大条数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>accessMessageInMemoryMaxRatio</code></td>\n<td style=\"text-align:left\">40</td>\n<td style=\"text-align:left\">内存访问比例阈值</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>索引管理</strong></td>\n<td style=\"text-align:left\"><code>messageIndexEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否启用消息索引</td>\n<td style=\"text-align:left\">✅ 建议开启（提高按 key 查询性能）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>messageIndexSafe</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否安全模式索引</td>\n<td style=\"text-align:left\">若磁盘可靠性差可设为 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>主从复制</strong></td>\n<td style=\"text-align:left\"><code>haMasterAddress</code></td>\n<td style=\"text-align:left\"><em>(空)</em></td>\n<td style=\"text-align:left\">Master 地址（Slave 模式使用）</td>\n<td style=\"text-align:left\">仅从节点配置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>brokerRole</code></td>\n<td style=\"text-align:left\">ASYNC_MASTER</td>\n<td style=\"text-align:left\">Broker 角色（ASYNC_MASTER / SYNC_MASTER / SLAVE）</td>\n<td style=\"text-align:left\">✅ 主节点建议 SYNC_MASTER 提高可靠性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>flushDiskType</code></td>\n<td style=\"text-align:left\">ASYNC_FLUSH</td>\n<td style=\"text-align:left\">刷盘策略（SYNC_FLUSH / ASYNC_FLUSH）</td>\n<td style=\"text-align:left\">✅ 高可靠建议 SYNC_FLUSH</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>cleanFileForciblyEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否强制清理文件</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>transientStorePoolEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 transient pool（堆外内存）</td>\n<td style=\"text-align:left\">✅ 可设为 true 提升性能（需足够内存）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>dispatchFromSenderThread</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否由发送线程分发</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>wakeCommitWhenPutMessage</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否在消息写入时唤醒 commit</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>wakeFlushWhenPutMessage</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否写入后立即 flush</td>\n<td style=\"text-align:left\">✅ 对延迟敏感业务可设为 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>消费进度清理</strong></td>\n<td style=\"text-align:left\"><code>enableCleanExpiredOffset</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 offset 清理</td>\n<td style=\"text-align:left\">默认 false</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>副本参数</strong></td>\n<td style=\"text-align:left\"><code>totalReplicas</code></td>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">副本总数</td>\n<td style=\"text-align:left\">✅ 多节点建议设为 3</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>inSyncReplicas</code></td>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">同步副本数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>minInSyncReplicas</code></td>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">最小同步副本</td>\n<td style=\"text-align:left\">✅ 建议设为 2 提高可靠性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>allAckInSyncStateSet</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否要求所有 ISR 确认</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\"><code>enableAutoInSyncReplicas</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否自动管理 ISR</td>\n<td style=\"text-align:left\">可保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>HA 与流控</strong></td>\n<td style=\"text-align:left\"><code>haFlowControlEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否开启主从流控</td>\n<td style=\"text-align:left\">✅ 多副本建议 true</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>推荐重点优化的关键项</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">类别</th>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">推荐值</th>\n<th style=\"text-align:left\">原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">注册</td>\n<td style=\"text-align:left\"><code>namesrvAddr</code></td>\n<td style=\"text-align:left\">必填</td>\n<td style=\"text-align:left\">Broker 必须向 NameServer 注册</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">安全</td>\n<td style=\"text-align:left\"><code>aclEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">启用访问控制</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">自动创建</td>\n<td style=\"text-align:left\"><code>autoCreateTopicEnable</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">防止误创建 topic</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">自动订阅</td>\n<td style=\"text-align:left\"><code>autoCreateSubscriptionGroup</code></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">防止误消费</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">刷盘策略</td>\n<td style=\"text-align:left\"><code>flushDiskType</code></td>\n<td style=\"text-align:left\">SYNC_FLUSH</td>\n<td style=\"text-align:left\">保证可靠性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">主从</td>\n<td style=\"text-align:left\"><code>brokerRole</code></td>\n<td style=\"text-align:left\">SYNC_MASTER（主） / SLAVE（从）</td>\n<td style=\"text-align:left\">提升可用性</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">存储路径</td>\n<td style=\"text-align:left\"><code>storePathRootDir</code></td>\n<td style=\"text-align:left\"><code>/data/rocketmq/store</code></td>\n<td style=\"text-align:left\">避免 <code>/root</code> 权限问题</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">延迟优化</td>\n<td style=\"text-align:left\"><code>transientStorePoolEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">堆外内存加速写入</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">清理</td>\n<td style=\"text-align:left\"><code>fileReservedTime</code></td>\n<td style=\"text-align:left\">48</td>\n<td style=\"text-align:left\">减少磁盘占用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息轨迹</td>\n<td style=\"text-align:left\"><code>traceTopicEnable</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">便于追踪消息链路</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 RocketMQ Broker 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 查看 Broker 配置项 查看全部默认配置项 1234# 查看全部默认配置项sh bin/mqbroker -p# 查看加载了指定配置文件后的全部配置项sh bin/mqbroker -p -c conf/broker.conf 查看重要的配置项 1234# 查看重要的默认配置项sh bin/mqbroker -m# 查看加载了指定配置文件后的重要配置项sh bin/mqbroker -m -c conf/broker.conf 配置项项目源码简介 在源码 rocketmq-all-5.3.2-source-release/broker 的启动类 org.apache.rocketmq.broker.BrokerStartup中 可以看到其启动时会初始化如下配置项的类 1234567final BrokerConfig brokerConfig = new BrokerConfig();final NettyServerConfig nettyServerConfig = new NettyServerConfig();final NettyClientConfig nettyClientConfig = new NettyClientConfig();final MessageStoreConfig messageStoreConfig = new MessageStoreConfig();final AuthConfig authConfig = new AuthConfig();nettyServerConfig.setListenPort(10911);messageStoreConfig.setHaListenPort(0); 配置项说明 Broker的全部配置项非常多，这里仅列出了重要的配置项。 分类 参数名 默认值 参数说明 优化 / 建议 基础配置 namesrvAddr (空) NameServer 地址列表（多个用 ; 分隔） ✅ 必须设置，否则 broker 无法注册到 nameserver。例：namesrvAddr=10.250.0.10:9876;10.250.0.11:9876 listenPort 6888 Broker 监听客户端连接的端口 ✅ 建议保持默认或显式设置为 10911（经典端口） brokerIP1 10.250.0.188 Broker 对外通信 IP ✅ 在多网卡环境务必指定公网/内网 IP recoverConcurrently false 是否并发恢复 CommitLog 默认即可（高安全性） Topic &amp; 订阅 autoCreateTopicEnable true 是否允许自动创建 Topic ✅ 生产建议设为 false，防止误创建 autoCreateSubscriptionGroup true 是否自动创建订阅组 ✅ 同上，建议 false msgTraceTopicName RMQ_SYS_TRACE_TOPIC 消息轨迹主题名 默认即可 traceTopicEnable false 是否开启消息轨迹功能 ✅ 建议设为 true 以便问题排查 事务消息 rejectTransactionMessage false 是否拒绝事务消息 若不使用事务可设为 true 减少负担 transactionTimeOut 6000 事务超时时间（ms） 默认即可 transactionCheckMax 15 事务最大回查次数 可调高（20）提高可靠性 transactionCheckInterval 30000 事务回查间隔（ms） 默认即可 访问控制 aclEnable false 是否启用 ACL 权限验证 ✅ 生产环境 必须 true 存储路径 storePathRootDir /root/store 消息存储根目录 ✅ 改为 /data/rocketmq/store storePathCommitLog (空) CommitLog 存储路径 若为空则使用上面的根目录 storePathDLedgerCommitLog (空) DLedger 模式存储路径 DLedger 模式才需要 storePathEpochFile (空) epoch 文件路径 Controller 模式使用 storePathBrokerIdentity (空) Broker 身份文件路径 默认即可 disappearTimeAfterStart -1 Broker 启动后失效等待时间 默认即可 storeType default 存储类型（default / dledger） ✅ 多副本部署建议 dledger 刷盘与写入 flushIntervalCommitLog 500 异步 flush 周期（ms） 默认即可 commitIntervalCommitLog 200 commit 间隔 默认即可 flushCommitLogTimed true 是否定时 flush 默认即可 文件清理 deleteWhen 04 删除过期文件时间点 每天凌晨 4 点 fileReservedTime 72 文件保留时间（小时） ✅ 可改为 48 减少磁盘压力 deleteFileBatchMax 10 删除文件批量数 默认即可 消息访问性能 maxTransferBytesOnMessageInMemory 262144 内存消息读取最大字节 默认即可 maxTransferCountOnMessageInMemory 32 内存消息读取最大条数 默认即可 maxTransferBytesOnMessageInDisk 65536 磁盘消息读取最大字节 默认即可 maxTransferCountOnMessageInDisk 8 磁盘消息读取最大条数 默认即可 accessMessageInMemoryMaxRatio 40 内存访问比例阈值 默认即可 索引管理 messageIndexEnable true 是否启用消息索引 ✅ 建议开启（提高按 key 查询性能） messageIndexSafe false 是否安全模式索引 若磁盘可靠性差可设为 true 主从复制 haMasterAddress (空) Master 地址（Slave 模式使用） 仅从节点配置 brokerRole ASYNC_MASTER Broker 角色（ASYNC_MASTER / SYNC_MASTER / SLAVE） ✅ 主节点建议 SYNC_MASTER 提高可靠性 flushDiskType ASYNC_FLUSH 刷盘策略（SYNC_FLUSH / ASYNC_FLUSH） ✅ 高可靠建议 SYNC_FLUSH cleanFileForciblyEnable true 是否强制清理文件 默认即可 transientStorePoolEnable false 是否启用 transient pool（堆外内存） ✅ 可设为 true 提升性能（需足够内存） dispatchFromSenderThread false 是否由发送线程分发 默认即可 wakeCommitWhenPutMessage true 是否在消息写入时唤醒 commit 默认即可 wakeFlushWhenPutMessage false 是否写入后立即 flush ✅ 对延迟敏感业务可设为 true 消费进度清理 enableCleanExpiredOffset false 是否启用 offset 清理 默认 false 副本参数 totalReplicas 1 副本总数 ✅ 多节点建议设为 3 inSyncReplicas 1 同步副本数 默认即可 minInSyncReplicas 1 最小同步副本 ✅ 建议设为 2 提高可靠性 allAckInSyncStateSet false 是否要求所有 ISR 确认 默认即可 enableAutoInSyncReplicas false 是否自动管理 ISR 可保持默认 HA 与流控 haFlowControlEnable false 是否开启主从流控 ✅ 多副本建议 true 推荐重点优化的关键项 类别 参数 推荐值 原因 注册 namesrvAddr 必填 Broker 必须向 NameServer 注册 安全 aclEnable true 启用访问控制 自动创建 autoCreateTopicEnable false 防止误创建 topic 自动订阅 autoCreateSubscriptionGroup false 防止误消费 刷盘策略 flushDiskType SYNC_FLUSH 保证可靠性 主从 brokerRole SYNC_MASTER（主） / SLAVE（从） 提升可用性 存储路径 storePathRootDir /data/rocketmq/store 避免 /root 权限问题 延迟优化 transientStorePoolEnable true 堆外内存加速写入 清理 fileReservedTime 48 减少磁盘占用 消息轨迹 traceTopicEnable true 便于追踪消息链路","summary":"摘要 本文介绍 RocketMQ Broker 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-28T13:31:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-03-namesvr-config/","url":"https://blog.hanqunfeng.com/2025/10/28/rocketmq-03-namesvr-config/","title":"RocketMQ NameServer 的配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RocketMQ NameServer 的配置项。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"查看-NameServer-配置项\">查看 NameServer 配置项</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看默认配置项</span></span><br><span class=\"line\">sh bin/mqnamesrv -p</span><br><span class=\"line\"><span class=\"comment\"># 查看加载了指定配置文件后的配置项，即配置文件中的配置项会覆盖默认配置项</span></span><br><span class=\"line\">sh bin/mqnamesrv -p -c conf/namesvr.conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项项目源码简介\">配置项项目源码简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在源码 <code>rocketmq-all-5.3.2-source-release/namesrv</code> 的启动类 <code>org.apache.rocketmq.namesrv.NamesrvStartup</code>中 可以看到其启动时会初始化如下配置项的类</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"type\">NamesrvConfig</span> <span class=\"variable\">namesrvConfig</span> <span class=\"operator\">=</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"type\">NettyServerConfig</span> <span class=\"variable\">nettyServerConfig</span> <span class=\"operator\">=</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"type\">NettyClientConfig</span> <span class=\"variable\">nettyClientConfig</span> <span class=\"operator\">=</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"type\">ControllerConfig</span> <span class=\"variable\">controllerConfig</span> <span class=\"operator\">=</span> <span class=\"literal\">null</span>;</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置项说明\">配置项说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>NameServer 配置项说明与建议</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数名</th>\n<th style=\"text-align:left\">默认值</th>\n<th style=\"text-align:left\">参数说明</th>\n<th style=\"text-align:left\">优化 / 建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>rocketmqHome</strong></td>\n<td style=\"text-align:left\">/usr/local/soft/rocketmq/rocketmq5</td>\n<td style=\"text-align:left\">RocketMQ 安装目录</td>\n<td style=\"text-align:left\">不建议修改</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>kvConfigPath</strong></td>\n<td style=\"text-align:left\">/root/namesrv/kvConfig.json</td>\n<td style=\"text-align:left\">KV 配置存储路径</td>\n<td style=\"text-align:left\">✅ 改为 <code>/data/rocketmq/namesrv/kvConfig.json</code> 更规范</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>configStorePath</strong></td>\n<td style=\"text-align:left\">/root/namesrv/namesrv.properties</td>\n<td style=\"text-align:left\">NameServer 启动配置文件路径</td>\n<td style=\"text-align:left\">✅ 放在非 root 路径下 <code>/etc/rocketmq/namesrv.properties</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>productEnvName</strong></td>\n<td style=\"text-align:left\">center</td>\n<td style=\"text-align:left\">产品环境名称标识</td>\n<td style=\"text-align:left\">可用于区分环境（dev/test/prod）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clusterTest</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用集群测试模式</td>\n<td style=\"text-align:left\">默认 false，生产勿启用</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>orderMessageEnable</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否开启顺序消息功能</td>\n<td style=\"text-align:left\">NameServer 一般无需开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>returnOrderTopicConfigToBroker</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否返回顺序消息主题配置给 broker</td>\n<td style=\"text-align:left\">保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientRequestThreadPoolNums</strong></td>\n<td style=\"text-align:left\">8</td>\n<td style=\"text-align:left\">客户端请求线程数</td>\n<td style=\"text-align:left\">✅ 若 NameServer 负载高可增至 16~32</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>defaultThreadPoolNums</strong></td>\n<td style=\"text-align:left\">16</td>\n<td style=\"text-align:left\">默认线程池线程数</td>\n<td style=\"text-align:left\">视 CPU 核心数调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientRequestThreadPoolQueueCapacity</strong></td>\n<td style=\"text-align:left\">50000</td>\n<td style=\"text-align:left\">客户端请求队列长度</td>\n<td style=\"text-align:left\">✅ 高并发环境可调高至 100000</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>defaultThreadPoolQueueCapacity</strong></td>\n<td style=\"text-align:left\">10000</td>\n<td style=\"text-align:left\">默认任务队列长度</td>\n<td style=\"text-align:left\">适度提高防止拒绝任务</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>scanNotActiveBrokerInterval</strong></td>\n<td style=\"text-align:left\">5000</td>\n<td style=\"text-align:left\">扫描失效 Broker 的间隔（ms）</td>\n<td style=\"text-align:left\">默认 5s，可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>unRegisterBrokerQueueCapacity</strong></td>\n<td style=\"text-align:left\">3000</td>\n<td style=\"text-align:left\">Broker 注销队列容量</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>supportActingMaster</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否支持 ActingMaster 功能</td>\n<td style=\"text-align:left\">✅ 若启用 controller 建议设为 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>enableAllTopicList</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否启用所有主题列表接口</td>\n<td style=\"text-align:left\">可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>enableTopicList</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否允许主题列表查询</td>\n<td style=\"text-align:left\">可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>notifyMinBrokerIdChanged</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否通知最小 brokerId 变化</td>\n<td style=\"text-align:left\">一般无需开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>enableControllerInNamesrv</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否在 NameServer 中启用 Controller 模块</td>\n<td style=\"text-align:left\">✅ 若部署简化集群可考虑 true（测试环境）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>needWaitForService</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否等待服务就绪再启动</td>\n<td style=\"text-align:left\">可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>waitSecondsForService</strong></td>\n<td style=\"text-align:left\">45</td>\n<td style=\"text-align:left\">启动等待时间</td>\n<td style=\"text-align:left\">可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>deleteTopicWithBrokerRegistration</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">注册时是否删除 topic</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>configBlackList</strong></td>\n<td style=\"text-align:left\">configBlackList;configStorePath;kvConfigPath</td>\n<td style=\"text-align:left\">黑名单配置项</td>\n<td style=\"text-align:left\">保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>bindAddress</strong></td>\n<td style=\"text-align:left\">0.0.0.0</td>\n<td style=\"text-align:left\">绑定的监听地址</td>\n<td style=\"text-align:left\">✅ 生产环境建议绑定内网 IP</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>listenPort</strong></td>\n<td style=\"text-align:left\">9876</td>\n<td style=\"text-align:left\">NameServer 监听端口</td>\n<td style=\"text-align:left\">✅ 可通过防火墙限制外部访问</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverWorkerThreads</strong></td>\n<td style=\"text-align:left\">8</td>\n<td style=\"text-align:left\">服务端业务处理线程数</td>\n<td style=\"text-align:left\">可根据负载调整</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverCallbackExecutorThreads</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">回调执行线程数</td>\n<td style=\"text-align:left\">0 表示自动设置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverSelectorThreads</strong></td>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">Selector 线程数</td>\n<td style=\"text-align:left\">一般 2~4 即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverOnewaySemaphoreValue</strong></td>\n<td style=\"text-align:left\">256</td>\n<td style=\"text-align:left\">单向请求并发限制</td>\n<td style=\"text-align:left\">可保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverAsyncSemaphoreValue</strong></td>\n<td style=\"text-align:left\">64</td>\n<td style=\"text-align:left\">异步请求并发限制</td>\n<td style=\"text-align:left\">可保持或略增</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverChannelMaxIdleTimeSeconds</strong></td>\n<td style=\"text-align:left\">120</td>\n<td style=\"text-align:left\">连接空闲关闭时间</td>\n<td style=\"text-align:left\">可调大到 300 提高容错</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverSocketSndBufSize</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">TCP 发送缓冲区大小</td>\n<td style=\"text-align:left\">0 表示使用系统默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverSocketRcvBufSize</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">TCP 接收缓冲区大小</td>\n<td style=\"text-align:left\">建议 131072（128KB）以上</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>writeBufferHighWaterMark</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">写缓冲高水位标记</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>writeBufferLowWaterMark</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">写缓冲低水位标记</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverSocketBacklog</strong></td>\n<td style=\"text-align:left\">1024</td>\n<td style=\"text-align:left\">TCP 连接等待队列</td>\n<td style=\"text-align:left\">✅ 高并发场景可调大至 2048</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverNettyWorkerGroupEnable</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否启用 Netty worker 线程组</td>\n<td style=\"text-align:left\">默认 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>serverPooledByteBufAllocatorEnable</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否启用 Netty 池化内存</td>\n<td style=\"text-align:left\">建议保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>enableShutdownGracefully</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否优雅关闭</td>\n<td style=\"text-align:left\">✅ 建议设为 true</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>shutdownWaitTimeSeconds</strong></td>\n<td style=\"text-align:left\">30</td>\n<td style=\"text-align:left\">优雅关闭等待时间</td>\n<td style=\"text-align:left\">建议 30~60</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>useEpollNativeSelector</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 Linux Epoll</td>\n<td style=\"text-align:left\">✅ Linux 环境建议设为 true 提高性能</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientWorkerThreads</strong></td>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">客户端 worker 线程数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientCallbackExecutorThreads</strong></td>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">客户端回调线程数</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientOnewaySemaphoreValue</strong></td>\n<td style=\"text-align:left\">65535</td>\n<td style=\"text-align:left\">客户端单向请求并发限制</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientAsyncSemaphoreValue</strong></td>\n<td style=\"text-align:left\">65535</td>\n<td style=\"text-align:left\">客户端异步请求并发限制</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>connectTimeoutMillis</strong></td>\n<td style=\"text-align:left\">3000</td>\n<td style=\"text-align:left\">连接超时（ms）</td>\n<td style=\"text-align:left\">✅ 可提高至 5000 增加容错</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>channelNotActiveInterval</strong></td>\n<td style=\"text-align:left\">60000</td>\n<td style=\"text-align:left\">检查通道非活动间隔</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>isScanAvailableNameSrv</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否扫描可用 NameServer</td>\n<td style=\"text-align:left\">保持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientChannelMaxIdleTimeSeconds</strong></td>\n<td style=\"text-align:left\">120</td>\n<td style=\"text-align:left\">客户端空闲连接超时</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientSocketSndBufSize</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">客户端 TCP 发送缓冲区</td>\n<td style=\"text-align:left\">建议 131072</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientSocketRcvBufSize</strong></td>\n<td style=\"text-align:left\">0</td>\n<td style=\"text-align:left\">客户端 TCP 接收缓冲区</td>\n<td style=\"text-align:left\">建议 131072</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientPooledByteBufAllocatorEnable</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">客户端是否启用池化</td>\n<td style=\"text-align:left\">✅ 建议设为 true 提高性能</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>clientCloseSocketIfTimeout</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">超时是否关闭 socket</td>\n<td style=\"text-align:left\">保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>useTLS</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否启用 TLS 通信</td>\n<td style=\"text-align:left\">✅ 若公网部署强烈建议开启</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>socksProxyConfig</strong></td>\n<td style=\"text-align:left\">{}</td>\n<td style=\"text-align:left\">SOCKS 代理配置</td>\n<td style=\"text-align:left\">内网部署无需设置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>disableCallbackExecutor</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否禁用回调执行器</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>disableNettyWorkerGroup</strong></td>\n<td style=\"text-align:left\">false</td>\n<td style=\"text-align:left\">是否禁用 Netty worker group</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>maxReconnectIntervalTimeSeconds</strong></td>\n<td style=\"text-align:left\">60</td>\n<td style=\"text-align:left\">最大重连间隔</td>\n<td style=\"text-align:left\">默认即可</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>enableReconnectForGoAway</strong></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">是否启用 goaway 自动重连</td>\n<td style=\"text-align:left\">保持 true 增强健壮性</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>推荐重点优化的关键项</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">类别</th>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">推荐值</th>\n<th style=\"text-align:left\">原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">性能</td>\n<td style=\"text-align:left\"><code>useEpollNativeSelector</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">Linux 性能显著提升</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">安全</td>\n<td style=\"text-align:left\"><code>bindAddress</code></td>\n<td style=\"text-align:left\">内网 IP</td>\n<td style=\"text-align:left\">防止暴露公网</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">安全</td>\n<td style=\"text-align:left\"><code>useTLS</code></td>\n<td style=\"text-align:left\">true（公网）</td>\n<td style=\"text-align:left\">启用加密传输</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">健壮性</td>\n<td style=\"text-align:left\"><code>enableShutdownGracefully</code></td>\n<td style=\"text-align:left\">true</td>\n<td style=\"text-align:left\">防止强制关闭导致状态不一致</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">负载</td>\n<td style=\"text-align:left\"><code>clientRequestThreadPoolNums</code></td>\n<td style=\"text-align:left\">16~32</td>\n<td style=\"text-align:left\">提高并发能力</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">网络</td>\n<td style=\"text-align:left\"><code>serverSocketBacklog</code></td>\n<td style=\"text-align:left\">2048</td>\n<td style=\"text-align:left\">减少连接拒绝</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">缓冲</td>\n<td style=\"text-align:left\"><code>serverSocketSndBufSize</code> / <code>RcvBufSize</code></td>\n<td style=\"text-align:left\">131072</td>\n<td style=\"text-align:left\">提高网络吞吐</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">文件路径</td>\n<td style=\"text-align:left\"><code>kvConfigPath</code> / <code>configStorePath</code></td>\n<td style=\"text-align:left\">非 root 路径</td>\n<td style=\"text-align:left\">避免权限问题</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 RocketMQ NameServer 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 查看 NameServer 配置项 1234# 查看默认配置项sh bin/mqnamesrv -p# 查看加载了指定配置文件后的配置项，即配置文件中的配置项会覆盖默认配置项sh bin/mqnamesrv -p -c conf/namesvr.conf 配置项项目源码简介 在源码 rocketmq-all-5.3.2-source-release/namesrv 的启动类 org.apache.rocketmq.namesrv.NamesrvStartup中 可以看到其启动时会初始化如下配置项的类 1234private static NamesrvConfig namesrvConfig = null;private static NettyServerConfig nettyServerConfig = null;private static NettyClientConfig nettyClientConfig = null;private static ControllerConfig controllerConfig = null; 配置项说明 NameServer 配置项说明与建议 参数名 默认值 参数说明 优化 / 建议 rocketmqHome /usr/local/soft/rocketmq/rocketmq5 RocketMQ 安装目录 不建议修改 kvConfigPath /root/namesrv/kvConfig.json KV 配置存储路径 ✅ 改为 /data/rocketmq/namesrv/kvConfig.json 更规范 configStorePath /root/namesrv/namesrv.properties NameServer 启动配置文件路径 ✅ 放在非 root 路径下 /etc/rocketmq/namesrv.properties productEnvName center 产品环境名称标识 可用于区分环境（dev/test/prod） clusterTest false 是否启用集群测试模式 默认 false，生产勿启用 orderMessageEnable false 是否开启顺序消息功能 NameServer 一般无需开启 returnOrderTopicConfigToBroker true 是否返回顺序消息主题配置给 broker 保持默认 clientRequestThreadPoolNums 8 客户端请求线程数 ✅ 若 NameServer 负载高可增至 16~32 defaultThreadPoolNums 16 默认线程池线程数 视 CPU 核心数调整 clientRequestThreadPoolQueueCapacity 50000 客户端请求队列长度 ✅ 高并发环境可调高至 100000 defaultThreadPoolQueueCapacity 10000 默认任务队列长度 适度提高防止拒绝任务 scanNotActiveBrokerInterval 5000 扫描失效 Broker 的间隔（ms） 默认 5s，可保持 unRegisterBrokerQueueCapacity 3000 Broker 注销队列容量 默认即可 supportActingMaster false 是否支持 ActingMaster 功能 ✅ 若启用 controller 建议设为 true enableAllTopicList true 是否启用所有主题列表接口 可保持 enableTopicList true 是否允许主题列表查询 可保持 notifyMinBrokerIdChanged false 是否通知最小 brokerId 变化 一般无需开启 enableControllerInNamesrv false 是否在 NameServer 中启用 Controller 模块 ✅ 若部署简化集群可考虑 true（测试环境） needWaitForService false 是否等待服务就绪再启动 可保持 waitSecondsForService 45 启动等待时间 可保持 deleteTopicWithBrokerRegistration false 注册时是否删除 topic 默认即可 configBlackList configBlackList;configStorePath;kvConfigPath 黑名单配置项 保持默认 bindAddress 0.0.0.0 绑定的监听地址 ✅ 生产环境建议绑定内网 IP listenPort 9876 NameServer 监听端口 ✅ 可通过防火墙限制外部访问 serverWorkerThreads 8 服务端业务处理线程数 可根据负载调整 serverCallbackExecutorThreads 0 回调执行线程数 0 表示自动设置 serverSelectorThreads 3 Selector 线程数 一般 2~4 即可 serverOnewaySemaphoreValue 256 单向请求并发限制 可保持 serverAsyncSemaphoreValue 64 异步请求并发限制 可保持或略增 serverChannelMaxIdleTimeSeconds 120 连接空闲关闭时间 可调大到 300 提高容错 serverSocketSndBufSize 0 TCP 发送缓冲区大小 0 表示使用系统默认 serverSocketRcvBufSize 0 TCP 接收缓冲区大小 建议 131072（128KB）以上 writeBufferHighWaterMark 0 写缓冲高水位标记 默认即可 writeBufferLowWaterMark 0 写缓冲低水位标记 默认即可 serverSocketBacklog 1024 TCP 连接等待队列 ✅ 高并发场景可调大至 2048 serverNettyWorkerGroupEnable true 是否启用 Netty worker 线程组 默认 true serverPooledByteBufAllocatorEnable true 是否启用 Netty 池化内存 建议保持 enableShutdownGracefully false 是否优雅关闭 ✅ 建议设为 true shutdownWaitTimeSeconds 30 优雅关闭等待时间 建议 30~60 useEpollNativeSelector false 是否启用 Linux Epoll ✅ Linux 环境建议设为 true 提高性能 clientWorkerThreads 4 客户端 worker 线程数 默认即可 clientCallbackExecutorThreads 2 客户端回调线程数 默认即可 clientOnewaySemaphoreValue 65535 客户端单向请求并发限制 默认即可 clientAsyncSemaphoreValue 65535 客户端异步请求并发限制 默认即可 connectTimeoutMillis 3000 连接超时（ms） ✅ 可提高至 5000 增加容错 channelNotActiveInterval 60000 检查通道非活动间隔 默认即可 isScanAvailableNameSrv true 是否扫描可用 NameServer 保持 clientChannelMaxIdleTimeSeconds 120 客户端空闲连接超时 默认即可 clientSocketSndBufSize 0 客户端 TCP 发送缓冲区 建议 131072 clientSocketRcvBufSize 0 客户端 TCP 接收缓冲区 建议 131072 clientPooledByteBufAllocatorEnable false 客户端是否启用池化 ✅ 建议设为 true 提高性能 clientCloseSocketIfTimeout true 超时是否关闭 socket 保持默认 useTLS false 是否启用 TLS 通信 ✅ 若公网部署强烈建议开启 socksProxyConfig {} SOCKS 代理配置 内网部署无需设置 disableCallbackExecutor false 是否禁用回调执行器 默认即可 disableNettyWorkerGroup false 是否禁用 Netty worker group 默认即可 maxReconnectIntervalTimeSeconds 60 最大重连间隔 默认即可 enableReconnectForGoAway true 是否启用 goaway 自动重连 保持 true 增强健壮性 推荐重点优化的关键项 类别 参数 推荐值 原因 性能 useEpollNativeSelector true Linux 性能显著提升 安全 bindAddress 内网 IP 防止暴露公网 安全 useTLS true（公网） 启用加密传输 健壮性 enableShutdownGracefully true 防止强制关闭导致状态不一致 负载 clientRequestThreadPoolNums 16~32 提高并发能力 网络 serverSocketBacklog 2048 减少连接拒绝 缓冲 serverSocketSndBufSize / RcvBufSize 131072 提高网络吞吐 文件路径 kvConfigPath / configStorePath 非 root 路径 避免权限问题","summary":"摘要 本文介绍 RocketMQ NameServer 的配置项。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-28T13:30:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/","url":"https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/","title":"RocketMQ Dashboard 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RocketMQ-Dashboard-简介\">RocketMQ Dashboard 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/04Dashboard\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>RocketMQ Dashboard 是 RocketMQ 的管控利器，为用户提供客户端和应用程序的各种事件、性能的统计信息，支持以可视化工具代替 Topic 配置、Broker 管理等命令行操作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>功能概览</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>面板</th>\n<th>功能说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>运维</strong></td>\n<td>修改 <strong>NameServer 地址</strong>；选择 <strong>VIPChannel</strong> 等运维配置。</td>\n</tr>\n<tr>\n<td><strong>驾驶舱</strong></td>\n<td>查看 <strong>Broker、Topic 消息量</strong> 等运行总览信息。</td>\n</tr>\n<tr>\n<td><strong>集群</strong></td>\n<td>查看 <strong>集群分布</strong>、Broker 配置、运行状态及详细信息。</td>\n</tr>\n<tr>\n<td><strong>主题（Topic）</strong></td>\n<td>搜索、筛选、删除、更新/新增主题；查看 <strong>消息路由</strong>；执行 <strong>发送消息</strong>、<strong>重置消费位点</strong> 等操作。</td>\n</tr>\n<tr>\n<td><strong>消费者（Consumer）</strong></td>\n<td>搜索、删除、新增/更新消费者组；查看 <strong>终端信息、消费详情、配置项</strong>。</td>\n</tr>\n<tr>\n<td><strong>消息（Message）</strong></td>\n<td>查看 <strong>消息记录、死信消息、消息轨迹</strong> 等消息级详情。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>系统要求 与 网络配置</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>项目</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>系统要求</strong></td>\n<td>操作系统</td>\n<td>Linux / Unix / macOS</td>\n</tr>\n<tr>\n<td></td>\n<td>JDK</td>\n<td>64 位 JDK, 1.x 版本需要<strong>1.8+</strong>，2.x版本需要 <strong>17+</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>构建工具</td>\n<td><strong>Maven 3.2.x</strong> 或更高版本</td>\n</tr>\n<tr>\n<td></td>\n<td>启动项</td>\n<td>启动 <strong>RocketMQ</strong>（包括 NameServer 与 Broker）</td>\n</tr>\n<tr>\n<td><strong>网络配置</strong></td>\n<td>网络访问</td>\n<td>云服务器需可远程访问，或本地虚拟机需可 <strong>PING 通外网</strong></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RocketMQ-Dashboard-的安装\">RocketMQ Dashboard 的安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>部署 RocketMQ Dashboard 2.x，需要安装 JDK17</p>\n</li>\n<li class=\"lvl-2\">\n<p>源码安装，<a href=\"https://github.com/apache/rocketmq-dashboard\">源码下载</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载源码</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq</span><br><span class=\"line\">wget https://github.com/apache/rocketmq-dashboard/archive/refs/tags/rocketmq-dashboard-2.1.0.tar.gz</span><br><span class=\"line\">tar -zxvf rocketmq-dashboard-2.1.0.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s rocketmq-dashboard-rocketmq-dashboard-2.1.0 rocketmq-dashboard</span><br><span class=\"line\"><span class=\"built_in\">cd</span> rocketmq-dashboard</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>bug 修复，当前<code>2.1.0</code>版本存在bug，只能通过<code>http://localhost:8082</code>访问，如果需要ip或域名访问，则需要修改源码</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> frontend-new/src/api/remoteApi</span><br><span class=\"line\">sed -i <span class=\"string\">&#x27;s|apiBaseUrl: &#x27;</span>\\&#x27;<span class=\"string\">&#x27;http://localhost:8082&#x27;</span>\\&#x27;<span class=\"string\">&#x27;|apiBaseUrl: process.env.REACT_APP_API_BASE_URL \\|\\| window.location.origin|&#x27;</span> remoteApi.js.bck</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 替换前：</span></span><br><span class=\"line\">const appConfig = &#123;</span><br><span class=\"line\">    apiBaseUrl: <span class=\"string\">&#x27;http://localhost:8082&#x27;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"comment\"># 替换后：</span></span><br><span class=\"line\">const appConfig = &#123;</span><br><span class=\"line\">    apiBaseUrl: process.env.REACT_APP_API_BASE_URL || window.location.origin</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>环境</th>\n<th>环境变量值</th>\n<th>结果 (<code>appConfig.apiBaseUrl</code>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>开发环境</td>\n<td><code>REACT_APP_API_BASE_URL=http://localhost:8080</code></td>\n<td><code>http://localhost:8080</code></td>\n</tr>\n<tr>\n<td>测试环境</td>\n<td><code>REACT_APP_API_BASE_URL=https://api.test.example.com</code></td>\n<td><code>https://api.test.example.com</code></td>\n</tr>\n<tr>\n<td>未设置变量</td>\n<td><em>(无该环境变量)</em> 则使用默认的 <code>window.location.origin</code>，其表示 当前网页的 协议 + 域名 + 端口号</td>\n<td>自动使用当前网站地址，如 <code>https://myapp.example.com</code></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>目前<code>2.1.0</code>版本的bug还比较多，GitHub仓库中的代码已经修复了包括该bug在内的部分bug，不过还没有发布到 release。<br>\n着急的小伙伴可以通过 <code>git clone</code> 项目，编译并运行，或者等待作者发布新版本。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/apache/rocketmq-dashboard.git</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编译</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq/rocketmq-dashboard</span><br><span class=\"line\"><span class=\"comment\"># 编译</span></span><br><span class=\"line\">JAVA_HOME=/usr/local/jdk/jdk17 mvn clean package -Dmaven.test.skip=<span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># 将jar包复制到run目录下，以避免重新编译时被覆盖</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> run</span><br><span class=\"line\"><span class=\"built_in\">cp</span> target/rocketmq-dashboard-2.1.0.jar run/</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>按需替换配置，</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># vim run/application.yaml # 按需替换配置</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">rocketmq:</span></span><br><span class=\"line\">  <span class=\"attr\">config:</span></span><br><span class=\"line\">    <span class=\"attr\">namesrvAddrs:</span>                <span class=\"comment\"># 填写NameServer地址列表</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.175</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.188</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.131</span><span class=\"string\">:9876</span></span><br><span class=\"line\">    <span class=\"attr\">dataPath:</span> <span class=\"string\">/usr/local/soft/rocketmq/data/dashboard</span> <span class=\"comment\"># Dashboard文件目录，登录用户配置文件所在目录</span></span><br><span class=\"line\">    <span class=\"attr\">loginRequired:</span> <span class=\"literal\">true</span>  <span class=\"comment\"># 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件</span></span><br><span class=\"line\">    <span class=\"comment\"># 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey</span></span><br><span class=\"line\"><span class=\"comment\">#    accessKey: mqadmin</span></span><br><span class=\"line\"><span class=\"comment\">#    secretKey: 1234567</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>users.properties</code> 文件格式如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 该文件支持热修改，即添加和修改用户时，不需要重新启动console</span></span><br><span class=\"line\"><span class=\"comment\"># 格式， 每行定义一个用户， username=password[,N]  #N是可选项，可以为0 (普通用户)； 1 （管理员）</span></span><br><span class=\"line\"><span class=\"comment\"># 定义管理员，管理员拥有全部权限</span></span><br><span class=\"line\">super=passwd,1</span><br><span class=\"line\"><span class=\"comment\"># 定义普通用户，普通用户的权限需要在 dataPath 下的 role-permission.yml 文件中定义，如果该目录下不存在此文件，则默认使用resources/role-permission.yml文件</span></span><br><span class=\"line\">user1=passwd</span><br><span class=\"line\">user2=passwd</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>role-permission.yml</code> 文件格式如下：</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 该文件支持热修改，即添加和修改用户时，不需要重新启动console</span></span><br><span class=\"line\"><span class=\"comment\"># 格式，如果增加和删除接口权限，直接在列表中增加和删除接口地址即可。</span></span><br><span class=\"line\"><span class=\"comment\"># 接口路径配置支持通配符</span></span><br><span class=\"line\"><span class=\"comment\"># * 表示匹配0或多个不是/的字符</span></span><br><span class=\"line\"><span class=\"comment\"># ** 表示匹配0或多个任意字符</span></span><br><span class=\"line\"><span class=\"comment\"># ? 表示匹配1个任意字符</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">rolePerms:</span></span><br><span class=\"line\">  <span class=\"comment\"># 普通用户，以下权限为默认权限，基本上就只是查询的权限</span></span><br><span class=\"line\">  <span class=\"attr\">Normal:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/rocketmq/nsaddr</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/ops/*</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/dashboard/**</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/topic/*.query</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/topic/sendTopicMessage.do</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/producer/*.query</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/message/*</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/messageTrace/*</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">/monitor/*</span></span><br><span class=\"line\">    <span class=\"string\">....</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> run</span><br><span class=\"line\"><span class=\"comment\"># 启动，默认会加载与jar包同级目录下的application.yaml文件</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> /usr/local/jdk/jdk17/bin/java -jar rocketmq-dashboard-2.1.0.jar 1&gt;dashboard.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看日志</span></span><br><span class=\"line\"><span class=\"built_in\">tail</span> -f dashboard.log</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/9F26eh.png\" alt=\"\" width=\"1400\" height=\"800\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/apache/rocketmq-dashboard/blob/master/docs/1_0_0/UserGuide_CN.md\">Dashboard 使用手册</a></p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ Dashboard 简介 官方文档 RocketMQ Dashboard 是 RocketMQ 的管控利器，为用户提供客户端和应用程序的各种事件、性能的统计信息，支持以可视化工具代替 Topic 配置、Broker 管理等命令行操作。 功能概览 面板 功能说明 运维 修改 NameServer 地址；选择 VIPChannel 等运维配置。 驾驶舱 查看 Broker、Topic 消息量 等运行总览信息。 集群 查看 集群分布、Broker 配置、运行状态及详细信息。 主题（Topic） 搜索、筛选、删除、更新/新增主题；查看 消息路由；执行 发送消息、重置消费位点 等操作。 消费者（Consumer） 搜索、删除、新增/更新消费者组；查看 终端信息、消费详情、配置项。 消息（Message） 查看 消息记录、死信消息、消息轨迹 等消息级详情。 系统要求 与 网络配置 类别 项目 说明 系统要求 操作系统 Linux / Unix / macOS JDK 64 位 JDK, 1.x 版本需要1.8+，2.x版本需要 17+ 构建工具 Maven 3.2.x 或更高版本 启动项 启动 RocketMQ（包括 NameServer 与 Broker） 网络配置 网络访问 云服务器需可远程访问，或本地虚拟机需可 PING 通外网 RocketMQ Dashboard 的安装 部署 RocketMQ Dashboard 2.x，需要安装 JDK17 源码安装，源码下载 123456# 下载源码cd /usr/local/soft/rocketmqwget https://github.com/apache/rocketmq-dashboard/archive/refs/tags/rocketmq-dashboard-2.1.0.tar.gztar -zxvf rocketmq-dashboard-2.1.0.tar.gzln -s rocketmq-dashboard-rocketmq-dashboard-2.1.0 rocketmq-dashboardcd rocketmq-dashboard bug 修复，当前2.1.0版本存在bug，只能通过http://localhost:8082访问，如果需要ip或域名访问，则需要修改源码 1234567891011cd frontend-new/src/api/remoteApised -i &#x27;s|apiBaseUrl: &#x27;\\&#x27;&#x27;http://localhost:8082&#x27;\\&#x27;&#x27;|apiBaseUrl: process.env.REACT_APP_API_BASE_URL \\|\\| window.location.origin|&#x27; remoteApi.js.bck# 替换前：const appConfig = &#123; apiBaseUrl: &#x27;http://localhost:8082&#x27;&#125;;# 替换后：const appConfig = &#123; apiBaseUrl: process.env.REACT_APP_API_BASE_URL || window.location.origin&#125;; 环境 环境变量值 结果 (appConfig.apiBaseUrl) 开发环境 REACT_APP_API_BASE_URL=http://localhost:8080 http://localhost:8080 测试环境 REACT_APP_API_BASE_URL=https://api.test.example.com https://api.test.example.com 未设置变量 (无该环境变量) 则使用默认的 window.location.origin，其表示 当前网页的 协议 + 域名 + 端口号 自动使用当前网站地址，如 https://myapp.example.com 目前2.1.0版本的bug还比较多，GitHub仓库中的代码已经修复了包括该bug在内的部分bug，不过还没有发布到 release。 着急的小伙伴可以通过 git clone 项目，编译并运行，或者等待作者发布新版本。 1git clone https://github.com/apache/rocketmq-dashboard.git 编译 123456cd /usr/local/soft/rocketmq/rocketmq-dashboard# 编译JAVA_HOME=/usr/local/jdk/jdk17 mvn clean package -Dmaven.test.skip=true# 将jar包复制到run目录下，以避免重新编译时被覆盖mkdir runcp target/rocketmq-dashboard-2.1.0.jar run/ 按需替换配置， 12345678910111213# vim run/application.yaml # 按需替换配置rocketmq: config: namesrvAddrs: # 填写NameServer地址列表 - 10.250.0.175:9876 - 10.250.0.188:9876 - 10.250.0.131:9876 dataPath: /usr/local/soft/rocketmq/data/dashboard # Dashboard文件目录，登录用户配置文件所在目录 loginRequired: true # 是否需要登录，此时需要在 dataPath 下创建 users.properties 文件，用于存放用户名和密码。如果该目录下不存在此文件，则默认使用resources/users.properties文件 # 如果 broker 开启了 ACL，则需要配置 accessKey 和 secretKey# accessKey: mqadmin# secretKey: 1234567 users.properties 文件格式如下： 1234567# 该文件支持热修改，即添加和修改用户时，不需要重新启动console# 格式， 每行定义一个用户， username=password[,N] #N是可选项，可以为0 (普通用户)； 1 （管理员）# 定义管理员，管理员拥有全部权限super=passwd,1# 定义普通用户，普通用户的权限需要在 dataPath 下的 role-permission.yml 文件中定义，如果该目录下不存在此文件，则默认使用resources/role-permission.yml文件user1=passwduser2=passwd role-permission.yml 文件格式如下： 1234567891011121314151617181920# 该文件支持热修改，即添加和修改用户时，不需要重新启动console# 格式，如果增加和删除接口权限，直接在列表中增加和删除接口地址即可。# 接口路径配置支持通配符# * 表示匹配0或多个不是/的字符# ** 表示匹配0或多个任意字符# ? 表示匹配1个任意字符rolePerms: # 普通用户，以下权限为默认权限，基本上就只是查询的权限 Normal: - /rocketmq/nsaddr - /ops/* - /dashboard/** - /topic/*.query - /topic/sendTopicMessage.do - /producer/*.query - /message/* - /messageTrace/* - /monitor/* .... 启动 123456cd run# 启动，默认会加载与jar包同级目录下的application.yaml文件nohup /usr/local/jdk/jdk17/bin/java -jar rocketmq-dashboard-2.1.0.jar 1&gt;dashboard.log 2&gt;&amp;1 &amp;# 查看日志tail -f dashboard.log Dashboard 使用手册","summary":"摘要 本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-24T13:30:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/","url":"https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/","title":"RocketMQ 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RocketMQ 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Apache-RocketMQ-简介\">Apache RocketMQ 简介</h2>\n<h3 id=\"一、RocketMQ-是什么？\">一、RocketMQ 是什么？</h3>\n<p>RocketMQ 是一个<strong>分布式、队列模型的消息中间件</strong>。它由阿里巴巴在2012年开源，并于2017年正式成为 Apache 基金会的顶级项目。</p>\n<p>你可以把它想象成一个在分布式系统中负责可靠传递消息的“邮局”或“快递系统”。当系统A需要发送数据给系统B，但它们之间不直接通信时，就可以通过 RocketMQ 来中转，确保消息不丢失、不重复，并且能按顺序送达。</p>\n<p><strong>RocketMQ 是一个高性能、高可靠、高实时的分布式消息中间件</strong>。它就像分布式系统的“中枢神经系统”，负责在各个服务之间可靠、高效地传递数据，是现代互联网架构中不可或缺的基础组件之一。</p>\n<p><strong>RocketMQ 5.x 通过引入 Proxy 模式，极大地提升了架构的灵活性、多语言支持能力和云原生亲和力</strong>，是其在消息中间件领域持续演进的重要里程碑。</p>\n<p>它与 Kafka、RabbitMQ 等都是业界顶级的消息队列，但各有侧重。RocketMQ 在事务消息、顺序消息和对在线业务的稳定性支持方面表现尤为出色。</p>\n<hr>\n<h3 id=\"二、核心特点与优势\">二、核心特点与优势</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">序号</th>\n<th style=\"text-align:left\">特性</th>\n<th style=\"text-align:left\">典型场景</th>\n<th style=\"text-align:left\">主要作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>1</strong></td>\n<td style=\"text-align:left\"><strong>削峰填谷</strong></td>\n<td style=\"text-align:left\">电商秒杀、大促活动时大量下单请求瞬间涌入</td>\n<td style=\"text-align:left\">将突发请求先缓存为消息，后端系统按自身能力平稳消费，避免系统过载崩溃</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>2</strong></td>\n<td style=\"text-align:left\"><strong>异步解耦</strong></td>\n<td style=\"text-align:left\">用户注册后触发多系统任务（邮件、优惠券、积分）</td>\n<td style=\"text-align:left\">主流程只负责发送消息，其他系统独立异步处理，降低系统间耦合、提高扩展性</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>3</strong></td>\n<td style=\"text-align:left\"><strong>顺序消息</strong></td>\n<td style=\"text-align:left\">订单状态变更（创建 → 付款 → 发货 → 收货）</td>\n<td style=\"text-align:left\">同一业务键（如订单ID）的消息按顺序发送和消费，保证业务逻辑正确性</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>4</strong></td>\n<td style=\"text-align:left\"><strong>持久化与高可靠性</strong></td>\n<td style=\"text-align:left\">关键业务消息必须不丢失（交易、支付、日志）</td>\n<td style=\"text-align:left\">所有消息写入磁盘并支持主从复制，即使服务器重启也能恢复，保证高可用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>5</strong></td>\n<td style=\"text-align:left\"><strong>消息回溯</strong></td>\n<td style=\"text-align:left\">消费逻辑出错、数据重算、补偿任务</td>\n<td style=\"text-align:left\">支持重置消费位点，重新消费历史消息，实现业务补偿与追溯</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>6</strong></td>\n<td style=\"text-align:left\"><strong>海量消息堆积能力</strong></td>\n<td style=\"text-align:left\">大规模异步日志收集、IoT 数据汇聚、埋点分析</td>\n<td style=\"text-align:left\">支持万亿级消息堆积，性能稳定不衰减，适用于大规模数据场景</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3 id=\"三、核心架构与概念\">三、核心架构与概念</h3>\n<p>要理解 RocketMQ，需要知道几个关键角色：<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/frTwo1.png\" alt=\"\"></p>\n<h4 id=\"经典核心组件\">经典核心组件</h4>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">序号</th>\n<th style=\"text-align:left\">组件名称</th>\n<th style=\"text-align:left\">主要作用</th>\n<th style=\"text-align:left\">说明 / 特点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>1</strong></td>\n<td style=\"text-align:left\"><strong>Producer（生产者）</strong></td>\n<td style=\"text-align:left\">发送消息的客户端</td>\n<td style=\"text-align:left\">负责将业务系统的消息发送到指定的 <strong>Topic</strong>，支持同步、异步、单向三种发送方式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>2</strong></td>\n<td style=\"text-align:left\"><strong>Consumer（消费者）</strong></td>\n<td style=\"text-align:left\">接收并消费消息的客户端</td>\n<td style=\"text-align:left\">从 Broker 拉取消息并进行业务处理，可分为 <strong>Push</strong> 和 <strong>Pull</strong> 两种消费模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>3</strong></td>\n<td style=\"text-align:left\"><strong>Consumer Group（消费者组）</strong></td>\n<td style=\"text-align:left\">实现负载均衡与高可用消费</td>\n<td style=\"text-align:left\">多个消费者订阅同一 Topic 时组成消费者组，一个分区只会被组内一个消费者消费</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>4</strong></td>\n<td style=\"text-align:left\"><strong>Broker（消息服务器）</strong></td>\n<td style=\"text-align:left\">存储和转发消息</td>\n<td style=\"text-align:left\">RocketMQ 的核心组件，负责消息的持久化、转发、主从复制和高可用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>5</strong></td>\n<td style=\"text-align:left\"><strong>Topic（主题）</strong></td>\n<td style=\"text-align:left\">消息的分类与路由单元</td>\n<td style=\"text-align:left\">Producer 发送消息到指定 Topic，Consumer 订阅 Topic 消费消息；一个 Topic 可包含多个消息队列（分区）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>6</strong></td>\n<td style=\"text-align:left\"><strong>Name Server（名字服务）</strong></td>\n<td style=\"text-align:left\">管理 Broker 地址信息</td>\n<td style=\"text-align:left\">类似轻量级注册中心，维护 Broker 元数据，帮助 Producer 和 Consumer 定位消息存储位置</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>7</strong></td>\n<td style=\"text-align:left\"><strong>Controller（控制器）</strong></td>\n<td style=\"text-align:left\">主从自动切换与高可用控制</td>\n<td style=\"text-align:left\">RocketMQ 5.x 引入，基于 Raft（DLedger）协议实现 Broker 自动选主和元数据管理</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>8</strong></td>\n<td style=\"text-align:left\"><strong>Proxy（代理层）</strong></td>\n<td style=\"text-align:left\">客户端访问入口与协议转换</td>\n<td style=\"text-align:left\">RocketMQ 5.x 新组件，无状态，可横向扩展；统一接入层，支持多协议（如 HTTP、gRPC），隔离客户端与 Broker</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p><strong>引入 Proxy 模式的优势：</strong></p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">**架构解耦与语言无关**：Proxy 作为通用代理，将复杂的 Broker 协议封装成更简单的接口（如 gRPC），使得用不同编程语言（如 Go, Python, C++ 等）开发的客户端更容易接入，而无需实现复杂的原生协议。</span><br><span class=\"line\">**简化客户端**：客户端不再需要感知 Name Server 和 Broker 的地址变化，只需连接固定的 Proxy 地址即可，大大降低了客户端的复杂度。</span><br><span class=\"line\">**增强安全性**：可以在 Proxy 层统一实现安全认证、限流、审计等策略，作为Broker集群的安全屏障。</span><br><span class=\"line\">**云原生友好**：无状态的 Proxy 非常适合在 Kubernetes 等容器化环境中进行部署和弹性伸缩。</span><br></pre></td></tr></table></figure>\n<hr>\n<h2 id=\"消息中间件功能对比表（ActiveMQ-vs-Kafka-vs-RabbitMQ-vs-RocketMQ）\">消息中间件功能对比表（ActiveMQ vs Kafka vs RabbitMQ vs RocketMQ）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://support.huaweicloud.com/intl/zh-cn/productdesc-hrm/hrm_pd_012.html\">参考资料</a></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">功能项</th>\n<th style=\"text-align:left\">ActiveMQ</th>\n<th style=\"text-align:left\">Kafka</th>\n<th style=\"text-align:left\">RabbitMQ</th>\n<th style=\"text-align:left\">RocketMQ</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">客户端 SDK</td>\n<td style=\"text-align:left\">Java、.NET、C++ 等</td>\n<td style=\"text-align:left\">Java、Scala 等</td>\n<td style=\"text-align:left\">Java、.NET、Go、Python、C 等</td>\n<td style=\"text-align:left\">Java、C++、Go</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">通信协议与规范</td>\n<td style=\"text-align:left\">推送模型（Push），支持 OpenWire、STOMP、AMQP、MQTT、JMS</td>\n<td style=\"text-align:left\">拉取模型（Pull），支持 TCP</td>\n<td style=\"text-align:left\">推送模型（Push），支持 AMQP、MQTT、STOMP、HTTP、WebSocket</td>\n<td style=\"text-align:left\">拉取模型（Pull），支持 TCP、JMS、OpenMessaging</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息有序性</td>\n<td style=\"text-align:left\">通过独占消费者（Exclusive Consumer）或独占队列（Exclusive Queues）保证顺序</td>\n<td style=\"text-align:left\">保证分区内消息顺序</td>\n<td style=\"text-align:left\">单队列内消息天然有序</td>\n<td style=\"text-align:left\">严格顺序消息，可平滑扩展</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">定时/延迟消息</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">支持（使用延迟插件）</td>\n<td style=\"text-align:left\">支持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">批量消息</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">支持（异步生产者）</td>\n<td style=\"text-align:left\">支持（Publisher Confirms 模式下）</td>\n<td style=\"text-align:left\">支持（同步模式可避免消息丢失）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">广播消息</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">支持（Fanout 交换机）</td>\n<td style=\"text-align:left\">支持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息过滤</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">支持（可用 Kafka Streams 实现）</td>\n<td style=\"text-align:left\">支持（基于 Exchange 的路由键或 Header）</td>\n<td style=\"text-align:left\">支持（基于 SQL92 属性过滤）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">服务器端触发重投递</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">支持（Nack 或 TTL+DLX）</td>\n<td style=\"text-align:left\">支持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息存储</td>\n<td style=\"text-align:left\">支持高性能持久化（JDBC + LevelDB/KahaDB）</td>\n<td style=\"text-align:left\">高性能文件存储</td>\n<td style=\"text-align:left\">内存+磁盘混合存储（Mnesia/基于 Erlang 的日志）</td>\n<td style=\"text-align:left\">高性能、低延迟文件存储</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息回溯（历史消息查询）</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">支持（通过 offset）</td>\n<td style=\"text-align:left\">不支持（消息被消费后无法回溯）</td>\n<td style=\"text-align:left\">支持（时间戳与 offset）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息优先级</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">支持（优先级队列）</td>\n<td style=\"text-align:left\">不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">高可用与故障转移</td>\n<td style=\"text-align:left\">依赖存储，如 LevelDB 需 ZooKeeper</td>\n<td style=\"text-align:left\">需要 ZooKeeper</td>\n<td style=\"text-align:left\">支持镜像队列（Classic / Quorum 模式）</td>\n<td style=\"text-align:left\">支持主从模式（无需额外组件）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息轨迹（Message Track）</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">不支持</td>\n<td style=\"text-align:left\">不支持（可通过插件扩展）</td>\n<td style=\"text-align:left\">支持</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">配置复杂度</td>\n<td style=\"text-align:left\">默认配置较低，需手动优化</td>\n<td style=\"text-align:left\">配置为键值对，可文件或代码提供</td>\n<td style=\"text-align:left\">开箱即用，配置灵活但选项较多</td>\n<td style=\"text-align:left\">开箱即用，仅需关注少量配置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">管理与运维工具</td>\n<td style=\"text-align:left\">支持</td>\n<td style=\"text-align:left\">支持（命令行监控）</td>\n<td style=\"text-align:left\">支持（Web 管理控制台、CLI）</td>\n<td style=\"text-align:left\">支持（丰富的 Web 与命令行工具）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RocketMQ-的安装\">RocketMQ 的安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RocketMQ 5.x 依赖 JDK 1.8+。</p>\n</li>\n</ul>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/quickStart/01quickstart\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>下载RocketMQ</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> -p /usr/local/soft/rocketmq/</span><br><span class=\"line\">wget https://dist.apache.org/repos/dist/release/rocketmq/5.3.2/rocketmq-all-5.3.2-bin-release.zip</span><br><span class=\"line\">unzip rocketmq-all-5.3.2-bin-release.zip</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s rocketmq-all-5.3.2-bin-release rocketmq5</span><br><span class=\"line\"><span class=\"built_in\">cd</span> rocketmq5</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">默认脚本中，NameServer需要4G内存，Broker 需要8G内存，如果内存不够，可以进入bin目录，对其中的<code>runserver.sh</code>和<code>runbroker.sh</code>两个脚本进行一下修改</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用vi runserver.sh指令，编辑这个脚本，找到下面的一行配置，调整Java进程的内存大小。</span></span><br><span class=\"line\"><span class=\"comment\"># NameServer,Controller,Proxy 都使用这个脚本启动</span></span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms4g -Xmx4g -Xmn2G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class=\"line\">修改为：</span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms1g -Xmx1g -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 接下来，同样调整runbroker.sh中的内存大小。Broker 使用这个脚本启动</span></span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g&quot;</span></span><br><span class=\"line\">修改为：</span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms2g -Xmx2g&quot;</span></span><br></pre></td></tr></table></figure>\n</div>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 NameServer</p>\n</li>\n</ul>\n<blockquote>\n<p>安装完RocketMQ包后，我们启动NameServer</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 启动namesrv</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqnamesrv &amp;</span><br><span class=\"line\"><span class=\"comment\">## 指定配置文件</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqnamesrv -c namesrv.conf &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 验证namesrv是否启动成功</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -f ~/logs/rocketmqlogs/namesrv.log</span><br><span class=\"line\"><span class=\"comment\"># 我们可以在namesrv.log 中看到 &#x27;The Name Server boot success..&#x27;， 表示NameServer 已成功启动。</span></span><br><span class=\"line\">The Name Server boot success. serializeType=JSON, address 0.0.0.0:9876</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>namesrv.conf 示例</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The port of nameserver</span></span><br><span class=\"line\">listenPort = 9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Broker+Proxy</p>\n</li>\n</ul>\n<blockquote>\n<p>NameServer成功启动后，我们启动Broker和Proxy。这里我们使用 Local 模式部署，即 Broker 和 Proxy 同进程部署。5.x 版本也支持 Broker 和 Proxy 分离部署以实现更灵活的集群能力。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 先启动broker</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqbroker -n localhost:9876 --enable-proxy &amp;</span><br><span class=\"line\"><span class=\"comment\"># 指定配置文件， 默认就是 conf/broker.conf</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqbroker -n localhost:9876 -c conf/broker.conf --enable-proxy &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上面的启动方式与下面的启动方式效果一样</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqproxy -n localhost:9876 -pc /usr/local/soft/rocketmq/rocketmq5/conf/rmq-proxy.json -bc /usr/local/soft/rocketmq/rocketmq5/conf/broker.conf -pm <span class=\"built_in\">local</span> &amp;</span><br><span class=\"line\"><span class=\"comment\">## 参数说明</span></span><br><span class=\"line\"><span class=\"comment\"># -n, --namesrvAddr NameServer 的地址</span></span><br><span class=\"line\"><span class=\"comment\"># -pc, --proxyConfigPath Proxy 配置文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -bc, --brokerConfigPath Broker 配置文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -pm, --proxyMode Proxy 模式，local or cluster</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 验证broker是否启动成功, 比如, broker的ip是192.168.1.2 然后名字是broker-a</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -f ~/logs/rocketmqlogs/proxy.log</span><br><span class=\"line\"><span class=\"comment\"># 我们可以在 proxy.log 中看到“The broker[brokerName,ip:port] boot success..”，这表明 broker 已成功启动。</span></span><br><span class=\"line\">The broker[broker-a, 10.250.0.175:10911] boot success. serializeType=JSON and name server is localhost:9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关闭服务器</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 先停止 Broker</span></span><br><span class=\"line\">$ sh bin/mqshutdown broker</span><br><span class=\"line\"><span class=\"comment\"># 停止 NameServer</span></span><br><span class=\"line\">$ sh bin/mqshutdown namesrv</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装-多节点（集群）多副本模式-异步复制\">集群安装:多节点（集群）多副本模式-异步复制</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/01deploy\">官网文档</a> 对集群安装的方式介绍了多种，本文仅实战一种：<code>多节点（集群）多副本模式-异步复制</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>每个Master配置一个Slave，有多组 Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；</li>\n<li class=\"lvl-6\">缺点：Master宕机，磁盘损坏情况下会丢失少量消息。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>该模式下，Master 节点和 Slave 节点之间是异步复制的，Master 节点挂掉后，Slave 节点不会自动切换为 Master 节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>集群规划</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># NameServer 3 台</span></span><br><span class=\"line\">NameServer1 10.250.0.175</span><br><span class=\"line\">NameServer2 10.250.0.188</span><br><span class=\"line\">NameServer3 10.250.0.31</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broker 2 Master 2 Replicas</span></span><br><span class=\"line\">Broker1 10.250.0.188 broker-a,broker-b-s</span><br><span class=\"line\">Broker2 10.250.0.31  broker-b,broker-a-s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Proxy 3 台</span></span><br><span class=\"line\">Proxy1 10.250.0.175</span><br><span class=\"line\">Proxy2 10.250.0.188</span><br><span class=\"line\">Proxy3 10.250.0.31</span><br></pre></td></tr></table></figure>\n<h4 id=\"部署-NameServer\">部署 NameServer</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在三台服务器上分别启动RocketMQ NameServer</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq/rocketmq5</span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqnamesrv &amp;</span><br></pre></td></tr></table></figure>\n<h4 id=\"部署Broker\">部署Broker</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-a.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-a              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=0                       <span class=\"comment\"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class=\"line\">deleteWhen=04                    <span class=\"comment\"># 表示凌晨 4 点清理</span></span><br><span class=\"line\">fileReservedTime=48              <span class=\"comment\"># 表示保存 48 小时的数据</span></span><br><span class=\"line\">brokerRole=ASYNC_MASTER          <span class=\"comment\"># 角色，表示异步复制的主节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH        <span class=\"comment\"># 表示异步刷盘</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径，后面会介绍</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=10911</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-a-s.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-a              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=1                       <span class=\"comment\"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE                 <span class=\"comment\"># 角色，表示异步复制的从节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=11011</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-b.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-b              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=0                       <span class=\"comment\"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class=\"line\">deleteWhen=04                    <span class=\"comment\"># 表示凌晨 4 点清理</span></span><br><span class=\"line\">fileReservedTime=48              <span class=\"comment\"># 表示保存 48 小时的数据</span></span><br><span class=\"line\">brokerRole=ASYNC_MASTER          <span class=\"comment\"># 角色，表示异步复制的主节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH        <span class=\"comment\"># 表示异步刷盘</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=10911</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-b-s.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-b              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=1                       <span class=\"comment\"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE                 <span class=\"comment\"># 角色，表示异步复制的从节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=11011</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Broker1 10.250.0.188 上启动 broker-a 和 broker-b-s</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 broker-a</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a.properties &amp;</span><br><span class=\"line\"><span class=\"comment\"># 启动 broker-b-s</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b-s.properties &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## nohup.out 中的输出类似与下面这种就表示启动成功</span></span><br><span class=\"line\">The broker[broker-a, 10.250.0.31:11011] boot success. serializeType=JSON and name server is 10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Broker2 10.250.0.31 上启动 broker-b 和 broker-a-s</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 broker-b</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b.properties &amp;</span><br><span class=\"line\"><span class=\"comment\"># 启动 broker-a-s</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a-s.properties &amp;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动成功后，可以通过如下命令检查机器状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）</span></span><br><span class=\"line\">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class=\"line\"><span class=\"comment\">## 输出类似如下</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class=\"line\">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-a                1     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600         <span class=\"literal\">false</span></span><br><span class=\"line\">DefaultCluster          broker-b                0     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-b                1     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900         <span class=\"literal\">false</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"配置-Proxy\">配置 Proxy</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在三台服务器上分别启动RocketMQ NameServer</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqproxy -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 指定配置文件，这里要注意，集群的名称要与 conf/rmq-proxy.json 中配置的集群名称必须一致，默认是 DefaultCluster</span></span><br><span class=\"line\"><span class=\"comment\">## 默认的配置文件就是 conf/rmq-proxy.json，但如果通过 -pc 指定配置文件，则必须使用绝对路径</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqproxy -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -pc /usr/local/soft/rocketmq/rocketmq5/conf/rmq-proxy.json &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看日志，输出如下内容就表示启动成功，tail -f nohup.out</span></span><br><span class=\"line\">rocketmq-proxy startup successfully</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>rmq-proxy.json 示例</p>\n</blockquote>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;rocketMQClusterName&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;DefaultCluster&quot;</span><span class=\"punctuation\">,</span> # 集群名称</span><br><span class=\"line\">  <span class=\"attr\">&quot;remotingListenPort&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">8080</span><span class=\"punctuation\">,</span>              # 监听端口，默认 <span class=\"number\">8080</span></span><br><span class=\"line\">  <span class=\"attr\">&quot;grpcServerPort&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">8081</span>                   # grpc 监听端口，默认 <span class=\"number\">8081</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>停止Proxy</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停止 Proxy</span></span><br><span class=\"line\">sh bin/mqshutdown proxy</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装-主备自动切换模式部署\">集群安装:主备自动切换模式部署</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RocketMQ 5.x 提供了一种新的部署方式 <code>Controller</code>，可以在主从模式下实现主备自动切换，当主节点挂掉时，自动切换到从节点上运行。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/03autofailover\">官方文档:主备自动切换模式部署</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>Controller 组件提供选主能力，若需要保证 Controller 具备容错能力，Controller 部署需要三副本及以上（遵循 Raft 的多数派协议）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>本文在上文“集群安装:多节点（集群）多副本模式-异步复制”的基础上进行修改</p>\n</li>\n<li class=\"lvl-2\">\n<p>Controller 部署有两种方式。一种是嵌入于 NameServer 进行部署，另一种是独立部署，本文采用独立部署 Controller 组件的方式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>集群规划</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Controller 3 台</span></span><br><span class=\"line\">Controller1 10.250.0.175</span><br><span class=\"line\">Controller2 10.250.0.188</span><br><span class=\"line\">Controller3 10.250.0.31</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别在每台机器上创建<code>controller.conf</code>配置文件，内容如下(注意修改节点Id)</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># controller.conf</span></span><br><span class=\"line\"><span class=\"comment\"># ---------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\"># DLedger Raft Group 的名字，同一集群保持一致</span></span><br><span class=\"line\">controllerDLegerGroup = group1</span><br><span class=\"line\"><span class=\"comment\"># 集群中三个节点的成员定义，每个节点都必须一致</span></span><br><span class=\"line\">controllerDLegerPeers = n0-10.250.0.175:9877;n1-10.250.0.188:9877;n2-10.250.0.31:9877</span><br><span class=\"line\"><span class=\"comment\"># 节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一</span></span><br><span class=\"line\">controllerDLegerSelfId = n0</span><br><span class=\"line\"><span class=\"comment\"># Controller 数据存储路径（非常关键！不要删除）</span></span><br><span class=\"line\">controllerStorePath = /usr/local/soft/rocketmq/data/DledgerController</span><br><span class=\"line\"><span class=\"comment\"># 是否允许从 SyncStateSet 外选举 Master</span></span><br><span class=\"line\"><span class=\"comment\"># true 会加快选举但可能丢消息，建议生产保持 false</span></span><br><span class=\"line\">enableElectUncleanMaster = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 当 Broker 副本角色变化时是否主动通知（建议开启）</span></span><br><span class=\"line\">notifyBrokerRoleChanged = <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># 启动端口，端口不能与 NameServer、Broker、Proxy 端口冲突</span></span><br><span class=\"line\">listenPort = 9877</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别启动每台机器上的 Controller</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqcontroller -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/controller.conf &amp;</span><br><span class=\"line\"><span class=\"comment\">## 启动成功后，查看 nohup.out 文件，输出如下内容就表示启动成功</span></span><br><span class=\"line\">load config properties file OK, conf/controller.conf</span><br><span class=\"line\">The Controller Server boot success. serializeType=JSON</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改 broker 配置文件，以 <code>broker-a.properties</code> 为例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 去掉如下配置，Controller 模式下 会自动分配</span></span><br><span class=\"line\"><span class=\"comment\"># brokerId=1                       # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class=\"line\"><span class=\"comment\"># brokerRole=ASYNC_MASTER          # 角色，表示异步复制的主节点</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加如下配置</span></span><br><span class=\"line\"><span class=\"comment\"># 启用 Controller 模式（自动主从切换模式的总开关）</span></span><br><span class=\"line\">enableControllerMode = <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># Controller 集群地址列表（建议与 Controller 集群保持一致）</span></span><br><span class=\"line\">controllerAddr = 10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>RocketMQ 5 Broker Controller 模式配置参数表</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数名</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:center\">默认值</th>\n<th style=\"text-align:left\">备注 / 建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>enableControllerMode</strong></td>\n<td style=\"text-align:left\">是否启用 Controller 模式（自动主从切换总开关）</td>\n<td style=\"text-align:center\"><code>false</code></td>\n<td style=\"text-align:left\">必须设为 <code>true</code> 才能启用自动主从切换</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>controllerAddr</strong></td>\n<td style=\"text-align:left\">Controller 集群地址列表（以分号分隔）</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:left\">所有 Broker 配置应一致，例如 <code>10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>syncBrokerMetadataPeriod</strong></td>\n<td style=\"text-align:left\">向 Controller 同步 Broker 副本信息的时间间隔（毫秒）</td>\n<td style=\"text-align:center\"><code>5000</code> (5s)</td>\n<td style=\"text-align:left\">保持默认即可；用于上报心跳与元数据</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>checkSyncStateSetPeriod</strong></td>\n<td style=\"text-align:left\">检查同步状态集（SyncStateSet）的时间间隔（毫秒）</td>\n<td style=\"text-align:center\"><code>5000</code> (5s)</td>\n<td style=\"text-align:left\">Controller 会定期剔除落后副本</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>syncControllerMetadataPeriod</strong></td>\n<td style=\"text-align:left\">同步 Controller 元数据的时间间隔（毫秒）</td>\n<td style=\"text-align:center\"><code>10000</code> (10s)</td>\n<td style=\"text-align:left\">Broker 定期从集群获取当前活跃 Controller 地址</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>haMaxTimeSlaveNotCatchup</strong></td>\n<td style=\"text-align:left\">Slave 未跟上 Master 的最大时间间隔（毫秒）</td>\n<td style=\"text-align:center\"><code>15000</code> (15s)</td>\n<td style=\"text-align:left\">超过该时间将 Slave 移出 SyncStateSet</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storePathEpochFile</strong></td>\n<td style=\"text-align:left\">Epoch 文件存储路径</td>\n<td style=\"text-align:center\"><code>store/epochFile</code></td>\n<td style=\"text-align:left\">非常重要！不要删除；存储主从任期、epoch 等元信息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>allAckInSyncStateSet</strong></td>\n<td style=\"text-align:left\">是否要求所有同步副本都 ACK 后才返回成功</td>\n<td style=\"text-align:center\"><code>false</code></td>\n<td style=\"text-align:left\"><code>true</code> 可保证强一致但性能下降；建议保持默认</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>syncFromLastFile</strong></td>\n<td style=\"text-align:left\">Slave 是否从最后一个文件开始复制（空盘启动时）</td>\n<td style=\"text-align:center\"><code>false</code></td>\n<td style=\"text-align:left\">若历史日志很大且 Slave 新建，可设为 <code>true</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>asyncLearner</strong></td>\n<td style=\"text-align:left\">是否为异步 learner 副本（不参与选主）</td>\n<td style=\"text-align:center\"><code>false</code></td>\n<td style=\"text-align:left\">用于远程灾备副本，不会被选举为 Master</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>inSyncReplicas</strong></td>\n<td style=\"text-align:left\">需保持同步的副本组数量</td>\n<td style=\"text-align:center\"><code>1</code></td>\n<td style=\"text-align:left\">若 <code>allAckInSyncStateSet=true</code>，该参数无效</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>minInSyncReplicas</strong></td>\n<td style=\"text-align:left\">最小同步副本数量，低于该值则拒绝写入</td>\n<td style=\"text-align:center\"><code>1</code></td>\n<td style=\"text-align:left\">防止写入过多未同步副本导致数据丢失风险</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重新启动 Broker，为保证主从数据一致性在重启时不被破坏，启动顺序应为先重新原Master，再重启原Slave</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动成功后，可以通过如下命令检查机器状态，可以看到集群内部自动分配了主从</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）</span></span><br><span class=\"line\">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class=\"line\"><span class=\"comment\">## 输出类似如下</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class=\"line\">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.48     0.2900          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-a                2     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  2-0(0.0w, 0.0, 0.0)               0  489268.48     0.2700         <span class=\"literal\">false</span></span><br><span class=\"line\">DefaultCluster          broker-b                0     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.48     0.2700          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-b                2     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489268.48     0.2900         <span class=\"literal\">false</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>验证主备自动切换，此时关闭 <code>broker-b</code> 的 Master，并查看集群状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class=\"line\"><span class=\"comment\">## 输出类似如下，可以看到`broker-b`原来的 Slave 被切换为 Master</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class=\"line\">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.58     0.2900          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-a                2     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  1-0(0.0w, 0.0, 0.0)               0  489268.58     0.2700         <span class=\"literal\">false</span></span><br><span class=\"line\">DefaultCluster          broker-b                0     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489268.58     0.2900          <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重新启动刚才关闭的 <code>broker-b</code> ，节点会自动加入集群，角色为 Slave</p>\n</li>\n<li class=\"lvl-2\">\n<p>停止 Controller</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停止 PrControlleroxy</span></span><br><span class=\"line\">sh bin/mqshutdown controller</span><br></pre></td></tr></table></figure>\n<h2 id=\"端口说明\">端口说明</h2>\n<table>\n<thead>\n<tr>\n<th>端口号</th>\n<th>协议</th>\n<th>组件/服务</th>\n<th>作用说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>9876</strong></td>\n<td>TCP</td>\n<td><strong>NameServer</strong></td>\n<td>RocketMQ 集群的 <strong>NameServer</strong> 服务端口。<br>用于 Broker 注册、客户端路由发现。<br>Producer/Consumer 连接此端口以获取 Broker 地址。</td>\n</tr>\n<tr>\n<td><strong>8080</strong></td>\n<td>TCP</td>\n<td><strong>Proxy (gRPC / HTTP)</strong></td>\n<td>RocketMQ 5 引入的 <strong>Proxy 服务</strong> 默认端口之一。<br>用于 <strong>HTTP/gRPC 客户端接入</strong>，例如 RocketMQ Proxy REST API、异步消息接口等。</td>\n</tr>\n<tr>\n<td><strong>8081</strong></td>\n<td>TCP</td>\n<td><strong>Proxy Admin / Dashboard / gRPC Alt</strong></td>\n<td>通常是 Proxy 的 <strong>管理接口</strong> 或 <strong>gRPC 辅助端口</strong>（依配置而定）。<br>也可能是控制面接口，用于与 Console 或控制工具通信。</td>\n</tr>\n<tr>\n<td><strong>10909</strong></td>\n<td>TCP</td>\n<td><strong>Broker HA (High Availability)</strong></td>\n<td>Broker <strong>主从同步端口</strong>（Master ↔ Slave 之间的数据复制）。<br>用于消息数据与元数据的同步。</td>\n</tr>\n<tr>\n<td><strong>10911</strong></td>\n<td>TCP</td>\n<td><strong>Broker 服务端口</strong></td>\n<td>Broker 的 <strong>主通信端口</strong>，客户端连接发送消息、消费消息、心跳等。<br>Producer 和 Consumer 通过 NameServer 获取该端口地址后进行通信。</td>\n</tr>\n<tr>\n<td><strong>10912</strong></td>\n<td>TCP</td>\n<td><strong>Broker HA 客户端端口</strong></td>\n<td>Broker <strong>主从复制中的 Slave 连接 Master</strong> 时使用的 <strong>客户端监听端口</strong>。<br>通常与 10909 配合使用，一主多从模式中 Slave 主动连接 Master。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"日志及数据存储路径\">日志及数据存储路径</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RocketMQ 5 主要有三类服务组件需要关注它们的存储目录</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">组件</th>\n<th style=\"text-align:left\">功能</th>\n<th style=\"text-align:left\">默认存储内容</th>\n<th style=\"text-align:left\">默认路径（Linux 环境）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>NameServer</strong></td>\n<td style=\"text-align:left\">路由服务（注册中心）</td>\n<td style=\"text-align:left\">各个组件的的注册</td>\n<td style=\"text-align:left\">日志文件：<code>~/logs/rocketmqlogs/namesrv.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.namesrv.logback.xml</code> <br> 配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/namesrv.conf</code>（可选）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Broker</strong></td>\n<td style=\"text-align:left\">核心消息存储与转发服务</td>\n<td style=\"text-align:left\">消息数据（CommitLog、ConsumeQueue、Index、Config）<br><strong>目录结构：</strong><br>├── <code>commitlog/</code> → 消息物理文件<br>├── <code>consumequeue/</code> → 消费队列索引<br>├── <code>index/</code> → 消息索引<br>├── <code>config/</code> → topic、offset、subscription 信息<br>├── <code>checkpoint</code> → 存储校验点<br>├── <code>abort</code> → 异常退出标志</td>\n<td style=\"text-align:left\"><strong>数据目录</strong>：<code>~/store</code><br>日志文件：<code>~/logs/rocketmqlogs/broker.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.broker.logback.xml</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/broker.conf</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Proxy</strong></td>\n<td style=\"text-align:left\">客户端访问入口层（无状态代理）<br>（5.x 新引入组件）</td>\n<td style=\"text-align:left\">转发日志、访问日志</td>\n<td style=\"text-align:left\">日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.proxy.logback.xml</code><br>日志文件：<code>~/logs/rocketmqlogs/proxy.log</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq-proxy.json</code></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Controller</strong></td>\n<td style=\"text-align:left\"><strong>Broker 主从协调与高可用管理</strong><br>（5.x 新引入组件）</td>\n<td style=\"text-align:left\">- 集群主从元数据（主从关系、broker注册信息）<br>- Controller 自身运行状态与选举元数据</td>\n<td style=\"text-align:left\"><strong>数据目录</strong>：<code>~/store/controller</code><br>日志文件：<code>~/logs/rocketmqlogs/controller.log</code><br>日志配置：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.controller.logback.xml</code><br>配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/controller.conf</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>NameServer 和 Proxy 都是无状态（stateless）组件，不会持久化业务数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Broker 数据路径说明</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">配置项</th>\n<th style=\"text-align:left\">默认路径</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">主要作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>storePathRootDir</strong></td>\n<td style=\"text-align:left\"><code>/home/rocketmq/store</code><br>（默认）</td>\n<td style=\"text-align:left\">消息存储的根目录</td>\n<td style=\"text-align:left\">作为所有存储文件的父级目录，其他路径若未单独配置，则在此目录下创建</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storePathCommitLog</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/commitlog</code></td>\n<td style=\"text-align:left\">CommitLog 文件存放路径</td>\n<td style=\"text-align:left\">存储消息主体内容，是最核心的数据文件（顺序写入）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storePathConsumeQueue</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/consumequeue</code></td>\n<td style=\"text-align:left\">消费队列文件存放路径</td>\n<td style=\"text-align:left\">存储消息在队列中的索引（逻辑队列），指向 CommitLog 的物理位置</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storePathIndex</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/index</code></td>\n<td style=\"text-align:left\">索引文件存放路径</td>\n<td style=\"text-align:left\">提供按 Key 查询消息的索引结构，便于通过 Message Key 快速检索消息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storePathConfig</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/config</code></td>\n<td style=\"text-align:left\">Broker 运行时配置存储路径</td>\n<td style=\"text-align:left\">存储运行时生成的配置文件，如 topic、consumerOffset、subscriptionGroup 等</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>storeCheckpoint</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/checkpoint</code></td>\n<td style=\"text-align:left\">Checkpoint 文件路径</td>\n<td style=\"text-align:left\">记录 CommitLog、ConsumeQueue、Index 三者的刷盘进度，用于崩溃恢复</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>abortFile</strong></td>\n<td style=\"text-align:left\"><code>$&#123;storePathRootDir&#125;/abort</code></td>\n<td style=\"text-align:left\">异常退出标志文件路径</td>\n<td style=\"text-align:left\">用于标识 Broker 是否异常退出，启动时据此判断是否执行恢复流程</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"安装过程中遇到的问题\">安装过程中遇到的问题</h2>\n<h3 id=\"1-启动-Proxy-失败\">1.启动 Proxy 失败</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论是 <code>Broker+Proxy</code> 启动，还是 单独启动 <code>Proxy</code>，都报如下错误：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 错误会在 nohup.out 中输出</span></span><br><span class=\"line\">Exception <span class=\"keyword\">in</span> thread <span class=\"string\">&quot;main&quot;</span> java.lang.UnsatisfiedLinkError: failed to load the required native library</span><br><span class=\"line\"></span><br><span class=\"line\">Caused by: java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_x86_64_fedora, netty_tcnative_linux_x86_64, netty_tcnative_x86_64, netty_tcnative]</span><br><span class=\"line\"></span><br><span class=\"line\">Suppressed: java.lang.UnsatisfiedLinkError: /tmp/libnetty_tcnative_linux_x86_642308675901892111861.so: libcrypt.so.1: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>原因分析</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">\n<ol>\n<li class=\"lvl-7\">Netty-tcnative 的编译依赖：RocketMQ 使用的 Netty 的 tcnative 模块是在较旧的环境中编译的，而动态链接的版本锁定：编译时链接的是 libcrypt.so.1，运行时必须找到相同主版本号的库</li>\n</ol>\n</li>\n<li class=\"lvl-4\">\n<ol start=\"2\">\n<li class=\"lvl-7\">而我当前使用的系统为 Amazon Linux 2023，基于更新的 glibc，其加密功能已经迁移到 libcrypt.so.2。（Amazon Linux 2：基于较旧的 glibc 版本，libcrypt.so.1 是主要的加密库）</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 检查 libcrypt 是否存在</span></span><br><span class=\"line\">$ ldconfig -p | grep libcrypt</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class=\"line\">\tlibcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class=\"line\">\tlibcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class=\"line\">\tlibcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class=\"line\">\tlibcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>解决办法</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装兼容性包</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> yum install libxcrypt-compat</span><br><span class=\"line\"><span class=\"comment\"># 检查 libcrypt 是否存在</span></span><br><span class=\"line\">$ ldconfig -p | grep libcrypt</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class=\"line\">\tlibcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class=\"line\">\tlibcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class=\"line\">\tlibcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class=\"line\">\tlibcrypt.so.1 (libc6,x86-64) =&gt; /lib64/libcrypt.so.1</span><br><span class=\"line\">\tlibcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-写入消息失败，并报如下错误\">2.写入消息失败，并报如下错误</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Caused by: org.apache.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now. It may be caused by one of the following reasons: the broker<span class=\"string\">&#x27;s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00], messages are put to the slave, message store has been shut down, etc. BROKER: 10.250.0.175:10911</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>错误原因</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">RocketMQ 返回的 CODE: 14 表示：Broker 当前 不接受消息写入（服务暂不可用）。</li>\n<li class=\"lvl-4\">the broker’s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00]: Broker 的磁盘已满</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CL: 0.95 → CommitLog 95% 已使用</span><br><span class=\"line\">CQ: 0.95 → ConsumeQueue 95% 已使用</span><br><span class=\"line\">INDEX: -1.00 → 索引异常或未采集</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>含义</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>diskMaxUsedSpaceRatio</code></td>\n<td>Broker 磁盘最大可用比例（超过后禁止写入）</td>\n<td><strong>75%</strong></td>\n</tr>\n<tr>\n<td><code>storePathCommitLog</code></td>\n<td>消息存储路径（CommitLog）</td>\n<td><code>~/store/commitlog</code></td>\n</tr>\n<tr>\n<td><code>storePathConsumeQueue</code></td>\n<td>消费队列路径（ConsumeQueue）</td>\n<td><code>~/store/consumequeue</code></td>\n</tr>\n<tr>\n<td><code>storePathIndex</code></td>\n<td>索引路径</td>\n<td><code>~/store/index</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p>总结：可以确认是 磁盘使用率过高 导致 Broker 自动进入 “写保护” 模式。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>解决方法</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">\n<ol>\n<li class=\"lvl-9\">清理磁盘：确认磁盘使用率过高，并清理磁盘空间，既降低磁盘使用率</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"2\">\n<li class=\"lvl-9\">磁盘扩容：如果清理磁盘空间后，磁盘使用率依然过高，则需要扩容磁盘</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"3\">\n<li class=\"lvl-9\">配置调整：调整 Broker 配置(<code>broker.conf</code>)，将 <code>diskMaxUsedSpaceRatio</code> 配置适当提高，如 96%(<code>diskMaxUsedSpaceRatio=96</code>)，调整后重启 Broker。仅建议在紧急情况下临时解决。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 CentOS9 中 RocketMQ 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 Apache RocketMQ 简介 一、RocketMQ 是什么？ RocketMQ 是一个分布式、队列模型的消息中间件。它由阿里巴巴在2012年开源，并于2017年正式成为 Apache 基金会的顶级项目。 你可以把它想象成一个在分布式系统中负责可靠传递消息的“邮局”或“快递系统”。当系统A需要发送数据给系统B，但它们之间不直接通信时，就可以通过 RocketMQ 来中转，确保消息不丢失、不重复，并且能按顺序送达。 RocketMQ 是一个高性能、高可靠、高实时的分布式消息中间件。它就像分布式系统的“中枢神经系统”，负责在各个服务之间可靠、高效地传递数据，是现代互联网架构中不可或缺的基础组件之一。 RocketMQ 5.x 通过引入 Proxy 模式，极大地提升了架构的灵活性、多语言支持能力和云原生亲和力，是其在消息中间件领域持续演进的重要里程碑。 它与 Kafka、RabbitMQ 等都是业界顶级的消息队列，但各有侧重。RocketMQ 在事务消息、顺序消息和对在线业务的稳定性支持方面表现尤为出色。 二、核心特点与优势 序号 特性 典型场景 主要作用 1 削峰填谷 电商秒杀、大促活动时大量下单请求瞬间涌入 将突发请求先缓存为消息，后端系统按自身能力平稳消费，避免系统过载崩溃 2 异步解耦 用户注册后触发多系统任务（邮件、优惠券、积分） 主流程只负责发送消息，其他系统独立异步处理，降低系统间耦合、提高扩展性 3 顺序消息 订单状态变更（创建 → 付款 → 发货 → 收货） 同一业务键（如订单ID）的消息按顺序发送和消费，保证业务逻辑正确性 4 持久化与高可靠性 关键业务消息必须不丢失（交易、支付、日志） 所有消息写入磁盘并支持主从复制，即使服务器重启也能恢复，保证高可用 5 消息回溯 消费逻辑出错、数据重算、补偿任务 支持重置消费位点，重新消费历史消息，实现业务补偿与追溯 6 海量消息堆积能力 大规模异步日志收集、IoT 数据汇聚、埋点分析 支持万亿级消息堆积，性能稳定不衰减，适用于大规模数据场景 三、核心架构与概念 要理解 RocketMQ，需要知道几个关键角色： 经典核心组件 序号 组件名称 主要作用 说明 / 特点 1 Producer（生产者） 发送消息的客户端 负责将业务系统的消息发送到指定的 Topic，支持同步、异步、单向三种发送方式 2 Consumer（消费者） 接收并消费消息的客户端 从 Broker 拉取消息并进行业务处理，可分为 Push 和 Pull 两种消费模式 3 Consumer Group（消费者组） 实现负载均衡与高可用消费 多个消费者订阅同一 Topic 时组成消费者组，一个分区只会被组内一个消费者消费 4 Broker（消息服务器） 存储和转发消息 RocketMQ 的核心组件，负责消息的持久化、转发、主从复制和高可用 5 Topic（主题） 消息的分类与路由单元 Producer 发送消息到指定 Topic，Consumer 订阅 Topic 消费消息；一个 Topic 可包含多个消息队列（分区） 6 Name Server（名字服务） 管理 Broker 地址信息 类似轻量级注册中心，维护 Broker 元数据，帮助 Producer 和 Consumer 定位消息存储位置 7 Controller（控制器） 主从自动切换与高可用控制 RocketMQ 5.x 引入，基于 Raft（DLedger）协议实现 Broker 自动选主和元数据管理 8 Proxy（代理层） 客户端访问入口与协议转换 RocketMQ 5.x 新组件，无状态，可横向扩展；统一接入层，支持多协议（如 HTTP、gRPC），隔离客户端与 Broker 引入 Proxy 模式的优势： 1234**架构解耦与语言无关**：Proxy 作为通用代理，将复杂的 Broker 协议封装成更简单的接口（如 gRPC），使得用不同编程语言（如 Go, Python, C++ 等）开发的客户端更容易接入，而无需实现复杂的原生协议。**简化客户端**：客户端不再需要感知 Name Server 和 Broker 的地址变化，只需连接固定的 Proxy 地址即可，大大降低了客户端的复杂度。**增强安全性**：可以在 Proxy 层统一实现安全认证、限流、审计等策略，作为Broker集群的安全屏障。**云原生友好**：无状态的 Proxy 非常适合在 Kubernetes 等容器化环境中进行部署和弹性伸缩。 消息中间件功能对比表（ActiveMQ vs Kafka vs RabbitMQ vs RocketMQ） 参考资料 功能项 ActiveMQ Kafka RabbitMQ RocketMQ 客户端 SDK Java、.NET、C++ 等 Java、Scala 等 Java、.NET、Go、Python、C 等 Java、C++、Go 通信协议与规范 推送模型（Push），支持 OpenWire、STOMP、AMQP、MQTT、JMS 拉取模型（Pull），支持 TCP 推送模型（Push），支持 AMQP、MQTT、STOMP、HTTP、WebSocket 拉取模型（Pull），支持 TCP、JMS、OpenMessaging 消息有序性 通过独占消费者（Exclusive Consumer）或独占队列（Exclusive Queues）保证顺序 保证分区内消息顺序 单队列内消息天然有序 严格顺序消息，可平滑扩展 定时/延迟消息 支持 不支持 支持（使用延迟插件） 支持 批量消息 不支持 支持（异步生产者） 支持（Publisher Confirms 模式下） 支持（同步模式可避免消息丢失） 广播消息 支持 不支持 支持（Fanout 交换机） 支持 消息过滤 支持 支持（可用 Kafka Streams 实现） 支持（基于 Exchange 的路由键或 Header） 支持（基于 SQL92 属性过滤） 服务器端触发重投递 不支持 不支持 支持（Nack 或 TTL+DLX） 支持 消息存储 支持高性能持久化（JDBC + LevelDB/KahaDB） 高性能文件存储 内存+磁盘混合存储（Mnesia/基于 Erlang 的日志） 高性能、低延迟文件存储 消息回溯（历史消息查询） 支持 支持（通过 offset） 不支持（消息被消费后无法回溯） 支持（时间戳与 offset） 消息优先级 支持 不支持 支持（优先级队列） 不支持 高可用与故障转移 依赖存储，如 LevelDB 需 ZooKeeper 需要 ZooKeeper 支持镜像队列（Classic / Quorum 模式） 支持主从模式（无需额外组件） 消息轨迹（Message Track） 不支持 不支持 不支持（可通过插件扩展） 支持 配置复杂度 默认配置较低，需手动优化 配置为键值对，可文件或代码提供 开箱即用，配置灵活但选项较多 开箱即用，仅需关注少量配置 管理与运维工具 支持 支持（命令行监控） 支持（Web 管理控制台、CLI） 支持（丰富的 Web 与命令行工具） RocketMQ 的安装 RocketMQ 5.x 依赖 JDK 1.8+。 单机安装 官方文档 下载RocketMQ 12345mkdir -p /usr/local/soft/rocketmq/wget https://dist.apache.org/repos/dist/release/rocketmq/5.3.2/rocketmq-all-5.3.2-bin-release.zipunzip rocketmq-all-5.3.2-bin-release.zipln -s rocketmq-all-5.3.2-bin-release rocketmq5cd rocketmq5 小贴士 默认脚本中，NameServer需要4G内存，Broker 需要8G内存，如果内存不够，可以进入bin目录，对其中的runserver.sh和runbroker.sh两个脚本进行一下修改 12345678910# 使用vi runserver.sh指令，编辑这个脚本，找到下面的一行配置，调整Java进程的内存大小。# NameServer,Controller,Proxy 都使用这个脚本启动JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;修改为：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms1g -Xmx1g -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;# 接下来，同样调整runbroker.sh中的内存大小。Broker 使用这个脚本启动JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g&quot;修改为：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms2g -Xmx2g&quot; 启动 NameServer 安装完RocketMQ包后，我们启动NameServer 123456789### 启动namesrv$ nohup sh bin/mqnamesrv &amp;## 指定配置文件$ nohup sh bin/mqnamesrv -c namesrv.conf &amp;### 验证namesrv是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.log# 我们可以在namesrv.log 中看到 &#x27;The Name Server boot success..&#x27;， 表示NameServer 已成功启动。The Name Server boot success. serializeType=JSON, address 0.0.0.0:9876 namesrv.conf 示例 12# The port of nameserverlistenPort = 9876 启动 Broker+Proxy NameServer成功启动后，我们启动Broker和Proxy。这里我们使用 Local 模式部署，即 Broker 和 Proxy 同进程部署。5.x 版本也支持 Broker 和 Proxy 分离部署以实现更灵活的集群能力。 1234567891011121314151617### 先启动broker$ nohup sh bin/mqbroker -n localhost:9876 --enable-proxy &amp;# 指定配置文件， 默认就是 conf/broker.conf$ nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf --enable-proxy &amp;# 上面的启动方式与下面的启动方式效果一样$ nohup sh bin/mqproxy -n localhost:9876 -pc /usr/local/soft/rocketmq/rocketmq5/conf/rmq-proxy.json -bc /usr/local/soft/rocketmq/rocketmq5/conf/broker.conf -pm local &amp;## 参数说明# -n, --namesrvAddr NameServer 的地址# -pc, --proxyConfigPath Proxy 配置文件路径# -bc, --brokerConfigPath Broker 配置文件路径# -pm, --proxyMode Proxy 模式，local or cluster### 验证broker是否启动成功, 比如, broker的ip是192.168.1.2 然后名字是broker-a$ tail -f ~/logs/rocketmqlogs/proxy.log# 我们可以在 proxy.log 中看到“The broker[brokerName,ip:port] boot success..”，这表明 broker 已成功启动。The broker[broker-a, 10.250.0.175:10911] boot success. serializeType=JSON and name server is localhost:9876 关闭服务器 1234# 先停止 Broker$ sh bin/mqshutdown broker# 停止 NameServer$ sh bin/mqshutdown namesrv 集群安装:多节点（集群）多副本模式-异步复制 官网文档 对集群安装的方式介绍了多种，本文仅实战一种：多节点（集群）多副本模式-异步复制 每个Master配置一个Slave，有多组 Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样； 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 该模式下，Master 节点和 Slave 节点之间是异步复制的，Master 节点挂掉后，Slave 节点不会自动切换为 Master 节点。 集群规划 12345678910111213# NameServer 3 台NameServer1 10.250.0.175NameServer2 10.250.0.188NameServer3 10.250.0.31# Broker 2 Master 2 ReplicasBroker1 10.250.0.188 broker-a,broker-b-sBroker2 10.250.0.31 broker-b,broker-a-s# Proxy 3 台Proxy1 10.250.0.175Proxy2 10.250.0.188Proxy3 10.250.0.31 部署 NameServer 在三台服务器上分别启动RocketMQ NameServer 12cd /usr/local/soft/rocketmq/rocketmq5nohup sh bin/mqnamesrv &amp; 部署Broker broker-a.properties 12345678910111213141516171819brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-a # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=0 # brokerId 必须唯一 ，且 master 的 brokerId 必须为 0deleteWhen=04 # 表示凌晨 4 点清理fileReservedTime=48 # 表示保存 48 小时的数据brokerRole=ASYNC_MASTER # 角色，表示异步复制的主节点flushDiskType=ASYNC_FLUSH # 表示异步刷盘# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径，后面会介绍storePathRootDir=/usr/local/soft/rocketmq/data/store-astorePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-a/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-a/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpointabortFile=/usr/local/soft/rocketmq/data/store-a/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=10911 broker-a-s.properties 12345678910111213141516171819brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-a # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=1 # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0deleteWhen=04fileReservedTime=48brokerRole=SLAVE # 角色，表示异步复制的从节点flushDiskType=ASYNC_FLUSH# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-astorePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-a/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-a/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpointabortFile=/usr/local/soft/rocketmq/data/store-a/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=11011 broker-b.properties 1234567891011121314151617181920brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-b # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=0 # brokerId 必须唯一 ，且 master 的 brokerId 必须为 0deleteWhen=04 # 表示凌晨 4 点清理fileReservedTime=48 # 表示保存 48 小时的数据brokerRole=ASYNC_MASTER # 角色，表示异步复制的主节点flushDiskType=ASYNC_FLUSH # 表示异步刷盘# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-bstorePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-b/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-b/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpointabortFile=/usr/local/soft/rocketmq/data/store-b/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=10911 broker-b-s.properties 1234567891011121314151617181920brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-b # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=1 # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0deleteWhen=04fileReservedTime=48brokerRole=SLAVE # 角色，表示异步复制的从节点flushDiskType=ASYNC_FLUSH# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-bstorePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-b/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-b/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpointabortFile=/usr/local/soft/rocketmq/data/store-b/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=11011 在 Broker1 10.250.0.188 上启动 broker-a 和 broker-b-s 1234567# 启动 broker-anohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-a.properties &amp;# 启动 broker-b-snohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-b-s.properties &amp;## nohup.out 中的输出类似与下面这种就表示启动成功The broker[broker-a, 10.250.0.31:11011] boot success. serializeType=JSON and name server is 10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876 在 Broker2 10.250.0.31 上启动 broker-b 和 broker-a-s 1234# 启动 broker-bnohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-b.properties &amp;# 启动 broker-a-snohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-a-s.properties &amp; 启动成功后，可以通过如下命令检查机器状态 12345678# 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）sh bin/mqadmin clusterList -n 10.250.0.175:9876## 输出类似如下#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #Timer(Progress) #PCWait(ms) #Hour #SPACE #ACTIVATEDDefaultCluster broker-a 0 10.250.0.188:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489250.72 0.2900 trueDefaultCluster broker-a 1 10.250.0.31:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 489250.72 0.2600 falseDefaultCluster broker-b 0 10.250.0.31:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489250.72 0.2600 trueDefaultCluster broker-b 1 10.250.0.188:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 489250.72 0.2900 false 配置 Proxy 在三台服务器上分别启动RocketMQ NameServer 12345678nohup sh bin/mqproxy -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; &amp;## 指定配置文件，这里要注意，集群的名称要与 conf/rmq-proxy.json 中配置的集群名称必须一致，默认是 DefaultCluster## 默认的配置文件就是 conf/rmq-proxy.json，但如果通过 -pc 指定配置文件，则必须使用绝对路径nohup sh bin/mqproxy -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -pc /usr/local/soft/rocketmq/rocketmq5/conf/rmq-proxy.json &amp;## 查看日志，输出如下内容就表示启动成功，tail -f nohup.outrocketmq-proxy startup successfully rmq-proxy.json 示例 12345&#123; &quot;rocketMQClusterName&quot;: &quot;DefaultCluster&quot;, # 集群名称 &quot;remotingListenPort&quot;: 8080, # 监听端口，默认 8080 &quot;grpcServerPort&quot;: 8081 # grpc 监听端口，默认 8081&#125; 停止Proxy 12# 停止 Proxysh bin/mqshutdown proxy 集群安装:主备自动切换模式部署 RocketMQ 5.x 提供了一种新的部署方式 Controller，可以在主从模式下实现主备自动切换，当主节点挂掉时，自动切换到从节点上运行。 官方文档:主备自动切换模式部署 Controller 组件提供选主能力，若需要保证 Controller 具备容错能力，Controller 部署需要三副本及以上（遵循 Raft 的多数派协议）。 本文在上文“集群安装:多节点（集群）多副本模式-异步复制”的基础上进行修改 Controller 部署有两种方式。一种是嵌入于 NameServer 进行部署，另一种是独立部署，本文采用独立部署 Controller 组件的方式。 集群规划 1234# Controller 3 台Controller1 10.250.0.175Controller2 10.250.0.188Controller3 10.250.0.31 分别在每台机器上创建controller.conf配置文件，内容如下(注意修改节点Id) 1234567891011121314151617# controller.conf# ---------------------------------------------------------# DLedger Raft Group 的名字，同一集群保持一致controllerDLegerGroup = group1# 集群中三个节点的成员定义，每个节点都必须一致controllerDLegerPeers = n0-10.250.0.175:9877;n1-10.250.0.188:9877;n2-10.250.0.31:9877# 节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一controllerDLegerSelfId = n0# Controller 数据存储路径（非常关键！不要删除）controllerStorePath = /usr/local/soft/rocketmq/data/DledgerController# 是否允许从 SyncStateSet 外选举 Master# true 会加快选举但可能丢消息，建议生产保持 falseenableElectUncleanMaster = false# 当 Broker 副本角色变化时是否主动通知（建议开启）notifyBrokerRoleChanged = true# 启动端口，端口不能与 NameServer、Broker、Proxy 端口冲突listenPort = 9877 分别启动每台机器上的 Controller 1234nohup sh bin/mqcontroller -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/controller.conf &amp;## 启动成功后，查看 nohup.out 文件，输出如下内容就表示启动成功load config properties file OK, conf/controller.confThe Controller Server boot success. serializeType=JSON 修改 broker 配置文件，以 broker-a.properties 为例 123456789# 去掉如下配置，Controller 模式下 会自动分配# brokerId=1 # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0# brokerRole=ASYNC_MASTER # 角色，表示异步复制的主节点# 添加如下配置# 启用 Controller 模式（自动主从切换模式的总开关）enableControllerMode = true# Controller 集群地址列表（建议与 Controller 集群保持一致）controllerAddr = 10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877 RocketMQ 5 Broker Controller 模式配置参数表 参数名 说明 默认值 备注 / 建议 enableControllerMode 是否启用 Controller 模式（自动主从切换总开关） false 必须设为 true 才能启用自动主从切换 controllerAddr Controller 集群地址列表（以分号分隔） 无 所有 Broker 配置应一致，例如 10.250.0.175:9877;10.250.0.188:9877;10.250.0.31:9877 syncBrokerMetadataPeriod 向 Controller 同步 Broker 副本信息的时间间隔（毫秒） 5000 (5s) 保持默认即可；用于上报心跳与元数据 checkSyncStateSetPeriod 检查同步状态集（SyncStateSet）的时间间隔（毫秒） 5000 (5s) Controller 会定期剔除落后副本 syncControllerMetadataPeriod 同步 Controller 元数据的时间间隔（毫秒） 10000 (10s) Broker 定期从集群获取当前活跃 Controller 地址 haMaxTimeSlaveNotCatchup Slave 未跟上 Master 的最大时间间隔（毫秒） 15000 (15s) 超过该时间将 Slave 移出 SyncStateSet storePathEpochFile Epoch 文件存储路径 store/epochFile 非常重要！不要删除；存储主从任期、epoch 等元信息 allAckInSyncStateSet 是否要求所有同步副本都 ACK 后才返回成功 false true 可保证强一致但性能下降；建议保持默认 syncFromLastFile Slave 是否从最后一个文件开始复制（空盘启动时） false 若历史日志很大且 Slave 新建，可设为 true asyncLearner 是否为异步 learner 副本（不参与选主） false 用于远程灾备副本，不会被选举为 Master inSyncReplicas 需保持同步的副本组数量 1 若 allAckInSyncStateSet=true，该参数无效 minInSyncReplicas 最小同步副本数量，低于该值则拒绝写入 1 防止写入过多未同步副本导致数据丢失风险 重新启动 Broker，为保证主从数据一致性在重启时不被破坏，启动顺序应为先重新原Master，再重启原Slave 启动成功后，可以通过如下命令检查机器状态，可以看到集群内部自动分配了主从 12345678# 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）sh bin/mqadmin clusterList -n 10.250.0.175:9876## 输出类似如下#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #Timer(Progress) #PCWait(ms) #Hour #SPACE #ACTIVATEDDefaultCluster broker-a 0 10.250.0.188:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489268.48 0.2900 trueDefaultCluster broker-a 2 10.250.0.31:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 2-0(0.0w, 0.0, 0.0) 0 489268.48 0.2700 falseDefaultCluster broker-b 0 10.250.0.31:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489268.48 0.2700 trueDefaultCluster broker-b 2 10.250.0.188:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 489268.48 0.2900 false 验证主备自动切换，此时关闭 broker-b 的 Master，并查看集群状态 123456sh bin/mqadmin clusterList -n 10.250.0.175:9876## 输出类似如下，可以看到`broker-b`原来的 Slave 被切换为 Master#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #Timer(Progress) #PCWait(ms) #Hour #SPACE #ACTIVATEDDefaultCluster broker-a 0 10.250.0.188:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489268.58 0.2900 trueDefaultCluster broker-a 2 10.250.0.31:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 1-0(0.0w, 0.0, 0.0) 0 489268.58 0.2700 falseDefaultCluster broker-b 0 10.250.0.188:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489268.58 0.2900 true 重新启动刚才关闭的 broker-b ，节点会自动加入集群，角色为 Slave 停止 Controller 12# 停止 PrControlleroxysh bin/mqshutdown controller 端口说明 端口号 协议 组件/服务 作用说明 9876 TCP NameServer RocketMQ 集群的 NameServer 服务端口。用于 Broker 注册、客户端路由发现。Producer/Consumer 连接此端口以获取 Broker 地址。 8080 TCP Proxy (gRPC / HTTP) RocketMQ 5 引入的 Proxy 服务 默认端口之一。用于 HTTP/gRPC 客户端接入，例如 RocketMQ Proxy REST API、异步消息接口等。 8081 TCP Proxy Admin / Dashboard / gRPC Alt 通常是 Proxy 的 管理接口 或 gRPC 辅助端口（依配置而定）。也可能是控制面接口，用于与 Console 或控制工具通信。 10909 TCP Broker HA (High Availability) Broker 主从同步端口（Master ↔ Slave 之间的数据复制）。用于消息数据与元数据的同步。 10911 TCP Broker 服务端口 Broker 的 主通信端口，客户端连接发送消息、消费消息、心跳等。Producer 和 Consumer 通过 NameServer 获取该端口地址后进行通信。 10912 TCP Broker HA 客户端端口 Broker 主从复制中的 Slave 连接 Master 时使用的 客户端监听端口。通常与 10909 配合使用，一主多从模式中 Slave 主动连接 Master。 日志及数据存储路径 RocketMQ 5 主要有三类服务组件需要关注它们的存储目录 组件 功能 默认存储内容 默认路径（Linux 环境） NameServer 路由服务（注册中心） 各个组件的的注册 日志文件：~/logs/rocketmqlogs/namesrv.log日志配置：$&#123;ROCKETMQ_HOME&#125;/conf/rmq.namesrv.logback.xml 配置文件：$&#123;ROCKETMQ_HOME&#125;/conf/namesrv.conf（可选） Broker 核心消息存储与转发服务 消息数据（CommitLog、ConsumeQueue、Index、Config）目录结构：├── commitlog/ → 消息物理文件├── consumequeue/ → 消费队列索引├── index/ → 消息索引├── config/ → topic、offset、subscription 信息├── checkpoint → 存储校验点├── abort → 异常退出标志 数据目录：~/store日志文件：~/logs/rocketmqlogs/broker.log日志配置：$&#123;ROCKETMQ_HOME&#125;/conf/rmq.broker.logback.xml配置文件：$&#123;ROCKETMQ_HOME&#125;/conf/broker.conf Proxy 客户端访问入口层（无状态代理）（5.x 新引入组件） 转发日志、访问日志 日志配置：$&#123;ROCKETMQ_HOME&#125;/conf/rmq.proxy.logback.xml日志文件：~/logs/rocketmqlogs/proxy.log配置文件：$&#123;ROCKETMQ_HOME&#125;/conf/rmq-proxy.json Controller Broker 主从协调与高可用管理（5.x 新引入组件） - 集群主从元数据（主从关系、broker注册信息）- Controller 自身运行状态与选举元数据 数据目录：~/store/controller日志文件：~/logs/rocketmqlogs/controller.log日志配置：$&#123;ROCKETMQ_HOME&#125;/conf/rmq.controller.logback.xml配置文件：$&#123;ROCKETMQ_HOME&#125;/conf/controller.conf NameServer 和 Proxy 都是无状态（stateless）组件，不会持久化业务数据。 Broker 数据路径说明 配置项 默认路径 说明 主要作用 storePathRootDir /home/rocketmq/store（默认） 消息存储的根目录 作为所有存储文件的父级目录，其他路径若未单独配置，则在此目录下创建 storePathCommitLog $&#123;storePathRootDir&#125;/commitlog CommitLog 文件存放路径 存储消息主体内容，是最核心的数据文件（顺序写入） storePathConsumeQueue $&#123;storePathRootDir&#125;/consumequeue 消费队列文件存放路径 存储消息在队列中的索引（逻辑队列），指向 CommitLog 的物理位置 storePathIndex $&#123;storePathRootDir&#125;/index 索引文件存放路径 提供按 Key 查询消息的索引结构，便于通过 Message Key 快速检索消息 storePathConfig $&#123;storePathRootDir&#125;/config Broker 运行时配置存储路径 存储运行时生成的配置文件，如 topic、consumerOffset、subscriptionGroup 等 storeCheckpoint $&#123;storePathRootDir&#125;/checkpoint Checkpoint 文件路径 记录 CommitLog、ConsumeQueue、Index 三者的刷盘进度，用于崩溃恢复 abortFile $&#123;storePathRootDir&#125;/abort 异常退出标志文件路径 用于标识 Broker 是否异常退出，启动时据此判断是否执行恢复流程 安装过程中遇到的问题 1.启动 Proxy 失败 无论是 Broker+Proxy 启动，还是 单独启动 Proxy，都报如下错误： 123456# 错误会在 nohup.out 中输出Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: failed to load the required native libraryCaused by: java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_x86_64_fedora, netty_tcnative_linux_x86_64, netty_tcnative_x86_64, netty_tcnative]Suppressed: java.lang.UnsatisfiedLinkError: /tmp/libnetty_tcnative_linux_x86_642308675901892111861.so: libcrypt.so.1: cannot open shared object file: No such file or directory 原因分析 Netty-tcnative 的编译依赖：RocketMQ 使用的 Netty 的 tcnative 模块是在较旧的环境中编译的，而动态链接的版本锁定：编译时链接的是 libcrypt.so.1，运行时必须找到相同主版本号的库 而我当前使用的系统为 Amazon Linux 2023，基于更新的 glibc，其加密功能已经迁移到 libcrypt.so.2。（Amazon Linux 2：基于较旧的 glibc 版本，libcrypt.so.1 是主要的加密库） 12345678# 检查 libcrypt 是否存在$ ldconfig -p | grep libcrypt## 输出 libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12 libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3 libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2 libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so 解决办法 1234567891011# 安装兼容性包sudo yum install libxcrypt-compat# 检查 libcrypt 是否存在$ ldconfig -p | grep libcrypt## 输出 libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12 libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3 libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2 libcrypt.so.1 (libc6,x86-64) =&gt; /lib64/libcrypt.so.1 libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so 2.写入消息失败，并报如下错误 1Caused by: org.apache.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now. It may be caused by one of the following reasons: the broker&#x27;s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00], messages are put to the slave, message store has been shut down, etc. BROKER: 10.250.0.175:10911 错误原因 RocketMQ 返回的 CODE: 14 表示：Broker 当前 不接受消息写入（服务暂不可用）。 the broker’s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00]: Broker 的磁盘已满 123CL: 0.95 → CommitLog 95% 已使用CQ: 0.95 → ConsumeQueue 95% 已使用INDEX: -1.00 → 索引异常或未采集 配置项 含义 默认值 diskMaxUsedSpaceRatio Broker 磁盘最大可用比例（超过后禁止写入） 75% storePathCommitLog 消息存储路径（CommitLog） ~/store/commitlog storePathConsumeQueue 消费队列路径（ConsumeQueue） ~/store/consumequeue storePathIndex 索引路径 ~/store/index 总结：可以确认是 磁盘使用率过高 导致 Broker 自动进入 “写保护” 模式。 解决方法 清理磁盘：确认磁盘使用率过高，并清理磁盘空间，既降低磁盘使用率 磁盘扩容：如果清理磁盘空间后，磁盘使用率依然过高，则需要扩容磁盘 配置调整：调整 Broker 配置(broker.conf)，将 diskMaxUsedSpaceRatio 配置适当提高，如 96%(diskMaxUsedSpaceRatio=96)，调整后重启 Broker。仅建议在紧急情况下临时解决。","summary":"摘要 本文介绍 CentOS9 中 RocketMQ 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-23T13:30:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/","url":"https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/","title":"Kafka 从 Zookeeper 迁移到 KRaft","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org/39/documentation.html#kraft_zk_migration\">官方文档：ZooKeeper到KRaft迁移</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"从-Zookeeper-模式迁移到-KRaft-模式（平滑迁移）\">从 Zookeeper 模式迁移到 KRaft 模式（平滑迁移）</h2>\n<p><em><strong>！！！迁移后将无法再恢复到 ZooKeeper 模式！！！</strong></em></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 官方在 3.4+ 引入了完整的 Zookeeper → KRaft 平滑迁移机制，称为 <code>ZK to KRaft (ZkMigration)</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>迁移背景与前提</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">项目</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">支持版本</td>\n<td style=\"text-align:left\">Kafka <strong>3.4.0+</strong>（建议至少使用 <strong>3.6.x ，目前最新版为 3.9.x</strong>）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">迁移目的</td>\n<td style=\"text-align:left\">摆脱 ZooKeeper，完全切换为 KRaft 自管理模式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">迁移模式</td>\n<td style=\"text-align:left\"><strong>在线迁移</strong>（无停机或最小停机）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">最终目标</td>\n<td style=\"text-align:left\">Kafka 的控制器与元数据完全由 KRaft 管理，不再依赖 ZooKeeper。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>整体迁移流程概览</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>阶段</th>\n<th>控制器类型</th>\n<th>Broker 模式</th>\n<th>ZooKeeper 角色</th>\n<th>KRaft 角色</th>\n<th>特征说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>初始阶段</strong></td>\n<td>ZooKeeper 控制器</td>\n<td>全部为 ZK 模式</td>\n<td>管理所有元数据</td>\n<td>尚未启用</td>\n<td>所有 Broker 都运行在 ZK 模式下，由 ZK 控制器管理集群。</td>\n</tr>\n<tr>\n<td><strong>初始元数据加载阶段</strong></td>\n<td>KRaft 控制器开始加载</td>\n<td>部分（或全部）仍为 ZK 模式</td>\n<td>提供元数据源</td>\n<td>从 ZK 加载元数据</td>\n<td>KRaft 法定节点（controller.quorum.voters）从 ZK 中读取并同步当前集群元数据。</td>\n</tr>\n<tr>\n<td><strong>混合阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>部分 ZK 模式，部分 KRaft 模式</td>\n<td>保留只读元数据</td>\n<td>管理并更新元数据</td>\n<td>KRaft 控制器成为主控，ZK 仍存在但只提供读取，Broker 可处于不同模式（混合状态）。</td>\n</tr>\n<tr>\n<td><strong>双写阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>全部为 KRaft 模式</td>\n<td>接收 KRaft 同步写入</td>\n<td>管理元数据并写入 ZK</td>\n<td>所有 Broker 都运行在 KRaft 模式，控制器将元数据同时写入 ZK 和 KRaft 日志。</td>\n</tr>\n<tr>\n<td><strong>迁移完成阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>全部为 KRaft 模式</td>\n<td>不再使用</td>\n<td>独立运行</td>\n<td>停止向 ZK 写入元数据，ZK 可安全关闭，Kafka 完全运行在无 Zookeeper 的 KRaft 模式下。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"开始迁移\">开始迁移</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里以前文 <a href=\"/2025/10/13/kafka-01-install-zookeeper/\" title=\"Kafka 的安装：基于 Zookeeper\">Kafka 的安装：基于 Zookeeper</a> 中的3个节点的集群为例。</p>\n</li>\n</ul>\n<h3 id=\"启动一个-Controller-节点\">启动一个 Controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在任意一个节点上启动一个 Controller 节点，这里为 worker1</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动前需要先获取当前 Kafka 集群的 Cluster ID</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ zookeeper-shell.sh localhost:2181 get /cluster/id</span><br><span class=\"line\">Connecting to localhost:2181</span><br><span class=\"line\"></span><br><span class=\"line\">WATCHER::</span><br><span class=\"line\"></span><br><span class=\"line\">WatchedEvent state:SyncConnected <span class=\"built_in\">type</span>:None path:null</span><br><span class=\"line\">&#123;<span class=\"string\">&quot;version&quot;</span>:<span class=\"string\">&quot;1&quot;</span>,<span class=\"string\">&quot;id&quot;</span>:<span class=\"string\">&quot;hp_Q0pihQ0ORcIvXlfHobQ&quot;</span>&#125;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>准备好 Controller 节点的配置文件，这里可以用 <code>config/kraft/controller.properties</code> 为模板进行修改</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色，这里只能是controller</span></span><br><span class=\"line\">process.roles=controller</span><br><span class=\"line\"><span class=\"comment\"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class=\"line\">node.id=3000</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点，因为我们当前只启动了一个controller节点，所以只能配置一个投票节点</span></span><br><span class=\"line\">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class=\"line\"><span class=\"comment\"># 配置监听器，注意端口不能重复</span></span><br><span class=\"line\">listeners=CONTROLLER://:9098</span><br><span class=\"line\">advertised.listeners=CONTROLLER://worker1:9098</span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录，这里存放的是元数据，在格式化时这个目录必须为空目录</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\">zookeeper.metadata.migration.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ZooKeeper client 连接</span></span><br><span class=\"line\">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 其它参数尽量保持与旧集群的配置一致</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Controller 节点</p>\n</li>\n</ul>\n<blockquote>\n<p>千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 <a href=\"http://kafka-storage.sh\">kafka-storage.sh</a> format ，那会把原有数据结构重置或踩坏。<br>\n必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 格式化元数据目录，log.dirs 参数指定元数据存放目录，首次运行前必须为空目录</span></span><br><span class=\"line\"><span class=\"comment\"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class=\"line\">kafka-storage.sh format --standalone -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br><span class=\"line\"><span class=\"comment\"># 启动，这里没有后台启动是为了方便观察日志输出</span></span><br><span class=\"line\">kafka-server-start.sh /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>模式</th>\n<th>format 命令</th>\n<th>quorum 状态</th>\n<th>是否从 ZK 加载</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>迁移阶段（standalone）</td>\n<td><code>--standalone</code></td>\n<td>无（单节点）</td>\n<td>✅ 是</td>\n</tr>\n<tr>\n<td>正式 KRaft 模式</td>\n<td>无 <code>--standalone</code></td>\n<td>✅ 多节点</td>\n<td>❌ 否（独立运行）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"将原先的三个节点作为-Broker-节点重新启动\">将原先的三个节点作为 Broker 节点重新启动</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改原先的配置文件 <code>server.properties</code>，只需要修改如下内容即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在最后加入 CONTROLLER:PLAINTEXT</span></span><br><span class=\"line\">listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,CONTROLLER:PLAINTEXT</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 以下是新加入的 配置项</span></span><br><span class=\"line\"><span class=\"comment\"># Set the IBP，当前 kafka 版本是 3.9.1，所以这里设置为 3.9</span></span><br><span class=\"line\">inter.broker.protocol.version=3.9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\">zookeeper.metadata.migration.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># KRaft controller quorum configuration，因为目前只启动了一个 controller 节点，所以只能配置一个投票节点</span></span><br><span class=\"line\">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class=\"line\"><span class=\"comment\"># 控制器监听器名称，要与 contreller 节点配置文件 controller.properties 中的配置一致</span></span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别重新启动三个节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 kafka</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br><span class=\"line\"><span class=\"comment\"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class=\"line\">ps -ef | grep kafka | grep  <span class=\"string\">&quot;server\\.properties&quot;</span> | grep -v grep | awk <span class=\"string\">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class=\"built_in\">kill</span> -9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新启动 kafka</span></span><br><span class=\"line\">kafka-server-start.sh /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当三个节点都以必要的配置重新启动后，迁移将自动开始。迁移完成后，可以在 Controller(worker1)节点 上看到类似如下日志：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ✅ 意味：从 ZooKeeper 到 KRaft 的初始元数据迁移已成功，共写入 62 条记录，当前 KRaft metadata offset 为 3179。这是迁移成功的明确证据。</span></span><br><span class=\"line\">Completed migration of metadata from ZooKeeper to KRaft. 62 records were generated <span class=\"keyword\">in</span> 300 ms across 1 batches. The average time spent waiting on a batch was 97.00 ms. The record types were &#123;TOPIC_RECORD=3, PARTITION_RECORD=56, CONFIG_RECORD=3&#125;. The current metadata offset is now 3179 with an epoch of 2. Saw 3 brokers <span class=\"keyword\">in</span> the migrated metadata [1, 2, 3]. (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：控制器已加载并生效新元数据与 feature set（与 offset 3179 对应）。</span></span><br><span class=\"line\">Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures=&#123;metadata.version=21&#125;, finalizedFeaturesEpoch=3179). (org.apache.kafka.metadata.publisher.FeaturesPublisher)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：内部迁移状态已更新，KRaft 上有了写入位置记录。</span></span><br><span class=\"line\">Finished initial migration of ZK metadata to KRaft <span class=\"keyword\">in</span> 3486479 ns. Transitioned migration state from ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=-1, kraftMetadataEpoch=-1, lastUpdatedTimeMs=1760682050169, migrationZkVersion=1, controllerZkEpoch=3, controllerZkVersion=3&#125; to ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=3179, kraftMetadataEpoch=2, lastUpdatedTimeMs=1760682050169, migrationZkVersion=2, controllerZkEpoch=3, controllerZkVersion=3&#125; (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：迁移流程按预期推进：先把 KRaft 的元数据与 ZK 对齐（sync），然后与 brokers 建立通信，最终进入 DUAL_WRITE（双写）。DUAL_WRITE 阶段表示控制器在写入 KRaft metadata log 的同时，仍然会把必要的写操作也写回 ZooKeeper（双写）——直到迁移完全完成并确认可以停止写 ZK 为止。</span></span><br><span class=\"line\">3000 transitioning from ZK_MIGRATION to SYNC_KRAFT_TO_ZK state</span><br><span class=\"line\">...</span><br><span class=\"line\">Performing a full metadata <span class=\"built_in\">sync</span> from KRaft to ZK.</span><br><span class=\"line\">Did not make any ZK writes when reconciling with KRaft state.</span><br><span class=\"line\">3000 transitioning ... to KRAFT_CONTROLLER_TO_BROKER_COMM</span><br><span class=\"line\">...</span><br><span class=\"line\">Sending RPCs to broker before moving to dual-write mode using at offset and epoch OffsetAndEpoch(offset=3179, epoch=2)</span><br><span class=\"line\">...</span><br><span class=\"line\">3000 transitioning ... to DUAL_WRITE state</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面的日志总体上表明，元数据迁移已成功完成并且控制器进入了双写（DUAL_WRITE）阶段。</p>\n</li>\n</ul>\n<h3 id=\"将三个Broker节点的配置修改为-KRaft-模式的-broker-节点\">将三个Broker节点的配置修改为 KRaft 模式的 broker 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改三个节点的配置文件 <code>server.properties</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 添加process.roles=broker</span></span><br><span class=\"line\">process.roles=broker</span><br><span class=\"line\"><span class=\"comment\"># 用 node.id 替换 broker.id，注意，node.id 需要与 broker.id 一致</span></span><br><span class=\"line\"><span class=\"comment\"># broker.id=1</span></span><br><span class=\"line\">node.id=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 去掉 zookeeper 相关配置</span></span><br><span class=\"line\"><span class=\"comment\"># Don&#x27;t set the IBP, KRaft uses &quot;metadata.version&quot; feature flag</span></span><br><span class=\"line\"><span class=\"comment\"># inter.broker.protocol.version=3.9</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove the migration enabled flag</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.metadata.migration.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove ZooKeeper client configuration</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别重新启动三个节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 kafka</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br><span class=\"line\"><span class=\"comment\"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class=\"line\">ps -ef | grep kafka | grep  <span class=\"string\">&quot;server\\.properties&quot;</span> | grep -v grep | awk <span class=\"string\">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class=\"built_in\">kill</span> -9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新启动 kafka</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<h3 id=\"将-Controller-节点的配置修改为-KRaft-模式的-controller-节点\">将 Controller 节点的配置修改为 KRaft 模式的 controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改 controller 节点的配置文件 <code>controller.properties</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 去掉去下内容</span></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.metadata.migration.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ZooKeeper client 连接</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重启启动 controller 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭后重新启动</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时你可以关闭 zookeeper 集群了，新的 kafka 集群将不再使用 ZooKeeper，也无法在恢复到 ZooKeeper 模式。</p>\n</li>\n</ul>\n<h3 id=\"加入新的-Controller-节点\">加入新的 Controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Controller 尽量保持 奇数个节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>之前已经在 <code>worker1</code> 节点上启动了 controller ，现在 <code>worker2</code> 和 <code>worker3</code> 上也来启动 controller 节点，并将它们加入到 kafka 集群中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在开始配置前，先将上面的 controller 节点 和 三个 broker 节点 的如下配置进行修改，并重启启动。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将 controller.quorum.bootstrap.servers 替换为 controller.quorum.voters</span></span><br><span class=\"line\">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.bootstrap.servers=worker1:9098</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.voters = 谁是正式投票成员（固定配置）</span></span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.bootstrap.servers = 临时找谁引导连接（迁移或初始化用）</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>作用</th>\n<th>适用阶段</th>\n<th>是否必需</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>controller.quorum.voters</code></strong></td>\n<td>定义 <strong>正式的 KRaft 控制器投票成员列表（voter set）</strong></td>\n<td>集群正常运行时</td>\n<td>✅ 是</td>\n<td>所有节点必须配置相同的值</td>\n</tr>\n<tr>\n<td><strong><code>controller.quorum.bootstrap.servers</code></strong></td>\n<td>定义 <strong>迁移阶段或初始化阶段的控制器连接地址（bootstrap controller endpoint）</strong></td>\n<td><strong>ZK → KRaft 迁移阶段</strong> 或 <strong>KRaft 集群初次启动</strong></td>\n<td>⚙️ 可选（仅特定阶段）</td>\n<td>用于在 controller quorum 尚未形成时的临时发现</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>参考 worker1 上的 controller 节点的配置文件 <code>controller.properties</code>，配置 woker2 的 controller 节点配置文件<code>controller.properties</code> ，worker3 也是类似的。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色，这里只能是controller</span></span><br><span class=\"line\">process.roles=controller</span><br><span class=\"line\"><span class=\"comment\"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class=\"line\">node.id=3001</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点</span></span><br><span class=\"line\">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># 配置监听器，注意端口不能重复</span></span><br><span class=\"line\">listeners=CONTROLLER://:9098</span><br><span class=\"line\">advertised.listeners=CONTROLLER://worker2:9098</span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录，这里存放的是元数据</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>初始化日志目录</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 只有 Controller 节点才需要初始化日志目录</span></span><br><span class=\"line\"><span class=\"comment\"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class=\"line\">kafka-storage.sh format -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别启动 worker2 和 worker3 上的 controller 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时新的 controller 节点不会立刻加入选举队列，新节点初始状态默认是 observer，需要执行下面的命令将节点加入选举队列</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别在 worker2 和 worker3 上执行</span></span><br><span class=\"line\">kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config /usr/local/kafka/kafka3/config/kraft/controller.properties add-controller</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看集群节点状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --replication</span><br><span class=\"line\">NodeId\tDirectoryId           \tLogEndOffset\tLag\tLastFetchTimestamp\tLastCaughtUpTimestamp\tStatus</span><br><span class=\"line\">3000  \tRJ4oOPGgTw-KxHFNn4SmiQ\t27820       \t0  \t1760696136345     \t1760696136345        \tLeader</span><br><span class=\"line\">3001  \tzGnWA7zYmRHG6bcTlFV2qA\t27820       \t0  \t1760696136259     \t1760696136259        \tFollower</span><br><span class=\"line\">3002  \tgIDkhOQJEHqg-GJBdezU1Q\t27820       \t0  \t1760696136257     \t1760696136257        \tFollower</span><br><span class=\"line\">2     \t9KeeAYKEQHT92DxqNSwYuA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\">1     \tQ8lr8JQ2vrDS35_DrI1MxA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\">3     \trgQR5wd_i5hLgU97dCKIvA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\"></span><br><span class=\"line\">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --status</span><br><span class=\"line\">ClusterId:              hp_Q0pihQ0ORcIvXlfHobQ</span><br><span class=\"line\">LeaderId:               3000</span><br><span class=\"line\">LeaderEpoch:            5</span><br><span class=\"line\">HighWatermark:          30094</span><br><span class=\"line\">MaxFollowerLag:         0</span><br><span class=\"line\">MaxFollowerLagTimeMs:   0</span><br><span class=\"line\">CurrentVoters:          [&#123;<span class=\"string\">&quot;id&quot;</span>: 3000, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;RJ4oOPGgTw-KxHFNn4SmiQ&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker1:9098&quot;</span>]&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3001, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;zGnWA7zYmRHG6bcTlFV2qA&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker2:9098&quot;</span>]&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3002, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;gIDkhOQJEHqg-GJBdezU1Q&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker3:9098&quot;</span>]&#125;]</span><br><span class=\"line\">CurrentObservers:       [&#123;<span class=\"string\">&quot;id&quot;</span>: 2, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;9KeeAYKEQHT92DxqNSwYuA&quot;</span>&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 1, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;Q8lr8JQ2vrDS35_DrI1MxA&quot;</span>&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;rgQR5wd_i5hLgU97dCKIvA&quot;</span>&#125;]</span><br></pre></td></tr></table></figure>\n<h3 id=\"加入-新的-Broker-节点\">加入 新的 Broker 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建新的 Broker 节点时，参考其它 Broker 节点 配置好配置文件 <code>server.properties</code>，并启动 Broker 节点即可。</p>\n</li>\n<li class=\"lvl-2\">\n<p>无需运行日志目录初始化命令，因为 Broker 节点只存放 消息 数据。</p>\n</li>\n</ul>\n<h2 id=\"迁移后注意事项\">迁移后注意事项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>迁移完成后，Kafka 客户端（Producer / Consumer / AdminClient）依然连接的是 Broker 节点，而不是 Controller 节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 在 ZooKeeper 模式与 KRaft 模式下的区别主要在于：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">控制平面（Control Plane）：ZK 模式下由 ZooKeeper + Controller Broker 共同管理；KRaft 模式下由 独立的 Controller 进程或角色 管理（通过 Raft 协议同步元数据）。</li>\n<li class=\"lvl-4\">数据平面（Data Plane）：无论是哪个模式，客户端发送、消费消息仍然是通过 Broker 节点 完成的。</li>\n<li class=\"lvl-4\">也就是说，Controller 管理集群元数据（主题、分区、副本、Leader 选举等），而 Broker 节点处理实际的消息流。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 官方文档：ZooKeeper到KRaft迁移 从 Zookeeper 模式迁移到 KRaft 模式（平滑迁移） ！！！迁移后将无法再恢复到 ZooKeeper 模式！！！ Kafka 官方在 3.4+ 引入了完整的 Zookeeper → KRaft 平滑迁移机制，称为 ZK to KRaft (ZkMigration)。 迁移背景与前提 项目 说明 支持版本 Kafka 3.4.0+（建议至少使用 3.6.x ，目前最新版为 3.9.x） 迁移目的 摆脱 ZooKeeper，完全切换为 KRaft 自管理模式 迁移模式 在线迁移（无停机或最小停机） 最终目标 Kafka 的控制器与元数据完全由 KRaft 管理，不再依赖 ZooKeeper。 整体迁移流程概览 阶段 控制器类型 Broker 模式 ZooKeeper 角色 KRaft 角色 特征说明 初始阶段 ZooKeeper 控制器 全部为 ZK 模式 管理所有元数据 尚未启用 所有 Broker 都运行在 ZK 模式下，由 ZK 控制器管理集群。 初始元数据加载阶段 KRaft 控制器开始加载 部分（或全部）仍为 ZK 模式 提供元数据源 从 ZK 加载元数据 KRaft 法定节点（controller.quorum.voters）从 ZK 中读取并同步当前集群元数据。 混合阶段 KRaft 控制器 部分 ZK 模式，部分 KRaft 模式 保留只读元数据 管理并更新元数据 KRaft 控制器成为主控，ZK 仍存在但只提供读取，Broker 可处于不同模式（混合状态）。 双写阶段 KRaft 控制器 全部为 KRaft 模式 接收 KRaft 同步写入 管理元数据并写入 ZK 所有 Broker 都运行在 KRaft 模式，控制器将元数据同时写入 ZK 和 KRaft 日志。 迁移完成阶段 KRaft 控制器 全部为 KRaft 模式 不再使用 独立运行 停止向 ZK 写入元数据，ZK 可安全关闭，Kafka 完全运行在无 Zookeeper 的 KRaft 模式下。 开始迁移 这里以前文 Kafka 的安装：基于 Zookeeper 中的3个节点的集群为例。 启动一个 Controller 节点 在任意一个节点上启动一个 Controller 节点，这里为 worker1 启动前需要先获取当前 Kafka 集群的 Cluster ID 1234567$ zookeeper-shell.sh localhost:2181 get /cluster/idConnecting to localhost:2181WATCHER::WatchedEvent state:SyncConnected type:None path:null&#123;&quot;version&quot;:&quot;1&quot;,&quot;id&quot;:&quot;hp_Q0pihQ0ORcIvXlfHobQ&quot;&#125; 准备好 Controller 节点的配置文件，这里可以用 config/kraft/controller.properties 为模板进行修改 123456789101112131415161718192021222324# 配置当前节点的角色，这里只能是controllerprocess.roles=controller# 节点ID，不能与现有Broker节点的ID一致node.id=3000# 配置集群的投票节点，因为我们当前只启动了一个controller节点，所以只能配置一个投票节点controller.quorum.bootstrap.servers=worker1:9098# 配置监听器，注意端口不能重复listeners=CONTROLLER://:9098advertised.listeners=CONTROLLER://worker1:9098controller.listener.names=CONTROLLER# 日志存放目录，这里存放的是元数据，在格式化时这个目录必须为空目录log.dirs=/usr/local/kafka/dataDir/kraft-meta# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程zookeeper.metadata.migration.enable=true# ZooKeeper client 连接zookeeper.connect=worker1:2181,worker2:2181,worker3:2181# 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。# 注意这里要与原先的 server.properties 中配置的监听器名称一致inter.broker.listener.name=PLAINTEXT# 其它参数尽量保持与旧集群的配置一致 启动 Controller 节点 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。 12345# 格式化元数据目录，log.dirs 参数指定元数据存放目录，首次运行前必须为空目录# -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster IDkafka-storage.sh format --standalone -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties# 启动，这里没有后台启动是为了方便观察日志输出kafka-server-start.sh /usr/local/kafka/kafka3/config/kraft/controller.properties 模式 format 命令 quorum 状态 是否从 ZK 加载 迁移阶段（standalone） --standalone 无（单节点） ✅ 是 正式 KRaft 模式 无 --standalone ✅ 多节点 ❌ 否（独立运行） 将原先的三个节点作为 Broker 节点重新启动 修改原先的配置文件 server.properties，只需要修改如下内容即可 1234567891011121314# 在最后加入 CONTROLLER:PLAINTEXTlistener.security.protocol.map=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,CONTROLLER:PLAINTEXT## 以下是新加入的 配置项# Set the IBP，当前 kafka 版本是 3.9.1，所以这里设置为 3.9inter.broker.protocol.version=3.9# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程zookeeper.metadata.migration.enable=true# KRaft controller quorum configuration，因为目前只启动了一个 controller 节点，所以只能配置一个投票节点controller.quorum.bootstrap.servers=worker1:9098# 控制器监听器名称，要与 contreller 节点配置文件 controller.properties 中的配置一致controller.listener.names=CONTROLLER 分别重新启动三个节点 1234567# 关闭 kafkakafka-server-stop.sh# 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.propertiesps -ef | grep kafka | grep &quot;server\\.properties&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9# 重新启动 kafkakafka-server-start.sh /usr/local/kafka/kafka3/config/server.properties 当三个节点都以必要的配置重新启动后，迁移将自动开始。迁移完成后，可以在 Controller(worker1)节点 上看到类似如下日志： 1234567891011121314151617181920# ✅ 意味：从 ZooKeeper 到 KRaft 的初始元数据迁移已成功，共写入 62 条记录，当前 KRaft metadata offset 为 3179。这是迁移成功的明确证据。Completed migration of metadata from ZooKeeper to KRaft. 62 records were generated in 300 ms across 1 batches. The average time spent waiting on a batch was 97.00 ms. The record types were &#123;TOPIC_RECORD=3, PARTITION_RECORD=56, CONFIG_RECORD=3&#125;. The current metadata offset is now 3179 with an epoch of 2. Saw 3 brokers in the migrated metadata [1, 2, 3]. (org.apache.kafka.metadata.migration.KRaftMigrationDriver)# ✅ 意味：控制器已加载并生效新元数据与 feature set（与 offset 3179 对应）。Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures=&#123;metadata.version=21&#125;, finalizedFeaturesEpoch=3179). (org.apache.kafka.metadata.publisher.FeaturesPublisher)# ✅ 意味：内部迁移状态已更新，KRaft 上有了写入位置记录。Finished initial migration of ZK metadata to KRaft in 3486479 ns. Transitioned migration state from ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=-1, kraftMetadataEpoch=-1, lastUpdatedTimeMs=1760682050169, migrationZkVersion=1, controllerZkEpoch=3, controllerZkVersion=3&#125; to ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=3179, kraftMetadataEpoch=2, lastUpdatedTimeMs=1760682050169, migrationZkVersion=2, controllerZkEpoch=3, controllerZkVersion=3&#125; (org.apache.kafka.metadata.migration.KRaftMigrationDriver)# ✅ 意味：迁移流程按预期推进：先把 KRaft 的元数据与 ZK 对齐（sync），然后与 brokers 建立通信，最终进入 DUAL_WRITE（双写）。DUAL_WRITE 阶段表示控制器在写入 KRaft metadata log 的同时，仍然会把必要的写操作也写回 ZooKeeper（双写）——直到迁移完全完成并确认可以停止写 ZK 为止。3000 transitioning from ZK_MIGRATION to SYNC_KRAFT_TO_ZK state...Performing a full metadata sync from KRaft to ZK.Did not make any ZK writes when reconciling with KRaft state.3000 transitioning ... to KRAFT_CONTROLLER_TO_BROKER_COMM...Sending RPCs to broker before moving to dual-write mode using at offset and epoch OffsetAndEpoch(offset=3179, epoch=2)...3000 transitioning ... to DUAL_WRITE state 上面的日志总体上表明，元数据迁移已成功完成并且控制器进入了双写（DUAL_WRITE）阶段。 将三个Broker节点的配置修改为 KRaft 模式的 broker 节点 修改三个节点的配置文件 server.properties 123456789101112131415# 添加process.roles=brokerprocess.roles=broker# 用 node.id 替换 broker.id，注意，node.id 需要与 broker.id 一致# broker.id=1node.id=1# 去掉 zookeeper 相关配置# Don&#x27;t set the IBP, KRaft uses &quot;metadata.version&quot; feature flag# inter.broker.protocol.version=3.9# Remove the migration enabled flag# zookeeper.metadata.migration.enable=true# Remove ZooKeeper client configuration# zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 分别重新启动三个节点 1234567# 关闭 kafkakafka-server-stop.sh# 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.propertiesps -ef | grep kafka | grep &quot;server\\.properties&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9# 重新启动 kafkakafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 将 Controller 节点的配置修改为 KRaft 模式的 controller 节点 修改 controller 节点的配置文件 controller.properties 123456## 去掉去下内容# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程# zookeeper.metadata.migration.enable=true# ZooKeeper client 连接# zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 重启启动 controller 节点 12# 关闭后重新启动kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties 此时你可以关闭 zookeeper 集群了，新的 kafka 集群将不再使用 ZooKeeper，也无法在恢复到 ZooKeeper 模式。 加入新的 Controller 节点 Controller 尽量保持 奇数个节点。 之前已经在 worker1 节点上启动了 controller ，现在 worker2 和 worker3 上也来启动 controller 节点，并将它们加入到 kafka 集群中。 在开始配置前，先将上面的 controller 节点 和 三个 broker 节点 的如下配置进行修改，并重启启动。 123456# 将 controller.quorum.bootstrap.servers 替换为 controller.quorum.voterscontroller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098# controller.quorum.bootstrap.servers=worker1:9098# controller.quorum.voters = 谁是正式投票成员（固定配置）# controller.quorum.bootstrap.servers = 临时找谁引导连接（迁移或初始化用） 配置项 作用 适用阶段 是否必需 说明 controller.quorum.voters 定义 正式的 KRaft 控制器投票成员列表（voter set） 集群正常运行时 ✅ 是 所有节点必须配置相同的值 controller.quorum.bootstrap.servers 定义 迁移阶段或初始化阶段的控制器连接地址（bootstrap controller endpoint） ZK → KRaft 迁移阶段 或 KRaft 集群初次启动 ⚙️ 可选（仅特定阶段） 用于在 controller quorum 尚未形成时的临时发现 参考 worker1 上的 controller 节点的配置文件 controller.properties，配置 woker2 的 controller 节点配置文件controller.properties ，worker3 也是类似的。 12345678910111213141516# 配置当前节点的角色，这里只能是controllerprocess.roles=controller# 节点ID，不能与现有Broker节点的ID一致node.id=3001# 配置集群的投票节点controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098# 配置监听器，注意端口不能重复listeners=CONTROLLER://:9098advertised.listeners=CONTROLLER://worker2:9098controller.listener.names=CONTROLLER# 日志存放目录，这里存放的是元数据log.dirs=/usr/local/kafka/dataDir/kraft-meta# 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。# 注意这里要与原先的 server.properties 中配置的监听器名称一致inter.broker.listener.name=PLAINTEXT 初始化日志目录 123# 只有 Controller 节点才需要初始化日志目录# -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster IDkafka-storage.sh format -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties 分别启动 worker2 和 worker3 上的 controller 节点 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties 此时新的 controller 节点不会立刻加入选举队列，新节点初始状态默认是 observer，需要执行下面的命令将节点加入选举队列 12# 分别在 worker2 和 worker3 上执行kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config /usr/local/kafka/kafka3/config/kraft/controller.properties add-controller 查看集群节点状态 123456789101112131415161718$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --replicationNodeId DirectoryId LogEndOffset Lag LastFetchTimestamp LastCaughtUpTimestamp Status3000 RJ4oOPGgTw-KxHFNn4SmiQ 27820 0 1760696136345 1760696136345 Leader3001 zGnWA7zYmRHG6bcTlFV2qA 27820 0 1760696136259 1760696136259 Follower3002 gIDkhOQJEHqg-GJBdezU1Q 27820 0 1760696136257 1760696136257 Follower2 9KeeAYKEQHT92DxqNSwYuA 27820 0 1760696136257 1760696136257 Observer1 Q8lr8JQ2vrDS35_DrI1MxA 27820 0 1760696136257 1760696136257 Observer3 rgQR5wd_i5hLgU97dCKIvA 27820 0 1760696136257 1760696136257 Observer$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --statusClusterId: hp_Q0pihQ0ORcIvXlfHobQLeaderId: 3000LeaderEpoch: 5HighWatermark: 30094MaxFollowerLag: 0MaxFollowerLagTimeMs: 0CurrentVoters: [&#123;&quot;id&quot;: 3000, &quot;directoryId&quot;: &quot;RJ4oOPGgTw-KxHFNn4SmiQ&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker1:9098&quot;]&#125;, &#123;&quot;id&quot;: 3001, &quot;directoryId&quot;: &quot;zGnWA7zYmRHG6bcTlFV2qA&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker2:9098&quot;]&#125;, &#123;&quot;id&quot;: 3002, &quot;directoryId&quot;: &quot;gIDkhOQJEHqg-GJBdezU1Q&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker3:9098&quot;]&#125;]CurrentObservers: [&#123;&quot;id&quot;: 2, &quot;directoryId&quot;: &quot;9KeeAYKEQHT92DxqNSwYuA&quot;&#125;, &#123;&quot;id&quot;: 1, &quot;directoryId&quot;: &quot;Q8lr8JQ2vrDS35_DrI1MxA&quot;&#125;, &#123;&quot;id&quot;: 3, &quot;directoryId&quot;: &quot;rgQR5wd_i5hLgU97dCKIvA&quot;&#125;] 加入 新的 Broker 节点 创建新的 Broker 节点时，参考其它 Broker 节点 配置好配置文件 server.properties，并启动 Broker 节点即可。 无需运行日志目录初始化命令，因为 Broker 节点只存放 消息 数据。 迁移后注意事项 迁移完成后，Kafka 客户端（Producer / Consumer / AdminClient）依然连接的是 Broker 节点，而不是 Controller 节点。 Kafka 在 ZooKeeper 模式与 KRaft 模式下的区别主要在于： 控制平面（Control Plane）：ZK 模式下由 ZooKeeper + Controller Broker 共同管理；KRaft 模式下由 独立的 Controller 进程或角色 管理（通过 Raft 协议同步元数据）。 数据平面（Data Plane）：无论是哪个模式，客户端发送、消费消息仍然是通过 Broker 节点 完成的。 也就是说，Controller 管理集群元数据（主题、分区、副本、Leader 选举等），而 Broker 节点处理实际的消息流。","summary":"摘要 本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 官方文档：ZooKeeper到KRaft迁移","date_published":"2025-10-16T14:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/","url":"https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/","title":"Kafka 的安装：基于 KRaft 模式","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p>本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"KRaft-简介\">KRaft 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kraft 是 Kafka 从 2.8.0 版本 开始⽀持的⼀种新的集群架构⽅式。其⽬的主要是为了摆脱Kafka对Zookeeper的依赖。因为以往基于Zookeeper搭建的集群，增加了Kafka演进与运维的难度，逐渐开始成为Kakfa拥抱云原⽣的⼀种障碍。使⽤Kraft集群后，Kafka集群就不再需要依赖Zookeeper，将之前基于Zookeeper管理的集群数据，转为由Kafka集群⾃⼰管理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>传统的Kafka集群，会将每个节点的状态信息统一保存在Zookeeper中，并通过Zookeeper动态选举产生一个Controller节点，通过Controller节点来管理Kafka集群，比如触发Partition的选举。而在Kraft集群中，会固定配置几台Broker节点来共同担任Controller的角色，各组Partition的Leader节点就会由这些Controller选举产生。原本保存在Zookeeper中的元数据也转而保存到Controller节点中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>🧭 Kafka KRaft 模式 vs Zookeeper 模式 对比表</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">对比项</th>\n<th style=\"text-align:left\"><strong>KRaft 模式（Kafka Raft 模式）</strong></th>\n<th style=\"text-align:left\"><strong>Zookeeper 模式（传统模式）</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>架构结构</strong></td>\n<td style=\"text-align:left\">去中心化架构，Kafka 自身内置控制平面，不依赖外部 Zookeeper。</td>\n<td style=\"text-align:left\">控制平面依赖外部 Zookeeper 集群，Kafka Broker 只负责数据平面。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>组件数量</strong></td>\n<td style=\"text-align:left\">无需部署 Zookeeper，只有 Kafka Broker 节点。</td>\n<td style=\"text-align:left\">需要单独维护 Zookeeper 集群。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>元数据存储</strong></td>\n<td style=\"text-align:left\">元数据存储在 Kafka 自身的内置日志中（<code>__cluster_metadata</code> topic）。</td>\n<td style=\"text-align:left\">元数据存储在 Zookeeper 的 znode 树结构中。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>一致性协议</strong></td>\n<td style=\"text-align:left\">使用 Kafka 自己实现的 Raft 协议（KRaft）来保证元数据一致性。</td>\n<td style=\"text-align:left\">使用 ZAB（Zookeeper Atomic Broadcast）协议保证一致性。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>启动速度</strong></td>\n<td style=\"text-align:left\">更快，控制器内嵌于 Broker 中，不需要等待外部 Zookeeper 启动。</td>\n<td style=\"text-align:left\">启动依赖 Zookeeper，启动顺序和连通性要求更严格。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>容错性</strong></td>\n<td style=\"text-align:left\">Raft 控制器具备日志复制机制，容错性与 Kafka 数据副本一致。</td>\n<td style=\"text-align:left\">容错性由 Zookeeper 决定，Zookeeper 挂掉可能导致 Kafka 控制面不可用。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>扩展性</strong></td>\n<td style=\"text-align:left\">元数据存储在 Kafka 主题中，水平扩展能力更强。</td>\n<td style=\"text-align:left\">Zookeeper 在高分区数场景下易成为性能瓶颈。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>运维复杂度</strong></td>\n<td style=\"text-align:left\">无需维护 Zookeeper 集群，统一运维 Kafka 即可。</td>\n<td style=\"text-align:left\">需要额外维护 Zookeeper 集群（监控、扩容、升级）。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>数据恢复</strong></td>\n<td style=\"text-align:left\">元数据恢复与 Kafka 主题一致，可通过日志回放恢复。</td>\n<td style=\"text-align:left\">Zookeeper 数据恢复相对复杂，依赖快照和事务日志。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>安全机制</strong></td>\n<td style=\"text-align:left\">统一 Kafka 的安全机制（SASL、SSL、ACL 等）。</td>\n<td style=\"text-align:left\">Zookeeper 有独立的安全配置体系，需单独管理。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>性能表现</strong></td>\n<td style=\"text-align:left\">元数据操作延迟更低（控制器与 Broker 本地通信）。</td>\n<td style=\"text-align:left\">元数据操作需要跨进程网络通信，延迟更高。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>控制器角色</strong></td>\n<td style=\"text-align:left\">由 Broker 中的控制器 quorum 选举产生（支持多控制器候选）。</td>\n<td style=\"text-align:left\">由 Zookeeper 选举控制器（单点控制器）。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>分区与副本管理</strong></td>\n<td style=\"text-align:left\">全部元数据存储在 Kafka 自身，可实现更快的分区变更和扩容。</td>\n<td style=\"text-align:left\">分区、副本元数据同步依赖 Zookeeper，性能相对较低。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>版本支持</strong></td>\n<td style=\"text-align:left\">从 Kafka 2.8 开始引入，Kafka 3.3+ 已经非常稳定，Kafka 3.5+ 默认推荐。</td>\n<td style=\"text-align:left\">Kafka 3.5 开始标记为“Legacy”，未来版本计划移除支持。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>兼容性</strong></td>\n<td style=\"text-align:left\">可通过元数据迁移工具从 Zookeeper 模式平滑迁移。</td>\n<td style=\"text-align:left\">不能直接迁移到 KRaft，需要工具辅助。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>运维监控</strong></td>\n<td style=\"text-align:left\">单一系统可监控（Kafka 自带的 JMX、Prometheus 等）。</td>\n<td style=\"text-align:left\">Kafka 与 Zookeeper 各自需要独立监控体系。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>未来发展方向</strong></td>\n<td style=\"text-align:left\">官方推荐和默认模式（Zookeeper 模式将逐步淘汰）。</td>\n<td style=\"text-align:left\">官方已不再建议新集群使用。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Kafka-的-KRaft-集群配置\">Kafka 的 KRaft 集群配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在Kafka的config目录下，提供了一个kraft的文件夹，在这里面提供了三个Kraft协议的参考配置文件</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">broker.properties: 数据节点，client连接时只连接broker数据节点</li>\n<li class=\"lvl-4\">controller.properties: Controller控制节点</li>\n<li class=\"lvl-4\">server.properties: 即可以是数据节点，又可以是Controller控制节点。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>实际上这些配置文件中的配置项基本与 serrver.properties 一致，只是去除了与 zookeeper 相关的配置项，同时增加了一些 Kraft 模式下的配置项。关于 server.properties 的配置项，请参考 <a href=\"https://kafka.apache.org/39/documentation/#brokerconfigs\">Kafka 官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里以 <code>kraft/serrver.properties</code> 为例进行修改，配置三个节点的Kafka集群，每个节点即是 controller 节点，也可以是 broker 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下面这四个配置项是 kraft 模式下新增加的</span></span><br><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色。Controller相当于Zookeeper的功能，负责集群管理。Broker提供具体的消息转发服务。</span></span><br><span class=\"line\"><span class=\"comment\"># 一个节点可以即是 Controller 又是 Broker，也可以只是 Controller 或 Broker。</span></span><br><span class=\"line\">process.roles=broker,controller</span><br><span class=\"line\"><span class=\"comment\"># 配置当前节点的id。与普通集群一样，要求集群内每个节点的ID不能重复。</span></span><br><span class=\"line\">node.id=1</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点。其中@前面的是节点的id，后面是节点的地址和端口，这个端口跟客户端访问的端口是不一样的，要与 CONTROLLER 协议对应的端口一致，这里配置为 9098</span></span><br><span class=\"line\"><span class=\"comment\"># 通常将集群内的所有Controllor节点都配置进去。</span></span><br><span class=\"line\">controller.quorum.voters=1@worker1:9098,2@worker2:9098,3@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># Controller服务协议的别名。默认就是CONTROLLER</span></span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 以下配置项与之前一样，按需进行配置即可</span></span><br><span class=\"line\"><span class=\"comment\"># 集群间通信仍使用内网</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 配置监听服务。不同的服务可以绑定不同的接口。这种配置方式在端口前面是省略了一个主机IP的，主机IP默认是使用的java.net.InetAddress.getCanonicalHostName()，这里同时开启外网访问，关于 sasl_plaintext 、sasl_ssl协议 的配置方式参考前文 kafka 通信协议</span></span><br><span class=\"line\">listeners=PLAINTEXT://:9092,CONTROLLER://:9098,EXTERNAL://0.0.0.0:9093</span><br><span class=\"line\"><span class=\"comment\"># Broker对客户端暴露的服务地址。基于PLAINTEXT协议。这里要替换为各个节点的IP地址</span></span><br><span class=\"line\">advertised.listeners=PLAINTEXT://worker1:9092,CONTROLLER://worker1:9098,EXTERNAL://161.189.227.200:9093</span><br><span class=\"line\"><span class=\"comment\"># 将监听器名称映射到安全协议类型，这里 CONTROLLER 协议对应的安全协议类型为 PLAINTEXT</span></span><br><span class=\"line\">listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 数据文件地址。默认配置在/tmp目录下。</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-logs</span><br><span class=\"line\"><span class=\"comment\"># topic默认的partition分区数。</span></span><br><span class=\"line\">num.partitions=2</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动Kafka集群\">启动Kafka集群</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动前要对日志目录进行格式化</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在worker1节点上生成集群ID</span></span><br><span class=\"line\">$ kafka-storage.sh random-uuid</span><br><span class=\"line\">oGwJsVANRDKYwE7Lhn2zIA</span><br><span class=\"line\"><span class=\"comment\"># 然后在集群的每个节点上执行如下命令，格式化日志目录，注意 --cluster-id 必须一致</span></span><br><span class=\"line\"><span class=\"comment\"># 必须在第一次启动前执行</span></span><br><span class=\"line\"><span class=\"comment\"># 不可以重复执行，否则会清空数据目录并破坏已有元数据</span></span><br><span class=\"line\"><span class=\"comment\"># 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。</span></span><br><span class=\"line\"><span class=\"comment\"># 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</span></span><br><span class=\"line\">$ kafka-storage.sh format --cluster-id oGwJsVANRDKYwE7Lhn2zIA --config /usr/local/kafka/kafka3/config/kraft/server.properties</span><br><span class=\"line\"><span class=\"comment\">## 格式化后会在日志目录下生成两个文件</span></span><br><span class=\"line\"><span class=\"comment\"># bootstrap.checkpoint # 存储元数据日志（Metadata Log）对应的初始快照偏移量（snapshot offset）。用于控制器在启动时恢复状态的起点。</span></span><br><span class=\"line\"><span class=\"comment\"># meta.properties # 存储节点元信息：cluster.id、node.id、version 等</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动集群，所以节点启动 kafka 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/server.properties</span><br></pre></td></tr></table></figure>\n<h2 id=\"注意事项\">注意事项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 集群的启动顺序不能乱，必须先启动 Controller 节点，再启动 Broker 节点，我们这里是将节点同时做为Controller 和 Broker ，实际生产环境建议分开。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Controller 节点至少3个，建议配置为奇数个。Broker 节点数量任意，但建议至少2个以上，以保证分区的备份可以分开存储。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Client 仅能与 Broker 节点通信，不能与 Controller 节点通信。</p>\n</li>\n</ul>\n<h2 id=\"Kafka-4-0-的新特性\">Kafka 4.0 的新特性</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>彻底以 KRaft（Kafka Raft）取代 ZooKeeper（KRaft 成为默认且唯一的元数据管理）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：4.x 系列标志性变化是完全移除 ZooKeeper，元数据由 KRaft 管理（Controller 与 Broker 更紧密集成）。对运维而言：不再部署/维护 ZooKeeper 集群、元数据迁移/格式化步骤是升级时的关键。</li>\n<li class=\"lvl-4\">影响/提示：必须按官方迁移流程把元数据从 ZK 导入 KRaft（若从旧版本升级）。测试迁移/备份元数据是必须项。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>新的 consumer-group 协议（更高效的 rebalance/群组管理）与消费模型改进（包括“Queues/Shared Group”支持）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：引入/稳定了新的 Consumer Group 协议（相关 KIP），显著改善大群组下的重平衡延迟与稳定性；同时引入了类似“队列/共享组（Queues for Kafka）”的消费模式（用例：点对点消费），允许多消费者同时处理同一分区消息。</li>\n<li class=\"lvl-4\">影响/提示：如果你有大规模消费者群组或依赖旧 rebalance 行为，需要测试新协议行为；某些客户端配置/行为可能需要调整。</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>指标类别</th>\n<th>旧协议（Eager Rebalance）</th>\n<th>新协议（Incremental / Cooperative Rebalance）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>重平衡延迟（大规模群组）</td>\n<td>约 <strong>60 秒</strong>（万级消费者规模）</td>\n<td>小于 <strong>1 秒</strong>（测试显示在千级任务时可在一分钟内完成） (<a href=\"https://www.confluent.io/blog/incremental-cooperative-rebalancing-in-kafka/?utm_source=chatgpt.com\" title=\"Incremental Cooperative Rebalancing in Apache Kafka\">Confluent</a>)</td>\n</tr>\n<tr>\n<td>资源消耗（CPU）</td>\n<td>较高（在重平衡期间系统停止或大规模迁移资源）</td>\n<td>据称可降低约 <strong>70%</strong> 的 CPU／系统中断负荷（社区经验）</td>\n</tr>\n<tr>\n<td>消费者群组扩展上限</td>\n<td>适用于“千级消费者”规模</td>\n<td>可扩展至“十万级消费者”规模（理论/社区宣称）</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>传统消费者组（Consumer Group）</strong></th>\n<th><strong>共享组（Shared Group / Queues for Kafka）</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>并行消费模型</strong></td>\n<td>分区数 = 消费者数（一个分区只能被一个消费者消费）</td>\n<td>消费者数 &gt; 分区数（同一分区可由多个消费者并行处理）</td>\n</tr>\n<tr>\n<td><strong>消息确认机制</strong></td>\n<td>通过提交偏移量（Offset Commit）实现确认</td>\n<td>每条消息单独确认（ACK/NACK 机制）</td>\n</tr>\n<tr>\n<td><strong>投递语义</strong></td>\n<td><strong>At-Least-Once</strong>（至少一次投递）</td>\n<td><strong>Exactly-Once（可选）</strong>，支持精确一次处理</td>\n</tr>\n<tr>\n<td><strong>典型场景</strong></td>\n<td>流式日志、监控、顺序性要求高的场景</td>\n<td>任务队列、并行计算、高吞吐任务处理</td>\n</tr>\n<tr>\n<td><strong>实现方式</strong></td>\n<td>基于 Topic-Partition 分配与偏移管理</td>\n<td>基于共享队列模型，允许多消费者竞争消费同一分区</td>\n</tr>\n<tr>\n<td><strong>Kafka 版本支持</strong></td>\n<td>Kafka ≤ 3.x</td>\n<td>Kafka 4.x 引入（KIP-932 “Queues for Kafka”）</td>\n</tr>\n<tr>\n<td><strong>优势</strong></td>\n<td>顺序保证强、模型成熟稳定</td>\n<td>并行能力强、吞吐提升、支持精确一次语义</td>\n</tr>\n<tr>\n<td><strong>劣势</strong></td>\n<td>分区限制吞吐，扩展受限</td>\n<td>顺序性可能减弱，实现更复杂</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除长期弃用的旧 API / 协议（向后不兼容的清理）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：4.x 移除了那些已弃用 ≥12 个月的接口/协议，旨在简化代码库并鼓励采用新功能。</li>\n<li class=\"lvl-4\">影响/提示：升级前务必检查你使用到的 Broker/Client/Streams/Connect API 是否依赖被移除的功能；测试客户端与第三方 Connector/插件兼容性。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Java 运行环境最低版本更新：Clients/Streams 与 Broker/Tools 的 JDK 要求提高</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：Kafka 4.x 将客户端（Kafka Clients、Kafka Streams）与 Broker/Connect/工具分别提出了更高的 Java baseline（Clients/Streams 最低 Java 11，Broker/Connect/Tools 最低 Java 17 等）。</li>\n<li class=\"lvl-4\">影响/提示：升级集群前先统一平台 JDK 版本，CI/CD/容器镜像也要对应更新。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>许多新的 KIP（功能增强）与性能/可观测性改进</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：包含改进的 Streams rebalance、更多 Admin/运维命令、节点注册/列举能力、插件/指标扩展点等（多项 KIP 在 4.0/4.1 陆续落地）。这些改进覆盖 Broker、Controller、Producer、Consumer、Admin 和 Streams 子系统。</li>\n<li class=\"lvl-4\">影响/提示：运维与监控面板可能受益（新增可观测指标/API）；如果你有自定义插件或监控接入，需要检查新的插件/metrics 注册机制。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。 KRaft 简介 Kraft 是 Kafka 从 2.8.0 版本 开始⽀持的⼀种新的集群架构⽅式。其⽬的主要是为了摆脱Kafka对Zookeeper的依赖。因为以往基于Zookeeper搭建的集群，增加了Kafka演进与运维的难度，逐渐开始成为Kakfa拥抱云原⽣的⼀种障碍。使⽤Kraft集群后，Kafka集群就不再需要依赖Zookeeper，将之前基于Zookeeper管理的集群数据，转为由Kafka集群⾃⼰管理。 传统的Kafka集群，会将每个节点的状态信息统一保存在Zookeeper中，并通过Zookeeper动态选举产生一个Controller节点，通过Controller节点来管理Kafka集群，比如触发Partition的选举。而在Kraft集群中，会固定配置几台Broker节点来共同担任Controller的角色，各组Partition的Leader节点就会由这些Controller选举产生。原本保存在Zookeeper中的元数据也转而保存到Controller节点中。 🧭 Kafka KRaft 模式 vs Zookeeper 模式 对比表 对比项 KRaft 模式（Kafka Raft 模式） Zookeeper 模式（传统模式） 架构结构 去中心化架构，Kafka 自身内置控制平面，不依赖外部 Zookeeper。 控制平面依赖外部 Zookeeper 集群，Kafka Broker 只负责数据平面。 组件数量 无需部署 Zookeeper，只有 Kafka Broker 节点。 需要单独维护 Zookeeper 集群。 元数据存储 元数据存储在 Kafka 自身的内置日志中（__cluster_metadata topic）。 元数据存储在 Zookeeper 的 znode 树结构中。 一致性协议 使用 Kafka 自己实现的 Raft 协议（KRaft）来保证元数据一致性。 使用 ZAB（Zookeeper Atomic Broadcast）协议保证一致性。 启动速度 更快，控制器内嵌于 Broker 中，不需要等待外部 Zookeeper 启动。 启动依赖 Zookeeper，启动顺序和连通性要求更严格。 容错性 Raft 控制器具备日志复制机制，容错性与 Kafka 数据副本一致。 容错性由 Zookeeper 决定，Zookeeper 挂掉可能导致 Kafka 控制面不可用。 扩展性 元数据存储在 Kafka 主题中，水平扩展能力更强。 Zookeeper 在高分区数场景下易成为性能瓶颈。 运维复杂度 无需维护 Zookeeper 集群，统一运维 Kafka 即可。 需要额外维护 Zookeeper 集群（监控、扩容、升级）。 数据恢复 元数据恢复与 Kafka 主题一致，可通过日志回放恢复。 Zookeeper 数据恢复相对复杂，依赖快照和事务日志。 安全机制 统一 Kafka 的安全机制（SASL、SSL、ACL 等）。 Zookeeper 有独立的安全配置体系，需单独管理。 性能表现 元数据操作延迟更低（控制器与 Broker 本地通信）。 元数据操作需要跨进程网络通信，延迟更高。 控制器角色 由 Broker 中的控制器 quorum 选举产生（支持多控制器候选）。 由 Zookeeper 选举控制器（单点控制器）。 分区与副本管理 全部元数据存储在 Kafka 自身，可实现更快的分区变更和扩容。 分区、副本元数据同步依赖 Zookeeper，性能相对较低。 版本支持 从 Kafka 2.8 开始引入，Kafka 3.3+ 已经非常稳定，Kafka 3.5+ 默认推荐。 Kafka 3.5 开始标记为“Legacy”，未来版本计划移除支持。 兼容性 可通过元数据迁移工具从 Zookeeper 模式平滑迁移。 不能直接迁移到 KRaft，需要工具辅助。 运维监控 单一系统可监控（Kafka 自带的 JMX、Prometheus 等）。 Kafka 与 Zookeeper 各自需要独立监控体系。 未来发展方向 官方推荐和默认模式（Zookeeper 模式将逐步淘汰）。 官方已不再建议新集群使用。 Kafka 的 KRaft 集群配置 在Kafka的config目录下，提供了一个kraft的文件夹，在这里面提供了三个Kraft协议的参考配置文件 broker.properties: 数据节点，client连接时只连接broker数据节点 controller.properties: Controller控制节点 server.properties: 即可以是数据节点，又可以是Controller控制节点。 实际上这些配置文件中的配置项基本与 serrver.properties 一致，只是去除了与 zookeeper 相关的配置项，同时增加了一些 Kraft 模式下的配置项。关于 server.properties 的配置项，请参考 Kafka 官方文档 这里以 kraft/serrver.properties 为例进行修改，配置三个节点的Kafka集群，每个节点即是 controller 节点，也可以是 broker 节点 12345678910111213141516171819202122232425# 下面这四个配置项是 kraft 模式下新增加的# 配置当前节点的角色。Controller相当于Zookeeper的功能，负责集群管理。Broker提供具体的消息转发服务。# 一个节点可以即是 Controller 又是 Broker，也可以只是 Controller 或 Broker。process.roles=broker,controller# 配置当前节点的id。与普通集群一样，要求集群内每个节点的ID不能重复。node.id=1# 配置集群的投票节点。其中@前面的是节点的id，后面是节点的地址和端口，这个端口跟客户端访问的端口是不一样的，要与 CONTROLLER 协议对应的端口一致，这里配置为 9098# 通常将集群内的所有Controllor节点都配置进去。controller.quorum.voters=1@worker1:9098,2@worker2:9098,3@worker3:9098# Controller服务协议的别名。默认就是CONTROLLERcontroller.listener.names=CONTROLLER# 以下配置项与之前一样，按需进行配置即可# 集群间通信仍使用内网inter.broker.listener.name=PLAINTEXT# 配置监听服务。不同的服务可以绑定不同的接口。这种配置方式在端口前面是省略了一个主机IP的，主机IP默认是使用的java.net.InetAddress.getCanonicalHostName()，这里同时开启外网访问，关于 sasl_plaintext 、sasl_ssl协议 的配置方式参考前文 kafka 通信协议listeners=PLAINTEXT://:9092,CONTROLLER://:9098,EXTERNAL://0.0.0.0:9093# Broker对客户端暴露的服务地址。基于PLAINTEXT协议。这里要替换为各个节点的IP地址advertised.listeners=PLAINTEXT://worker1:9092,CONTROLLER://worker1:9098,EXTERNAL://161.189.227.200:9093# 将监听器名称映射到安全协议类型，这里 CONTROLLER 协议对应的安全协议类型为 PLAINTEXTlistener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT# 数据文件地址。默认配置在/tmp目录下。log.dirs=/usr/local/kafka/dataDir/kraft-logs# topic默认的partition分区数。num.partitions=2 启动Kafka集群 启动前要对日志目录进行格式化 123456789101112# 在worker1节点上生成集群ID$ kafka-storage.sh random-uuidoGwJsVANRDKYwE7Lhn2zIA# 然后在集群的每个节点上执行如下命令，格式化日志目录，注意 --cluster-id 必须一致# 必须在第一次启动前执行# 不可以重复执行，否则会清空数据目录并破坏已有元数据# 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。# 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。$ kafka-storage.sh format --cluster-id oGwJsVANRDKYwE7Lhn2zIA --config /usr/local/kafka/kafka3/config/kraft/server.properties## 格式化后会在日志目录下生成两个文件# bootstrap.checkpoint # 存储元数据日志（Metadata Log）对应的初始快照偏移量（snapshot offset）。用于控制器在启动时恢复状态的起点。# meta.properties # 存储节点元信息：cluster.id、node.id、version 等 启动集群，所以节点启动 kafka 服务 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/server.properties 注意事项 Kafka 集群的启动顺序不能乱，必须先启动 Controller 节点，再启动 Broker 节点，我们这里是将节点同时做为Controller 和 Broker ，实际生产环境建议分开。 Controller 节点至少3个，建议配置为奇数个。Broker 节点数量任意，但建议至少2个以上，以保证分区的备份可以分开存储。 Client 仅能与 Broker 节点通信，不能与 Controller 节点通信。 Kafka 4.0 的新特性 彻底以 KRaft（Kafka Raft）取代 ZooKeeper（KRaft 成为默认且唯一的元数据管理） 说明：4.x 系列标志性变化是完全移除 ZooKeeper，元数据由 KRaft 管理（Controller 与 Broker 更紧密集成）。对运维而言：不再部署/维护 ZooKeeper 集群、元数据迁移/格式化步骤是升级时的关键。 影响/提示：必须按官方迁移流程把元数据从 ZK 导入 KRaft（若从旧版本升级）。测试迁移/备份元数据是必须项。 新的 consumer-group 协议（更高效的 rebalance/群组管理）与消费模型改进（包括“Queues/Shared Group”支持） 说明：引入/稳定了新的 Consumer Group 协议（相关 KIP），显著改善大群组下的重平衡延迟与稳定性；同时引入了类似“队列/共享组（Queues for Kafka）”的消费模式（用例：点对点消费），允许多消费者同时处理同一分区消息。 影响/提示：如果你有大规模消费者群组或依赖旧 rebalance 行为，需要测试新协议行为；某些客户端配置/行为可能需要调整。 指标类别 旧协议（Eager Rebalance） 新协议（Incremental / Cooperative Rebalance） 重平衡延迟（大规模群组） 约 60 秒（万级消费者规模） 小于 1 秒（测试显示在千级任务时可在一分钟内完成） (Confluent) 资源消耗（CPU） 较高（在重平衡期间系统停止或大规模迁移资源） 据称可降低约 70% 的 CPU／系统中断负荷（社区经验） 消费者群组扩展上限 适用于“千级消费者”规模 可扩展至“十万级消费者”规模（理论/社区宣称） 特性 传统消费者组（Consumer Group） 共享组（Shared Group / Queues for Kafka） 并行消费模型 分区数 = 消费者数（一个分区只能被一个消费者消费） 消费者数 &gt; 分区数（同一分区可由多个消费者并行处理） 消息确认机制 通过提交偏移量（Offset Commit）实现确认 每条消息单独确认（ACK/NACK 机制） 投递语义 At-Least-Once（至少一次投递） Exactly-Once（可选），支持精确一次处理 典型场景 流式日志、监控、顺序性要求高的场景 任务队列、并行计算、高吞吐任务处理 实现方式 基于 Topic-Partition 分配与偏移管理 基于共享队列模型，允许多消费者竞争消费同一分区 Kafka 版本支持 Kafka ≤ 3.x Kafka 4.x 引入（KIP-932 “Queues for Kafka”） 优势 顺序保证强、模型成熟稳定 并行能力强、吞吐提升、支持精确一次语义 劣势 分区限制吞吐，扩展受限 顺序性可能减弱，实现更复杂 删除长期弃用的旧 API / 协议（向后不兼容的清理） 说明：4.x 移除了那些已弃用 ≥12 个月的接口/协议，旨在简化代码库并鼓励采用新功能。 影响/提示：升级前务必检查你使用到的 Broker/Client/Streams/Connect API 是否依赖被移除的功能；测试客户端与第三方 Connector/插件兼容性。 Java 运行环境最低版本更新：Clients/Streams 与 Broker/Tools 的 JDK 要求提高 说明：Kafka 4.x 将客户端（Kafka Clients、Kafka Streams）与 Broker/Connect/工具分别提出了更高的 Java baseline（Clients/Streams 最低 Java 11，Broker/Connect/Tools 最低 Java 17 等）。 影响/提示：升级集群前先统一平台 JDK 版本，CI/CD/容器镜像也要对应更新。 许多新的 KIP（功能增强）与性能/可观测性改进 说明：包含改进的 Streams rebalance、更多 Admin/运维命令、节点注册/列举能力、插件/指标扩展点等（多项 KIP 在 4.0/4.1 陆续落地）。这些改进覆盖 Broker、Controller、Producer、Consumer、Admin 和 Streams 子系统。 影响/提示：运维与监控面板可能受益（新增可观测指标/API）；如果你有自定义插件或监控接入，需要检查新的插件/metrics 注册机制。","summary":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。","date_published":"2025-10-16T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/","url":"https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/","title":"Kafka 的 常用命令","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 常用命令</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/kafka-3-demo\">Java-Client 代码示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"topic\">topic</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --partitions 3 --replication-factor 2</span><br><span class=\"line\"><span class=\"comment\"># --bootstrap-server 指定 kafka 集群地址</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 创建的 topic 名称</span></span><br><span class=\"line\"><span class=\"comment\"># --partitions 指定分区数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class=\"line\"><span class=\"comment\"># --replication-factor 指定副本数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 列出 topic</span></span><br><span class=\"line\">kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class=\"line\"><span class=\"comment\"># 查看 topic 详情</span></span><br><span class=\"line\">kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">Topic: <span class=\"built_in\">test</span>\tTopicId: Ru0tWQJ4RMWcjjGsKAdWQg\tPartitionCount: 3\tReplicationFactor: 3\tConfigs:</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 0\tLeader: 3\tReplicas: 3,1,2\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 1\tLeader: 1\tReplicas: 1,2,3\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 2\tLeader: 2\tReplicas: 2,3,1\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\"><span class=\"comment\">## 输出说明</span></span><br><span class=\"line\"><span class=\"comment\"># 总体信息（Topic 概览）Topic: test\tTopicId: Ru0tWQJ4RMWcjjGsKAdWQg\tPartitionCount: 3\tReplicationFactor: 3\tConfigs:</span></span><br><span class=\"line\">| 字段                                  | 含义                                                            |</span><br><span class=\"line\">| ----------------------------------- | ------------------------------------------------------------- |</span><br><span class=\"line\">| **Topic: disTopic**                 | Topic 名称，即当前描述的主题。                                            |</span><br><span class=\"line\">| **TopicId: VUK7Mc9oQdS1mjGG7OhQzQ** | Kafka 内部自动生成的唯一标识符（UUID），Kafka 3.x 之后引入，用于区分同名但不同生命周期的 topic。 |</span><br><span class=\"line\">| **PartitionCount: 3**               | 该主题有 3 个分区（partition）。每个分区存储一部分消息。                            |</span><br><span class=\"line\">| **ReplicationFactor:**              | 副本因子。这里虽然输出中没显示具体值，但可从每行分区配置推断是 **3**（每个分区有 3 个副本）。           |</span><br><span class=\"line\">| **Configs:**                        | topic 的配置项（例如清理策略、压缩类型等），如果为空，说明使用默认配置。                       |</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分区详情（每个 Partition 一行）</span></span><br><span class=\"line\"></span><br><span class=\"line\">| 字段                                | 含义                                                          |</span><br><span class=\"line\">| --------------------------------- | ----------------------------------------------------------- |</span><br><span class=\"line\">| **Partition: 0**                  | 第 0 号分区。                                                    |</span><br><span class=\"line\">| **Leader: 2**                     | 该分区当前的 **Leader Broker 是 broker ID = 2**，只有 Leader 才处理读写请求。 |</span><br><span class=\"line\">| **Replicas: 2,3,1**               | 该分区的所有副本存放在哪些 Broker 上（即副本分布,AR），分别是 broker 2、3、1。             |</span><br><span class=\"line\">| **Isr (In-Sync Replicas): 2,3,1** | 当前与 Leader 保持同步的副本集合。这里所有副本都在同步中（健康状态 👍）。                  |</span><br><span class=\"line\">| **Elr / LastKnownElr**            | Kafka 新版本中引入的 <span class=\"string\">&quot;Enhanced Leader Replica&quot;</span> 状态，目前未启用（N/A）。      |</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 删除 topic</span></span><br><span class=\"line\">kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"consumer\">consumer</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 consumer</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --group <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 指定 topic</span></span><br><span class=\"line\"><span class=\"comment\"># --group 指定 consumer 组</span></span><br><span class=\"line\"></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span>  --from-beginning</span><br><span class=\"line\"><span class=\"comment\"># --from-beginning 从 topic 的最开始消费</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"consumer-group\">consumer-group</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 列出 consumer 组</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span><br><span class=\"line\"><span class=\"comment\"># --bootstrap-server 集群地址</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 consumer 组详情</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">GROUP  TOPIC  PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                             HOST         CLIENT-ID</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   0          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   1          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   2          1               1               0    console-consumer-9ac45b29-d8f3-4649-ab09-7b567aa2ba53  /10.250.0.108 console-consumer</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 输出说明</span></span><br><span class=\"line\"><span class=\"comment\"># GROUP       消费组名称</span></span><br><span class=\"line\"><span class=\"comment\"># TOPIC       topic 名称</span></span><br><span class=\"line\"><span class=\"comment\"># PARTITION   分区编号</span></span><br><span class=\"line\"><span class=\"comment\"># CURRENT-OFFSET  当前消费的 offset</span></span><br><span class=\"line\"><span class=\"comment\"># LOG-END-OFFSET   topic 中最大的 offset</span></span><br><span class=\"line\"><span class=\"comment\"># LAG         当前消费的 offset 与 topic 中最大的 offset 的差值，即剩余未消费的 消息数量</span></span><br><span class=\"line\"><span class=\"comment\"># CONSUMER-ID  当前消费的 consumer 的 id</span></span><br><span class=\"line\"><span class=\"comment\"># HOST        当前消费的 consumer 的主机名</span></span><br><span class=\"line\"><span class=\"comment\"># CLIENT-ID   当前消费的 consumer 的客户端名称</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 删除 consumer 组</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"producer\">producer</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 producer</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 指定 topic</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"手动触发-Kafka-Partitoin-的-Leader-选举-自平衡\">手动触发 Kafka Partitoin 的 Leader 选举(自平衡)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>kafka的自平衡默认开启，每隔 300秒扫描一次，如果需要平衡的比例高于 10%，则会触发一次</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开启自动平衡</span></span><br><span class=\"line\">auto.leader.rebalance.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># 间隔扫描时间 默认 300 秒</span></span><br><span class=\"line\">eader.imbalance.check.interval.seconds=300</span><br><span class=\"line\"><span class=\"comment\"># 触发比例，即扫描的 broker 上需要平衡的 partition 占当前 broker 全部 partition 的比例，默认 10%</span></span><br><span class=\"line\">leader.imbalance.per.broker.percentage=10</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>建议关闭，改为业务低峰时手动触发</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 自动平衡</span></span><br><span class=\"line\">kafka-leader-election.sh --bootstrap-server localhost:9092  --election-type preferred --topic <span class=\"built_in\">test</span> --partition 0</span><br><span class=\"line\"><span class=\"comment\"># --topic 指定要触发的 topic</span></span><br><span class=\"line\"><span class=\"comment\"># --partition 0 触发 partition 0 的 leader 选举</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>🧩 参数说明：–election-type</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数值</th>\n<th>含义</th>\n<th>触发条件</th>\n<th>典型使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>preferred</code></strong></td>\n<td><strong>首选 Leader 选举</strong>（Preferred Leader Election）<br>Kafka 会尝试将分区的 leader 重新切换为「首选副本」（通常是第一个副本）。</td>\n<td>只有当前 leader <strong>不是</strong> 首选副本时才执行。</td>\n<td>某些副本被自动选举成 leader 后，希望恢复原有「首选 leader」结构，以实现负载均衡。</td>\n</tr>\n<tr>\n<td><strong><code>unclean</code></strong></td>\n<td><strong>非干净 Leader 选举</strong>（Unclean Leader Election）<br>允许从不同步的副本中选举新的 leader。</td>\n<td>仅在分区 <strong>没有可用 leader</strong> 时执行。</td>\n<td>在紧急恢复场景下（比如所有 ISR 副本都下线），为了恢复服务可用性，即使会导致数据丢失。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Leader Partition⾃动平衡机制</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">Leader Partitoin选举机制能够保证每⼀个Partition同⼀时刻有且仅有⼀个Leader Partition。但是，是不是只要分配好了Leader Partition就够了呢？</li>\n<li class=\"lvl-6\">在⼀组Partiton中，Leader Partition通常是⽐较繁忙的节点，因为他要负责与客户端的数据交互，以及向Follower同步数据。默认情况下，Kafka会尽量将Leader Partition分配到不同的Broker节点上，⽤以保证整个集群的性能压⼒能够⽐较平均。</li>\n<li class=\"lvl-6\">但是，经过Leader Partition选举后，这种平衡就有可能会被打破，让Leader Partition过多的集中到同⼀个Broker上。这样，这个Broker的压⼒就会明显⾼于其他Broker，从⽽影响到集群的整体性能。</li>\n<li class=\"lvl-6\">为此，Kafka设计了Leader Partition⾃动平衡机制，当发现Leader分配不均衡时，⾃动进⾏Leader Partition调整。</li>\n<li class=\"lvl-6\">Kafka在进⾏Leader Partition⾃平衡时的逻辑是这样的：他会认为AR(Replicas副本集)当中的第⼀个节点就应该是Leader节点。这种选举结果成为preferred election 理想选举结果。</li>\n<li class=\"lvl-6\">Controller会定期检测集群的Partition平衡情况，在开始检测时，Controller会依次检查所有的Broker。当发现这个Broker上的不平衡的Partition⽐例⾼于<code>leader.imbalance.per.broker.percentage</code>阈值时，就会触发⼀次Leader Partiton的⾃平衡。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 Kafka 的 常用命令 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Java-Client 代码示例 topic 12345678910111213141516171819202122232425262728293031323334353637383940# 创建 topickafka-topics.sh --create --bootstrap-server localhost:9092 --topic test --partitions 3 --replication-factor 2# --bootstrap-server 指定 kafka 集群地址# --topic 创建的 topic 名称# --partitions 指定分区数，不设置则默认使用 server.properties 中设置的默认值# --replication-factor 指定副本数，不设置则默认使用 server.properties 中设置的默认值# 列出 topickafka-topics.sh --list --bootstrap-server localhost:9092# 查看 topic 详情kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test## 输出Topic: test TopicId: Ru0tWQJ4RMWcjjGsKAdWQg PartitionCount: 3 ReplicationFactor: 3 Configs: Topic: test Partition: 0 Leader: 3 Replicas: 3,1,2 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A Topic: test Partition: 1 Leader: 1 Replicas: 1,2,3 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A Topic: test Partition: 2 Leader: 2 Replicas: 2,3,1 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A## 输出说明# 总体信息（Topic 概览）Topic: test TopicId: Ru0tWQJ4RMWcjjGsKAdWQg PartitionCount: 3 ReplicationFactor: 3 Configs:| 字段 | 含义 || ----------------------------------- | ------------------------------------------------------------- || **Topic: disTopic** | Topic 名称，即当前描述的主题。 || **TopicId: VUK7Mc9oQdS1mjGG7OhQzQ** | Kafka 内部自动生成的唯一标识符（UUID），Kafka 3.x 之后引入，用于区分同名但不同生命周期的 topic。 || **PartitionCount: 3** | 该主题有 3 个分区（partition）。每个分区存储一部分消息。 || **ReplicationFactor:** | 副本因子。这里虽然输出中没显示具体值，但可从每行分区配置推断是 **3**（每个分区有 3 个副本）。 || **Configs:** | topic 的配置项（例如清理策略、压缩类型等），如果为空，说明使用默认配置。 |# 分区详情（每个 Partition 一行）| 字段 | 含义 || --------------------------------- | ----------------------------------------------------------- || **Partition: 0** | 第 0 号分区。 || **Leader: 2** | 该分区当前的 **Leader Broker 是 broker ID = 2**，只有 Leader 才处理读写请求。 || **Replicas: 2,3,1** | 该分区的所有副本存放在哪些 Broker 上（即副本分布,AR），分别是 broker 2、3、1。 || **Isr (In-Sync Replicas): 2,3,1** | 当前与 Leader 保持同步的副本集合。这里所有副本都在同步中（健康状态 👍）。 || **Elr / LastKnownElr** | Kafka 新版本中引入的 &quot;Enhanced Leader Replica&quot; 状态，目前未启用（N/A）。 |# 删除 topickafka-topics.sh --delete --bootstrap-server localhost:9092 --topic test consumer 1234567# 创建 consumerkafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --group test# --topic 指定 topic# --group 指定 consumer 组kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning# --from-beginning 从 topic 的最开始消费 consumer-group 12345678910111213141516171819202122232425# 列出 consumer 组kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# --bootstrap-server 集群地址# 查看 consumer 组详情kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test## 输出GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDtest test 0 2 2 0 console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1 /10.250.0.7 console-consumertest test 1 2 2 0 console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1 /10.250.0.7 console-consumertest test 2 1 1 0 console-consumer-9ac45b29-d8f3-4649-ab09-7b567aa2ba53 /10.250.0.108 console-consumer## 输出说明# GROUP 消费组名称# TOPIC topic 名称# PARTITION 分区编号# CURRENT-OFFSET 当前消费的 offset# LOG-END-OFFSET topic 中最大的 offset# LAG 当前消费的 offset 与 topic 中最大的 offset 的差值，即剩余未消费的 消息数量# CONSUMER-ID 当前消费的 consumer 的 id# HOST 当前消费的 consumer 的主机名# CLIENT-ID 当前消费的 consumer 的客户端名称# 删除 consumer 组kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group test producer 123# 创建 producerkafka-console-producer.sh --bootstrap-server localhost:9092 --topic test# --topic 指定 topic 手动触发 Kafka Partitoin 的 Leader 选举(自平衡) kafka的自平衡默认开启，每隔 300秒扫描一次，如果需要平衡的比例高于 10%，则会触发一次 123456# 开启自动平衡auto.leader.rebalance.enable=true# 间隔扫描时间 默认 300 秒eader.imbalance.check.interval.seconds=300# 触发比例，即扫描的 broker 上需要平衡的 partition 占当前 broker 全部 partition 的比例，默认 10%leader.imbalance.per.broker.percentage=10 建议关闭，改为业务低峰时手动触发 1234# 自动平衡kafka-leader-election.sh --bootstrap-server localhost:9092 --election-type preferred --topic test --partition 0# --topic 指定要触发的 topic# --partition 0 触发 partition 0 的 leader 选举 🧩 参数说明：–election-type 参数值 含义 触发条件 典型使用场景 preferred 首选 Leader 选举（Preferred Leader Election）Kafka 会尝试将分区的 leader 重新切换为「首选副本」（通常是第一个副本）。 只有当前 leader 不是 首选副本时才执行。 某些副本被自动选举成 leader 后，希望恢复原有「首选 leader」结构，以实现负载均衡。 unclean 非干净 Leader 选举（Unclean Leader Election）允许从不同步的副本中选举新的 leader。 仅在分区 没有可用 leader 时执行。 在紧急恢复场景下（比如所有 ISR 副本都下线），为了恢复服务可用性，即使会导致数据丢失。 Leader Partition⾃动平衡机制 Leader Partitoin选举机制能够保证每⼀个Partition同⼀时刻有且仅有⼀个Leader Partition。但是，是不是只要分配好了Leader Partition就够了呢？ 在⼀组Partiton中，Leader Partition通常是⽐较繁忙的节点，因为他要负责与客户端的数据交互，以及向Follower同步数据。默认情况下，Kafka会尽量将Leader Partition分配到不同的Broker节点上，⽤以保证整个集群的性能压⼒能够⽐较平均。 但是，经过Leader Partition选举后，这种平衡就有可能会被打破，让Leader Partition过多的集中到同⼀个Broker上。这样，这个Broker的压⼒就会明显⾼于其他Broker，从⽽影响到集群的整体性能。 为此，Kafka设计了Leader Partition⾃动平衡机制，当发现Leader分配不均衡时，⾃动进⾏Leader Partition调整。 Kafka在进⾏Leader Partition⾃平衡时的逻辑是这样的：他会认为AR(Replicas副本集)当中的第⼀个节点就应该是Leader节点。这种选举结果成为preferred election 理想选举结果。 Controller会定期检测集群的Partition平衡情况，在开始检测时，Controller会依次检查所有的Broker。当发现这个Broker上的不平衡的Partition⽐例⾼于leader.imbalance.per.broker.percentage阈值时，就会触发⼀次Leader Partiton的⾃平衡。","summary":"摘要 本文介绍 Kafka 的 常用命令 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Java-Client 代码示例","date_published":"2025-10-15T12:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/","url":"https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/","title":"Kafka 的 server.properties 配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-3-x-server-properties-主要配置项清单\">Kafka 3.x server.properties 主要配置项清单</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关于 server.properties 的配置项，请参考 <a href=\"https://kafka.apache.org/39/documentation/#brokerconfigs\">Kafka 官方文档</a></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>分类</th>\n<th>参数名</th>\n<th>默认值</th>\n<th>说明</th>\n<th>推荐/备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>🗂️ <strong>基本信息</strong></td>\n<td><code>broker.id</code></td>\n<td>0</td>\n<td>Broker 唯一标识</td>\n<td>集群中必须唯一</td>\n</tr>\n<tr>\n<td></td>\n<td><code>node.id</code></td>\n<td>-</td>\n<td>Raft 模式（KRaft）下使用</td>\n<td>ZK 模式忽略</td>\n</tr>\n<tr>\n<td></td>\n<td><code>process.roles</code></td>\n<td>-</td>\n<td>KRaft 模式角色（controller, broker）</td>\n<td>ZK 模式不配置</td>\n</tr>\n<tr>\n<td>🔌 <strong>网络与监听配置</strong></td>\n<td><code>listeners</code></td>\n<td>PLAINTEXT://:9092</td>\n<td>Broker 监听地址</td>\n<td>可用多个协议，如 SASL_PLAINTEXT, SSL</td>\n</tr>\n<tr>\n<td></td>\n<td><code>advertised.listeners</code></td>\n<td>-</td>\n<td>客户端连接时看到的地址</td>\n<td>外网访问需配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>listener.security.protocol.map</code></td>\n<td>PLAINTEXT:PLAINTEXT</td>\n<td>映射监听器协议</td>\n<td>多协议时配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>inter.broker.listener.name</code></td>\n<td>-（Kafka 2.4+ 默认第一个 listener）</td>\n<td>指定 broker 间通信使用哪个 listener（如 INTERNAL）</td>\n<td>集群内部通信必须一致；常配合多 listener 使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.network.threads</code></td>\n<td>3</td>\n<td>网络线程数</td>\n<td>一般不需修改</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.io.threads</code></td>\n<td>8</td>\n<td>处理请求的 IO 线程数</td>\n<td>根据 CPU 调整</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.send.buffer.bytes</code></td>\n<td>102400</td>\n<td>发送缓冲区大小</td>\n<td>网络优化参数</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.receive.buffer.bytes</code></td>\n<td>102400</td>\n<td>接收缓冲区大小</td>\n<td>网络优化参数</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.request.max.bytes</code></td>\n<td>104857600</td>\n<td>单请求最大大小 (100MB)</td>\n<td>大消息需调大</td>\n</tr>\n<tr>\n<td>⚙️ <strong>集群与元数据</strong></td>\n<td><code>log.dirs</code></td>\n<td>/tmp/kafka-logs</td>\n<td>数据存储路径</td>\n<td>多目录可提升性能</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.recovery.threads.per.data.dir</code></td>\n<td>1</td>\n<td>每个数据目录的恢复线程数</td>\n<td>多磁盘时可增加</td>\n</tr>\n<tr>\n<td></td>\n<td><code>auto.create.topics.enable</code></td>\n<td>true</td>\n<td>是否允许自动创建 Topic</td>\n<td>生产建议禁用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controlled.shutdown.enable</code></td>\n<td>true</td>\n<td>优雅关闭 Broker</td>\n<td>建议开启</td>\n</tr>\n<tr>\n<td></td>\n<td><code>delete.topic.enable</code></td>\n<td>true</td>\n<td>是否允许删除 Topic</td>\n<td>生产慎用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>auto.leader.rebalance.enable</code></td>\n<td>true</td>\n<td>是否自动均衡 Leader</td>\n<td>建议开启</td>\n</tr>\n<tr>\n<td></td>\n<td><code>leader.imbalance.check.interval.seconds</code></td>\n<td>300</td>\n<td>检查 leader 失衡间隔</td>\n<td>与上配合使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>leader.imbalance.per.broker.percentage</code></td>\n<td>10</td>\n<td>触发 leader 重平衡的阈值</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td>🧱 <strong>副本与复制机制</strong></td>\n<td><code>default.replication.factor</code></td>\n<td>1</td>\n<td>新 Topic 默认副本数</td>\n<td>生产建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>offsets.topic.replication.factor</code></td>\n<td>1</td>\n<td>消费组偏移主题副本数</td>\n<td>建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>transaction.state.log.replication.factor</code></td>\n<td>1</td>\n<td>事务状态主题副本数</td>\n<td>建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>transaction.state.log.min.isr</code></td>\n<td>1</td>\n<td>事务状态日志最小 ISR 数</td>\n<td>建议 2</td>\n</tr>\n<tr>\n<td></td>\n<td><code>min.insync.replicas</code></td>\n<td>1</td>\n<td>Leader 写入时要求的最小 ISR 副本数</td>\n<td>建议 <code>replication.factor - 1</code></td>\n</tr>\n<tr>\n<td></td>\n<td><code>unclean.leader.election.enable</code></td>\n<td>false</td>\n<td>是否允许非同步副本选为 leader</td>\n<td>生产建议 false</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.replica.fetchers</code></td>\n<td>1</td>\n<td>follower 拉取线程数</td>\n<td>可提升复制性能</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.max.bytes</code></td>\n<td>1048576 (1MB)</td>\n<td>follower 拉取单分区最大数据量</td>\n<td>增大可提速</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.response.max.bytes</code></td>\n<td>10485760 (10MB)</td>\n<td>follower 一次拉取响应总量</td>\n<td>可调大</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.wait.max.ms</code></td>\n<td>500</td>\n<td>follower 等待新数据的最大时长</td>\n<td>延迟与吞吐折中</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.backoff.ms</code></td>\n<td>1000</td>\n<td>拉取失败后退避时间</td>\n<td>网络不稳时调整</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.socket.timeout.ms</code></td>\n<td>30000</td>\n<td>follower 与 leader 通信超时</td>\n<td>≥ <a href=\"http://fetch.wait.ms\">fetch.wait.ms</a></td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.socket.receive.buffer.bytes</code></td>\n<td>65536</td>\n<td>拉取 socket 缓冲区</td>\n<td>调大可提速</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.lag.time.max.ms</code></td>\n<td>10000</td>\n<td>follower 落后 leader 的最大时间</td>\n<td>影响 ISR</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.high.watermark.checkpoint.interval.ms</code></td>\n<td>5000</td>\n<td>高水位写入 checkpoint 周期</td>\n<td>影响恢复速度</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.selector.class</code></td>\n<td>-</td>\n<td>自定义副本选择类</td>\n<td>一般保持默认</td>\n</tr>\n<tr>\n<td>🧮 <strong>日志与段文件</strong></td>\n<td><code>log.segment.bytes</code></td>\n<td>1073741824 (1GB)</td>\n<td>单日志段文件大小</td>\n<td>调小便于删除</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.segment.ms</code></td>\n<td>604800000 (7天)</td>\n<td>强制滚动日志的时间</td>\n<td>适用于时间控制</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.hours</code></td>\n<td>168</td>\n<td>日志保留时间（小时）</td>\n<td>与磁盘空间相关</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.bytes</code></td>\n<td>-1</td>\n<td>日志总大小限制</td>\n<td>-1 表示不限制</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.check.interval.ms</code></td>\n<td>300000</td>\n<td>检查日志保留策略间隔</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.enable</code></td>\n<td>true</td>\n<td>是否启用日志压缩</td>\n<td>compact 主题需启用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.threads</code></td>\n<td>1</td>\n<td>清理线程数</td>\n<td>大集群可增加</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.io.max.bytes.per.second</code></td>\n<td>None</td>\n<td>限制清理 IO 带宽</td>\n<td>控制磁盘负载</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.flush.interval.messages</code></td>\n<td>Long.MAX_VALUE</td>\n<td>累计消息数达到后强制 flush</td>\n<td>通常保持默认</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.flush.interval.ms</code></td>\n<td>None</td>\n<td>每隔多久强制 flush</td>\n<td>SSD 可调大</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.partitions</code></td>\n<td>1</td>\n<td>新 Topic 默认分区数</td>\n<td>通常 3~6 起步</td>\n</tr>\n<tr>\n<td>🧵 <strong>生产与消费相关</strong></td>\n<td><code>message.max.bytes</code></td>\n<td>1048576</td>\n<td>允许的最大消息大小</td>\n<td>与 Producer <code>max.request.size</code> 对齐</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.max.bytes</code></td>\n<td>1048576</td>\n<td>与 Producer/Consumer 对应的限制</td>\n<td>防止大消息卡死</td>\n</tr>\n<tr>\n<td></td>\n<td><code>compression.type</code></td>\n<td>producer</td>\n<td>压缩算法（none, gzip, snappy, lz4, zstd）</td>\n<td>建议 zstd</td>\n</tr>\n<tr>\n<td></td>\n<td><code>queued.max.requests</code></td>\n<td>500</td>\n<td>Broker 最大排队请求数</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td>🛠️ <strong>控制器与协调器</strong></td>\n<td><code>controller.socket.timeout.ms</code></td>\n<td>30000</td>\n<td>控制器通信超时</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controller.quorum.voters</code></td>\n<td>-</td>\n<td>KRaft 模式选举成员</td>\n<td>ZK 模式不需</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controller.listener.names</code></td>\n<td>-</td>\n<td>控制器监听名</td>\n<td>ZK 模式忽略</td>\n</tr>\n<tr>\n<td>📈 <strong>监控与指标</strong></td>\n<td><code>metric.reporters</code></td>\n<td>空</td>\n<td>指标上报类</td>\n<td>可接 Prometheus</td>\n</tr>\n<tr>\n<td></td>\n<td><code>metrics.num.samples</code></td>\n<td>2</td>\n<td>指标采样数</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>metrics.sample.window.ms</code></td>\n<td>30000</td>\n<td>指标采样窗口</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetchers.metrics.enabled</code></td>\n<td>true</td>\n<td>是否启用副本拉取指标</td>\n<td>Kafka 3.x 新增</td>\n</tr>\n<tr>\n<td>🔒 <strong>安全</strong></td>\n<td><code>authorizer.class.name</code></td>\n<td>空</td>\n<td>授权类实现</td>\n<td>开启 ACL 时配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>super.users</code></td>\n<td>空</td>\n<td>超级用户列表</td>\n<td>ACL 模式下配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>ssl.keystore.location</code></td>\n<td>-</td>\n<td>SSL 证书路径</td>\n<td>启用 SSL 时使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>ssl.truststore.location</code></td>\n<td>-</td>\n<td>信任证书路径</td>\n<td>启用 SSL 时使用</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参数使用建议总结\">参数使用建议总结</h2>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>推荐配置</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>高可靠性集群</strong></td>\n<td><code>default.replication.factor=3</code>, <code>min.insync.replicas=2</code>, <code>unclean.leader.election.enable=false</code></td>\n</tr>\n<tr>\n<td><strong>吞吐优先</strong></td>\n<td>提高 <code>num.replica.fetchers</code>、<code>replica.fetch.max.bytes</code></td>\n</tr>\n<tr>\n<td><strong>快速恢复</strong></td>\n<td>减少 <code>replica.high.watermark.checkpoint.interval.ms</code></td>\n</tr>\n<tr>\n<td><strong>节省磁盘</strong></td>\n<td>启用 <code>log.cleaner.enable</code> 并设置 <code>log.retention.hours</code></td>\n</tr>\n<tr>\n<td><strong>事务或精确一次语义</strong></td>\n<td>设置 <code>transaction.state.log.replication.factor=3</code>、<code>transaction.state.log.min.isr=2</code></td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 3.x server.properties 主要配置项清单 关于 server.properties 的配置项，请参考 Kafka 官方文档 分类 参数名 默认值 说明 推荐/备注 🗂️ 基本信息 broker.id 0 Broker 唯一标识 集群中必须唯一 node.id - Raft 模式（KRaft）下使用 ZK 模式忽略 process.roles - KRaft 模式角色（controller, broker） ZK 模式不配置 🔌 网络与监听配置 listeners PLAINTEXT://:9092 Broker 监听地址 可用多个协议，如 SASL_PLAINTEXT, SSL advertised.listeners - 客户端连接时看到的地址 外网访问需配置 listener.security.protocol.map PLAINTEXT:PLAINTEXT 映射监听器协议 多协议时配置 inter.broker.listener.name -（Kafka 2.4+ 默认第一个 listener） 指定 broker 间通信使用哪个 listener（如 INTERNAL） 集群内部通信必须一致；常配合多 listener 使用 num.network.threads 3 网络线程数 一般不需修改 num.io.threads 8 处理请求的 IO 线程数 根据 CPU 调整 socket.send.buffer.bytes 102400 发送缓冲区大小 网络优化参数 socket.receive.buffer.bytes 102400 接收缓冲区大小 网络优化参数 socket.request.max.bytes 104857600 单请求最大大小 (100MB) 大消息需调大 ⚙️ 集群与元数据 log.dirs /tmp/kafka-logs 数据存储路径 多目录可提升性能 num.recovery.threads.per.data.dir 1 每个数据目录的恢复线程数 多磁盘时可增加 auto.create.topics.enable true 是否允许自动创建 Topic 生产建议禁用 controlled.shutdown.enable true 优雅关闭 Broker 建议开启 delete.topic.enable true 是否允许删除 Topic 生产慎用 auto.leader.rebalance.enable true 是否自动均衡 Leader 建议开启 leader.imbalance.check.interval.seconds 300 检查 leader 失衡间隔 与上配合使用 leader.imbalance.per.broker.percentage 10 触发 leader 重平衡的阈值 默认即可 🧱 副本与复制机制 default.replication.factor 1 新 Topic 默认副本数 生产建议 3 offsets.topic.replication.factor 1 消费组偏移主题副本数 建议 3 transaction.state.log.replication.factor 1 事务状态主题副本数 建议 3 transaction.state.log.min.isr 1 事务状态日志最小 ISR 数 建议 2 min.insync.replicas 1 Leader 写入时要求的最小 ISR 副本数 建议 replication.factor - 1 unclean.leader.election.enable false 是否允许非同步副本选为 leader 生产建议 false num.replica.fetchers 1 follower 拉取线程数 可提升复制性能 replica.fetch.max.bytes 1048576 (1MB) follower 拉取单分区最大数据量 增大可提速 replica.fetch.response.max.bytes 10485760 (10MB) follower 一次拉取响应总量 可调大 replica.fetch.wait.max.ms 500 follower 等待新数据的最大时长 延迟与吞吐折中 replica.fetch.backoff.ms 1000 拉取失败后退避时间 网络不稳时调整 replica.socket.timeout.ms 30000 follower 与 leader 通信超时 ≥ fetch.wait.ms replica.socket.receive.buffer.bytes 65536 拉取 socket 缓冲区 调大可提速 replica.lag.time.max.ms 10000 follower 落后 leader 的最大时间 影响 ISR replica.high.watermark.checkpoint.interval.ms 5000 高水位写入 checkpoint 周期 影响恢复速度 replica.selector.class - 自定义副本选择类 一般保持默认 🧮 日志与段文件 log.segment.bytes 1073741824 (1GB) 单日志段文件大小 调小便于删除 log.segment.ms 604800000 (7天) 强制滚动日志的时间 适用于时间控制 log.retention.hours 168 日志保留时间（小时） 与磁盘空间相关 log.retention.bytes -1 日志总大小限制 -1 表示不限制 log.retention.check.interval.ms 300000 检查日志保留策略间隔 默认即可 log.cleaner.enable true 是否启用日志压缩 compact 主题需启用 log.cleaner.threads 1 清理线程数 大集群可增加 log.cleaner.io.max.bytes.per.second None 限制清理 IO 带宽 控制磁盘负载 log.flush.interval.messages Long.MAX_VALUE 累计消息数达到后强制 flush 通常保持默认 log.flush.interval.ms None 每隔多久强制 flush SSD 可调大 num.partitions 1 新 Topic 默认分区数 通常 3~6 起步 🧵 生产与消费相关 message.max.bytes 1048576 允许的最大消息大小 与 Producer max.request.size 对齐 replica.fetch.max.bytes 1048576 与 Producer/Consumer 对应的限制 防止大消息卡死 compression.type producer 压缩算法（none, gzip, snappy, lz4, zstd） 建议 zstd queued.max.requests 500 Broker 最大排队请求数 默认即可 🛠️ 控制器与协调器 controller.socket.timeout.ms 30000 控制器通信超时 默认即可 controller.quorum.voters - KRaft 模式选举成员 ZK 模式不需 controller.listener.names - 控制器监听名 ZK 模式忽略 📈 监控与指标 metric.reporters 空 指标上报类 可接 Prometheus metrics.num.samples 2 指标采样数 默认即可 metrics.sample.window.ms 30000 指标采样窗口 默认即可 replica.fetchers.metrics.enabled true 是否启用副本拉取指标 Kafka 3.x 新增 🔒 安全 authorizer.class.name 空 授权类实现 开启 ACL 时配置 super.users 空 超级用户列表 ACL 模式下配置 ssl.keystore.location - SSL 证书路径 启用 SSL 时使用 ssl.truststore.location - 信任证书路径 启用 SSL 时使用 参数使用建议总结 场景 推荐配置 高可靠性集群 default.replication.factor=3, min.insync.replicas=2, unclean.leader.election.enable=false 吞吐优先 提高 num.replica.fetchers、replica.fetch.max.bytes 快速恢复 减少 replica.high.watermark.checkpoint.interval.ms 节省磁盘 启用 log.cleaner.enable 并设置 log.retention.hours 事务或精确一次语义 设置 transaction.state.log.replication.factor=3、transaction.state.log.min.isr=2","summary":"摘要 本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-14T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/","title":"Kafka 的 Web UI 之 Kafbat UI","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 Web UI 之 Kafbat UI</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafbat.io\">Kafbat UI 官网</a>，<a href=\"https://github.com/kafbat/kafka-ui\">Kafbat UI Github</a>，<a href=\"https://ui.docs.kafbat.io\">Kafbat UI 文档</a>，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。</p>\n</li>\n<li class=\"lvl-2\">\n<p>与 Kafbat UI 类似的 Kafka Web UI 还有一个 <a href=\"https://github.com/obsidiandynamics/kafdrop\">kafdrop</a>，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafbat-UI-简介\">Kafbat UI 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafbat UI 是一个免费的开源 Web 用户界面，用于监控和管理 Apache Kafka 集群。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafbat UI 是一个简单的工具，使您的数据流变得可观察，帮助更快地发现和排除问题，并提供最佳性能。其轻量级的仪表盘使您能够轻松跟踪 Kafka 集群的关键指标: 包括 Brokers、Topics、Partitions、生产和消费情况。</p>\n</li>\n</ul>\n<h2 id=\"运行-Kafbat-UI\">运行 Kafbat UI</h2>\n<h3 id=\"Docker-运行\">Docker 运行</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -p 8080:8080 \\</span><br><span class=\"line\">    --name kafka-ui \\</span><br><span class=\"line\">    -e KAFKA_CLUSTERS_0_NAME=kafka_c01 \\</span><br><span class=\"line\">    -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092 \\</span><br><span class=\"line\">    -e TZ=Asia/Shanghai \\</span><br><span class=\"line\">    -d ghcr.io/kafbat/kafka-ui:latest</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"Jar-运行\">Jar 运行</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>从<a href=\"https://github.com/kafbat/kafka-ui/releases\">Github</a>上下载最新版jar包，要求 <code>jdk 21+</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /Users/hanqf/myservice_dir/kafka_webui</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置kafka集群，可以同时配置多个，序号从0开始依次递增</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_NAME=kafka_c01</span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网PLAINTEXT访问</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网SASL_PLAINTEXT访问</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9094,68.79.13.235:9094,43.192.84.195:9094</span></span><br><span class=\"line\"><span class=\"comment\"># # SASL_PLAINTEXT认证配置</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网SASL_SSL访问</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9095,68.79.13.235:9095,43.192.84.195:9095</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_SSL</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=<span class=\"string\">&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># SSL配置</span></span><br><span class=\"line\"><span class=\"comment\"># JKS 格式证书</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=123456</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># PEM 格式证书</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_TYPE=PEM</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=<span class=\"string\">&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># ============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第二个集群配置示例</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_1_NAME=kafka_c02</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 时区</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> TZ=Asia/Shanghai</span><br><span class=\"line\"><span class=\"comment\"># 语言</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LANG=zh_CN.UTF-8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># webui访问路径</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SERVER_SERVLET_CONTEXT_PATH=/</span><br><span class=\"line\"><span class=\"comment\"># 认证方式，支持NONE(无认证)，LOGIN_FORM(登录表单认证)</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> AUTH_TYPE=LOGIN_FORM</span><br><span class=\"line\"><span class=\"comment\"># webui认证用户名密码</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPRING_SECURITY_USER_NAME=admin</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPRING_SECURITY_USER_PASSWORD=admin</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=<span class=\"string\">&quot;-Xms512m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 启动</span></span><br><span class=\"line\">/Users/hanqf/develop_soft/jdk21/bin/java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED  <span class=\"variable\">$JAVA_OPTS</span> -jar api-v1.3.0.jar</span><br></pre></td></tr></table></figure>\n<h2 id=\"访问-Kafbat-UI\">访问 Kafbat UI</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>访问 <a href=\"http://localhost:8080\">http://localhost:8080</a><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/ykd6F4.png\" alt=\"\"></p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 Kafka 的 Web UI 之 Kafbat UI Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafbat UI 官网，Kafbat UI Github，Kafbat UI 文档，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。 与 Kafbat UI 类似的 Kafka Web UI 还有一个 kafdrop，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。 Kafbat UI 简介 Kafbat UI 是一个免费的开源 Web 用户界面，用于监控和管理 Apache Kafka 集群。 Kafbat UI 是一个简单的工具，使您的数据流变得可观察，帮助更快地发现和排除问题，并提供最佳性能。其轻量级的仪表盘使您能够轻松跟踪 Kafka 集群的关键指标: 包括 Brokers、Topics、Partitions、生产和消费情况。 运行 Kafbat UI Docker 运行 1234567docker run -it -p 8080:8080 \\ --name kafka-ui \\ -e KAFKA_CLUSTERS_0_NAME=kafka_c01 \\ -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092 \\ -e TZ=Asia/Shanghai \\ -d ghcr.io/kafbat/kafka-ui:latest Jar 运行 从Github上下载最新版jar包，要求 jdk 21+ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859cd /Users/hanqf/myservice_dir/kafka_webui# 配置kafka集群，可以同时配置多个，序号从0开始依次递增export KAFKA_CLUSTERS_0_NAME=kafka_c01# =============================================================================================================# 外网PLAINTEXT访问# export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093# =============================================================================================================# =============================================================================================================# 外网SASL_PLAINTEXT访问# export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9094,68.79.13.235:9094,43.192.84.195:9094# # SASL_PLAINTEXT认证配置# export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT# export KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN# export KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;# =============================================================================================================# =============================================================================================================# 外网SASL_SSL访问export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9095,68.79.13.235:9095,43.192.84.195:9095export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_SSLexport KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAINexport KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;# SSL配置# JKS 格式证书export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jksexport KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=123456# PEM 格式证书# export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt# export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_TYPE=PEM# 禁用主机名验证export KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=&#x27;&#x27;# ============================================================================================================# 第二个集群配置示例export KAFKA_CLUSTERS_1_NAME=kafka_c02export KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093# 时区export TZ=Asia/Shanghai# 语言export LANG=zh_CN.UTF-8# webui访问路径export SERVER_SERVLET_CONTEXT_PATH=/# 认证方式，支持NONE(无认证)，LOGIN_FORM(登录表单认证)export AUTH_TYPE=LOGIN_FORM# webui认证用户名密码export SPRING_SECURITY_USER_NAME=adminexport SPRING_SECURITY_USER_PASSWORD=adminJAVA_OPTS=&quot;-Xms512m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m&quot;# 启动/Users/hanqf/develop_soft/jdk21/bin/java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED $JAVA_OPTS -jar api-v1.3.0.jar 访问 Kafbat UI 访问 http://localhost:8080","summary":"摘要 本文介绍 Kafka 的 Web UI 之 Kafbat UI Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafbat UI 官网，Kafbat UI Github，Kafbat UI 文档，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。 与 Kafbat UI 类似的 Kafka Web UI 还有一个 kafdrop，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。","date_published":"2025-10-13T15:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/","title":"Kafka 通信协议、SSL加密和身份验证","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 通信协议，以及如何开启外网访问。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-的-通信协议\">Kafka 的 通信协议</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 主要支持四种安全协议</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>协议名称</th>\n<th>加密</th>\n<th>认证</th>\n<th>说明</th>\n<th>推荐场景</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>PLAINTEXT</strong></td>\n<td>❌ 否</td>\n<td>❌ 否</td>\n<td>无加密、无认证（默认最简单）</td>\n<td>开发 / 测试环境、内网集群通信</td>\n<td>简单、易调试；网络可信，性能优先</td>\n</tr>\n<tr>\n<td><strong>SSL</strong></td>\n<td>✅ 是</td>\n<td>✅ 可选</td>\n<td>使用 TLS/SSL 加密通信，可配置客户端证书认证</td>\n<td>外网客户端访问</td>\n<td>支持数据加密，可选认证，保证安全</td>\n</tr>\n<tr>\n<td><strong>SASL_PLAINTEXT</strong></td>\n<td>❌ 否</td>\n<td>✅ 是</td>\n<td>使用 SASL（用户名密码）认证，但不加密数据</td>\n<td>需要用户认证但局域网环境</td>\n<td>有认证，但不加密，性能开销低</td>\n</tr>\n<tr>\n<td><strong>SASL_SSL</strong></td>\n<td>✅ 是</td>\n<td>✅ 是</td>\n<td>同时支持 SASL 认证和 SSL 加密（最安全）</td>\n<td>外网客户端访问</td>\n<td>既有认证又加密，安全性最高</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 <code>config/server.properties</code> 文件中 可以看到如下配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 套接字服务器监听的地址。</span></span><br><span class=\"line\"><span class=\"comment\"># 如果未配置，则主机名默认等于 `java.net.InetAddress.getCanonicalHostName()` 的返回值，</span></span><br><span class=\"line\"><span class=\"comment\"># 使用监听器名称 `PLAINTEXT`，端口号为 9092。</span></span><br><span class=\"line\"><span class=\"comment\">#   格式：</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = listener_name://host_name:port</span></span><br><span class=\"line\"><span class=\"comment\">#   示例：</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"><span class=\"comment\">#listeners=PLAINTEXT://:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broker 向客户端“通告”的监听器名称、主机名和端口。</span></span><br><span class=\"line\"><span class=\"comment\"># 客户端实际会连接这个地址，而不是直接使用 listeners 的地址。</span></span><br><span class=\"line\"><span class=\"comment\"># 如果未设置，则默认使用 `listeners` 的值。</span></span><br><span class=\"line\"><span class=\"comment\">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将监听器名称映射到安全协议类型。</span></span><br><span class=\"line\"><span class=\"comment\"># 默认情况下，监听器名称与安全协议同名。</span></span><br><span class=\"line\"><span class=\"comment\"># 例如：PLAINTEXT→PLAINTEXT、SSL→SSL、SASL_PLAINTEXT→SASL_PLAINTEXT、SASL_SSL→SASL_SSL。</span></span><br><span class=\"line\"><span class=\"comment\"># 更多细节可参考 Kafka 官方配置文档。</span></span><br><span class=\"line\"><span class=\"comment\">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>作用</th>\n<th>说明值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>listeners</code></td>\n<td>Kafka 实际监听的地址（Broker 对外开放的端口）</td>\n<td><code>PLAINTEXT://:9092</code>这里 PLAINTEXT 是监听器名称，并不是协议名称，实际上可以配置为任何值，具体协议是通过 <code>listener.security.protocol.map</code> 配置的映射关系来确定。</td>\n</tr>\n<tr>\n<td><code>advertised.listeners</code></td>\n<td>Kafka 告诉客户端应该用哪个地址连接（客户端最终连的）</td>\n<td>默认使用 <code>listeners</code> 的值</td>\n</tr>\n<tr>\n<td><code>listener.security.protocol.map</code></td>\n<td>映射监听器名称到通信安全协议（如明文、SSL、SASL 等）</td>\n<td><code>PLAINTEXT:PLAINTEXT</code>，前面是监听器名称，后面是协议名称</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"仅需内网访问\">仅需内网访问</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://worker1:9092 <span class=\"comment\"># 这里是内网ip</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"允许外网访问\">允许外网访问</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://161.189.227.200:9092 <span class=\"comment\"># 这里是外网ip</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"内外网都要访问（推荐双通道方式）\">内外网都要访问（推荐双通道方式）</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里 INTERNAL 和 EXTERNAL 分别是自定义的监听器名称，此时内网端口为 9092，外网端口为 9093</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093</span><br><span class=\"line\"><span class=\"comment\"># 告诉客户端应该用哪个地址连接</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9093</span><br><span class=\"line\"><span class=\"comment\"># 映射监听器名称到通信安全协议的映射关系</span></span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 集群间通信仍使用内网</span></span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br></pre></td></tr></table></figure>\n<h2 id=\"开启-SASL-PLAINTEXT\">开启 SASL_PLAINTEXT</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里设置外网访问时开启 SASL_PLAINTEXT</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9094</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 集群间通信 still use INTERNAL</span></span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，因为 inter.broker.listener.name=INTERNAL，所以 INTERNAL:SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建 kafka_jaas.conf</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">############################</span></span><br><span class=\"line\"><span class=\"comment\"># Kafka Broker (服务端)</span></span><br><span class=\"line\"><span class=\"comment\">############################</span></span><br><span class=\"line\">KafkaServer &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">    org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class=\"line\">    <span class=\"comment\"># Broker 自己的身份（用于 broker 之间通信，本示例中没有使用）</span></span><br><span class=\"line\">    username=<span class=\"string\">&quot;admin&quot;</span></span><br><span class=\"line\">    password=<span class=\"string\">&quot;admin-secret&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 客户端可用账号，即 user_xxx，这里 xxx 为用户名，= 右边的为密码</span></span><br><span class=\"line\">    user_admin=<span class=\"string\">&quot;admin-secret&quot;</span></span><br><span class=\"line\">    user_alice=<span class=\"string\">&quot;alice-secret&quot;</span></span><br><span class=\"line\">    user_bob=<span class=\"string\">&quot;bob-secret&quot;</span>;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在启动 Kafka Broker 前，设置环境变量指向 JAAS 文件</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_OPTS=<span class=\"string\">&quot;-Djava.security.auth.login.config=/usr/local/kafka/kafka3/config/kafka_jaas.conf&quot;</span></span><br><span class=\"line\">kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure>\n<h3 id=\"客户端访问\">客户端访问</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建 client.conf</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行访问</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建topic</span></span><br><span class=\"line\">kafka-topics.sh --create --topic test-topic --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class=\"line\"><span class=\"comment\"># 查看topic</span></span><br><span class=\"line\">kafka-topics.sh --list --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class=\"line\"><span class=\"comment\"># 创建消费者，--group 指定消费者组名称</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --consumer.config=client.conf --group=test-group</span><br><span class=\"line\"><span class=\"comment\"># 创建生产者</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --producer.config=client.conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"开启-SASL-SSL\">开启 SASL_SSL</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里设置外网访问时开启 SASL_SSL</p>\n</li>\n</ul>\n<h3 id=\"创建证书\">创建证书</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org/39/documentation.html#security_ssl\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>生成 Broker keystore，用于 存储 broker 的私钥和证书。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -keystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -validity 3650 \\</span><br><span class=\"line\">  -genkey -keyalg RSA \\</span><br><span class=\"line\">  -dname <span class=\"string\">&quot;CN=broker, OU=Kafka, O=YourOrg, L=City, ST=State, C=CN&quot;</span> \\</span><br><span class=\"line\">  -storepass 123456 \\</span><br><span class=\"line\">  -keypass 123456</span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：生成的 keystore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -validity 3650：有效期 3650 天</span></span><br><span class=\"line\"><span class=\"comment\"># -keyalg RSA：密钥算法</span></span><br><span class=\"line\"><span class=\"comment\"># -dname：证书信息</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：keystore 密码</span></span><br><span class=\"line\"><span class=\"comment\"># -keypass：密钥密码</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>导出 Broker 证书（用于客户端 truststore）,生成 kafka.server.crt，客户端会用它来验证 broker。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -keystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -<span class=\"built_in\">export</span> -file kafka.server.crt \\</span><br><span class=\"line\">  -storepass 123456</span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：keystore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -file kafka.server.crt：导出的证书文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：keystore 密码</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>生成 Broker truststore，truststore 用于 存储信任的证书（这里把自己生成的证书导入进去即可）,生成 kafka.truststore.jks</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 注意：这里 server 端 和 client 端 可以共用一个 truststore，也可以分别创建</span></span><br><span class=\"line\">keytool -keystore kafka.truststore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -import -file kafka.server.crt \\</span><br><span class=\"line\">  -storepass 123456 -noprompt</span><br><span class=\"line\"><span class=\"comment\"># 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：生成的 truststore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -file kafka.server.crt：导入的证书文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：truststore 密码</span></span><br><span class=\"line\"><span class=\"comment\"># -noprompt：不提示</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"server-properties-配置-SASL-SSL\">server.properties 配置 SASL_SSL</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SASL</span></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL</span></span><br><span class=\"line\">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/kafka.server.keystore.jks</span><br><span class=\"line\">ssl.keystore.password=123456</span><br><span class=\"line\">ssl.key.password=123456</span><br><span class=\"line\">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\">ssl.truststore.password=123456</span><br><span class=\"line\"><span class=\"comment\"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class=\"line\">ssl.client.auth=none</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka 前同样需要先创建好 kafka_jaas.conf，与 SASL_PLAINTEXT 一样。</p>\n</li>\n</ul>\n<h3 id=\"客户端访问-2\">客户端访问</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>将 <code>kafka.truststore.jks</code> 拷贝到客户端</p>\n</li>\n<li class=\"lvl-2\">\n<p>与 SASL_PLAINTEXT 一样，创建 client.conf，并添加如下信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_SSL</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL 配置</span></span><br><span class=\"line\">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\">ssl.truststore.password=123456</span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证，否则会校验证书的 SAN，证书域名校验开关，为空则表示关闭，这里需要保持关闭状态，必须设置为空</span></span><br><span class=\"line\">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行访问 与 SASL_PLAINTEXT 一样，这里不再赘述</p>\n</li>\n<li class=\"lvl-2\">\n<p>关于 Kafka JKS格式的SSL证书的创建及配置可以参考<a href=\"https://support.huaweicloud.com/usermanual-kafka/kafka-ug-0008.html\">制作和替换Kafka JKS格式的SSL证书</a></p>\n</li>\n</ul>\n<h4 id=\"PEM-证书\">PEM 证书</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 的 证书 默认使用 JKS 格式，但从 2.7.0 开始支持 PEM 格式</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SASL</span></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 CRAM-SHA-256、SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL-PEM</span></span><br><span class=\"line\">ssl.keystore.type=PEM <span class=\"comment\"># 指定证书类型是PEM，支持的类型 PEM、JKS</span></span><br><span class=\"line\">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/fullchain.pem <span class=\"comment\"># 包含私钥和公钥</span></span><br><span class=\"line\"><span class=\"comment\"># 指定客户端使用的证书类型是PEM</span></span><br><span class=\"line\">ssl.truststore.type=PEM</span><br><span class=\"line\">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/server.crt <span class=\"comment\"># 公钥</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class=\"line\">ssl.client.auth=none</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>client.conf 配置如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_SSL</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL 配置，将 server 端的 server.crt 拷贝到 client 端</span></span><br><span class=\"line\">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span><br><span class=\"line\">ssl.truststore.type=PEM</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证</span></span><br><span class=\"line\">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>jks 证书转换为 pem 格式</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">从 JKS 导出为 PKCS#12 (.p12)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -importkeystore \\</span><br><span class=\"line\">  -srckeystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -srcstoretype JKS \\</span><br><span class=\"line\">  -destkeystore kafka.server.p12 \\</span><br><span class=\"line\">  -deststoretype PKCS12 \\</span><br><span class=\"line\">  -srcstorepass 123456 \\</span><br><span class=\"line\">  -deststorepass 123456 \\</span><br><span class=\"line\">  -J<span class=\"string\">&quot;-Djdk.tls.disabledAlgorithms=&quot;</span> \\</span><br><span class=\"line\">  -J<span class=\"string\">&quot;-Dkeystore.pkcs12.legacy=false&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\">  <span class=\"comment\"># -srcstoretype JKS：原始格式；</span></span><br><span class=\"line\">  <span class=\"comment\"># -deststoretype PKCS12：转换为通用格式；</span></span><br><span class=\"line\">  <span class=\"comment\"># .p12 是 PEM 的“中间格式”。</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">导出证书[公钥] (.crt，这里是 PEM 格式)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -clcerts -nokeys -out server.crt -password pass:123456 -provider legacy -provider default</span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -clcerts：只导出证书；</span></span><br><span class=\"line\"><span class=\"comment\"># -nokeys：不导出密钥；</span></span><br><span class=\"line\"><span class=\"comment\"># -out server.crt：导出文件名；</span></span><br><span class=\"line\"><span class=\"comment\"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br><span class=\"line\"><span class=\"comment\"># -provider legacy：启用旧算法支持模块，在 OpenSSL 3.0（及更高版本）中，引入了一个新机制 —— Provider（算法提供者）,默认情况下，OpenSSL 只加载 modern provider（default provider），而许多老旧算法（例如 RC2、MD5、DES、SHA1）被移到了一个单独的 legacy provider 模块中。</span></span><br><span class=\"line\"><span class=\"comment\"># -provider default：同时启用默认 provider，因为有些命令（比如涉及现代加密算法或证书签名）还依赖默认 provider，所以两者一起使用最安全、最兼容</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">导出私钥 (.key，这里是 PEM 格式)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -nocerts -out server.key -nodes -password pass:123456 -provider legacy -provider default</span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -nocerts：只导出密钥；</span></span><br><span class=\"line\"><span class=\"comment\"># -out server.key：导出文件名；</span></span><br><span class=\"line\"><span class=\"comment\"># -nodes：不加密导出的密钥文件</span></span><br><span class=\"line\"><span class=\"comment\"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">fullchain.pem</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -out fullchain.pem -nodes -password pass:123456 -provider legacy -provider default</span><br></pre></td></tr></table></figure>\n</div>\n","content_text":"摘要 本文介绍 Kafka 的 通信协议，以及如何开启外网访问。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 的 通信协议 Kafka 主要支持四种安全协议 协议名称 加密 认证 说明 推荐场景 理由 PLAINTEXT ❌ 否 ❌ 否 无加密、无认证（默认最简单） 开发 / 测试环境、内网集群通信 简单、易调试；网络可信，性能优先 SSL ✅ 是 ✅ 可选 使用 TLS/SSL 加密通信，可配置客户端证书认证 外网客户端访问 支持数据加密，可选认证，保证安全 SASL_PLAINTEXT ❌ 否 ✅ 是 使用 SASL（用户名密码）认证，但不加密数据 需要用户认证但局域网环境 有认证，但不加密，性能开销低 SASL_SSL ✅ 是 ✅ 是 同时支持 SASL 认证和 SSL 加密（最安全） 外网客户端访问 既有认证又加密，安全性最高 在 config/server.properties 文件中 可以看到如下配置 12345678910111213141516171819# 套接字服务器监听的地址。# 如果未配置，则主机名默认等于 `java.net.InetAddress.getCanonicalHostName()` 的返回值，# 使用监听器名称 `PLAINTEXT`，端口号为 9092。# 格式：# listeners = listener_name://host_name:port# 示例：# listeners = PLAINTEXT://your.host.name:9092#listeners=PLAINTEXT://:9092# Broker 向客户端“通告”的监听器名称、主机名和端口。# 客户端实际会连接这个地址，而不是直接使用 listeners 的地址。# 如果未设置，则默认使用 `listeners` 的值。#advertised.listeners=PLAINTEXT://your.host.name:9092# 将监听器名称映射到安全协议类型。# 默认情况下，监听器名称与安全协议同名。# 例如：PLAINTEXT→PLAINTEXT、SSL→SSL、SASL_PLAINTEXT→SASL_PLAINTEXT、SASL_SSL→SASL_SSL。# 更多细节可参考 Kafka 官方配置文档。#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL 配置项 作用 说明值 listeners Kafka 实际监听的地址（Broker 对外开放的端口） PLAINTEXT://:9092这里 PLAINTEXT 是监听器名称，并不是协议名称，实际上可以配置为任何值，具体协议是通过 listener.security.protocol.map 配置的映射关系来确定。 advertised.listeners Kafka 告诉客户端应该用哪个地址连接（客户端最终连的） 默认使用 listeners 的值 listener.security.protocol.map 映射监听器名称到通信安全协议（如明文、SSL、SASL 等） PLAINTEXT:PLAINTEXT，前面是监听器名称，后面是协议名称 仅需内网访问 12listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://worker1:9092 # 这里是内网ip 允许外网访问 12listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://161.189.227.200:9092 # 这里是外网ip 内外网都要访问（推荐双通道方式） 12345678# 这里 INTERNAL 和 EXTERNAL 分别是自定义的监听器名称，此时内网端口为 9092，外网端口为 9093listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093# 告诉客户端应该用哪个地址连接advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9093# 映射监听器名称到通信安全协议的映射关系listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT# 集群间通信仍使用内网inter.broker.listener.name=INTERNAL 开启 SASL_PLAINTEXT 这里设置外网访问时开启 SASL_PLAINTEXT 12345678910111213# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9094listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT# 集群间通信 still use INTERNALinter.broker.listener.name=INTERNAL# 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，因为 inter.broker.listener.name=INTERNAL，所以 INTERNAL:SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN 创建 kafka_jaas.conf 123456789101112131415############################# Kafka Broker (服务端)############################KafkaServer &#123; # 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required org.apache.kafka.common.security.plain.PlainLoginModule required # Broker 自己的身份（用于 broker 之间通信，本示例中没有使用） username=&quot;admin&quot; password=&quot;admin-secret&quot; # 客户端可用账号，即 user_xxx，这里 xxx 为用户名，= 右边的为密码 user_admin=&quot;admin-secret&quot; user_alice=&quot;alice-secret&quot; user_bob=&quot;bob-secret&quot;;&#125;; 启动 kafka 123# 在启动 Kafka Broker 前，设置环境变量指向 JAAS 文件export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/usr/local/kafka/kafka3/config/kafka_jaas.conf&quot;kafka-server-start.sh config/server.properties 客户端访问 创建 client.conf 12345security.protocol=SASL_PLAINTEXT# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;; 命令行访问 12345678# 创建topickafka-topics.sh --create --topic test-topic --bootstrap-server=161.189.227.200:9094 --command-config=client.conf# 查看topickafka-topics.sh --list --bootstrap-server=161.189.227.200:9094 --command-config=client.conf# 创建消费者，--group 指定消费者组名称kafka-console-consumer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --consumer.config=client.conf --group=test-group# 创建生产者kafka-console-producer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --producer.config=client.conf 开启 SASL_SSL 这里设置外网访问时开启 SASL_SSL 创建证书 官方文档 生成 Broker keystore，用于 存储 broker 的私钥和证书。 1234567891011121314keytool -keystore kafka.server.keystore.jks \\ -alias broker -validity 3650 \\ -genkey -keyalg RSA \\ -dname &quot;CN=broker, OU=Kafka, O=YourOrg, L=City, ST=State, C=CN&quot; \\ -storepass 123456 \\ -keypass 123456## 参数说明：# -keystore：生成的 keystore 文件路径# -alias broker：证书别名# -validity 3650：有效期 3650 天# -keyalg RSA：密钥算法# -dname：证书信息# -storepass：keystore 密码# -keypass：密钥密码 导出 Broker 证书（用于客户端 truststore）,生成 kafka.server.crt，客户端会用它来验证 broker。 12345678keytool -keystore kafka.server.keystore.jks \\ -alias broker -export -file kafka.server.crt \\ -storepass 123456## 参数说明：# -keystore：keystore 文件路径# -alias broker：证书别名# -file kafka.server.crt：导出的证书文件路径# -storepass：keystore 密码 生成 Broker truststore，truststore 用于 存储信任的证书（这里把自己生成的证书导入进去即可）,生成 kafka.truststore.jks 12345678910# 注意：这里 server 端 和 client 端 可以共用一个 truststore，也可以分别创建keytool -keystore kafka.truststore.jks \\ -alias broker -import -file kafka.server.crt \\ -storepass 123456 -noprompt# 参数说明：# -keystore：生成的 truststore 文件路径# -alias broker：证书别名# -file kafka.server.crt：导入的证书文件路径# -storepass：truststore 密码# -noprompt：不提示 server.properties 配置 SASL_SSL 1234567891011121314151617181920212223# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSLinter.broker.listener.name=INTERNAL# SASL# 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN# SSLssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/kafka.server.keystore.jksssl.keystore.password=123456ssl.key.password=123456ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/kafka.truststore.jksssl.truststore.password=123456# 如果不要求客户端证书，可以设置 none ，要求则设置为 requiredssl.client.auth=none 启动 kafka 前同样需要先创建好 kafka_jaas.conf，与 SASL_PLAINTEXT 一样。 客户端访问 将 kafka.truststore.jks 拷贝到客户端 与 SASL_PLAINTEXT 一样，创建 client.conf，并添加如下信息 1234567891011security.protocol=SASL_SSL# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;# SSL 配置ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jksssl.truststore.password=123456# 禁用主机名验证，否则会校验证书的 SAN，证书域名校验开关，为空则表示关闭，这里需要保持关闭状态，必须设置为空ssl.endpoint.identification.algorithm= 命令行访问 与 SASL_PLAINTEXT 一样，这里不再赘述 关于 Kafka JKS格式的SSL证书的创建及配置可以参考制作和替换Kafka JKS格式的SSL证书 PEM 证书 Kafka 的 证书 默认使用 JKS 格式，但从 2.7.0 开始支持 PEM 格式 123456789101112131415161718192021222324# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSLinter.broker.listener.name=INTERNAL# SASL# 认证机制（常见为 PLAIN，也可以是 CRAM-SHA-256、SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN# SSL-PEMssl.keystore.type=PEM # 指定证书类型是PEM，支持的类型 PEM、JKSssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/fullchain.pem # 包含私钥和公钥# 指定客户端使用的证书类型是PEMssl.truststore.type=PEMssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/server.crt # 公钥# 如果不要求客户端证书，可以设置 none ，要求则设置为 requiredssl.client.auth=none client.conf 配置如下： 123456789101112security.protocol=SASL_SSL# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;# SSL 配置，将 server 端的 server.crt 拷贝到 client 端ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crtssl.truststore.type=PEM# 禁用主机名验证ssl.endpoint.identification.algorithm= jks 证书转换为 pem 格式 从 JKS 导出为 PKCS#12 (.p12) 1234567891011121314keytool -importkeystore \\ -srckeystore kafka.server.keystore.jks \\ -srcstoretype JKS \\ -destkeystore kafka.server.p12 \\ -deststoretype PKCS12 \\ -srcstorepass 123456 \\ -deststorepass 123456 \\ -J&quot;-Djdk.tls.disabledAlgorithms=&quot; \\ -J&quot;-Dkeystore.pkcs12.legacy=false&quot;## 说明： # -srcstoretype JKS：原始格式； # -deststoretype PKCS12：转换为通用格式； # .p12 是 PEM 的“中间格式”。 导出证书[公钥] (.crt，这里是 PEM 格式) 12345678openssl pkcs12 -in kafka.server.p12 -clcerts -nokeys -out server.crt -password pass:123456 -provider legacy -provider default## 说明：# -clcerts：只导出证书；# -nokeys：不导出密钥；# -out server.crt：导出文件名；# -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:# -provider legacy：启用旧算法支持模块，在 OpenSSL 3.0（及更高版本）中，引入了一个新机制 —— Provider（算法提供者）,默认情况下，OpenSSL 只加载 modern provider（default provider），而许多老旧算法（例如 RC2、MD5、DES、SHA1）被移到了一个单独的 legacy provider 模块中。# -provider default：同时启用默认 provider，因为有些命令（比如涉及现代加密算法或证书签名）还依赖默认 provider，所以两者一起使用最安全、最兼容 导出私钥 (.key，这里是 PEM 格式) 123456openssl pkcs12 -in kafka.server.p12 -nocerts -out server.key -nodes -password pass:123456 -provider legacy -provider default## 说明：# -nocerts：只导出密钥；# -out server.key：导出文件名；# -nodes：不加密导出的密钥文件# -password：kafka.server.p12的密钥密码，注意密码前面加上 pass: fullchain.pem 1openssl pkcs12 -in kafka.server.p12 -out fullchain.pem -nodes -password pass:123456 -provider legacy -provider default","summary":"摘要 本文介绍 Kafka 的 通信协议，以及如何开启外网访问。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-13T14:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/","title":"Kafka 的安装：基于 Zookeeper","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-简介\">Kafka 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Apache Kafka 是一个 <code>分布式的流处理/事件流平台</code>，既可以作为<code>消息系统</code>，也可以作为持久化的 <code>日志/记录存储与流处理平台</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它的设计目标是高吞吐、低延迟、可水平扩展、容错，以及可持久化数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 Kafka 中，消息被归类为 <code>主题（Topic）</code>，每个主题可以根据配置被拆分为多个 <code>分区（Partition）</code>，每个分区内部消息是<code>严格有序</code>的，并以<code>追加</code>方式写入。消费者可以按<code>偏移量（offset）</code>读取消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 提供多个 API：Producer、Consumer、Streams（流处理）、Connect（与外部系统整合）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 的核心架构要素与工作机制</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>组件 / 概念</th>\n<th>作用 / 描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Broker（节点 / 服务器）</td>\n<td>Kafka 集群中的服务器实例，负责接收、存储、分发消息</td>\n</tr>\n<tr>\n<td>Topic</td>\n<td>消息的“分类”逻辑单元，Producer 写入、Consumer 读取</td>\n</tr>\n<tr>\n<td>Partition</td>\n<td>一个 Topic 被划分的子单元。分区使得主题可以横向扩展，并支持并行读写</td>\n</tr>\n<tr>\n<td>Offset</td>\n<td>每条消息在某个分区中的唯一位置标识，消费者根据 offset 来决定下一条读取</td>\n</tr>\n<tr>\n<td>Replication（副本）</td>\n<td>为了容错性，每个分区可以有多个副本（副本分布在不同 Broker 上）</td>\n</tr>\n<tr>\n<td>Leader / Follower</td>\n<td>在副本中，一个副本为 Leader，接受读写请求；其他为 Follower，从 Leader 同步数据</td>\n</tr>\n<tr>\n<td>Consumer Group</td>\n<td>一组消费者共同消费一个 Topic。每个分区在同一个消费者组中通常只被一个消费者 “拥有”</td>\n</tr>\n<tr>\n<td>ZooKeeper / KRaft</td>\n<td>用于元数据管理、集群协调（在较老版本中是 ZooKeeper；新版本推向 KRaft）</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Xe43JY.png\" alt=\"\" width=\"900\" height=\"600\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>消息写入流程（简化）：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Producer 将消息发送给某个 Topic 的 Leader 分区节点</li>\n<li class=\"lvl-4\">Leader 接收到消息后，将其追加写入本地日志，并返回确认（ACK）</li>\n<li class=\"lvl-4\">Follower 副本从 Leader 拉取数据进行同步</li>\n<li class=\"lvl-4\">消费者根据自己的 offset 从对应 Partition 中读取消息</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>消费控制与容错：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">消费者维护自己的 offset（可以自动提交，也可手动控制），这样即使消费者重启，也可以从上次停止的位置继续。</li>\n<li class=\"lvl-4\">如果某个 Broker 宕机，副本可以切换（Leader 选举），保证服务继续。</li>\n<li class=\"lvl-4\">分区与副本机制使得 Kafka 能够扩展容量 &amp; 提高可靠性。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 的典型使用场景</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景类别</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>实时数据管道 / 数据集成</strong></td>\n<td>用于将各种数据源（如日志、数据库变更、传感器、用户事件等）实时采集、传输、分发到下游系统（如 OLAP、搜索引擎、监控平台等），构建高效的数据通道。</td>\n</tr>\n<tr>\n<td><strong>事件驱动 / 事件溯源</strong></td>\n<td>记录系统内部或跨系统的事件（状态变化），实现事件驱动架构（EDA）或事件溯源（Event Sourcing），可用于审计、回放、状态重建等。</td>\n</tr>\n<tr>\n<td><strong>日志聚合 / 分析</strong></td>\n<td>将分布式系统中的应用日志、监控指标、操作日志等统一收集到 Kafka 中，集中存储与分析，常与 ELK、ClickHouse 等结合。</td>\n</tr>\n<tr>\n<td><strong>流处理</strong></td>\n<td>与 Kafka Streams、Apache Flink、Spark Streaming 等流处理框架配合，对流经 Kafka 的数据进行实时计算、聚合、过滤、窗口统计等操作。</td>\n</tr>\n<tr>\n<td><strong>系统解耦 / 异步通信</strong></td>\n<td>作为系统间的消息中间件，实现发布-订阅模式，减少系统间耦合，支持异步通信、流量削峰、缓冲等，提升系统稳定性与扩展性。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Kafka-安装\">Kafka 安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里先介绍基于 Zookeeper 的安装方式，下文会介绍基于 KRaft 的安装方式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 3.9.1 的安装与运行需要 JDK 8+，所有我们需要提前安装 JDK 8+。可以选择OpenJDK，<a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">清华大学镜像站</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># root 用户</span></span><br><span class=\"line\"><span class=\"comment\"># 创建安装目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"comment\"># 下载JDK</span></span><br><span class=\"line\">wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class=\"line\">tar -zxvf OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s jdk8u462-b08 jdk8</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export JAVA_HOME=/usr/local/jdk/jdk8&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 注意这里是 单引号，双引号会解析变量，导致配置失败</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export PATH=$JAVA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 检查JDK安装</span></span><br><span class=\"line\">java -version</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>安装过程参考官网文档<a href=\"https://kafka.apache.org/39/documentation.html#quickstart\">Kafka Quick Start</a>。</p>\n</li>\n</ul>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>部署kafka都会使用集群模式，单机模式只作为学习试用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>下载Kafka，<a href=\"https://kafka.apache.org/downloads\">下载页面</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># root 用户</span></span><br><span class=\"line\"><span class=\"comment\"># 创建安装目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> /usr/local/kafka</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/kafka</span><br><span class=\"line\"><span class=\"comment\"># 下载Kafka</span></span><br><span class=\"line\">wget https://dlcdn.apache.org/kafka/3.9.1/kafka_2.13-3.9.1.tgz</span><br><span class=\"line\">tar -zxvf kafka_2.13-3.9.1.tgz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s kafka_2.13-3.9.1 kafka3</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export KAFKA_HOME=/usr/local/kafka/kafka3&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export PATH=$KAFKA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看Kafka版本</span></span><br><span class=\"line\">kafka-topics.sh --version</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Zookeeper，kafka内置了zookeeper，所以不需要单独安装。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 前台运行</span></span><br><span class=\"line\">zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties</span><br><span class=\"line\"><span class=\"comment\"># 后台运行</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties &gt; zookeeper.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 关闭zookeeper，kill进程，过滤 java &amp; QuorumPeerMain</span></span><br><span class=\"line\">zookeeper-server-stop.sh</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -daemon 后台运行</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检查kafka是否启动成功</span></span><br><span class=\"line\">jps -l | grep kafka</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止 kafka，kill进程，过滤 java &amp; &#x27;kafka\\.Kafka&#x27;</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">注意：默认情况下 启动 kafka 需要的内存大小为 1G，这一点可以在 <a href=\"http://kafka-server-start.sh\">kafka-server-start.sh</a> 脚本中查看到</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"string\">&quot;x<span class=\"variable\">$KAFKA_HEAP_OPTS</span>&quot;</span> = <span class=\"string\">&quot;x&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">export</span> KAFKA_HEAP_OPTS=<span class=\"string\">&quot;-Xmx1G -Xms1G&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">所以如果内存不够，可以设置环境变量后再启动kafka</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_HEAP_OPTS=<span class=\"string\">&quot;-Xmx512M -Xms512M&quot;</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n</div>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动消费者</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --from-beginning</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动生产者</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\">&gt; hello world <span class=\"comment\"># 输入内容，消费者会收到</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装\">集群安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群安装需要准备多个节点，这里我准备三个节点，分别如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.7</span><br><span class=\"line\">10.250.0.174</span><br><span class=\"line\">10.250.0.108</span><br></pre></td></tr></table></figure>\n<h4 id=\"搭建-Zookeeper-集群\">搭建 Zookeeper 集群</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关于如何搭建 Zookeeper 集群，可以参考我之前的文章 <a href=\"/2025/09/15/zookeeper-study/\" title=\"Zookeeper 的安装及使用\">Zookeeper 的安装及使用</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>如果图省事也可以直接使用 Kafka 自带的 zookeeper，编辑其配置文件 <code>config/zookeeper.properties</code>如下，注意要在 <code>dataDir</code> 目录下创建<code>myid</code>文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataDir=/usr/local/kafka/dataDir/zookeeper</span><br><span class=\"line\"><span class=\"comment\"># the port at which the clients will connect</span></span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\"><span class=\"comment\"># disable the per-ip limit on the number of connections since this is a non-production config</span></span><br><span class=\"line\">maxClientCnxns=0</span><br><span class=\"line\"><span class=\"comment\"># Disable the adminserver by default to avoid port conflicts.</span></span><br><span class=\"line\"><span class=\"comment\"># Set the port to something non-conflicting if choosing to enable this</span></span><br><span class=\"line\">admin.enableServer=<span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># admin.serverPort=8080</span></span><br><span class=\"line\"></span><br><span class=\"line\">initLimit=10</span><br><span class=\"line\">syncLimit=5</span><br><span class=\"line\"></span><br><span class=\"line\">server.1=10.250.0.7:2888:3888</span><br><span class=\"line\">server.2=10.250.0.174:2888:3888</span><br><span class=\"line\">server.3=10.250.0.108:2888:3888</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置-Kafka-集群\">配置 Kafka 集群</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改主机的主机名</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl hostname worker1</span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname worker2</span></span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname worker3</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>为了后续方便维护，将ip地址映射到 hosts 文件中</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.7 worker1</span><br><span class=\"line\">10.250.0.174 worker2</span><br><span class=\"line\">10.250.0.108 worker3</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编辑 <code>config/server.properties</code> 文件，需要修改如下配置项</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#broker 的全局唯⼀编号，不能重复，只能是数字。</span></span><br><span class=\"line\">broker.id=1 <span class=\"comment\"># 这里分别设置为1、2、3</span></span><br><span class=\"line\"><span class=\"comment\">#服务监听地址</span></span><br><span class=\"line\">listeners=PLAINTEXT://worker1:9092</span><br><span class=\"line\"><span class=\"comment\">#数据⽂件地址。同样默认是给的/tmp⽬录。</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kafka-logs</span><br><span class=\"line\"><span class=\"comment\">#默认的每个Topic的分区数，创建Topic时，如果未指定分区数，则默认为1个分区。</span></span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"><span class=\"comment\"># 每个⽇志⽂件删除之前保存的时间，默认是168小时，即7天。</span></span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"><span class=\"comment\">#zookeeper的服务地址，如果是自建的 Zookeeper 集群，则这里需要填写集群的连接地址</span></span><br><span class=\"line\">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别在三个节点上启动 Kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --bootstrap-server worker1:9092 --create --replication-factor 3 --partitions 3 --topic disTopic</span><br><span class=\"line\"><span class=\"comment\">## 参数说明</span></span><br><span class=\"line\"><span class=\"comment\"># --replication-factor 3 表示创建的副本数</span></span><br><span class=\"line\"><span class=\"comment\"># --partitions 3 表示创建的分区数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 topic 详情</span></span><br><span class=\"line\">kafka-topics.sh --bootstrap-server worker1:9092 --describe --topic disTopic</span><br><span class=\"line\">Topic: disTopic\tTopicId: VUK7Mc9oQdS1mjGG7OhQzQ\tPartitionCount: 3\tReplicationFactor: Configs:</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 0\tLeader: 2\tReplicas: 2,3,1\tIsr: 2,3,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 1\tLeader: 3\tReplicas: 3,1,2\tIsr: 3,1,2\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 2\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: N/A\tLastKnownElr: N/A</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 简介 Apache Kafka 是一个 分布式的流处理/事件流平台，既可以作为消息系统，也可以作为持久化的 日志/记录存储与流处理平台。 它的设计目标是高吞吐、低延迟、可水平扩展、容错，以及可持久化数据。 在 Kafka 中，消息被归类为 主题（Topic），每个主题可以根据配置被拆分为多个 分区（Partition），每个分区内部消息是严格有序的，并以追加方式写入。消费者可以按偏移量（offset）读取消息。 Kafka 提供多个 API：Producer、Consumer、Streams（流处理）、Connect（与外部系统整合）等。 Kafka 的核心架构要素与工作机制 组件 / 概念 作用 / 描述 Broker（节点 / 服务器） Kafka 集群中的服务器实例，负责接收、存储、分发消息 Topic 消息的“分类”逻辑单元，Producer 写入、Consumer 读取 Partition 一个 Topic 被划分的子单元。分区使得主题可以横向扩展，并支持并行读写 Offset 每条消息在某个分区中的唯一位置标识，消费者根据 offset 来决定下一条读取 Replication（副本） 为了容错性，每个分区可以有多个副本（副本分布在不同 Broker 上） Leader / Follower 在副本中，一个副本为 Leader，接受读写请求；其他为 Follower，从 Leader 同步数据 Consumer Group 一组消费者共同消费一个 Topic。每个分区在同一个消费者组中通常只被一个消费者 “拥有” ZooKeeper / KRaft 用于元数据管理、集群协调（在较老版本中是 ZooKeeper；新版本推向 KRaft） 消息写入流程（简化）： Producer 将消息发送给某个 Topic 的 Leader 分区节点 Leader 接收到消息后，将其追加写入本地日志，并返回确认（ACK） Follower 副本从 Leader 拉取数据进行同步 消费者根据自己的 offset 从对应 Partition 中读取消息 消费控制与容错： 消费者维护自己的 offset（可以自动提交，也可手动控制），这样即使消费者重启，也可以从上次停止的位置继续。 如果某个 Broker 宕机，副本可以切换（Leader 选举），保证服务继续。 分区与副本机制使得 Kafka 能够扩展容量 &amp; 提高可靠性。 Kafka 的典型使用场景 场景类别 说明 实时数据管道 / 数据集成 用于将各种数据源（如日志、数据库变更、传感器、用户事件等）实时采集、传输、分发到下游系统（如 OLAP、搜索引擎、监控平台等），构建高效的数据通道。 事件驱动 / 事件溯源 记录系统内部或跨系统的事件（状态变化），实现事件驱动架构（EDA）或事件溯源（Event Sourcing），可用于审计、回放、状态重建等。 日志聚合 / 分析 将分布式系统中的应用日志、监控指标、操作日志等统一收集到 Kafka 中，集中存储与分析，常与 ELK、ClickHouse 等结合。 流处理 与 Kafka Streams、Apache Flink、Spark Streaming 等流处理框架配合，对流经 Kafka 的数据进行实时计算、聚合、过滤、窗口统计等操作。 系统解耦 / 异步通信 作为系统间的消息中间件，实现发布-订阅模式，减少系统间耦合，支持异步通信、流量削峰、缓冲等，提升系统稳定性与扩展性。 Kafka 安装 这里先介绍基于 Zookeeper 的安装方式，下文会介绍基于 KRaft 的安装方式。 Kafka 3.9.1 的安装与运行需要 JDK 8+，所有我们需要提前安装 JDK 8+。可以选择OpenJDK，清华大学镜像站 123456789101112131415# root 用户# 创建安装目录mkdir /usr/local/jdkcd /usr/local/jdk# 下载JDKwget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gztar -zxvf OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gzln -s jdk8u462-b08 jdk8# 配置环境变量echo &#x27;export JAVA_HOME=/usr/local/jdk/jdk8&#x27; &gt;&gt; /etc/profile# 注意这里是 单引号，双引号会解析变量，导致配置失败echo &#x27;export PATH=$JAVA_HOME/bin:$PATH&#x27; &gt;&gt; /etc/profilesource /etc/profile# 检查JDK安装java -version 安装过程参考官网文档Kafka Quick Start。 单机安装 部署kafka都会使用集群模式，单机模式只作为学习试用。 下载Kafka，下载页面 1234567891011121314# root 用户# 创建安装目录mkdir /usr/local/kafkacd /usr/local/kafka# 下载Kafkawget https://dlcdn.apache.org/kafka/3.9.1/kafka_2.13-3.9.1.tgztar -zxvf kafka_2.13-3.9.1.tgzln -s kafka_2.13-3.9.1 kafka3# 配置环境变量echo &#x27;export KAFKA_HOME=/usr/local/kafka/kafka3&#x27; &gt;&gt; /etc/profileecho &#x27;export PATH=$KAFKA_HOME/bin:$PATH&#x27; &gt;&gt; /etc/profilesource /etc/profile# 查看Kafka版本kafka-topics.sh --version 启动 Zookeeper，kafka内置了zookeeper，所以不需要单独安装。 1234567# 前台运行zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties# 后台运行nohup zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties &gt; zookeeper.log 2&gt;&amp;1 &amp;# 关闭zookeeper，kill进程，过滤 java &amp; QuorumPeerMainzookeeper-server-stop.sh 启动 kafka 12345678# -daemon 后台运行kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties# 检查kafka是否启动成功jps -l | grep kafka# 停止 kafka，kill进程，过滤 java &amp; &#x27;kafka\\.Kafka&#x27;kafka-server-stop.sh 小贴士 注意：默认情况下 启动 kafka 需要的内存大小为 1G，这一点可以在 kafka-server-start.sh 脚本中查看到 123if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;fi 所以如果内存不够，可以设置环境变量后再启动kafka 12export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Xms512M&quot;kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 测试 123456789# 创建 topickafka-topics.sh --create --bootstrap-server localhost:9092 --topic test# 启动消费者kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning# 启动生产者kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test&gt; hello world # 输入内容，消费者会收到 集群安装 集群安装需要准备多个节点，这里我准备三个节点，分别如下： 12310.250.0.710.250.0.17410.250.0.108 搭建 Zookeeper 集群 关于如何搭建 Zookeeper 集群，可以参考我之前的文章 Zookeeper 的安装及使用 如果图省事也可以直接使用 Kafka 自带的 zookeeper，编辑其配置文件 config/zookeeper.properties如下，注意要在 dataDir 目录下创建myid文件 12345678910111213141516dataDir=/usr/local/kafka/dataDir/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0# Disable the adminserver by default to avoid port conflicts.# Set the port to something non-conflicting if choosing to enable thisadmin.enableServer=false# admin.serverPort=8080initLimit=10syncLimit=5server.1=10.250.0.7:2888:3888server.2=10.250.0.174:2888:3888server.3=10.250.0.108:2888:3888 配置 Kafka 集群 修改主机的主机名 123hostnamectl hostname worker1# hostnamectl hostname worker2# hostnamectl hostname worker3 为了后续方便维护，将ip地址映射到 hosts 文件中 12310.250.0.7 worker110.250.0.174 worker210.250.0.108 worker3 编辑 config/server.properties 文件，需要修改如下配置项 123456789101112#broker 的全局唯⼀编号，不能重复，只能是数字。broker.id=1 # 这里分别设置为1、2、3#服务监听地址listeners=PLAINTEXT://worker1:9092#数据⽂件地址。同样默认是给的/tmp⽬录。log.dirs=/usr/local/kafka/dataDir/kafka-logs#默认的每个Topic的分区数，创建Topic时，如果未指定分区数，则默认为1个分区。num.partitions=1# 每个⽇志⽂件删除之前保存的时间，默认是168小时，即7天。log.retention.hours=168#zookeeper的服务地址，如果是自建的 Zookeeper 集群，则这里需要填写集群的连接地址zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 分别在三个节点上启动 Kafka 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 测试 123456789101112# 创建 topickafka-topics.sh --bootstrap-server worker1:9092 --create --replication-factor 3 --partitions 3 --topic disTopic## 参数说明# --replication-factor 3 表示创建的副本数# --partitions 3 表示创建的分区数# 查看 topic 详情kafka-topics.sh --bootstrap-server worker1:9092 --describe --topic disTopicTopic: disTopic TopicId: VUK7Mc9oQdS1mjGG7OhQzQ PartitionCount: 3 ReplicationFactor: Configs: Topic: disTopic Partition: 0 Leader: 2 Replicas: 2,3,1 Isr: 2,3,1 Elr: N/A LastKnownElr: N/A Topic: disTopic Partition: 1 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2 Elr: N/A LastKnownElr: N/A Topic: disTopic Partition: 2 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3 Elr: N/A LastKnownElr: N/A","summary":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-13T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/","url":"https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/","title":"RabbitMQ 之 Cluster","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RabbitMQ-Cluster-集群-简介\">RabbitMQ Cluster(集群) 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/clustering\">Cluster（集群）</a> 是多个节点组成的集合，用于实现高可用和负载均衡。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 集群是一个或多个（三个、五个、七个或更多）节点的逻辑分组， 每个节点共享 用户、虚拟主机、队列、流、交换、绑定、运行时参数和其他分布式状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，Cluster（集群）的节点分为两种：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">磁盘节点(disk)：会把集群的所有元数据信息（比如交换机、绑定、队列、虚拟主机等信息）持久化到磁盘中。Master 节点必须是磁盘节点。</li>\n<li class=\"lvl-4\">内存节点(ram)：只会将这些信息保存到内存中，如果该节点宕机或重启，内存节点的数据会全部丢失，而磁盘节点的数据不会丢失。Slave 节点可以是内存节点。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 开始， 集群不再区分 <code>普通集群模式（Classic Cluster）</code> 与 <code>镜像集群模式（Mirrored Queue Cluster）</code> ，集群创建好后，会根据队列的<code>初始复制因子参数</code>决定为该队列创建多少个副本，比如 <code>Quroum Queue</code> 的参数是 <code>x-quorum-initial-group-size</code>，默认为3。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 开始，<code>Quroum Queue</code> 和 <code>Stream Queue</code> 默认开启节点间<code>消息复制</code>，但是 <code>Classic Queue</code> 队列不支持节点间的<code>消息复制</code>;</p>\n</li>\n</ul>\n<div class=\"tips\">\n<p><em><strong>RabbitMQ 4.0以前的 集群分为两种模式</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">\n<ol>\n<li class=\"lvl-5\">普通集群模式（Classic Cluster）</li>\n</ol>\n<ul class=\"lvl-3\">\n<li class=\"lvl-4\">在 普通集群模式下，RabbitMQ 节点通过 Erlang 分布式系统实现互联，集群内的各个节点共享 消息队列、交换机、绑定等元素。</li>\n<li class=\"lvl-4\">普通集群的特点：\n<ul class=\"lvl-5\">\n<li class=\"lvl-6\">共享队列：队列数据仅存储在单一节点上，只有该节点可以处理队列中的消息。</li>\n<li class=\"lvl-6\">不自动复制数据：在普通集群中，消息并不会自动复制到其他节点。如果某个节点挂掉，队列上的消息就会丢失，无法恢复。</li>\n<li class=\"lvl-6\">负载均衡：交换机（Exchange）会把消息发送到不同的队列，但队列数据仍然只在一个节点上。因此，普通集群适合不要求极高可用性的场景。</li>\n<li class=\"lvl-6\">不具备高可用性：由于数据不会在集群的其他节点中复制，普通集群在某个节点宕机时，可能会导致消息丢失和系统不可用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<ol start=\"2\">\n<li class=\"lvl-5\">镜像集群模式（Mirrored Queue Cluster）</li>\n</ol>\n<ul class=\"lvl-3\">\n<li class=\"lvl-4\">镜像集群模式 是为了 高可用性 设计的，在该模式下，队列的数据会在集群中的多个节点上进行 复制（镜像），从而保证即使某个节点出现故障，数据也不会丢失。</li>\n<li class=\"lvl-4\">镜像集群的特点：\n<ul class=\"lvl-5\">\n<li class=\"lvl-6\">队列镜像：在镜像集群模式中，队列数据会在集群中的多个节点上复制。每个队列都有一个主节点和多个镜像节点。</li>\n<li class=\"lvl-6\">高可用性：消息会被复制到集群的其他节点上，从而保证如果一个节点宕机，数据不会丢失，系统能迅速恢复。</li>\n<li class=\"lvl-6\">节点故障恢复：当一个节点挂掉时，其他节点会继续处理该队列的消息，保证业务的高可用性。</li>\n<li class=\"lvl-6\">网络负担较重：由于需要在多个节点之间进行数据同步和复制，所以镜像队列模式会增加集群的网络负担和磁盘 I/O。</li>\n<li class=\"lvl-6\">性能影响：镜像队列模式会稍微影响性能，因为每次消息处理后，都需要将数据同步到其他镜像节点，增加了延迟。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</div>\n<h2 id=\"集群搭建\">集群搭建</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>准备三台服务器，分别安装 RabbitMQ ，安装方法参看 <a href=\"/2025/09/18/rabbitmq-install-01/\" title=\"RabbitMQ 的安装及使用\">RabbitMQ 的安装及使用</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>开放端口</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>端口范围</strong></th>\n<th><strong>用途</strong></th>\n<th><strong>备注</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>4369</strong></td>\n<td>epmd（Erlang Port Mapper Daemon）</td>\n<td>RabbitMQ 节点和 CLI 工具使用的帮助程序发现守护进程。</td>\n</tr>\n<tr>\n<td><strong>6000-6500</strong></td>\n<td>RabbitMQ Stream 复制使用</td>\n<td>用于 RabbitMQ Stream 的数据复制。</td>\n</tr>\n<tr>\n<td><strong>25672</strong></td>\n<td>Erlang 分发服务器端口</td>\n<td>用于节点间和 CLI 工具通信，默认情况下仅限于单个端口（AMQP端口 + 20000）。</td>\n</tr>\n<tr>\n<td><strong>35672-35682</strong></td>\n<td>Erlang 分发客户端端口</td>\n<td>用于 CLI 工具与节点通信，计算为服务器分发端口 + 10000 到 服务器分发端口 + 10010。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别修改三台服务器的 <code>hostname</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl hostname rabbitmq01</span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname rabbitmq02</span></span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname rabbitmq03</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别修改三台服务器的 <code>/etc/hosts</code> 文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.56  rabbitmq01</span><br><span class=\"line\">10.250.0.232 rabbitmq02</span><br><span class=\"line\">10.250.0.97  rabbitmq03</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>同步集群节点中的cookie</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">默认会在 <code>/var/lib/rabbitmq/</code>目录下生成一个<code>.erlang.cookie</code>，里面有一个字符串。</li>\n<li class=\"lvl-4\">我们使用 <code>rabbitmq01</code> 节点作为集群的主节点，其他节点作为集群的成员节点，我们要做的就是保证集群中三个节点的这个<code>cookie字符串一致</code>。</li>\n<li class=\"lvl-4\">将 <code>rabbitmq01</code> 的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中的<code>cookie字符串</code>复制到其他节点的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>分别启动三台服务器的 RabbitMQ 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start rabbitmq-server</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别登录 <code>rabbitmq02</code> 和 <code>rabbitmq03</code> 节点，执行如下命令，将节点加入集群</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停掉rabbitmq应用</span></span><br><span class=\"line\">rabbitmqctl stop_app</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重置rabbitmq、交换机、队列</span></span><br><span class=\"line\">rabbitmqctl reset</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加入集群，注意此时 rabbitmq01 是主节点，必须处于运行状态，</span></span><br><span class=\"line\"><span class=\"comment\"># --ram 表示以 ram 内存节点 加入集群。如果不带参数默认为 disk 磁盘节点</span></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ的集群节点分为 disk 和 ram，disk节点会将元数据保存到硬盘当中，而ram节点只是在内存中保存元数据。</span></span><br><span class=\"line\">rabbitmqctl join_cluster rabbit@rabbitmq01 --ram</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动rabbitmq应用</span></span><br><span class=\"line\">rabbitmqctl start_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录 任意 节点，执行如下命令，查看集群状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl cluster_status</span><br><span class=\"line\"><span class=\"comment\">## 输出类似</span></span><br><span class=\"line\">Cluster status of node rabbit@rabbitmq01 ...</span><br><span class=\"line\">Basics</span><br><span class=\"line\"></span><br><span class=\"line\">Cluster name: rabbit@rabbitmq01</span><br><span class=\"line\">Total CPU cores available cluster-wide: 6</span><br><span class=\"line\"></span><br><span class=\"line\">Cluster Tags</span><br><span class=\"line\"></span><br><span class=\"line\">(none)</span><br><span class=\"line\"></span><br><span class=\"line\">Disk Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq01</span><br><span class=\"line\"></span><br><span class=\"line\">RAM Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq02</span><br><span class=\"line\">rabbit@rabbitmq03</span><br><span class=\"line\"></span><br><span class=\"line\">Running Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq01</span><br><span class=\"line\">rabbit@rabbitmq02</span><br><span class=\"line\">rabbit@rabbitmq03</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>PS: 由于ram节点减少了很多与硬盘的交互，所以，ram节点的元数据使用性能会比较高。但是，同时，这也意味着元数据的安全性是不如disk节点的。在我们这个集群中， rabbitmq02 和 rabbitmq03 都以 ram节点 的身份加入到 rabbitmq01 集群里，因此，是存在单点故障的。如果 rabbitmq01 节点服务崩溃，那么元数据就有可能丢失。在企业进行部署时，性能与安全性需要自己进行平衡。</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录任意节点的管理页面，查看集群状态<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/R195gJ.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>此时我们在任意节点中创建虚拟主机、队列、交换机和绑定关系 等元数据，都会自动同步到其他节点中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>我们也可以在 管理控制台 中查看队列时看到，此时多个一列，<code>Node</code>列，显示该队列在哪些节点中存在。只有 <code>Quorum 队列</code> 和 <code>Stream 队列</code> 才会显示多个节点，因为 <code>Classic 队列</code> 不支持多节点复制。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/GjHcLN.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>查看某个具体的 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，可以看到更详细的说明<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/XtIkpp.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>此时新建队列，会要求我们指定主节点(Leader)，即负责存储消息的的节点，而 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，会自动将消息复制到其它节点(Members)。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Leader: 队列的主节点，负责存储消息。</li>\n<li class=\"lvl-4\">Members: 队列的成员节点，负责存储消息的副本。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"演示队列复制\">演示队列复制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>默认情况下，<code>Quorum 队列</code> 和 <code>Stream 队列</code> 的 复制数 都为 3，这里为了演示，我在增加一个节点 <code>rabbitmq04</code>，请自行按上面的方法添加。</p>\n</li>\n</ul>\n<h3 id=\"Quorum-队列\">Quorum 队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在页面上创建一个 <code>Quorum 队列</code>，与单节点上创建队列的区别就是需要我们选择主节点。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/JYfKgg.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 客户端 创建队列时，默认情况下，连接哪个节点，哪个节点就是Leader，但也可以通过参数<code>x-queue-leader-locator</code>指定主节点的选择策略。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqadmin queues <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;/vtest&quot;</span> --name <span class=\"string\">&quot;target.quorum.queue.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;quorum&quot;</span> --durable <span class=\"literal\">true</span> --arguments <span class=\"string\">&#x27;&#123;&quot;x-queue-leader-locator&quot;:&quot;balanced&quot;&#125;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># x-queue-leader-locator 有两种选择策略</span></span><br><span class=\"line\"><span class=\"comment\">## client-local：选择声明队列的客户端所连接的节点。这是默认值。</span></span><br><span class=\"line\"><span class=\"comment\">## balanced：如果队列总数少于 1000 个（经典队列、仲裁队列和流）， 选择托管最小数量的仲裁队列领导者的节点。 如果队列总体超过 1000 个，则随机选择一个节点。</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建成功后，可以看到 <code>Quorum 队列</code> 的主节点和成员节点，可以看到这里成员节点有三个，除了主节点外，其余节点由集群自动选择。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qBfNNh.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>也就是说，默认情况下，<code>Quorum 队列</code> 的复制数是 <code>3</code>，如果我们希望改变复制数，可以在创建队列时指定参数 <code>x-quorum-initial-group-size</code>，其值为 <code>大于 0 的整数</code>，若设置值大于实际成员节点数，则以实际成员节点数为准。<code>x-quorum-initial-group-size</code> 设置为 <code>1</code> 时便不进行复制了。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果集群中增加了新的节点，希望队列也被复制到新的节点中，可以通过如下命令，将新的节点加入成员节点中:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues add_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-queues add_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>如果希望将节点从成员节点中移除，可以通过如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues delete_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-queues delete_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>另外，当通过 <code>forget_cluster_node</code> 命令从集群中永久删除节点时，会自动将队列关联的节点从成员节点中移除。</p>\n</li>\n<li class=\"lvl-2\">\n<p>删除节点时，请使用如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 因为要删除 rabbitmq04 节点，所以以下命令不能在 rabbitmq04 节点执行</span></span><br><span class=\"line\"><span class=\"comment\"># 删除前需要先关闭应用</span></span><br><span class=\"line\">rabbitmqctl -n rabbit@rabbitmq04 stop_app</span><br><span class=\"line\"><span class=\"comment\"># 删除节点</span></span><br><span class=\"line\"><span class=\"comment\"># rabbitmqctl forget_cluster_node &lt;node&gt;</span></span><br><span class=\"line\">rabbitmqctl forget_cluster_node rabbit@rabbitmq04</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>新增节点后，一个个的对原有的队列进行复制扩展非常麻烦，可以通过如下命令快速对符合条件的队列进行复制扩展:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues grow &lt;node&gt; &lt;all | even&gt; [--vhost-pattern &lt;pattern&gt;] [--queue-pattern &lt;pattern&gt;]</span></span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;node&gt;: 这个参数指定了 RabbitMQ 节点的名称，通常是 rabbit@&lt;hostname&gt;。它表示在哪个节点上执行增长操作。</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;all | even&gt;: 这个参数指定了要扩展的队列类型。all 表示扩展所有队列，even 表示扩展偶数编号的队列。</span></span><br><span class=\"line\"><span class=\"comment\"># --vhost-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的虚拟主机名称。</span></span><br><span class=\"line\"><span class=\"comment\"># --queue-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的队列名称。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 示例</span></span><br><span class=\"line\"><span class=\"comment\"># 扩展所有虚拟主机下的所有队列的副本：</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 all</span><br><span class=\"line\"><span class=\"comment\"># 扩展所有虚拟主机下的偶数编号的队列的副本：</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 even</span><br><span class=\"line\"><span class=\"comment\"># 扩展特定虚拟主机和队列名称的队列</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 all --vhost-pattern /vtest --queue-pattern <span class=\"string\">&quot;^q_&quot;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Stream-队列\">Stream 队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Stream 队列 与 Quorum 队列 类似，通过哪个节点创建队列，哪个节点就是 Leader，但也是可以通过参数 <code>x-queue-leader-locator</code> 指定主节点的选择策略。</p>\n</li>\n<li class=\"lvl-2\">\n<p>创建 Stream 队列时，默认复制数就是当前集群的节点数（Quorum 队列 默认是 3），可以通过指定参数 <code>x-initial-cluster-size</code> 进行初始设置。</p>\n</li>\n<li class=\"lvl-2\">\n<p>添加新的节点时，与 Quorum 队列 类似，Stream 队列 也不会自动进行复制，可以通过如下命令手动复制</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-streams add_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除成员节点时，请使用如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-streams delete_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看节点复制状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class=\"line\">rabbitmq-streams stream_status -p /vtest sq_2</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当流出现异常状态（如副本分布异常、领导节点挂掉）时，为了恢复可用性，可以重启流</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams restart_stream [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class=\"line\">rabbitmq-streams restart_stream -p /vtest sq_2</span><br><span class=\"line\"><span class=\"comment\">## 重启操作</span></span><br><span class=\"line\"><span class=\"comment\"># 1.停止流的当前副本/分区。</span></span><br><span class=\"line\"><span class=\"comment\"># 2.重新初始化流的存储和元数据。</span></span><br><span class=\"line\"><span class=\"comment\"># 3.让流在集群中恢复为可用状态。</span></span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 RabbitMQ Cluster(集群) 简介 在 RabbitMQ 中，Cluster（集群） 是多个节点组成的集合，用于实现高可用和负载均衡。 RabbitMQ 集群是一个或多个（三个、五个、七个或更多）节点的逻辑分组， 每个节点共享 用户、虚拟主机、队列、流、交换、绑定、运行时参数和其他分布式状态。 在 RabbitMQ 中，Cluster（集群）的节点分为两种： 磁盘节点(disk)：会把集群的所有元数据信息（比如交换机、绑定、队列、虚拟主机等信息）持久化到磁盘中。Master 节点必须是磁盘节点。 内存节点(ram)：只会将这些信息保存到内存中，如果该节点宕机或重启，内存节点的数据会全部丢失，而磁盘节点的数据不会丢失。Slave 节点可以是内存节点。 RabbitMQ 4.0 开始， 集群不再区分 普通集群模式（Classic Cluster） 与 镜像集群模式（Mirrored Queue Cluster） ，集群创建好后，会根据队列的初始复制因子参数决定为该队列创建多少个副本，比如 Quroum Queue 的参数是 x-quorum-initial-group-size，默认为3。 RabbitMQ 4.0 开始，Quroum Queue 和 Stream Queue 默认开启节点间消息复制，但是 Classic Queue 队列不支持节点间的消息复制; RabbitMQ 4.0以前的 集群分为两种模式 普通集群模式（Classic Cluster） 在 普通集群模式下，RabbitMQ 节点通过 Erlang 分布式系统实现互联，集群内的各个节点共享 消息队列、交换机、绑定等元素。 普通集群的特点： 共享队列：队列数据仅存储在单一节点上，只有该节点可以处理队列中的消息。 不自动复制数据：在普通集群中，消息并不会自动复制到其他节点。如果某个节点挂掉，队列上的消息就会丢失，无法恢复。 负载均衡：交换机（Exchange）会把消息发送到不同的队列，但队列数据仍然只在一个节点上。因此，普通集群适合不要求极高可用性的场景。 不具备高可用性：由于数据不会在集群的其他节点中复制，普通集群在某个节点宕机时，可能会导致消息丢失和系统不可用。 镜像集群模式（Mirrored Queue Cluster） 镜像集群模式 是为了 高可用性 设计的，在该模式下，队列的数据会在集群中的多个节点上进行 复制（镜像），从而保证即使某个节点出现故障，数据也不会丢失。 镜像集群的特点： 队列镜像：在镜像集群模式中，队列数据会在集群中的多个节点上复制。每个队列都有一个主节点和多个镜像节点。 高可用性：消息会被复制到集群的其他节点上，从而保证如果一个节点宕机，数据不会丢失，系统能迅速恢复。 节点故障恢复：当一个节点挂掉时，其他节点会继续处理该队列的消息，保证业务的高可用性。 网络负担较重：由于需要在多个节点之间进行数据同步和复制，所以镜像队列模式会增加集群的网络负担和磁盘 I/O。 性能影响：镜像队列模式会稍微影响性能，因为每次消息处理后，都需要将数据同步到其他镜像节点，增加了延迟。 集群搭建 准备三台服务器，分别安装 RabbitMQ ，安装方法参看 RabbitMQ 的安装及使用 开放端口 端口范围 用途 备注 4369 epmd（Erlang Port Mapper Daemon） RabbitMQ 节点和 CLI 工具使用的帮助程序发现守护进程。 6000-6500 RabbitMQ Stream 复制使用 用于 RabbitMQ Stream 的数据复制。 25672 Erlang 分发服务器端口 用于节点间和 CLI 工具通信，默认情况下仅限于单个端口（AMQP端口 + 20000）。 35672-35682 Erlang 分发客户端端口 用于 CLI 工具与节点通信，计算为服务器分发端口 + 10000 到 服务器分发端口 + 10010。 分别修改三台服务器的 hostname 123hostnamectl hostname rabbitmq01# hostnamectl hostname rabbitmq02# hostnamectl hostname rabbitmq03 分别修改三台服务器的 /etc/hosts 文件 12310.250.0.56 rabbitmq0110.250.0.232 rabbitmq0210.250.0.97 rabbitmq03 同步集群节点中的cookie 默认会在 /var/lib/rabbitmq/目录下生成一个.erlang.cookie，里面有一个字符串。 我们使用 rabbitmq01 节点作为集群的主节点，其他节点作为集群的成员节点，我们要做的就是保证集群中三个节点的这个cookie字符串一致。 将 rabbitmq01 的 /var/lib/rabbitmq/.erlang.cookie 文件中的cookie字符串复制到其他节点的 /var/lib/rabbitmq/.erlang.cookie 文件中。 分别启动三台服务器的 RabbitMQ 服务 1systemctl start rabbitmq-server 分别登录 rabbitmq02 和 rabbitmq03 节点，执行如下命令，将节点加入集群 12345678910111213# 停掉rabbitmq应用rabbitmqctl stop_app# 重置rabbitmq、交换机、队列rabbitmqctl reset# 加入集群，注意此时 rabbitmq01 是主节点，必须处于运行状态，# --ram 表示以 ram 内存节点 加入集群。如果不带参数默认为 disk 磁盘节点# RabbitMQ的集群节点分为 disk 和 ram，disk节点会将元数据保存到硬盘当中，而ram节点只是在内存中保存元数据。rabbitmqctl join_cluster rabbit@rabbitmq01 --ram# 启动rabbitmq应用rabbitmqctl start_app 登录 任意 节点，执行如下命令，查看集群状态 1234567891011121314151617181920212223242526rabbitmqctl cluster_status## 输出类似Cluster status of node rabbit@rabbitmq01 ...BasicsCluster name: rabbit@rabbitmq01Total CPU cores available cluster-wide: 6Cluster Tags(none)Disk Nodesrabbit@rabbitmq01RAM Nodesrabbit@rabbitmq02rabbit@rabbitmq03Running Nodesrabbit@rabbitmq01rabbit@rabbitmq02rabbit@rabbitmq03 PS: 由于ram节点减少了很多与硬盘的交互，所以，ram节点的元数据使用性能会比较高。但是，同时，这也意味着元数据的安全性是不如disk节点的。在我们这个集群中， rabbitmq02 和 rabbitmq03 都以 ram节点 的身份加入到 rabbitmq01 集群里，因此，是存在单点故障的。如果 rabbitmq01 节点服务崩溃，那么元数据就有可能丢失。在企业进行部署时，性能与安全性需要自己进行平衡。 登录任意节点的管理页面，查看集群状态 此时我们在任意节点中创建虚拟主机、队列、交换机和绑定关系 等元数据，都会自动同步到其他节点中。 我们也可以在 管理控制台 中查看队列时看到，此时多个一列，Node列，显示该队列在哪些节点中存在。只有 Quorum 队列 和 Stream 队列 才会显示多个节点，因为 Classic 队列 不支持多节点复制。 查看某个具体的 Quorum 队列 或 Stream 队列，可以看到更详细的说明 此时新建队列，会要求我们指定主节点(Leader)，即负责存储消息的的节点，而 Quorum 队列 或 Stream 队列，会自动将消息复制到其它节点(Members)。 Leader: 队列的主节点，负责存储消息。 Members: 队列的成员节点，负责存储消息的副本。 演示队列复制 默认情况下，Quorum 队列 和 Stream 队列 的 复制数 都为 3，这里为了演示，我在增加一个节点 rabbitmq04，请自行按上面的方法添加。 Quorum 队列 在页面上创建一个 Quorum 队列，与单节点上创建队列的区别就是需要我们选择主节点。 通过 客户端 创建队列时，默认情况下，连接哪个节点，哪个节点就是Leader，但也可以通过参数x-queue-leader-locator指定主节点的选择策略。 1234rabbitmqadmin queues declare --vhost &quot;/vtest&quot; --name &quot;target.quorum.queue.name&quot; --type &quot;quorum&quot; --durable true --arguments &#x27;&#123;&quot;x-queue-leader-locator&quot;:&quot;balanced&quot;&#125;&#x27;# x-queue-leader-locator 有两种选择策略## client-local：选择声明队列的客户端所连接的节点。这是默认值。## balanced：如果队列总数少于 1000 个（经典队列、仲裁队列和流）， 选择托管最小数量的仲裁队列领导者的节点。 如果队列总体超过 1000 个，则随机选择一个节点。 创建成功后，可以看到 Quorum 队列 的主节点和成员节点，可以看到这里成员节点有三个，除了主节点外，其余节点由集群自动选择。 也就是说，默认情况下，Quorum 队列 的复制数是 3，如果我们希望改变复制数，可以在创建队列时指定参数 x-quorum-initial-group-size，其值为 大于 0 的整数，若设置值大于实际成员节点数，则以实际成员节点数为准。x-quorum-initial-group-size 设置为 1 时便不进行复制了。 如果集群中增加了新的节点，希望队列也被复制到新的节点中，可以通过如下命令，将新的节点加入成员节点中: 12# rabbitmq-queues add_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;rabbitmq-queues add_member -p /vtest q_4 rabbit@rabbitmq02 如果希望将节点从成员节点中移除，可以通过如下命令: 12# rabbitmq-queues delete_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;rabbitmq-queues delete_member -p /vtest q_4 rabbit@rabbitmq02 另外，当通过 forget_cluster_node 命令从集群中永久删除节点时，会自动将队列关联的节点从成员节点中移除。 删除节点时，请使用如下命令: 123456# 因为要删除 rabbitmq04 节点，所以以下命令不能在 rabbitmq04 节点执行# 删除前需要先关闭应用rabbitmqctl -n rabbit@rabbitmq04 stop_app# 删除节点# rabbitmqctl forget_cluster_node &lt;node&gt;rabbitmqctl forget_cluster_node rabbit@rabbitmq04 新增节点后，一个个的对原有的队列进行复制扩展非常麻烦，可以通过如下命令快速对符合条件的队列进行复制扩展: 1234567891011121314# rabbitmq-queues grow &lt;node&gt; &lt;all | even&gt; [--vhost-pattern &lt;pattern&gt;] [--queue-pattern &lt;pattern&gt;]## 参数说明：# &lt;node&gt;: 这个参数指定了 RabbitMQ 节点的名称，通常是 rabbit@&lt;hostname&gt;。它表示在哪个节点上执行增长操作。# &lt;all | even&gt;: 这个参数指定了要扩展的队列类型。all 表示扩展所有队列，even 表示扩展偶数编号的队列。# --vhost-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的虚拟主机名称。# --queue-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的队列名称。## 示例# 扩展所有虚拟主机下的所有队列的副本：rabbitmq-queues grow rabbit@rabbitmq04 all# 扩展所有虚拟主机下的偶数编号的队列的副本：rabbitmq-queues grow rabbit@rabbitmq04 even# 扩展特定虚拟主机和队列名称的队列rabbitmq-queues grow rabbit@rabbitmq04 all --vhost-pattern /vtest --queue-pattern &quot;^q_&quot; Stream 队列 Stream 队列 与 Quorum 队列 类似，通过哪个节点创建队列，哪个节点就是 Leader，但也是可以通过参数 x-queue-leader-locator 指定主节点的选择策略。 创建 Stream 队列时，默认复制数就是当前集群的节点数（Quorum 队列 默认是 3），可以通过指定参数 x-initial-cluster-size 进行初始设置。 添加新的节点时，与 Quorum 队列 类似，Stream 队列 也不会自动进行复制，可以通过如下命令手动复制 12# rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;rabbitmq-streams add_replica -p /vtest sq_2 rabbit@rabbitmq02 删除成员节点时，请使用如下命令: 12# rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;rabbitmq-streams delete_replica -p /vtest sq_2 rabbit@rabbitmq02 查看节点复制状态 12# rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;rabbitmq-streams stream_status -p /vtest sq_2 当流出现异常状态（如副本分布异常、领导节点挂掉）时，为了恢复可用性，可以重启流 123456# rabbitmq-streams restart_stream [-p &lt;vhost&gt;] &lt;stream-name&gt;rabbitmq-streams restart_stream -p /vtest sq_2## 重启操作# 1.停止流的当前副本/分区。# 2.重新初始化流的存储和元数据。# 3.让流在集群中恢复为可用状态。","summary":"摘要 本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-25T14:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/","url":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/","title":"RabbitMQ 之 Message","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Message 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Message-消息-是什么？\">Message(消息) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，Message（消息）是消息队列中的数据单元。消息包含消息内容、消息属性等信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Message 组成：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">\n<ol>\n<li class=\"lvl-7\">消息内容：消息的内容，可以是任意数据。</li>\n</ol>\n</li>\n<li class=\"lvl-4\">\n<ol start=\"2\">\n<li class=\"lvl-7\">消息属性：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Web-控制台-中-Message-的使用\">Web 控制台 中 Message 的使用</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Exchange 和 Queue 的管理界面中，都可以在其详情页面测试 Message 的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>关于如何在代码中使用 Message，我会在下一节中详细介绍。</p>\n</li>\n</ul>\n<h3 id=\"Publish-message\">Publish message</h3>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/dHsDyt.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Payload：消息的内容，可以是任意数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Payload encoding：消息内容的编码方式，<code>String</code> 或者 <code>Base64</code>，默认为 <code>String</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Delivery mode：消息的持久化模式，1-Non-persistent 表示非持久化，2-Persistent 表示持久化。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Headers：消息的头信息，用于与 <code>Headers Exchange（头部交换机）</code>中的配置进行匹配。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Properties：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>属性名</th>\n<th>中文含义</th>\n<th>数据类型</th>\n<th>默认值</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>content_type</td>\n<td>内容类型</td>\n<td>String</td>\n<td>null</td>\n<td>指定消息的 MIME 类型，如 <code>&quot;text/plain&quot;</code>、<code>&quot;application/json&quot;</code></td>\n</tr>\n<tr>\n<td>content_encoding</td>\n<td>内容编码</td>\n<td>String</td>\n<td>null</td>\n<td>指定消息内容的编码方式，如 <code>&quot;gzip&quot;</code></td>\n</tr>\n<tr>\n<td>priority</td>\n<td>消息优先级</td>\n<td>Integer (0-255)</td>\n<td>0</td>\n<td>结合 <code>x-max-priority</code> 控制消息处理顺序，数值越大优先级越高</td>\n</tr>\n<tr>\n<td>correlation_id</td>\n<td>关联 ID</td>\n<td>String</td>\n<td>null</td>\n<td>RPC 模式中关联请求与响应</td>\n</tr>\n<tr>\n<td>reply_to</td>\n<td>回复队列名</td>\n<td>String</td>\n<td>null</td>\n<td>RPC 模式中指定响应消息的返回队列</td>\n</tr>\n<tr>\n<td>expiration</td>\n<td>消息过期时间</td>\n<td>String (ms)</td>\n<td>null</td>\n<td>消息的 TTL，毫秒为单位，过期后将被丢弃或进入死信队列</td>\n</tr>\n<tr>\n<td>message_id</td>\n<td>消息 ID</td>\n<td>String</td>\n<td>null</td>\n<td>唯一标识一条消息，通常由生产者指定</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>时间戳</td>\n<td>Date / Long</td>\n<td>null</td>\n<td>消息发送时间，通常是 Unix 时间戳</td>\n</tr>\n<tr>\n<td>type</td>\n<td>消息类型</td>\n<td>String</td>\n<td>null</td>\n<td>描述消息类型，如 <code>&quot;order&quot;</code> 或 <code>&quot;event&quot;</code></td>\n</tr>\n<tr>\n<td>user_id</td>\n<td>用户 ID</td>\n<td>String</td>\n<td>null</td>\n<td>标识发送消息的用户，通常用于安全或审计</td>\n</tr>\n<tr>\n<td>app_id</td>\n<td>应用 ID</td>\n<td>String</td>\n<td>null</td>\n<td>标识发送消息的应用程序</td>\n</tr>\n<tr>\n<td>cluster_id</td>\n<td>集群 ID</td>\n<td>String</td>\n<td>null</td>\n<td>RabbitMQ 集群 ID，实际中很少使用</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>与队列重叠的属性：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>队列参数（Queue Arguments）</th>\n<th>消息属性（Message Properties）</th>\n<th>谁的优先级更高 / 生效方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>priority / x-max-priority</strong></td>\n<td><code>x-max-priority</code>: 定义队列支持的<strong>最大优先级值</strong></td>\n<td><code>priority</code>: 为单个消息设置优先级</td>\n<td>队列先定义范围，消息只能在这个范围内取值 <br> 若 <code>priority &gt; x-max-priority</code>，则以<code>x-max-priority</code>为准</td>\n</tr>\n<tr>\n<td><strong>expiration / x-message-ttl</strong></td>\n<td><code>x-message-ttl</code>: 队列级别的消息<strong>统一 TTL</strong></td>\n<td><code>expiration</code>: 为单个消息设置 TTL（毫秒）</td>\n<td>如果同时设置，<strong>较短的 TTL</strong> 会生效</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"Get-message\">Get message</h3>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Ar9qob.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Ack Mode：消息确认模式</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Nack message requeue true: 确认失败，消息重新入队，这是默认选择，主要是为了测试后消息依旧存在。</li>\n<li class=\"lvl-4\">Automatic ack: 自动确认</li>\n<li class=\"lvl-4\">Reject requeue true: 拒绝，消息重新入队</li>\n<li class=\"lvl-4\">Reject requeue false: 拒绝，消息不重新入队</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Encoding：消息内容编码方式</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\"><code>Auto String / Base64</code>，默认。如果消息载荷可以解释为UTF-8编码的字符串，就是 <code>String</code>，否则就是 <code>Base64</code>。</li>\n<li class=\"lvl-4\"><code>Base64</code>。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Messages: 一次获取消息数量，默认为 1。</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Message 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Message(消息) 是什么？ 在 RabbitMQ 中，Message（消息）是消息队列中的数据单元。消息包含消息内容、消息属性等信息。 Message 组成： 消息内容：消息的内容，可以是任意数据。 消息属性：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。 Web 控制台 中 Message 的使用 在 Exchange 和 Queue 的管理界面中，都可以在其详情页面测试 Message 的使用。 关于如何在代码中使用 Message，我会在下一节中详细介绍。 Publish message Payload：消息的内容，可以是任意数据。 Payload encoding：消息内容的编码方式，String 或者 Base64，默认为 String。 Delivery mode：消息的持久化模式，1-Non-persistent 表示非持久化，2-Persistent 表示持久化。 Headers：消息的头信息，用于与 Headers Exchange（头部交换机）中的配置进行匹配。 Properties：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。 属性名 中文含义 数据类型 默认值 典型用途 content_type 内容类型 String null 指定消息的 MIME 类型，如 &quot;text/plain&quot;、&quot;application/json&quot; content_encoding 内容编码 String null 指定消息内容的编码方式，如 &quot;gzip&quot; priority 消息优先级 Integer (0-255) 0 结合 x-max-priority 控制消息处理顺序，数值越大优先级越高 correlation_id 关联 ID String null RPC 模式中关联请求与响应 reply_to 回复队列名 String null RPC 模式中指定响应消息的返回队列 expiration 消息过期时间 String (ms) null 消息的 TTL，毫秒为单位，过期后将被丢弃或进入死信队列 message_id 消息 ID String null 唯一标识一条消息，通常由生产者指定 timestamp 时间戳 Date / Long null 消息发送时间，通常是 Unix 时间戳 type 消息类型 String null 描述消息类型，如 &quot;order&quot; 或 &quot;event&quot; user_id 用户 ID String null 标识发送消息的用户，通常用于安全或审计 app_id 应用 ID String null 标识发送消息的应用程序 cluster_id 集群 ID String null RabbitMQ 集群 ID，实际中很少使用 与队列重叠的属性： 参数名称 队列参数（Queue Arguments） 消息属性（Message Properties） 谁的优先级更高 / 生效方式 priority / x-max-priority x-max-priority: 定义队列支持的最大优先级值 priority: 为单个消息设置优先级 队列先定义范围，消息只能在这个范围内取值 若 priority &gt; x-max-priority，则以x-max-priority为准 expiration / x-message-ttl x-message-ttl: 队列级别的消息统一 TTL expiration: 为单个消息设置 TTL（毫秒） 如果同时设置，较短的 TTL 会生效 Get message Ack Mode：消息确认模式 Nack message requeue true: 确认失败，消息重新入队，这是默认选择，主要是为了测试后消息依旧存在。 Automatic ack: 自动确认 Reject requeue true: 拒绝，消息重新入队 Reject requeue false: 拒绝，消息不重新入队 Encoding：消息内容编码方式 Auto String / Base64，默认。如果消息载荷可以解释为UTF-8编码的字符串，就是 String，否则就是 Base64。 Base64。 Messages: 一次获取消息数量，默认为 1。","summary":"摘要 本文介绍 RabbitMQ 的 Message 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-21T14:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/","url":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/","title":"RabbitMQ 之 Exchange","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Exchange-交换机-是什么？\">Exchange(交换机) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/exchanges\">Exchange（交换机）</a> 是消息路由的核心组件。它负责接收生产者发送的消息，并根据预定义的路由规则将消息转发到一个或多个队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Exchange 类型决定了消息的路由方式。RabbitMQ 支持的 Exchange 类型</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Exchange 类型</th>\n<th>声明类型</th>\n<th>路由规则描述</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Direct</strong></td>\n<td><code>direct</code></td>\n<td>消息根据 <strong>路由键（routing key）</strong> 精确匹配绑定键（binding key）进行路由。</td>\n<td>精确消息传递，如日志分类、任务分发等。</td>\n</tr>\n<tr>\n<td><strong>Fanout</strong></td>\n<td><code>fanout</code></td>\n<td>消息广播到所有绑定的队列，<strong>忽略路由键</strong>。</td>\n<td>广播消息，如发布/订阅模式、实时通知等。</td>\n</tr>\n<tr>\n<td><strong>Topic</strong></td>\n<td><code>topic</code></td>\n<td>消息根据路由键与绑定键模式的匹配进行路由，支持通配符 <code>*</code>（匹配一个词）和 <code>#</code>（匹配零个或多个词）。</td>\n<td>模块化路由，如日志系统、事件驱动架构等。</td>\n</tr>\n<tr>\n<td><strong>Headers</strong></td>\n<td><code>headers</code></td>\n<td>消息根据 <strong>消息头部（headers）</strong> 与绑定时指定的头部匹配进行路由，支持 <code>x-match</code> 参数（<code>any</code> 或 <code>all</code>）。</td>\n<td>多条件路由，如复杂过滤、动态路由等。</td>\n</tr>\n<tr>\n<td><strong>Local Random Exchange</strong></td>\n<td><code>x-local-random</code></td>\n<td>消息始终被路由到本地队列，如果有多个本地队列绑定，则随机选择一个进行投递。</td>\n<td>请求-响应（RPC）模式，低延迟通信</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 默认为我们提供了如下的交换机<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/SKlqQK.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>每新创建一个 Vhost，RabbitMQ 就会自动创建以下交换机，比如 <code>/vtest</code><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oGJ1oj.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>当然我们也可以根据需要创建新的交换机<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QjnZin.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>配置说明</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Durability: 指定 Exchange 是否持久化。\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">Durable: 持久化的 Exchange 会被保存在磁盘上，重启 RabbitMQ 时会自动恢复。</li>\n<li class=\"lvl-6\">Transient: 非持久化的 Exchange 会被保存在内存中，重启 RabbitMQ 时会丢失。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Auto-delete: 指定 Exchange 是否自动删除。\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">yes: 如果没有队列或交换机绑定该 Exchange，则该 Exchange 会自动删除。</li>\n<li class=\"lvl-6\">no: 该 Exchange 不会自动删除。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Internal: 用于控制交换机是否可以被生产者直接发布消息\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">yes: 不能被生产者直接发送消息，该交换机只能用于 将消息从其他交换机转发到该交换机。</li>\n<li class=\"lvl-6\">no: 可以被生产者直接发送消息。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Arguments: 用于设置 Exchange 的其他参数，目前仅支持一个参数\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">Alternate exchange(alternate-exchange): 指定该 Exchange 的备用交换机，如果无法以其他方式将发往此交换机的消息路由出去，则将它们发送至此处指定的备用交换机。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Direct-Exchange（直接交换机）\">Direct Exchange（直接交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的路由键与队列的绑定键完全匹配时，消息被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：需要精确匹配的场景，如日志分类、任务分发等。</p>\n</li>\n</ul>\n<h2 id=\"Fanout-Exchange（扇出交换机）\">Fanout Exchange（扇出交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息广播到所有绑定的队列，忽略路由键。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：无论消息的路由键是什么，都会被路由到所有绑定的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：广播消息，如发布/订阅模式、实时通知等。</p>\n</li>\n</ul>\n<h2 id=\"Topic-Exchange（主题交换机）\">Topic Exchange（主题交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的路由键与队列的绑定键模式匹配时，消息被路由到该队列。支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定键为 <em>.orange.</em>，则路由键为 quick.orange.rabbit 的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：模块化路由，如日志系统、事件驱动架构等。</p>\n</li>\n</ul>\n<h2 id=\"Headers-Exchange（头部交换机）\">Headers Exchange（头部交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的头部与队列的绑定头部匹配时，消息被路由到该队列。支持 x-match 参数（any 或 all）。即使配置了路由键也会忽略。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定头部为 { “x-match”: “all”, “format”: “pdf”, “priority”: “high” }，则只有同时满足这两个条件的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：多条件路由，如复杂过滤、动态路由等。</p>\n</li>\n</ul>\n<h2 id=\"Local-Random-Exchange（本地随机交换机）\">Local Random Exchange（本地随机交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Local Random Exchange 是 RabbitMQ 4.0 引入的交换机类型，旨在优化<code>请求-响应</code>模式下的消息路由，特别适用于低延迟和高吞吐量的场景。通过结合独占队列使用，可以确保消息快速传递到本地消费者，减少网络延迟，提高系统性能。</p>\n</li>\n<li class=\"lvl-2\">\n<p>路由规则：消息始终被路由到本地队列（位于同一节点上），如果有多个本地队列绑定，则随机选择一个进行投递。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：假设节点 A 上有两个绑定了 x-local-random 交换机的队列 Q1 和 Q2，发布的消息会随机路由到 Q1 或 Q2，但不会路由到其他节点的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：请求-响应（RPC）模式下的低延迟通信，适合微服务架构中每个节点上都有消费者的场景。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在使用 Local Random Exchange 时，必须满足以下条件：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">独占队列：消费者应声明独占队列，以确保队列仅绑定到当前节点。</li>\n<li class=\"lvl-4\">每个节点至少一个消费者：每个 RabbitMQ 节点上应至少有一个消费者，否则在该节点上发布的消息将被丢弃。</li>\n<li class=\"lvl-4\">交换机类型声明：使用 <code>x-local-random</code> 类型声明交换机。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Exchange-与-Queue-绑定-Binding\">Exchange 与 Queue 绑定(Binding)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建好 Exchange 之后，需要将 Exchange 与 Queue 绑定，才能将消息发送到指定的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Exchange 与 Queue 的绑定关系，即 Exchange 发送的消息，会根据路由键与队列的绑定键进行匹配，如果匹配成功，则将消息发送到对应的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 Exchange 页面点击 Exchange 的名称，进入 Exchange 详情页面，此处可以进行 Exchange 与 Queue 绑定配置<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/taKUjm.png\" alt=\"\"></p>\n<blockquote>\n<p>这里的<code>Arguments</code>用于设置 绑定 的其他参数，比如 <code>Headers Exchange</code> 需要设置 <code>x-match</code> 参数等。</p>\n</blockquote>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Exchange(交换机) 是什么？ 在 RabbitMQ 中，Exchange（交换机） 是消息路由的核心组件。它负责接收生产者发送的消息，并根据预定义的路由规则将消息转发到一个或多个队列。 Exchange 类型决定了消息的路由方式。RabbitMQ 支持的 Exchange 类型 Exchange 类型 声明类型 路由规则描述 典型用途 Direct direct 消息根据 路由键（routing key） 精确匹配绑定键（binding key）进行路由。 精确消息传递，如日志分类、任务分发等。 Fanout fanout 消息广播到所有绑定的队列，忽略路由键。 广播消息，如发布/订阅模式、实时通知等。 Topic topic 消息根据路由键与绑定键模式的匹配进行路由，支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。 模块化路由，如日志系统、事件驱动架构等。 Headers headers 消息根据 消息头部（headers） 与绑定时指定的头部匹配进行路由，支持 x-match 参数（any 或 all）。 多条件路由，如复杂过滤、动态路由等。 Local Random Exchange x-local-random 消息始终被路由到本地队列，如果有多个本地队列绑定，则随机选择一个进行投递。 请求-响应（RPC）模式，低延迟通信 RabbitMQ 默认为我们提供了如下的交换机 每新创建一个 Vhost，RabbitMQ 就会自动创建以下交换机，比如 /vtest 当然我们也可以根据需要创建新的交换机 配置说明 Durability: 指定 Exchange 是否持久化。 Durable: 持久化的 Exchange 会被保存在磁盘上，重启 RabbitMQ 时会自动恢复。 Transient: 非持久化的 Exchange 会被保存在内存中，重启 RabbitMQ 时会丢失。 Auto-delete: 指定 Exchange 是否自动删除。 yes: 如果没有队列或交换机绑定该 Exchange，则该 Exchange 会自动删除。 no: 该 Exchange 不会自动删除。 Internal: 用于控制交换机是否可以被生产者直接发布消息 yes: 不能被生产者直接发送消息，该交换机只能用于 将消息从其他交换机转发到该交换机。 no: 可以被生产者直接发送消息。 Arguments: 用于设置 Exchange 的其他参数，目前仅支持一个参数 Alternate exchange(alternate-exchange): 指定该 Exchange 的备用交换机，如果无法以其他方式将发往此交换机的消息路由出去，则将它们发送至此处指定的备用交换机。 Direct Exchange（直接交换机） 路由规则：消息的路由键与队列的绑定键完全匹配时，消息被路由到该队列。 示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。 适用场景：需要精确匹配的场景，如日志分类、任务分发等。 Fanout Exchange（扇出交换机） 路由规则：消息广播到所有绑定的队列，忽略路由键。 示例：无论消息的路由键是什么，都会被路由到所有绑定的队列。 适用场景：广播消息，如发布/订阅模式、实时通知等。 Topic Exchange（主题交换机） 路由规则：消息的路由键与队列的绑定键模式匹配时，消息被路由到该队列。支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。 示例：如果队列绑定键为 .orange.，则路由键为 quick.orange.rabbit 的消息会被路由到该队列。 适用场景：模块化路由，如日志系统、事件驱动架构等。 Headers Exchange（头部交换机） 路由规则：消息的头部与队列的绑定头部匹配时，消息被路由到该队列。支持 x-match 参数（any 或 all）。即使配置了路由键也会忽略。 示例：如果队列绑定头部为 { “x-match”: “all”, “format”: “pdf”, “priority”: “high” }，则只有同时满足这两个条件的消息会被路由到该队列。 适用场景：多条件路由，如复杂过滤、动态路由等。 Local Random Exchange（本地随机交换机） Local Random Exchange 是 RabbitMQ 4.0 引入的交换机类型，旨在优化请求-响应模式下的消息路由，特别适用于低延迟和高吞吐量的场景。通过结合独占队列使用，可以确保消息快速传递到本地消费者，减少网络延迟，提高系统性能。 路由规则：消息始终被路由到本地队列（位于同一节点上），如果有多个本地队列绑定，则随机选择一个进行投递。 示例：假设节点 A 上有两个绑定了 x-local-random 交换机的队列 Q1 和 Q2，发布的消息会随机路由到 Q1 或 Q2，但不会路由到其他节点的队列。 适用场景：请求-响应（RPC）模式下的低延迟通信，适合微服务架构中每个节点上都有消费者的场景。 在使用 Local Random Exchange 时，必须满足以下条件： 独占队列：消费者应声明独占队列，以确保队列仅绑定到当前节点。 每个节点至少一个消费者：每个 RabbitMQ 节点上应至少有一个消费者，否则在该节点上发布的消息将被丢弃。 交换机类型声明：使用 x-local-random 类型声明交换机。 Exchange 与 Queue 绑定(Binding) 创建好 Exchange 之后，需要将 Exchange 与 Queue 绑定，才能将消息发送到指定的队列。 Exchange 与 Queue 的绑定关系，即 Exchange 发送的消息，会根据路由键与队列的绑定键进行匹配，如果匹配成功，则将消息发送到对应的队列。 在 Exchange 页面点击 Exchange 的名称，进入 Exchange 详情页面，此处可以进行 Exchange 与 Queue 绑定配置 这里的Arguments用于设置 绑定 的其他参数，比如 Headers Exchange 需要设置 x-match 参数等。","summary":"摘要 本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-21T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/","url":"https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/","title":"RabbitMQ 之 Queue","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Queue 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Queue-队列-是什么？\">Queue(队列) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/queues\">队列（Queue）</a> 是一种用于存储消息的 数据结构，消息会一直保存在队列中，直到被应用程序或服务消费为止。</p>\n</li>\n<li class=\"lvl-2\">\n<p>生产者（Publisher） 把消息放进队列，消费者（Consumer） 从队列中取出消息。队列中的消息会按照 FIFO（先进先出）的顺序进行消费。</p>\n</li>\n<li class=\"lvl-2\">\n<p>队列在生产者和消费者之间起到缓冲区的作用。生产者不需要知道消费者的存在，它们只需把消息发送到队列。消费者可以根据自身处理速度，按需消费消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 目前 支持三种队列类型：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>队列类型</th>\n<th>描述</th>\n<th>特点</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Classic Queue（经典队列）</strong></td>\n<td>最常用的队列类型，消息按 FIFO（先进先出）顺序存储和消费</td>\n<td>支持持久化、优先级、TTL、死信等</td>\n<td>大多数常规消息场景</td>\n</tr>\n<tr>\n<td><strong>Quorum Queue（仲裁队列）</strong></td>\n<td>基于 Raft 协议的队列，确保高可用和数据一致性</td>\n<td>内置复制（副本数量可配置）、适合高可靠性场景，但吞吐量略低于经典队列</td>\n<td>关键任务消息、高可靠性场景</td>\n</tr>\n<tr>\n<td><strong>Stream Queue（流式队列）</strong></td>\n<td>面向大量消息的高吞吐队列，支持消息按偏移量读取</td>\n<td>类似 Kafka，可随机访问历史消息、顺序读取、可持久化大量消息</td>\n<td>大数据流、日志处理、事件溯源</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Classic-Queue-经典队列\">Classic Queue(经典队列)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/classic-queues\">RabbitMQ 经典队列（原始队列类型）</a>是一种通用队列类型。实际上它是在 3.8.x 版本之前唯一的队列类型。</p>\n</li>\n<li class=\"lvl-2\">\n<p>经典队列适用于数据安全不是优先事项的用例，因为存储在经典队列中的数据不会被复制。 经典队列使用非复制的 FIFO 队列实现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>经典队列不适合积累太多的消息，如果队列中积累的消息太多了，会严重影响客户端生产消息以及消费消息的性能。因此，经典队列主要用在数据量比较小，并且生产消息和消费消息的速度比较稳定的业务场景。比如内部系统之间的服务调用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 删除了对经典队列 <code>version1</code> 的支持，同时也不再支持将 经典队列 的消息在节点间复制。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MAdpRV.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Auto expire</strong></td>\n<td><code>x-expires</code></td>\n<td>整数（毫秒）</td>\n<td>队列在 <strong>指定时间内无人使用（无消费者、无发布、无访问）</strong> 时自动删除</td>\n<td>类似“队列空闲过期时间”，节省资源</td>\n</tr>\n<tr>\n<td><strong>Message TTL</strong></td>\n<td><code>x-message-ttl</code></td>\n<td>整数（毫秒）</td>\n<td>消息的 <strong>存活时间</strong>，超过时间后消息会被丢弃或发送到死信队列</td>\n<td>用于限制消息时效性，如延迟消息或短期缓存</td>\n</tr>\n<tr>\n<td><strong>Overflow behaviour</strong></td>\n<td><code>x-overflow</code></td>\n<td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td>\n<td>当队列达到 <strong>最大长度</strong> 或 <strong>最大字节数</strong> 时的行为</td>\n<td>- <code>drop-head</code>：丢弃最早的消息 <br> - <code>reject-publish</code>：拒绝新的消息</td>\n</tr>\n<tr>\n<td><strong>Single active consumer</strong></td>\n<td><code>x-single-active-consumer</code></td>\n<td>布尔值（true/false）</td>\n<td>是否启用 <strong>单活消费者模式</strong>，一次只允许一个消费者消费队列</td>\n<td>用于严格顺序消费，保证某个消息不会被多个消费者同时处理</td>\n</tr>\n<tr>\n<td><strong>Dead letter exchange (DLX)</strong></td>\n<td><code>x-dead-letter-exchange</code></td>\n<td>字符串</td>\n<td>指定队列的 <strong>死信交换机</strong>，用于接收无法消费或过期的消息</td>\n<td>常用于失败重试、消息补偿场景</td>\n</tr>\n<tr>\n<td><strong>Dead letter routing key</strong></td>\n<td><code>x-dead-letter-routing-key</code></td>\n<td>字符串</td>\n<td>消息转发到 DLX 时的 <strong>路由键</strong></td>\n<td>可以灵活转发到不同队列</td>\n</tr>\n<tr>\n<td><strong>Max length</strong></td>\n<td><code>x-max-length</code></td>\n<td>整数</td>\n<td>队列中 <strong>最大消息条数</strong></td>\n<td>超过时按照 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>队列中 <strong>消息总字节数上限</strong></td>\n<td>超过时按照 Overflow behaviour 处理，适合大消息场景</td>\n</tr>\n<tr>\n<td><strong>Maximum priority</strong></td>\n<td><code>x-max-priority</code></td>\n<td>整数</td>\n<td>启用优先级队列时，队列可设置的 <strong>最大优先级值</strong></td>\n<td>消息优先级范围是 0 到这个值，优先级高的消息先被消费</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td>\n<td><code>client-local</code>（默认）：选择客户端所在节点作为Leader <br> <code>balanced</code>：在节点间均衡Leader分布，用于 HA 队列优化</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Quorum-Queue-仲裁队列\">Quorum Queue(仲裁队列)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/quorum-queues\">仲裁队列（Quorum Queue）</a> 是 RabbitMQ 从3.8.0版本之后引入的一种现代队列类型，也是目前官方比较推荐的一种对列类型。未来有可能取代 经典队列 成为默认队列类型。</p>\n</li>\n<li class=\"lvl-2\">\n<p>其基于 Raft 共识算法 实现 持久化、复制和高可用。它保证 数据安全性、可靠的主节点选举，即使在升级或集群波动期间也能保持高可用性。</p>\n</li>\n<li class=\"lvl-2\">\n<p>仲裁队列支持 毒消息处理、至少一次死信投递 以及 AMQP 修改（AMQP.modified）的处理结果。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它适合 以数据安全为首要目标 的场景。与经典队列相比，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oQ8YiT.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>仲裁队列（Quorum Queue）的 <code>Durability</code> 只能设置为 Durable(true)。<code>Auto delete</code> 只能为 No(false)。</p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Auto expire</strong></td>\n<td><code>x-expires</code></td>\n<td>整数（毫秒）</td>\n<td>队列在指定时间内无人使用（无消费者、无发布、无访问）时自动删除</td>\n<td>节省资源，队列空闲过期时间</td>\n</tr>\n<tr>\n<td><strong>Message TTL</strong></td>\n<td><code>x-message-ttl</code></td>\n<td>整数（毫秒）</td>\n<td>队列中消息的生存时间，超过时间后消息会被丢弃或转入死信队列</td>\n<td>控制消息时效性</td>\n</tr>\n<tr>\n<td><strong>Overflow behaviour</strong></td>\n<td><code>x-overflow</code></td>\n<td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td>\n<td>当队列达到最大长度时的处理方式</td>\n<td><code>drop-head</code>：丢弃最早消息，<code>reject-publish</code>：拒绝新消息</td>\n</tr>\n<tr>\n<td><strong>Single active consumer</strong></td>\n<td><code>x-single-active-consumer</code></td>\n<td>布尔值（true/false）</td>\n<td>是否启用单活消费者模式，一次只允许一个消费者消费队列</td>\n<td>保证严格顺序消费</td>\n</tr>\n<tr>\n<td><strong>Dead letter exchange (DLX)</strong></td>\n<td><code>x-dead-letter-exchange</code></td>\n<td>字符串</td>\n<td>指定队列的死信交换机，用于接收无法消费或过期的消息</td>\n<td>与 DLX 配合使用处理失败消息</td>\n</tr>\n<tr>\n<td><strong>Dead letter routing key</strong></td>\n<td><code>x-dead-letter-routing-key</code></td>\n<td>字符串</td>\n<td>消息转发到 DLX 时的路由键</td>\n<td>灵活路由死信消息</td>\n</tr>\n<tr>\n<td><strong>Max length</strong></td>\n<td><code>x-max-length</code></td>\n<td>整数</td>\n<td>队列中最大消息条数</td>\n<td>超过时按 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>队列消息总字节数上限</td>\n<td>超过时按 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Delivery limit</strong></td>\n<td><code>x-delivery-limit</code></td>\n<td>整数</td>\n<td>消息允许投递的最大次数，超过后变为死信</td>\n<td>控制消息重试次数</td>\n</tr>\n<tr>\n<td><strong>Initial cluster size</strong></td>\n<td><code>x-quorum-initial-group-size</code></td>\n<td>整数</td>\n<td>队列在创建时需要的最小节点数</td>\n<td>用于保证仲裁队列的高可用性</td>\n</tr>\n<tr>\n<td><strong>Target cluster size</strong></td>\n<td><code>x-quorum-target-group-size</code></td>\n<td>整数</td>\n<td>队列运行时的目标节点数</td>\n<td>当集群节点变化时，仲裁队列会尝试调整副本数量</td>\n</tr>\n<tr>\n<td><strong>Dead letter strategy</strong></td>\n<td><code>x-dead-letter-strategy</code></td>\n<td>字符串（<code>at-most-once</code>、<code>at-least-once</code>）</td>\n<td>设置仲裁队列的死信处理策略</td>\n<td>仅适用于 Quorum Queue。<br><code>at-most-once</code>（默认）：消息最多投递一次，可能丢失。<br><code>at-least-once</code>：确保消息至少投递一次，必须将 Overflow behaviour 设置为 <code>reject-publish</code>，否则回退到 <code>at-most-once</code>。</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td>\n<td><code>client-local</code>：选择客户端所在节点作为 Leader <br> <code>balanced</code>：在节点间均衡 Leader 分布</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Quorum Queues 和 Classic Queues 的功能对比如下：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>中文含义</th>\n<th>Classic queues</th>\n<th>Quorum queues</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-durable queues</td>\n<td>非持久化队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 总是持久化，不支持非持久化</td>\n</tr>\n<tr>\n<td>Message replication</td>\n<td>消息复制</td>\n<td>no</td>\n<td>yes</td>\n<td>Quorum queues 内置消息复制，Classic queues 需镜像策略</td>\n</tr>\n<tr>\n<td>Exclusivity</td>\n<td>独占队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Classic queues 支持独占队列，Quorum queues 不支持独占</td>\n</tr>\n<tr>\n<td>Per message persistence</td>\n<td>消息级持久化</td>\n<td>per message</td>\n<td>always</td>\n<td>Quorum queues 消息总是持久化</td>\n</tr>\n<tr>\n<td>Membership changes</td>\n<td>节点成员变更</td>\n<td>no</td>\n<td>semi-automatic</td>\n<td>Quorum queues 节点变化时半自动处理复制</td>\n</tr>\n<tr>\n<td>Message TTL (Time-To-Live)</td>\n<td>消息存活时间</td>\n<td>yes</td>\n<td>yes</td>\n<td>两者都支持消息过期时间</td>\n</tr>\n<tr>\n<td>Queue TTL</td>\n<td>队列存活时间</td>\n<td>yes</td>\n<td>partially</td>\n<td>Quorum queues 的 lease 不会因重新声明而续期</td>\n</tr>\n<tr>\n<td>Queue length limits</td>\n<td>队列长度限制</td>\n<td>yes</td>\n<td>yes</td>\n<td>Quorum queues 支持长度限制，但 <code>x-overflow=reject-publish-dlx</code> 不支持</td>\n</tr>\n<tr>\n<td>Keeps messages in memory</td>\n<td>消息内存保存</td>\n<td>see Classic Queues</td>\n<td>never</td>\n<td>Quorum queues 消息总是写入磁盘，不保留在内存</td>\n</tr>\n<tr>\n<td>Message priority</td>\n<td>消息优先级</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持消息优先级</td>\n</tr>\n<tr>\n<td>Single Active Consumer</td>\n<td>单活消费者</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持单活消费者</td>\n</tr>\n<tr>\n<td>Consumer exclusivity</td>\n<td>独占消费者</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 不支持独占消费者，需使用 Single Active Consumer</td>\n</tr>\n<tr>\n<td>Consumer priority</td>\n<td>消费者优先级</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持消费者优先级</td>\n</tr>\n<tr>\n<td>Dead letter exchanges</td>\n<td>死信交换机</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持死信交换机</td>\n</tr>\n<tr>\n<td>Adheres to policies</td>\n<td>遵循策略</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持策略，但 Quorum queues 的部分策略行为不同</td>\n</tr>\n<tr>\n<td>Poison message handling</td>\n<td>毒消息处理</td>\n<td>no</td>\n<td>yes</td>\n<td>Quorum queues 支持毒消息处理</td>\n</tr>\n<tr>\n<td>Server-named queues</td>\n<td>服务器自动命名队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 不支持服务器自动命名队列</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Stream-流\">Stream(流)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/streams\">Stream</a> 是RabbitMQ自 3.9.0 版本开始引入的一种新的数据队列类型。这种队列类型的消息是持久化到磁盘并且具备分布式备份的，更适合于消费者多，读消息非常频繁的场景。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 的核心是以append-only只添加的日志来记录消息，整体来说，就是消息将以append-only的方式持久化到日志文件中，然后通过调整每个消费者的消费进度offset，来实现消息的多次分发。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 不支持死信交换机，不支持处理毒消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 Stream 不属于队列，流（Streams） 是一种 持久化、可复制的数据结构，功能上类似队列：从生产者缓冲消息供消费者读取。但它与队列有两个重要区别：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">存储模型 – 流是 追加日志（append-only log），消息可以 重复读取直到过期。</li>\n<li class=\"lvl-4\">消费模型 – 流提供 非破坏性消费语义（non-destructive consumer semantics），多个消费者可以多次读取同一条消息而不会删除它。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 始终是持久化和复制的，保证数据安全。消费者可以通过 RabbitMQ 客户端库 或 专用二进制协议插件 读取流，其中插件方式可以 访问所有流特性 并提供 最佳性能。合理的客户端连接策略有助于提升 吞吐量和效率。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/8KqZY9.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>流中允许存储的 <strong>最大数据总字节数</strong></td>\n<td>超过时流将停止接收新消息，适合控制存储容量</td>\n</tr>\n<tr>\n<td><strong>Max time retention</strong></td>\n<td><code>x-max-age</code></td>\n<td>字符串（时间单位，例如 <code>1h</code>, <code>30m</code>, <code>1d</code>）</td>\n<td>设置流队列中消息的 <strong>最大保留时间</strong>，超过时间的消息会被删除</td>\n<td>支持时间单位：Y=年, M=月, D=天, h=小时, m=分钟, s=秒。例如 <code>&quot;1h&quot;</code> 表示只保留最近 1 小时的消息，用于控制数据量和自动清理过期消息</td>\n</tr>\n<tr>\n<td><strong>Max segment size in bytes</strong></td>\n<td><code>x-stream-max-segment-size</code></td>\n<td>整数（字节）</td>\n<td>流分段存储时的 <strong>每个段的最大字节数</strong></td>\n<td>控制单个文件段大小，有利于 I/O 性能和管理</td>\n</tr>\n<tr>\n<td><strong>Filter size (per chunk) in bytes</strong></td>\n<td><code>x-stream-filter-size-bytes</code></td>\n<td>整数（字节）</td>\n<td>流内部 <strong>过滤索引每块的大小</strong></td>\n<td>用于加速消息定位和读取，影响内存使用和检索效率</td>\n</tr>\n<tr>\n<td><strong>Initial cluster size</strong></td>\n<td><code>x-initial-cluster-size</code></td>\n<td>整数</td>\n<td>流在创建时的 <strong>最小节点数</strong></td>\n<td>保证流的复制和高可用性</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明流时，主节点（Leader）的选取规则</td>\n<td><code>client-local</code>：客户端所在节点作为 Leader（默认）<br><code>balanced</code>：在节点间均衡 Leader 分布，用于优化 HA</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Classic Queue vs Stream Queue Feature Matrix</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>中文含义</th>\n<th>Classic queues</th>\n<th>Stream queues</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-durable queues</td>\n<td>非持久化队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列总是持久化，不支持非持久化</td>\n</tr>\n<tr>\n<td>Exclusivity</td>\n<td>独占队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Classic 队列支持独占，Stream 队列不支持独占</td>\n</tr>\n<tr>\n<td>Per message persistence</td>\n<td>消息级持久化</td>\n<td>per message</td>\n<td>always</td>\n<td>Stream 队列的消息总是持久化</td>\n</tr>\n<tr>\n<td>Membership changes</td>\n<td>节点成员变更</td>\n<td>no</td>\n<td>manual</td>\n<td>Stream 队列节点变更需要手动管理</td>\n</tr>\n<tr>\n<td>TTL</td>\n<td>消息存活时间</td>\n<td>yes</td>\n<td>no (but see Retention)</td>\n<td>Stream 队列没有消息 TTL，但可通过 Retention 控制过期</td>\n</tr>\n<tr>\n<td>Queue length limits</td>\n<td>队列长度限制</td>\n<td>yes</td>\n<td>no (but see Retention)</td>\n<td>Stream 队列没有固定长度限制，通过 Retention 控制数据量</td>\n</tr>\n<tr>\n<td>Keeps messages in memory</td>\n<td>消息内存保存</td>\n<td>see Classic Queues</td>\n<td>never</td>\n<td>Stream 队列消息不保存在内存中，只写入磁盘</td>\n</tr>\n<tr>\n<td>Message priority</td>\n<td>消息优先级</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持消息优先级</td>\n</tr>\n<tr>\n<td>Consumer priority</td>\n<td>消费者优先级</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持消费者优先级</td>\n</tr>\n<tr>\n<td>Dead letter exchanges</td>\n<td>死信交换机</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持死信交换机</td>\n</tr>\n<tr>\n<td>Adheres to policies</td>\n<td>遵循策略</td>\n<td>yes</td>\n<td>yes (see Retention)</td>\n<td>Stream 队列支持策略，但主要通过 Retention 控制行为</td>\n</tr>\n<tr>\n<td>Reacts to memory alarms</td>\n<td>内存告警响应</td>\n<td>yes</td>\n<td>no (uses minimal RAM)</td>\n<td>Stream 队列使用最小内存，不触发内存告警</td>\n</tr>\n<tr>\n<td>Poison message handling</td>\n<td>毒消息处理</td>\n<td>no</td>\n<td>no</td>\n<td>Stream 队列不支持毒消息处理</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>我们可以激活<code>流插件</code>来使用流的特有功能</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmq-plugins <span class=\"built_in\">enable</span> rabbitmq_stream rabbitmq_stream_management</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>激活<code>流插件</code>后，Stream队列的操作方式可以更高级，具体可以参考<a href=\"https://www.rabbitmq.com/tutorials/tutorial-two-java-stream\">官方文档</a>，作者在<a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo/rabbitmq-stream\">Java Client 示例</a>中也给出了示例代码。</p>\n</li>\n</ul>\n<h3 id=\"超级流-Super-Streams\">超级流(Super Streams)</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>超级流（Super streams） 是一种通过将一个大的流分区成更小的流来实现扩展的方式。它们与 单个消费者（Single Active Consumer） 集成，以在分区内保持消息顺序。超级流从 RabbitMQ 3.11 开始可用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>一个超级流是由多个普通流组成的逻辑流。它是一种通过 RabbitMQ Streams 来扩展发布和消费的方法：一个大型逻辑流被划分成多个分区流，将存储和流量分散到多个集群节点上。</p>\n</li>\n<li class=\"lvl-2\">\n<p>超级流依然是一个逻辑实体：由于客户端库的智能化处理，应用程序会把它视为一个“大型”流。超级流的拓扑结构基于 AMQP 0.9.1 模型，也就是交换机（exchange）、队列（queue）和它们之间的绑定（binding）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>可以使用任何 AMQP 0.9.1 库或管理插件创建超级流的拓扑。它需要创建一个直连交换机（direct exchange）、分区流（partition streams），并将它们绑定在一起。</p>\n</li>\n<li class=\"lvl-2\">\n<p>通过管理控制台创建超级流<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/j2G1HC.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>也可以通过命令创建超级流，以下是如何用命令创建一个包含 3 个分区的超级流：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams add_super_stream [-p &lt;vhost&gt;] &lt;stream-name&gt; [--partitions &lt;number&gt;]</span></span><br><span class=\"line\">rabbitmq-streams add_super_stream -p /vtest sq_3 --partitions 3</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>创建的Stream<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4py5OE.png\" alt=\"\"><br>\n创建的 Exchange，名称 sq_3<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/EwfTRM.png\" alt=\"\"><br>\n绑定关系<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/NErhQX.png\" alt=\"\"></p>\n</blockquote>\n<h2 id=\"队列类型扩展\">队列类型扩展</h2>\n<h3 id=\"懒队列\">懒队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>从3.6.x版本到3.12.x版本，RabbitMQ提供了一种针对Classic Queue的优化配置，<code>lazy-mode</code>，<a href=\"https://www.rabbitmq.com/docs/lazy-queues\">懒对列</a>。懒队列会尽可能早的将消息内容保存到硬盘当中，并且只有在用户请求到时，才临时从硬盘加载到RAM内存当中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>默认情况下，RabbitMQ接收到消息时，会保存到内存以便使用，同时把消息写到硬盘。但是，消息写入硬盘的过程中，是会阻塞队列的。RabbitMQ虽然针对写入硬盘速度做了很多算法优化，但是在长队列中，依然表现不是很理想，所以就有了懒队列的出现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>懒队列会尝试尽可能早的把消息写到硬盘中。这意味着在正常操作的大多数情况下，RAM中要保存的消息要少得多。当然，这是以增加磁盘IO为代价的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>懒队列适合消息量大且长期有堆积的队列，可以减少内存使用，加快消费速度。但是这是以大量消耗集群的网络及磁盘IO为代价的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>从3.12往后的版本中，RabbitMQ 不再支持“惰性”模式，因为 经典队列 当前的特性就类似于以前的 懒队列。</p>\n</li>\n</ul>\n<h3 id=\"死信队列\">死信队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/dlx\">死信队列（Dead Letter Queue）</a>，新版中叫做 死信交换机（Dead Letter Exchange, DLX），是RabbitMQ对于未能正常消费的消息进行的一种补救机制，用于保存无法被正常处理的消息。当消息被消费者处理失败时，RabbitMQ会将消息发送到死信队列中，等待消费者处理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>死信队列也是一个普通的队列，同样可以在队列上声明消费者，继续对消息进行消费处理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>有以下几种情况，RabbitMQ会将一个正常消息转成死信</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">消息被拒绝（Message rejection）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">由 AMQP 1.0 接收端使用 rejected 结果拒绝</li>\n<li class=\"lvl-6\">由 AMQP 0.9.1 消费者使用 basic.reject 或 basic.nack，并且参数 requeue=false</li>\n</ul>\n</li>\n<li class=\"lvl-4\">消息过期（Message expiration）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">消息超过其配置的 TTL（生存时间） 后过期。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">队列长度超限（Queue length exceeded）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">队列中的消息数量或总字节数达到配置的最大限制后，被丢弃的消息会死信化。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">投递次数超限（仅适用于仲裁队列 Quorum Queue）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">消息的投递次数超过了仲裁队列中配置的 delivery-limit。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>使用场景</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">你可以在队列上配置 死信交换机（DLX） 和 死信路由键（Dead Letter Routing Key）。</li>\n<li class=\"lvl-4\">当消息成为死信时，会被 重新发布到 DLX，这样你可以：\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">做错误日志记录</li>\n<li class=\"lvl-6\">进行失败消息重试</li>\n<li class=\"lvl-6\">用于监控和告警</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>死信交换机的配置方法（How Dead Lettering is Configured）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">在 RabbitMQ 中，任何队列都可以通过 客户端 或者 策略（policies） 来配置 死信交换机（DLX）。</li>\n<li class=\"lvl-4\">配置时主要涉及两个核心参数：</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>配置参数名</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>dead-letter-exchange</strong></td>\n<td>指定用于接收死信消息的 <strong>死信交换机名称</strong></td>\n</tr>\n<tr>\n<td><strong>dead-letter-routing-key</strong></td>\n<td>指定死信消息重新发布时使用的 <strong>路由键（Routing Key）</strong></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>死信在转移到死信队列时，他的 routingkey 也会保存下来。但是如果配置了 <code>x-dead-letter-routing-key</code> 这个参数的话，routingkey 就会被替换为配置的这个值。</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在创建队列时，我们可以通过为队列添加 <code>x-dead-letter-exchange</code> 和 <code>x-dead-letter-routing-key</code> 参数，来指定 死信交换机（DLX）和 死信路由键（Dead Letter Routing Key）。但是这样做很麻烦，每个队列都要单独配置，因此，我们可以使用 策略（policies） 来统一配置。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 仅指定死信交换机，这里交换机的名称是 my-dlx，交换机要提前创建好</span></span><br><span class=\"line\">rabbitmqctl set_policy DLX <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br><span class=\"line\"><span class=\"comment\"># 同时指定 死信交换机 和 路由键</span></span><br><span class=\"line\">rabbitmqctl set_policy DLX <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>参数说明：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具</td>\n</tr>\n<tr>\n<td><code>set_policy</code></td>\n<td>设置一个策略（Policy），用于动态配置交换机、队列或绑定的参数</td>\n</tr>\n<tr>\n<td><code>DLX</code></td>\n<td>策略的名称，用户自定义，例如这里叫 <code>DLX</code></td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code></td>\n<td>正则表达式，匹配对象的名称。<code>.*</code> 表示匹配 <strong>所有队列</strong>，也可以指定具体队列名，比如 <code>^my-queue$</code></td>\n</tr>\n<tr>\n<td><code>&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;</code></td>\n<td>策略内容，这里设置了死信交换机名称和路由键：<br> - <code>dead-letter-exchange</code>: 设置死信交换机名称为 <code>my-dlx</code><br> - <code>dead-letter-routing-key</code>: 设置路由键为 <code>my-routing-key</code></td>\n</tr>\n<tr>\n<td><code>--apply-to queues</code></td>\n<td>指定策略作用对象为 <strong>队列（queues）</strong>，而不是交换机（exchanges）或绑定（bindings）</td>\n</tr>\n<tr>\n<td><code>--priority 7</code></td>\n<td>策略的优先级，值越大优先级越高。多个策略作用在同一对象时，优先级高的会覆盖低的</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>执行这条命令后：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">所有队列都会自动带上 <code>x-dead-letter-exchange=my-dlx</code> 和 <code>x-dead-letter-routing-key=my-routing-key</code> 配置。</li>\n<li class=\"lvl-4\">队列中被拒绝、过期、超长或超过投递次数的消息会被重新发布到 <code>my-dlx</code> 交换机，并使用 <code>my-routing-key</code> 作为路由键。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>消息被作为死信转移到死信队列后，会在Header当中增加⼀些消息。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x-first-death-queue：该消息首次成为死信时所在的队列名称</span><br><span class=\"line\">x-first-death-reason：该消息首次被判定为死信的原因</span><br><span class=\"line\">x-first-death-exchange：该消息在首次成为死信前被发布到的交换机名称</span><br><span class=\"line\">x-last-death-queue：该消息最近一次成为死信时所在的队列名称</span><br><span class=\"line\">x-last-death-reason：该消息最近一次被判定为死信的原因</span><br><span class=\"line\">x-last-death-exchange：该消息在最近一次成为死信前被发布到的交换机名称</span><br></pre></td></tr></table></figure>\n<h3 id=\"延迟队列\">延迟队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>延迟队列（Delayed Message Queue）: 延迟队列是一种特殊类型的队列，用于延迟消息的投递。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ中，是不存在延迟队列的功能的，而通常如果要用到延迟队列，就会采用 <code>TTL</code> + <code>死信队列</code> 的方式来实现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>延迟队列的实现原理：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">创建一个普通队列，并设置队列的 TTL（x-message-ttl）参数，以及指定一个死信队列(x-dead-letter-exchange)</li>\n<li class=\"lvl-4\">当消息的 TTL 到期时，消息会被自动从当前队列中删除，并进入死信队列。</li>\n<li class=\"lvl-4\">为死信队列创建一个消费者，并监听死信队列，处理延迟消息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优先级队列\">优先级队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>优先级队列（Priority Queue）: RabbitMQ 支持为经典队列（classic queues）添加“优先级”功能。启用“优先级”功能的经典队列通常被称为“优先级队列”（priority queues）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 支持 1 到 255 之间的优先级值，但强烈建议使用 1 到 5 之间的值。需要注意的是，优先级值越高，会消耗更多的 CPU 和内存资源，因为 RabbitMQ 在内部需要为每个优先级（从 1 到最大配置值）维护一个子队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>只有经典队列支持通过参数<code>x-max-priority</code>指定队列支持的最大优先级，且不支持 通过 策略（policies） 将经典队列声明为优先级队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>发布消息时，可以通过参数 <code>priority</code> 指定消息的优先级。是的，消息也是可以设置参数的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>优先级队列如何与消费者协同工作</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">若消费者连接到一个 空队列，然后消息陆续被发布，那么这些消息可能 不会 在队列中等待（即刚发布就被消费者接收），此时优先级功能没有机会上场。优先级是在消息排队（ready 消息）状态时才能体现其作用。</li>\n<li class=\"lvl-4\">推荐在消费者端使用 basic.qos(prefetch) 设置（在 manual ack 模式下），以限制消费者同时处理的未确认消息数。这样能让优先级的分级效果更加明显，因为如果 prefetch 数量未满，高优先级消息可以先被取出。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>注意事项</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">未设置 <code>priority</code> 的消息 会被当作优先级 0 处理。若消息指定的优先级大于队列的最大值（x-max-priority），则该消息的优先级就是<code>x-max-priority</code>。</li>\n<li class=\"lvl-4\">TTL / 消息过期 (message expiration)：即使设置了 TTL，过期的消息只会在队列头被检查。这意味着如果一个低优先级的消息在前面但还没过期，而高优先级的消息在后面，低优先级的消息可能会阻塞队列头，导致高优先级的消息被延迟。</li>\n<li class=\"lvl-4\">队列最大长度限制 (max-length)：如果队列设置了最大长度，队列会从头部 (head) 丢弃消息以维持长度限制。这可能导致高优先级消息也被丢弃，从而违背直觉。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Queue 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Queue(队列) 是什么？ 在 RabbitMQ 中，队列（Queue） 是一种用于存储消息的 数据结构，消息会一直保存在队列中，直到被应用程序或服务消费为止。 生产者（Publisher） 把消息放进队列，消费者（Consumer） 从队列中取出消息。队列中的消息会按照 FIFO（先进先出）的顺序进行消费。 队列在生产者和消费者之间起到缓冲区的作用。生产者不需要知道消费者的存在，它们只需把消息发送到队列。消费者可以根据自身处理速度，按需消费消息。 RabbitMQ 目前 支持三种队列类型： 队列类型 描述 特点 典型用途 Classic Queue（经典队列） 最常用的队列类型，消息按 FIFO（先进先出）顺序存储和消费 支持持久化、优先级、TTL、死信等 大多数常规消息场景 Quorum Queue（仲裁队列） 基于 Raft 协议的队列，确保高可用和数据一致性 内置复制（副本数量可配置）、适合高可靠性场景，但吞吐量略低于经典队列 关键任务消息、高可靠性场景 Stream Queue（流式队列） 面向大量消息的高吞吐队列，支持消息按偏移量读取 类似 Kafka，可随机访问历史消息、顺序读取、可持久化大量消息 大数据流、日志处理、事件溯源 Classic Queue(经典队列) RabbitMQ 经典队列（原始队列类型）是一种通用队列类型。实际上它是在 3.8.x 版本之前唯一的队列类型。 经典队列适用于数据安全不是优先事项的用例，因为存储在经典队列中的数据不会被复制。 经典队列使用非复制的 FIFO 队列实现。 经典队列不适合积累太多的消息，如果队列中积累的消息太多了，会严重影响客户端生产消息以及消费消息的性能。因此，经典队列主要用在数据量比较小，并且生产消息和消费消息的速度比较稳定的业务场景。比如内部系统之间的服务调用。 RabbitMQ 4.0 删除了对经典队列 version1 的支持，同时也不再支持将 经典队列 的消息在节点间复制。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Auto expire x-expires 整数（毫秒） 队列在 指定时间内无人使用（无消费者、无发布、无访问） 时自动删除 类似“队列空闲过期时间”，节省资源 Message TTL x-message-ttl 整数（毫秒） 消息的 存活时间，超过时间后消息会被丢弃或发送到死信队列 用于限制消息时效性，如延迟消息或短期缓存 Overflow behaviour x-overflow 字符串（drop-head 或 reject-publish） 当队列达到 最大长度 或 最大字节数 时的行为 - drop-head：丢弃最早的消息 - reject-publish：拒绝新的消息 Single active consumer x-single-active-consumer 布尔值（true/false） 是否启用 单活消费者模式，一次只允许一个消费者消费队列 用于严格顺序消费，保证某个消息不会被多个消费者同时处理 Dead letter exchange (DLX) x-dead-letter-exchange 字符串 指定队列的 死信交换机，用于接收无法消费或过期的消息 常用于失败重试、消息补偿场景 Dead letter routing key x-dead-letter-routing-key 字符串 消息转发到 DLX 时的 路由键 可以灵活转发到不同队列 Max length x-max-length 整数 队列中 最大消息条数 超过时按照 Overflow behaviour 处理 Max length bytes x-max-length-bytes 整数（字节） 队列中 消息总字节数上限 超过时按照 Overflow behaviour 处理，适合大消息场景 Maximum priority x-max-priority 整数 启用优先级队列时，队列可设置的 最大优先级值 消息优先级范围是 0 到这个值，优先级高的消息先被消费 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明队列时，队列主节点（Leader）的选取规则 client-local（默认）：选择客户端所在节点作为Leader balanced：在节点间均衡Leader分布，用于 HA 队列优化 Quorum Queue(仲裁队列) 仲裁队列（Quorum Queue） 是 RabbitMQ 从3.8.0版本之后引入的一种现代队列类型，也是目前官方比较推荐的一种对列类型。未来有可能取代 经典队列 成为默认队列类型。 其基于 Raft 共识算法 实现 持久化、复制和高可用。它保证 数据安全性、可靠的主节点选举，即使在升级或集群波动期间也能保持高可用性。 仲裁队列支持 毒消息处理、至少一次死信投递 以及 AMQP 修改（AMQP.modified）的处理结果。 它适合 以数据安全为首要目标 的场景。与经典队列相比，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。 仲裁队列（Quorum Queue）的 Durability 只能设置为 Durable(true)。Auto delete 只能为 No(false)。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Auto expire x-expires 整数（毫秒） 队列在指定时间内无人使用（无消费者、无发布、无访问）时自动删除 节省资源，队列空闲过期时间 Message TTL x-message-ttl 整数（毫秒） 队列中消息的生存时间，超过时间后消息会被丢弃或转入死信队列 控制消息时效性 Overflow behaviour x-overflow 字符串（drop-head 或 reject-publish） 当队列达到最大长度时的处理方式 drop-head：丢弃最早消息，reject-publish：拒绝新消息 Single active consumer x-single-active-consumer 布尔值（true/false） 是否启用单活消费者模式，一次只允许一个消费者消费队列 保证严格顺序消费 Dead letter exchange (DLX) x-dead-letter-exchange 字符串 指定队列的死信交换机，用于接收无法消费或过期的消息 与 DLX 配合使用处理失败消息 Dead letter routing key x-dead-letter-routing-key 字符串 消息转发到 DLX 时的路由键 灵活路由死信消息 Max length x-max-length 整数 队列中最大消息条数 超过时按 Overflow behaviour 处理 Max length bytes x-max-length-bytes 整数（字节） 队列消息总字节数上限 超过时按 Overflow behaviour 处理 Delivery limit x-delivery-limit 整数 消息允许投递的最大次数，超过后变为死信 控制消息重试次数 Initial cluster size x-quorum-initial-group-size 整数 队列在创建时需要的最小节点数 用于保证仲裁队列的高可用性 Target cluster size x-quorum-target-group-size 整数 队列运行时的目标节点数 当集群节点变化时，仲裁队列会尝试调整副本数量 Dead letter strategy x-dead-letter-strategy 字符串（at-most-once、at-least-once） 设置仲裁队列的死信处理策略 仅适用于 Quorum Queue。at-most-once（默认）：消息最多投递一次，可能丢失。at-least-once：确保消息至少投递一次，必须将 Overflow behaviour 设置为 reject-publish，否则回退到 at-most-once。 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明队列时，队列主节点（Leader）的选取规则 client-local：选择客户端所在节点作为 Leader balanced：在节点间均衡 Leader 分布 Quorum Queues 和 Classic Queues 的功能对比如下： Feature 中文含义 Classic queues Quorum queues 说明 Non-durable queues 非持久化队列 yes no Quorum queues 总是持久化，不支持非持久化 Message replication 消息复制 no yes Quorum queues 内置消息复制，Classic queues 需镜像策略 Exclusivity 独占队列 yes no Classic queues 支持独占队列，Quorum queues 不支持独占 Per message persistence 消息级持久化 per message always Quorum queues 消息总是持久化 Membership changes 节点成员变更 no semi-automatic Quorum queues 节点变化时半自动处理复制 Message TTL (Time-To-Live) 消息存活时间 yes yes 两者都支持消息过期时间 Queue TTL 队列存活时间 yes partially Quorum queues 的 lease 不会因重新声明而续期 Queue length limits 队列长度限制 yes yes Quorum queues 支持长度限制，但 x-overflow=reject-publish-dlx 不支持 Keeps messages in memory 消息内存保存 see Classic Queues never Quorum queues 消息总是写入磁盘，不保留在内存 Message priority 消息优先级 yes yes 支持消息优先级 Single Active Consumer 单活消费者 yes yes 支持单活消费者 Consumer exclusivity 独占消费者 yes no Quorum queues 不支持独占消费者，需使用 Single Active Consumer Consumer priority 消费者优先级 yes yes 支持消费者优先级 Dead letter exchanges 死信交换机 yes yes 支持死信交换机 Adheres to policies 遵循策略 yes yes 支持策略，但 Quorum queues 的部分策略行为不同 Poison message handling 毒消息处理 no yes Quorum queues 支持毒消息处理 Server-named queues 服务器自动命名队列 yes no Quorum queues 不支持服务器自动命名队列 Stream(流) Stream 是RabbitMQ自 3.9.0 版本开始引入的一种新的数据队列类型。这种队列类型的消息是持久化到磁盘并且具备分布式备份的，更适合于消费者多，读消息非常频繁的场景。 Stream 的核心是以append-only只添加的日志来记录消息，整体来说，就是消息将以append-only的方式持久化到日志文件中，然后通过调整每个消费者的消费进度offset，来实现消息的多次分发。 Stream 不支持死信交换机，不支持处理毒消息。 实际上 Stream 不属于队列，流（Streams） 是一种 持久化、可复制的数据结构，功能上类似队列：从生产者缓冲消息供消费者读取。但它与队列有两个重要区别： 存储模型 – 流是 追加日志（append-only log），消息可以 重复读取直到过期。 消费模型 – 流提供 非破坏性消费语义（non-destructive consumer semantics），多个消费者可以多次读取同一条消息而不会删除它。 Stream 始终是持久化和复制的，保证数据安全。消费者可以通过 RabbitMQ 客户端库 或 专用二进制协议插件 读取流，其中插件方式可以 访问所有流特性 并提供 最佳性能。合理的客户端连接策略有助于提升 吞吐量和效率。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Max length bytes x-max-length-bytes 整数（字节） 流中允许存储的 最大数据总字节数 超过时流将停止接收新消息，适合控制存储容量 Max time retention x-max-age 字符串（时间单位，例如 1h, 30m, 1d） 设置流队列中消息的 最大保留时间，超过时间的消息会被删除 支持时间单位：Y=年, M=月, D=天, h=小时, m=分钟, s=秒。例如 &quot;1h&quot; 表示只保留最近 1 小时的消息，用于控制数据量和自动清理过期消息 Max segment size in bytes x-stream-max-segment-size 整数（字节） 流分段存储时的 每个段的最大字节数 控制单个文件段大小，有利于 I/O 性能和管理 Filter size (per chunk) in bytes x-stream-filter-size-bytes 整数（字节） 流内部 过滤索引每块的大小 用于加速消息定位和读取，影响内存使用和检索效率 Initial cluster size x-initial-cluster-size 整数 流在创建时的 最小节点数 保证流的复制和高可用性 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明流时，主节点（Leader）的选取规则 client-local：客户端所在节点作为 Leader（默认）balanced：在节点间均衡 Leader 分布，用于优化 HA Classic Queue vs Stream Queue Feature Matrix Feature 中文含义 Classic queues Stream queues 说明 Non-durable queues 非持久化队列 yes no Stream 队列总是持久化，不支持非持久化 Exclusivity 独占队列 yes no Classic 队列支持独占，Stream 队列不支持独占 Per message persistence 消息级持久化 per message always Stream 队列的消息总是持久化 Membership changes 节点成员变更 no manual Stream 队列节点变更需要手动管理 TTL 消息存活时间 yes no (but see Retention) Stream 队列没有消息 TTL，但可通过 Retention 控制过期 Queue length limits 队列长度限制 yes no (but see Retention) Stream 队列没有固定长度限制，通过 Retention 控制数据量 Keeps messages in memory 消息内存保存 see Classic Queues never Stream 队列消息不保存在内存中，只写入磁盘 Message priority 消息优先级 yes no Stream 队列不支持消息优先级 Consumer priority 消费者优先级 yes no Stream 队列不支持消费者优先级 Dead letter exchanges 死信交换机 yes no Stream 队列不支持死信交换机 Adheres to policies 遵循策略 yes yes (see Retention) Stream 队列支持策略，但主要通过 Retention 控制行为 Reacts to memory alarms 内存告警响应 yes no (uses minimal RAM) Stream 队列使用最小内存，不触发内存告警 Poison message handling 毒消息处理 no no Stream 队列不支持毒消息处理 我们可以激活流插件来使用流的特有功能 1rabbitmq-plugins enable rabbitmq_stream rabbitmq_stream_management 激活流插件后，Stream队列的操作方式可以更高级，具体可以参考官方文档，作者在Java Client 示例中也给出了示例代码。 超级流(Super Streams) 超级流（Super streams） 是一种通过将一个大的流分区成更小的流来实现扩展的方式。它们与 单个消费者（Single Active Consumer） 集成，以在分区内保持消息顺序。超级流从 RabbitMQ 3.11 开始可用。 一个超级流是由多个普通流组成的逻辑流。它是一种通过 RabbitMQ Streams 来扩展发布和消费的方法：一个大型逻辑流被划分成多个分区流，将存储和流量分散到多个集群节点上。 超级流依然是一个逻辑实体：由于客户端库的智能化处理，应用程序会把它视为一个“大型”流。超级流的拓扑结构基于 AMQP 0.9.1 模型，也就是交换机（exchange）、队列（queue）和它们之间的绑定（binding）。 可以使用任何 AMQP 0.9.1 库或管理插件创建超级流的拓扑。它需要创建一个直连交换机（direct exchange）、分区流（partition streams），并将它们绑定在一起。 通过管理控制台创建超级流 也可以通过命令创建超级流，以下是如何用命令创建一个包含 3 个分区的超级流： 12# rabbitmq-streams add_super_stream [-p &lt;vhost&gt;] &lt;stream-name&gt; [--partitions &lt;number&gt;]rabbitmq-streams add_super_stream -p /vtest sq_3 --partitions 3 创建的Stream 创建的 Exchange，名称 sq_3 绑定关系 队列类型扩展 懒队列 从3.6.x版本到3.12.x版本，RabbitMQ提供了一种针对Classic Queue的优化配置，lazy-mode，懒对列。懒队列会尽可能早的将消息内容保存到硬盘当中，并且只有在用户请求到时，才临时从硬盘加载到RAM内存当中。 默认情况下，RabbitMQ接收到消息时，会保存到内存以便使用，同时把消息写到硬盘。但是，消息写入硬盘的过程中，是会阻塞队列的。RabbitMQ虽然针对写入硬盘速度做了很多算法优化，但是在长队列中，依然表现不是很理想，所以就有了懒队列的出现。 懒队列会尝试尽可能早的把消息写到硬盘中。这意味着在正常操作的大多数情况下，RAM中要保存的消息要少得多。当然，这是以增加磁盘IO为代价的。 懒队列适合消息量大且长期有堆积的队列，可以减少内存使用，加快消费速度。但是这是以大量消耗集群的网络及磁盘IO为代价的。 从3.12往后的版本中，RabbitMQ 不再支持“惰性”模式，因为 经典队列 当前的特性就类似于以前的 懒队列。 死信队列 死信队列（Dead Letter Queue），新版中叫做 死信交换机（Dead Letter Exchange, DLX），是RabbitMQ对于未能正常消费的消息进行的一种补救机制，用于保存无法被正常处理的消息。当消息被消费者处理失败时，RabbitMQ会将消息发送到死信队列中，等待消费者处理。 死信队列也是一个普通的队列，同样可以在队列上声明消费者，继续对消息进行消费处理。 有以下几种情况，RabbitMQ会将一个正常消息转成死信 消息被拒绝（Message rejection） 由 AMQP 1.0 接收端使用 rejected 结果拒绝 由 AMQP 0.9.1 消费者使用 basic.reject 或 basic.nack，并且参数 requeue=false 消息过期（Message expiration） 消息超过其配置的 TTL（生存时间） 后过期。 队列长度超限（Queue length exceeded） 队列中的消息数量或总字节数达到配置的最大限制后，被丢弃的消息会死信化。 投递次数超限（仅适用于仲裁队列 Quorum Queue） 消息的投递次数超过了仲裁队列中配置的 delivery-limit。 使用场景 你可以在队列上配置 死信交换机（DLX） 和 死信路由键（Dead Letter Routing Key）。 当消息成为死信时，会被 重新发布到 DLX，这样你可以： 做错误日志记录 进行失败消息重试 用于监控和告警 死信交换机的配置方法（How Dead Lettering is Configured） 在 RabbitMQ 中，任何队列都可以通过 客户端 或者 策略（policies） 来配置 死信交换机（DLX）。 配置时主要涉及两个核心参数： 配置参数名 说明 dead-letter-exchange 指定用于接收死信消息的 死信交换机名称 dead-letter-routing-key 指定死信消息重新发布时使用的 路由键（Routing Key） 死信在转移到死信队列时，他的 routingkey 也会保存下来。但是如果配置了 x-dead-letter-routing-key 这个参数的话，routingkey 就会被替换为配置的这个值。 在创建队列时，我们可以通过为队列添加 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数，来指定 死信交换机（DLX）和 死信路由键（Dead Letter Routing Key）。但是这样做很麻烦，每个队列都要单独配置，因此，我们可以使用 策略（policies） 来统一配置。 1234# 仅指定死信交换机，这里交换机的名称是 my-dlx，交换机要提前创建好rabbitmqctl set_policy DLX &quot;.*&quot; &#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;&#125;&#x27; --apply-to queues --priority 7# 同时指定 死信交换机 和 路由键rabbitmqctl set_policy DLX &quot;.*&quot; &#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;&#x27; --apply-to queues --priority 7 参数说明： 部分 含义 rabbitmqctl RabbitMQ 的命令行管理工具 set_policy 设置一个策略（Policy），用于动态配置交换机、队列或绑定的参数 DLX 策略的名称，用户自定义，例如这里叫 DLX &quot;.*&quot; 正则表达式，匹配对象的名称。.* 表示匹配 所有队列，也可以指定具体队列名，比如 ^my-queue$ &#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125; 策略内容，这里设置了死信交换机名称和路由键： - dead-letter-exchange: 设置死信交换机名称为 my-dlx - dead-letter-routing-key: 设置路由键为 my-routing-key --apply-to queues 指定策略作用对象为 队列（queues），而不是交换机（exchanges）或绑定（bindings） --priority 7 策略的优先级，值越大优先级越高。多个策略作用在同一对象时，优先级高的会覆盖低的 执行这条命令后： 所有队列都会自动带上 x-dead-letter-exchange=my-dlx 和 x-dead-letter-routing-key=my-routing-key 配置。 队列中被拒绝、过期、超长或超过投递次数的消息会被重新发布到 my-dlx 交换机，并使用 my-routing-key 作为路由键。 消息被作为死信转移到死信队列后，会在Header当中增加⼀些消息。 123456x-first-death-queue：该消息首次成为死信时所在的队列名称x-first-death-reason：该消息首次被判定为死信的原因x-first-death-exchange：该消息在首次成为死信前被发布到的交换机名称x-last-death-queue：该消息最近一次成为死信时所在的队列名称x-last-death-reason：该消息最近一次被判定为死信的原因x-last-death-exchange：该消息在最近一次成为死信前被发布到的交换机名称 延迟队列 延迟队列（Delayed Message Queue）: 延迟队列是一种特殊类型的队列，用于延迟消息的投递。 RabbitMQ中，是不存在延迟队列的功能的，而通常如果要用到延迟队列，就会采用 TTL + 死信队列 的方式来实现。 延迟队列的实现原理： 创建一个普通队列，并设置队列的 TTL（x-message-ttl）参数，以及指定一个死信队列(x-dead-letter-exchange) 当消息的 TTL 到期时，消息会被自动从当前队列中删除，并进入死信队列。 为死信队列创建一个消费者，并监听死信队列，处理延迟消息。 优先级队列 优先级队列（Priority Queue）: RabbitMQ 支持为经典队列（classic queues）添加“优先级”功能。启用“优先级”功能的经典队列通常被称为“优先级队列”（priority queues）。 RabbitMQ 支持 1 到 255 之间的优先级值，但强烈建议使用 1 到 5 之间的值。需要注意的是，优先级值越高，会消耗更多的 CPU 和内存资源，因为 RabbitMQ 在内部需要为每个优先级（从 1 到最大配置值）维护一个子队列。 只有经典队列支持通过参数x-max-priority指定队列支持的最大优先级，且不支持 通过 策略（policies） 将经典队列声明为优先级队列。 发布消息时，可以通过参数 priority 指定消息的优先级。是的，消息也是可以设置参数的。 优先级队列如何与消费者协同工作 若消费者连接到一个 空队列，然后消息陆续被发布，那么这些消息可能 不会 在队列中等待（即刚发布就被消费者接收），此时优先级功能没有机会上场。优先级是在消息排队（ready 消息）状态时才能体现其作用。 推荐在消费者端使用 basic.qos(prefetch) 设置（在 manual ack 模式下），以限制消费者同时处理的未确认消息数。这样能让优先级的分级效果更加明显，因为如果 prefetch 数量未满，高优先级消息可以先被取出。 注意事项 未设置 priority 的消息 会被当作优先级 0 处理。若消息指定的优先级大于队列的最大值（x-max-priority），则该消息的优先级就是x-max-priority。 TTL / 消息过期 (message expiration)：即使设置了 TTL，过期的消息只会在队列头被检查。这意味着如果一个低优先级的消息在前面但还没过期，而高优先级的消息在后面，低优先级的消息可能会阻塞队列头，导致高优先级的消息被延迟。 队列最大长度限制 (max-length)：如果队列设置了最大长度，队列会从头部 (head) 丢弃消息以维持长度限制。这可能导致高优先级消息也被丢弃，从而违背直觉。","summary":"摘要 本文介绍 RabbitMQ 的 Queue 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-20T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/","url":"https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/","title":"RabbitMQ 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RabbitMQ 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RabbitMQ-简介\">RabbitMQ 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 是一个开源的 消息队列中间件，基于 AMQP（Advanced Message Queuing Protocol，高级消息队列协议） 实现，用于在分布式系统中 解耦、缓冲和异步处理消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它的主要作用是让 <code>不同系统</code> 或 <code>应用</code> 之间可靠地传递消息，即使发送方或接收方暂时不可用，也能保证消息不丢失。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 的核心特点</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>核心特点</th>\n<th>具体说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>可靠性</strong></td>\n<td>- 支持消息确认（ACK）机制<br>- 消息持久化到磁盘<br>- 支持事务或确认模式，保证消息不会丢失</td>\n</tr>\n<tr>\n<td><strong>灵活的路由</strong></td>\n<td>- 通过 <strong>交换机（Exchange）</strong> 将消息路由到不同的 <strong>队列（Queue）</strong><br>- 支持多种路由策略：<br>  • direct：直连，按队列名路由<br>  • fanout：广播，所有队列都收到<br>  • topic：主题匹配，类似订阅模式<br>  • headers：按消息头匹配</td>\n</tr>\n<tr>\n<td><strong>高性能</strong></td>\n<td>- 内存队列快速处理消息<br>- 支持异步 IO 和 Erlang 的并发模型</td>\n</tr>\n<tr>\n<td><strong>多语言支持</strong></td>\n<td>- 客户端库丰富：Java、Python、Go、C#、Node.js 等<br>- 可在多种平台和框架中使用</td>\n</tr>\n<tr>\n<td><strong>集群与高可用</strong></td>\n<td>- 支持集群模式<br>- 队列可以镜像到多个节点，保证高可用</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的核心概念</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>含义</th>\n<th>作用范围</th>\n<th>类比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Broker</strong></td>\n<td>一个 <strong>RabbitMQ 服务实例</strong>，包含整个 AMQP 服务、管理插件、队列、交换机等资源</td>\n<td>运行在一台服务器上，或集群中的一个节点</td>\n<td>类似于数据库的 <strong>实例</strong></td>\n</tr>\n<tr>\n<td><strong>Vhost</strong></td>\n<td>Broker 内部的 <strong>逻辑分区</strong>，用于隔离不同的队列、交换机、绑定等资源</td>\n<td>一个 Broker 可以有多个 vhost，每个 vhost 彼此隔离</td>\n<td>类似于数据库实例里的 <strong>schema</strong>，实际使用中建议为每个业务配置一个独立的 vhost，并为每个vhost单独配置一个管理用户</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Producer</strong></td>\n<td>消息生产者，发送消息到 RabbitMQ</td>\n</tr>\n<tr>\n<td><strong>Queue</strong></td>\n<td>队列，存储消息的地方</td>\n</tr>\n<tr>\n<td><strong>Consumer</strong></td>\n<td>消息消费者，从队列获取消息</td>\n</tr>\n<tr>\n<td><strong>Exchange</strong></td>\n<td>交换机，接收 Producer 的消息并根据规则路由到队列</td>\n</tr>\n<tr>\n<td><strong>Binding</strong></td>\n<td>绑定，定义 Exchange 与 Queue 的路由规则</td>\n</tr>\n<tr>\n<td><strong>Message</strong></td>\n<td>消息，RabbitMQ 传递的数据单元</td>\n</tr>\n<tr>\n<td><strong>Connection</strong></td>\n<td>连接，客户端与 RabbitMQ Broker 之间的 <strong>TCP 连接</strong>，是通信的物理通道</td>\n</tr>\n<tr>\n<td><strong>Channel</strong></td>\n<td>通道，Connection 内部的 <strong>逻辑连接</strong>，轻量级且多路复用，一个连接可开多个通道</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                        ┌─ Broker (RabbitMQ 实例)──────────┐</span><br><span class=\"line\">                        │                                 │</span><br><span class=\"line\">                        │    ┌───── Virtual Host ─────┐   │</span><br><span class=\"line\">        Producer ─── TCP ──────&gt; Exchange ──&gt; Queue ────────&gt; TCP ── Consumer</span><br><span class=\"line\">(Connection ──&gt; Channel)│    └────────────────────────┘   │</span><br><span class=\"line\">                        │                                 │</span><br><span class=\"line\">                        └─────────────────────────────────┘</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qgdFHL.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的典型应用场景</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>应用场景</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>异步处理</strong></td>\n<td>用户请求不直接处理，消息入队后由后台异步消费，例如邮件发送、图片处理</td>\n</tr>\n<tr>\n<td><strong>削峰填谷</strong></td>\n<td>缓冲高峰流量，平滑系统压力</td>\n</tr>\n<tr>\n<td><strong>系统解耦</strong></td>\n<td>不同服务之间不直接调用，降低耦合</td>\n</tr>\n<tr>\n<td><strong>广播/通知</strong></td>\n<td>发布/订阅模式，实现多服务同时收到消息</td>\n</tr>\n<tr>\n<td><strong>日志收集</strong></td>\n<td>统一接收、分发日志到不同处理系统</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-4-0-有哪些升级\">RabbitMQ 4.0+ 有哪些升级</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>特性标志（Feature Flags）的优化与强制性要求</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>在升级到 4.0 之前，用户必须先升级到 3.13.x 版本并手动启用所有稳定的特性标志。</p>\n</li>\n<li class=\"lvl-3\">\n<p>从 4.0+ 开始，如果集群中的所有节点都支持某个必需的特性标志，系统会在节点启动时自动启用该标志，无需人工干预。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>AMQP 协议的增强</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>新增了对 AMQP 过滤表达式（AMQP Filter Expressions）Version 1.0 Working Draft 09 的支持。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>MQTT 协议的改进</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>默认的 MQTT 最大包大小从之前的 256 MiB 降低到 16 MiB，同时仍允许用户通过配置项 mqtt.max_packet_size_authenticated 自定义该值</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Classic队列的变化</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>删除了对 Classic队列 <code>version1</code> 的支持，默认就是 <code>version2</code></p>\n</li>\n<li class=\"lvl-3\">\n<p>不再支持 Classic队列 的镜像功能，官方推荐使用 Quorum 队列 ，未来会将 Quorum 队列 作为默认队列。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群状态下创建 Quorum 队列 和 Stream 队列 会自动升级为 复制队列（镜像）</p>\n</li>\n</ul>\n<h2 id=\"RabbitMQ-单机安装\">RabbitMQ 单机安装</h2>\n<h3 id=\"安装Erlang\">安装Erlang</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ是基于Erlang语言开发的，所以安装RabbitMQ之前需要安装Erlang语言环境。需要注意的是RabbitMQ与Erlang语言之间是有版本对应关系的。参考官方文档<a href=\"https://www.rabbitmq.com/docs/which-erlang\">Erlang Version Requirements</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>目前RabbitMQ最新版本是<code>4.1.4</code>，Erlang版本可以选择 <code>27.x</code>，<a href=\"https://github.com/rabbitmq/erlang-rpm/releases\">GitHub下载地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载 el9 的版本，对应 CentOS 9</span></span><br><span class=\"line\">wget https://github.com/rabbitmq/erlang-rpm/releases/download/v27.3.4.3/erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rpm -ivh erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class=\"line\"><span class=\"comment\"># 查看安装的版本</span></span><br><span class=\"line\">erl</span><br><span class=\"line\"><span class=\"comment\"># 输出类似于，这里 Erlang/OTP 27 就表示安装的是 27.x 版本</span></span><br><span class=\"line\">Erlang/OTP 27 [erts-15.2.7.2] [<span class=\"built_in\">source</span>] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:1] [jit:ns]</span><br><span class=\"line\"></span><br><span class=\"line\">Eshell V15.2.7.2 (press Ctrl+G to abort, <span class=\"built_in\">type</span> <span class=\"built_in\">help</span>(). <span class=\"keyword\">for</span> <span class=\"built_in\">help</span>)</span><br><span class=\"line\">1&gt; q().  <span class=\"comment\"># 退出命令，注意是括号后面还有一个点。输入 help(). 显示帮助信息</span></span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装-RabbitMQ\">安装 RabbitMQ</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>目前RabbitMQ最新版本是<code>4.1.4</code>，<a href=\"https://github.com/rabbitmq/rabbitmq-server/releases\">GitHub下载地址</a>]</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载，noarch 表示架构无关，即 X86_64 和 ARM64 都可以</span></span><br><span class=\"line\"><span class=\"comment\"># 因为没有对应的 el9 的包，所以只能用 el8 的包了，实际使用中没有问题。</span></span><br><span class=\"line\">wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v4.1.4/rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rpm -ivh rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class=\"line\"><span class=\"comment\"># 查看版本信息</span></span><br><span class=\"line\">rabbitmq-diagnostics version <span class=\"comment\"># 无需启动服务</span></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ 服务启动后方可正确输出</span></span><br><span class=\"line\">rabbitmqctl version</span><br></pre></td></tr></table></figure>\n<h3 id=\"RabbitMQ-启动与停止命令\">RabbitMQ 启动与停止命令</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Erlang VM 是 Erlang 语言运行环境，RabbitMQ 应用运行在 Erlang VM 下。</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动 RabbitMQ 服务(Erlang VM) + 应用</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者，--detached 后台运行，不加就是前台运行</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmq-server -detached</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 单独启动 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl start_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>停止 RabbitMQ 服务(Erlang VM) + 应用</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停止 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者，单机模式 stop，集群模式 shutdown</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl stop / shutdown</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 单独停止 RabbitMQ 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl stop_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看RabbitMQ 服务状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl status rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl status</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 在 CentOS 9 (RPM 安装) 的目录结构</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>目录路径</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>配置文件</td>\n<td><code>/etc/rabbitmq</code></td>\n<td><code>rabbitmq.conf</code>、<code>advanced.config</code> 等配置</td>\n</tr>\n<tr>\n<td>日志文件</td>\n<td><code>/var/log/rabbitmq</code></td>\n<td>RabbitMQ 运行日志，默认存放在这里</td>\n</tr>\n<tr>\n<td>数据目录</td>\n<td><code>/var/lib/rabbitmq/mnesia</code></td>\n<td>消息队列、元数据存储目录</td>\n</tr>\n<tr>\n<td>Erlang Cookie</td>\n<td><code>/var/lib/rabbitmq/.erlang.cookie</code></td>\n<td>Erlang 节点间通信的 cookie 文件</td>\n</tr>\n<tr>\n<td>可执行文件</td>\n<td><code>/usr/lib/rabbitmq/bin</code></td>\n<td><code>rabbitmq-server</code>、<code>rabbitmqctl</code> 等命令</td>\n</tr>\n<tr>\n<td>启动脚本</td>\n<td><code>/usr/lib/systemd/system/rabbitmq-server.service</code></td>\n<td>systemd 管理 RabbitMQ 的启动脚本</td>\n</tr>\n<tr>\n<td>插件目录</td>\n<td><code>/usr/lib/rabbitmq/lib/rabbitmq_server-&lt;version&gt;/plugins</code></td>\n<td>所有插件文件存放路径</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"激活Web管理控制台插件\">激活Web管理控制台插件</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>对于 RabbitMQ 所有的操作基本都可以通过命令行完成，但是使用起来并不方便，这时我们可以激活 <code>rabbitmq_management</code> 插件，该插件提供了 Web 管理控制台，我们可以通过 Web 管理控制台来管理 RabbitMQ</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/management\">rabbitmq_management</a> 插件为 官方插件，默认已经安装，不需要下载，直接激活即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 激活插件</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmq-plugins <span class=\"built_in\">enable</span> rabbitmq_management</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>该插件除了提供了 <code>Web 管理控制台</code> ，还提供 <code>基于 HTTP 的 API</code> 用于管理和监控 RabbitMQ 节点和集群，以及 <code>命令行工具 rabbitmqadmin</code>，这个后面会介绍。</p>\n</li>\n</ul>\n<h4 id=\"设置远程访问帐号\">设置远程访问帐号</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>插件激活后可以通过浏览器访问 <code>http://&lt;ip&gt;:15672</code>，rabbitmq_management 插件默认用户名和密码都是 <code>guest</code>，但是默认情况下其只能通过 <code>127.0.0.1</code> 访问，此时我们有两种方法可以解决</p>\n</li>\n</ul>\n<h5 id=\"1-允许-guest-账号远程访问\">1. 允许 <code>guest</code> 账号远程访问</h5>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 修改 /etc/rabbitmq/rabbitmq.conf 文件</span></span><br><span class=\"line\"><span class=\"comment\"># 允许guest用户远程访问，`官方不推荐` 一直开启，建议开启后在 web 控制台中创建一个管理员账号，然后立刻关闭该配置</span></span><br><span class=\"line\">loopback_users.guest = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 默认的用户名和密码，注意这里 user 如果改成 admin，则上面的开启远程访问中的 guest 也要改成 admin</span></span><br><span class=\"line\">default_user = guest</span><br><span class=\"line\">default_pass = guest</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改完成后，重启 RabbitMQ 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl restart rabbitmq-server</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-新创建一个可以远程访问的管理员账号\">2. 新创建一个可以远程访问的管理员账号</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建管理员账号，比如这里 用户名为 <code>admin</code>，密码为 <code>rabbitmq</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl add_user admin rabbitmq</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>给管理员账号添加资源管理权限</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl set_permissions -p / admin <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&quot;.*&quot;</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具，用于管理用户、权限、队列、交换机等。</td>\n</tr>\n<tr>\n<td><code>set_permissions</code></td>\n<td>设置指定用户在某个虚拟主机（vhost）下的权限。</td>\n</tr>\n<tr>\n<td><code>-p /</code></td>\n<td>指定虚拟主机（vhost）。这里的 <code>/</code> 是默认虚拟主机。</td>\n</tr>\n<tr>\n<td><code>admin</code></td>\n<td>用户名，这里是为 <code>admin</code> 用户设置权限。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（配置权限）</td>\n<td>第一个正则表达式，控制用户对资源配置的权限，比如创建交换机、队列、绑定等。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（写权限）</td>\n<td>第二个正则表达式，控制用户向哪些资源发送消息。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（读权限）</td>\n<td>第三个正则表达式，控制用户从哪些资源消费消息。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>设置admin账号为控制台管理员</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl set_user_tags admin administrator</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具。</td>\n</tr>\n<tr>\n<td><code>set_user_tags</code></td>\n<td>用来为用户设置标签（tag），标签决定了用户在管理界面或 API 中的权限级别。</td>\n</tr>\n<tr>\n<td><code>admin</code></td>\n<td>用户名，这里是为 <code>admin</code> 用户设置标签。</td>\n</tr>\n<tr>\n<td><code>administrator</code></td>\n<td>标签名，表示给该用户赋予管理员权限。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>常见的用户标签</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>标签</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>administrator</code></td>\n<td>管理员，拥有最高权限，可通过 Web 管理界面、CLI、API 管理 RabbitMQ 所有内容</td>\n</tr>\n<tr>\n<td><code>monitoring</code></td>\n<td>监控用户，可查看所有监控信息，但不能修改配置</td>\n</tr>\n<tr>\n<td><code>management</code></td>\n<td>普通管理用户，可以登录管理界面，但权限受限</td>\n</tr>\n<tr>\n<td><code>policymaker</code></td>\n<td>策略管理用户，可以管理策略和参数，但不能管理其他用户</td>\n</tr>\n<tr>\n<td>无标签</td>\n<td>普通用户，只能收发消息，不能登录管理界面</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>set_permissions</code> 与 <code>set_user_tags</code> 总结对比</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>控制范围</th>\n<th>主要作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>set_permissions</code></td>\n<td>vhost 内的资源</td>\n<td>发消息、收消息、创建队列、交换机</td>\n</tr>\n<tr>\n<td><code>set_user_tags</code></td>\n<td>管理界面、管理 API</td>\n<td>用户管理、策略管理、集群管理</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4lP2cD.png\" alt=\"\"></p>\n<h3 id=\"启用所有稳定的-Feature-Flags\">启用所有稳定的 Feature Flags</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录控制台后我们会看到一条告警信息，参考：<a href=\"https://www.rabbitmq.com/docs/feature-flags\">Feature Flags</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">⚠ All stable feature flags must be enabled after completing an upgrade.</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>它的意思是：RabbitMQ 在新版本中引入了一些 Feature Flags（特性标志），这些特性标志用于控制一些新的功能或行为是否启用。升级 RabbitMQ 后，有些功能会处于 <code>未启用状态</code>，需要你手动开启，确保集群完全运行在最新的功能模式下。</p>\n</li>\n<li class=\"lvl-2\">\n<p>背景：为什么有 Feature Flags？</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">向后兼容：RabbitMQ 升级时，可能引入了新的数据格式或内部机制，如果立即启用，旧版本节点可能无法理解。</li>\n<li class=\"lvl-4\">滚动升级支持：升级集群时，可以先升级节点，再统一启用功能，避免中途出问题。</li>\n<li class=\"lvl-4\">可控性：你可以选择在确认集群稳定后再启用新功能。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>查看当前 Feature Flags 状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl -q --formatter pretty_table list_feature_flags</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出会类似这样：</span></span><br><span class=\"line\">┌──────────────────────────────────────┬──────────┐</span><br><span class=\"line\">│ name                                 │ state    │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ classic_mirrored_queue_version       │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ classic_queue_type_delivery_support  │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ detailed_queues_endpoint             │ disabled │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ direct_exchange_routing_v2           │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\"></span><br><span class=\"line\">&gt; enabled：特性已启用</span><br><span class=\"line\">&gt; disabled：特性未启用</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>可以输出 其它 格式，显示更详细的信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># json</span></span><br><span class=\"line\">rabbitmqctl -q --formatter json list_feature_flags name state provided_by desc doc_url | jq</span><br><span class=\"line\"><span class=\"comment\"># table</span></span><br><span class=\"line\">rabbitmqctl -q --formatter pretty_table list_feature_flags name state provided_by desc doc_url</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启用所有已标记为 stable 的特性，建议升级下一个 RabbitMQ 版本 前一定要确保当前版本的 Feature Flags 都是启用的，避免升级后无法顺利启动服务。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl enable_feature_flag all</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在控制台中也可以查看和开启这些 Feature Flags 的状态<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/VqNm1y.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里要注意，<strong>Feature Flags 一旦开启就无法关闭。</strong></p>\n</li>\n</ul>\n<h2 id=\"RabbitMQ-配置文件\">RabbitMQ 配置文件</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>对于 RPM/YUM/DNF 安装的 RabbitMQ，配置文件默认路径是</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>文件类型</th>\n<th>默认位置</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>主配置文件（推荐）</td>\n<td><code>/etc/rabbitmq/rabbitmq.conf</code></td>\n<td>使用 <strong>INI 格式</strong>，主要配置都在这里</td>\n</tr>\n<tr>\n<td>环境变量配置</td>\n<td><code>/etc/rabbitmq/rabbitmq-env.conf</code></td>\n<td>定义节点名、Cookie 位置、数据/日志目录等</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>安装后 <code>/etc/rabbitmq/</code> 目录可能是空的，你需要手动创建 <code>rabbitmq.conf</code>，详细的参数说明可以参看<a href=\"https://rabbitmq.com/configure.html\">官网指南</a>，<a href=\"https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbit/docs/rabbitmq.conf.example\">rabbitmq.conf 示例</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/rabbitmq/rabbitmq.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 监听端口</span></span><br><span class=\"line\">listeners.tcp.default = 5672</span><br><span class=\"line\"><span class=\"comment\"># 管理界面端口</span></span><br><span class=\"line\">management.tcp.port = 15672</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmq-env.conf</code> 用来 定义节点名、Cookie 、数据/日志目录等的环境变量，RabbitMQ 启动时会自动读取该文件，以下是通过 RPM 安装的 RabbitMQ 的默认值</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/rabbitmq/rabbitmq-env.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 节点名称，默认使用主机短名(hostname -s)，例如 rabbit@myhost</span></span><br><span class=\"line\">NODENAME=rabbit@&lt;hostname&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绑定的 IP 地址，留空表示监听所有地址，等价于 0.0.0.0</span></span><br><span class=\"line\">NODE_IP_ADDRESS=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># AMQP 协议端口，默认 5672</span></span><br><span class=\"line\">NODE_PORT=5672</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ 数据库存储目录</span></span><br><span class=\"line\">MNESIA_BASE=/var/lib/rabbitmq/mnesia</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录</span></span><br><span class=\"line\">LOG_BASE=/var/log/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置文件路径，不带 .conf 后缀</span></span><br><span class=\"line\">CONFIG_FILE=/etc/rabbitmq/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 是否使用长主机名，true/false (长主机名 hostname -f)</span></span><br><span class=\"line\">USE_LONGNAME=<span class=\"literal\">false</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>两个文件的作用</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>文件</th>\n<th>作用范围</th>\n<th>典型参数</th>\n<th>何时加载</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>rabbitmq-env.conf</strong></td>\n<td>设置 RabbitMQ 启动时的 <strong>环境变量</strong></td>\n<td>NODENAME, NODE_IP_ADDRESS, NODE_PORT, LOG_BASE, MNESIA_BASE</td>\n<td>在启动 RabbitMQ 服务前由 <code>rabbitmq-env</code> 脚本读取</td>\n</tr>\n<tr>\n<td><strong>rabbitmq.conf</strong></td>\n<td>RabbitMQ <strong>运行时配置</strong>（内部参数、插件配置等）</td>\n<td>listeners.tcp.default, log, cluster_formation 等</td>\n<td>RabbitMQ 启动后由 Erlang VM 内部读取</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><code>rabbitmq-env.conf</code> 决定 RabbitMQ 启动时的基本环境，比如节点名、数据目录、监听 IP 等，必须在启动前就确定。</p>\n</li>\n<li class=\"lvl-4\">\n<p><code>rabbitmq.conf</code> 决定运行时的功能，比如端口监听、日志等级、集群配置等，可以动态修改，重启应用后生效。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><code>rabbitmq-env.conf</code> 变量</th>\n<th><code>rabbitmq.conf</code> 对应配置</th>\n<th>优先级</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NODE_IP_ADDRESS</td>\n<td><code>listeners.tcp.default = &lt;IP&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>只要在 <code>rabbitmq.conf</code> 里配置，就覆盖环境变量</td>\n</tr>\n<tr>\n<td>NODE_PORT</td>\n<td><code>listeners.tcp.default = &lt;Port&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>同上，IP 和端口可以一起配置</td>\n</tr>\n<tr>\n<td>NODENAME</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>节点名只能通过 <code>rabbitmq-env.conf</code> 或环境变量设定</td>\n</tr>\n<tr>\n<td>MNESIA_BASE</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>数据目录只能在启动前设定</td>\n</tr>\n<tr>\n<td>LOG_BASE</td>\n<td><code>log.dir = &lt;path&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>运行时配置覆盖环境变量</td>\n</tr>\n<tr>\n<td>CONFIG_FILE</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>这个只决定加载哪个 <code>rabbitmq.conf</code> 文件</td>\n</tr>\n<tr>\n<td>USE_LONGNAME</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>节点名是否使用长主机名只能启动前决定</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-环境变量\">RabbitMQ 环境变量</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmq-env.conf</code> 文件就是用来定义环境变量的，但要注意，<code>rabbitmq-env.conf</code> 文件中定义的变量 去掉了 <code>RABBITMQ_</code> 前缀，例如在环境中设置的变量名通常是 <code>RABBITMQ_NODENAME</code>，但在 <code>rabbitmq-env.conf</code> 中，设置变量时会去掉 <code>RABBITMQ_</code> 前缀，直接使用 <code>NODENAME</code>。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在 rabbitmq-env.conf 中配置</span></span><br><span class=\"line\">NODENAME=rabbit@localhost</span><br><span class=\"line\">NODE_PORT=5672</span><br><span class=\"line\">LOG_BASE=/var/log/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 而在环境中，你实际设置的变量是</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_NODENAME=rabbit@localhost</span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_NODE_PORT=5672</span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_LOG_BASE=/var/log/rabbitmq</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>环境变量名称</th>\n<th>描述</th>\n<th>Linux RPM 安装的默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RABBITMQ_BASE</strong></td>\n<td>只针对 Windows 系统。该基目录包含 RabbitMQ 服务器的数据库和日志文件的子目录。</td>\n<td>无（仅适用于 Windows）</td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_CONFIG_FILE</strong></td>\n<td>配置文件的路径，没有 <code>.config</code> 扩展名。RabbitMQ 服务器使用该配置文件来配置组件。</td>\n<td>默认配置文件路径：<code>/etc/rabbitmq/rabbitmq.conf</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_GENERATED_CONFIG_DIR</strong></td>\n<td>RabbitMQ 写入其生成的配置文件的目录。</td>\n<td>默认生成路径：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_MNESIA_BASE</strong></td>\n<td>RabbitMQ 服务器节点数据库、消息存储和集群状态文件的基目录，每个节点一个。通常会覆盖 <code>RABBITMQ_MNESIA_DIR</code>。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_MNESIA_DIR</strong></td>\n<td>存储 RabbitMQ 节点数据的目录，包含模式数据库、消息存储、集群成员信息和其他持久节点状态。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_SCHEMA_DIR</strong></td>\n<td>RabbitMQ 保存新格式配置文件使用的配置模式的目录。</td>\n<td>默认值：<code>/etc/rabbitmq</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_LOG_BASE</strong></td>\n<td>该基目录包含 RabbitMQ 服务器的日志文件。</td>\n<td>默认值：<code>/var/log/rabbitmq</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_LOGS</strong></td>\n<td>RabbitMQ 服务器的 Erlang 日志文件的路径。</td>\n<td>默认值：<code>/var/log/rabbitmq/rabbitmq.log</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PLUGINS_DIR</strong></td>\n<td>RabbitMQ 的插件目录。路径由特定操作系统的分隔符定义（Unix 使用 <code>:</code>，Windows 使用 <code>;</code>）。</td>\n<td>默认值：<code>/usr/lib/rabbitmq/plugins</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PLUGINS_EXPAND_DIR</strong></td>\n<td>用于展开启用的插件的工作目录。确保有效的 RabbitMQ 用户有足够权限读取和创建该目录中的文件。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_ENABLED_PLUGINS_FILE</strong></td>\n<td>显式记录启用的插件的文件，启用或禁用插件时会重新创建该文件。确保有效的 RabbitMQ 用户有足够权限随时读取、写入和创建该文件。</td>\n<td>默认值：<code>/var/lib/rabbitmq/.enabled_plugins</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PID_FILE</strong></td>\n<td>用于 <code>rabbitmqctl</code> 的进程 ID 文件。</td>\n<td>默认值：<code>/var/run/rabbitmq/rabbitmq.pid</code></td>\n</tr>\n</tbody>\n</table>\n<div class=\"warning\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">安装好 RabbitMQ 后，不要随便修改 <code>hostname</code>，因为默认情况下，RabbitMQ 的数据目录是基于 <code>hostname</code> 创建的，如果修改了 <code>hostname</code>，RabbitMQ 就会指向新的数据目录</li>\n<li class=\"lvl-2\">数据目录默认是 <code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></li>\n<li class=\"lvl-2\">如果修改了 <code>hostname</code>，但仍要使用原来的数据目录，可以设置 <code>RABBITMQ_MNESIA_DIR</code> 环境变量，指向原来的数据目录</li>\n</ul>\n</div>\n<h2 id=\"RabbitMQ-相关命令\">RabbitMQ 相关命令</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>日常使用中，基本都是通过 Web 管理界面操作，这里仅对命令进行简要介绍。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（简要）</th>\n<th>常用示例（典型用法 + 中文说明）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmq-defaults</code></td>\n<td>定义/显示 RabbitMQ 安装默认目录和运行时前缀</td>\n<td><code>编辑 sbin/rabbitmq-defaults 中 PREFIX/SYS_PREFIX</code>（修改默认目录到系统目录）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-diagnostics</code></td>\n<td>健康检查 / 诊断工具，可用于监控</td>\n<td><code>rabbitmq-diagnostics -q ping</code>（检查节点是否可达）<br><code>rabbitmq-diagnostics -q status</code>（查看节点状态）<br><code>rabbitmq-diagnostics -q check_running</code>（确认节点运行中）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-env</code></td>\n<td><code>rabbitmq-env</code> 其实不是一个直接在命令行里单独使用的工具，而是 RabbitMQ 服务启动脚本 中用来加载 RabbitMQ 环境变量的脚本。</td>\n<td>在 <code>/etc/rabbitmq/rabbitmq-env.conf</code> 中设置：<br><code>RABBITMQ_NODENAME=myrabbit</code>（设置节点名）<br>或用 <code>rabbitmq-env</code> 输出查看实际环境</td>\n</tr>\n<tr>\n<td><code>rabbitmq-plugins</code></td>\n<td>插件管理：列出/启用/禁用插件</td>\n<td><code>rabbitmq-plugins list</code>（列出所有插件）<br><code>rabbitmq-plugins enable rabbitmq_management</code>（启用 Web 管理插件）<br><code>rabbitmq-plugins disable --offline plugin</code>（离线禁用插件）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-queues</code></td>\n<td>队列副本管理：rebalance/grow/shrink</td>\n<td><code>rabbitmq-queues rebalance all --vhost-pattern &quot;.*&quot; --queue-pattern &quot;.*&quot;</code>（重平衡所有队列副本）<br><code>rabbitmq-queues add_member --vhost / qname rabbit@node</code>（为队列增加节点副本）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-server</code></td>\n<td>启动 RabbitMQ 节点（前台/后台）</td>\n<td><code>rabbitmq-server</code>（前台启动）<br><code>rabbitmq-server -detached</code>（后台启动）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-upgrade</code></td>\n<td>升级相关操作：drain/恢复等</td>\n<td><code>rabbitmq-upgrade drain</code>（让节点进入维护模式，停止接收新连接）<br><code>rabbitmq-upgrade post_upgrade</code>（执行升级后收尾操作）<br><code>rabbitmq-upgrade revive</code>（恢复维护模式中的节点）</td>\n</tr>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>最常用管理命令：用户、队列、集群管理</td>\n<td><code>rabbitmqctl status</code>（查看节点状态）<br><code>rabbitmqctl list_queues</code>（列出所有队列）<br><code>rabbitmqctl add_user bob s3cr3t</code>（添加用户 bob，密码 s3cr3t）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-streams</code></td>\n<td>管理 Streams（流式队列）</td>\n<td><code>rabbitmq-streams stream_status --vhost / my-stream</code>（查看 my-stream 状态）<br><code>rabbitmq-streams add_replica --vhost / my-stream rabbit@node</code>（为 my-stream 增加副本节点）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"最常用的命令-rabbitmqctl\">最常用的命令 <code>rabbitmqctl</code></h3>\n<h4 id=\"命令自动补全\">命令自动补全</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl</code> 有一个 <code>autocomplete</code> 参数，可以自动完成命令参数，我们可以利用这个命令来实现命令自动补全</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>vim ~/.bashrc</code> 添加如下内容：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"title\">_rabbitmqctl_completion</span></span>() &#123;</span><br><span class=\"line\">    <span class=\"built_in\">local</span> cur opts</span><br><span class=\"line\">    cur=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span>           <span class=\"comment\"># 当前光标所在单词</span></span><br><span class=\"line\">    opts=$(rabbitmqctl autocomplete <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>)   <span class=\"comment\"># 只传当前单词作为前缀</span></span><br><span class=\"line\">    COMPREPLY=( $(compgen -W <span class=\"string\">&quot;<span class=\"variable\">$&#123;opts&#125;</span>&quot;</span> -- <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>) )</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">complete -F _rabbitmqctl_completion rabbitmqctl</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>实际上 RabbitMQ 的大部分命令都有 <code>autocomplete</code> 参数，都可以自动完成命令参数</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义通用补全函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">_rabbitmq_completion</span></span>() &#123;</span><br><span class=\"line\">    <span class=\"built_in\">local</span> cur opts</span><br><span class=\"line\">    cur=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 当前命令名，自动判断</span></span><br><span class=\"line\">    <span class=\"built_in\">local</span> cmd=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[0]&#125;</span>&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 给对应命令传当前前缀</span></span><br><span class=\"line\">    opts=$(<span class=\"variable\">$cmd</span> autocomplete <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span> 2&gt;/dev/null)</span><br><span class=\"line\">    COMPREPLY=( $(compgen -W <span class=\"string\">&quot;<span class=\"variable\">$&#123;opts&#125;</span>&quot;</span> -- <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>) )</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 一次性绑定多个命令</span></span><br><span class=\"line\">complete -F _rabbitmq_completion rabbitmqctl rabbitmq-plugins rabbitmq-diagnostics rabbitmq-queues rabbitmq-upgrade</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使补全生效</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br><span class=\"line\"><span class=\"comment\"># tab 补全</span></span><br><span class=\"line\">rabbitmqctl st&lt;TAB&gt;</span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">start_app  status     stop       stop_app</span><br></pre></td></tr></table></figure>\n<h4 id=\"常用命令参数\">常用命令参数</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl help</code> 获取所有命令参数的简介</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl help &lt;command&gt;</code> 获取指定命令的帮助</p>\n</li>\n<li class=\"lvl-2\">\n<p>日常使用中基本都是通过 <code>web 控制台</code> 完成，这里只做了解。</p>\n</li>\n</ul>\n<h5 id=\"1-节点管理\">1.节点管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>status</code></td>\n<td>查看节点状态，包括运行状态、版本、内存、队列数量等</td>\n<td><code>rabbitmqctl status</code></td>\n</tr>\n<tr>\n<td><code>stop</code></td>\n<td>停止 RabbitMQ 节点</td>\n<td><code>rabbitmqctl stop</code></td>\n</tr>\n<tr>\n<td><code>stop_app</code></td>\n<td>停止 RabbitMQ 应用（保留节点运行）</td>\n<td><code>rabbitmqctl stop_app</code></td>\n</tr>\n<tr>\n<td><code>start_app</code></td>\n<td>启动 RabbitMQ 应用</td>\n<td><code>rabbitmqctl start_app</code></td>\n</tr>\n<tr>\n<td><code>reset</code></td>\n<td>重置 RabbitMQ 节点，删除所有队列和数据（慎用）</td>\n<td><code>rabbitmqctl reset</code></td>\n</tr>\n<tr>\n<td><code>force_reset</code></td>\n<td>强制重置节点（即使在集群中也会重置）</td>\n<td><code>rabbitmqctl force_reset</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"2-用户和权限管理\">2. 用户和权限管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_users</code></td>\n<td>列出所有用户</td>\n<td><code>rabbitmqctl list_users</code></td>\n</tr>\n<tr>\n<td><code>add_user &lt;user&gt; &lt;password&gt;</code></td>\n<td>添加新用户</td>\n<td><code>rabbitmqctl add_user alice mypassword</code></td>\n</tr>\n<tr>\n<td><code>delete_user &lt;user&gt;</code></td>\n<td>删除用户</td>\n<td><code>rabbitmqctl delete_user alice</code></td>\n</tr>\n<tr>\n<td><code>change_password &lt;user&gt; &lt;password&gt;</code></td>\n<td>修改用户密码</td>\n<td><code>rabbitmqctl change_password alice newpass</code></td>\n</tr>\n<tr>\n<td><code>list_permissions &lt;user&gt;</code></td>\n<td>查看某用户的权限</td>\n<td><code>rabbitmqctl list_permissions alice</code></td>\n</tr>\n<tr>\n<td><code>set_permissions -p &lt;vhost&gt; &lt;user&gt; &quot;&lt;conf&gt;&quot; &quot;&lt;write&gt;&quot; &quot;&lt;read&gt;&quot;</code></td>\n<td>设置用户在虚拟主机的权限</td>\n<td><code>rabbitmqctl set_permissions -p / alice &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"3-虚拟主机（vhost）管理\">3. 虚拟主机（vhost）管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_vhosts</code></td>\n<td>列出所有虚拟主机</td>\n<td><code>rabbitmqctl list_vhosts</code></td>\n</tr>\n<tr>\n<td><code>add_vhost &lt;vhost&gt;</code></td>\n<td>添加虚拟主机</td>\n<td><code>rabbitmqctl add_vhost my_vhost</code></td>\n</tr>\n<tr>\n<td><code>delete_vhost &lt;vhost&gt;</code></td>\n<td>删除虚拟主机</td>\n<td><code>rabbitmqctl delete_vhost my_vhost</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"4-队列管理\">4. 队列管理</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>队列可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看和删除队列</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_queues</code></td>\n<td>列出队列</td>\n<td><code>rabbitmqctl list_queues</code></td>\n</tr>\n<tr>\n<td><code>list_queues name messages consumers</code></td>\n<td>列出队列及消息数、消费者数</td>\n<td><code>rabbitmqctl list_queues name messages consumers</code></td>\n</tr>\n<tr>\n<td><code>purge_queue &lt;queue&gt;</code></td>\n<td>清空队列消息</td>\n<td><code>rabbitmqctl purge_queue my_queue</code></td>\n</tr>\n<tr>\n<td><code>delete_queue &lt;queue&gt;</code></td>\n<td>删除队列</td>\n<td><code>rabbitmqctl delete_queue my_queue</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"5-交换机和绑定\">5. 交换机和绑定</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>交换机可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_exchanges</code></td>\n<td>列出交换机</td>\n<td><code>rabbitmqctl list_exchanges</code></td>\n</tr>\n<tr>\n<td><code>list_bindings</code></td>\n<td>列出绑定关系</td>\n<td><code>rabbitmqctl list_bindings</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"6-集群管理\">6. 集群管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>cluster_status</code></td>\n<td>查看集群状态</td>\n<td><code>rabbitmqctl cluster_status</code></td>\n</tr>\n<tr>\n<td><code>join_cluster &lt;node&gt;</code></td>\n<td>节点加入集群</td>\n<td><code>rabbitmqctl join_cluster rabbit@node1</code></td>\n</tr>\n<tr>\n<td><code>forget_cluster_node &lt;node&gt;</code></td>\n<td>将节点从集群中移除</td>\n<td><code>rabbitmqctl forget_cluster_node rabbit@node2</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"7-日志和调试\">7. 日志和调试</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>report</code></td>\n<td>输出节点诊断报告</td>\n<td><code>rabbitmqctl report</code></td>\n</tr>\n<tr>\n<td><code>eval &lt;expression&gt;</code></td>\n<td>执行 Erlang 表达式</td>\n<td><code>rabbitmqctl eval 'rabbit_mnesia:info().'</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"8-其他命令\">8. 其他命令</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>help</code></td>\n<td>查看帮助命令</td>\n<td><code>rabbitmqctl help</code></td>\n</tr>\n<tr>\n<td><code>version</code></td>\n<td>查看 RabbitMQ 版本</td>\n<td><code>rabbitmqctl version</code></td>\n</tr>\n<tr>\n<td><code>authenticate_user &lt;user&gt; &lt;password&gt;</code></td>\n<td>验证用户密码</td>\n<td><code>rabbitmqctl authenticate_user alice mypassword</code></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-HTTP-API\">RabbitMQ HTTP API</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的 HTTP API 是一个 基于 REST 的管理接口，主要用于对 RabbitMQ 的 资源管理和监控，它是 管理插件 <code>rabbitmq_management</code> 提供的功能。通过 HTTP API，你可以不用 <code>rabbitmqctl</code> 就能操作 RabbitMQ。</p>\n</li>\n<li class=\"lvl-2\">\n<p>要使用 HTTP API，你需要在 RabbitMQ 节点上确保 <code>rabbitmq_management</code> 插件已经启动。前面我们介绍<code>web 管理控制台</code>时已经启动了该插件，所以你可以直接使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 <code>Web管理控制台</code> 就是通过发送 AJAX 请求到 <code>/api/…</code> 接口来获取数据和执行操作。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/980Wwu.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里有 HTTP API 的详细说明，本文不再赘述。</p>\n</li>\n</ul>\n<h2 id=\"rabbitmqadmin\">rabbitmqadmin</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 是 管理插件 <code>rabbitmq_management</code> 提供的命令行工具，用于管理 RabbitMQ 的资源，如创建队列、交换机、绑定关系、查看队列、交换机、绑定关系等。</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 是一个使用 <code>HTTP API</code> 的命令行工具，所以底层实际上是调用了 <code>HTTP API</code> 。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/rabbitmq/rabbitmqadmin-ng/releases\">下载地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /usr/local/bin/rabbitmqadmin https://github.com/rabbitmq/rabbitmqadmin-ng/releases/download/v2.10.0/rabbitmqadmin-2.10.0-x86_64-unknown-linux-gnu</span><br><span class=\"line\"><span class=\"comment\"># 设置权限</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">chmod</span> +x /usr/local/bin/rabbitmqadmin</span><br><span class=\"line\"><span class=\"comment\"># 查看帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看子命令帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> &lt;<span class=\"built_in\">command</span>&gt;</span><br><span class=\"line\"><span class=\"comment\">## 示例</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 队列 帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> queues</span><br><span class=\"line\"><span class=\"comment\"># 查看 队列声明 帮助，子子命令</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> queues <span class=\"built_in\">declare</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 的功能非常强大，但是因为<code>HTTP API</code>故意没有公开某些操作，所以其不能替代 <code>rabbitmqctl</code> 或 <code>rabbitmq-plugins</code>等命令。</p>\n</li>\n<li class=\"lvl-2\">\n<p>因为实际使用中很少直接通过命令行，所以这里只做简单介绍。上文提到了 <code>rabbitmqctl</code> 不支持声明(创建) 交换机和队列，这个通过 <code>rabbitmqadmin</code> 实现</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建虚拟主机</span></span><br><span class=\"line\">rabbitmqadmin vhosts <span class=\"built_in\">declare</span> --name <span class=\"string\">&quot;my-vhost&quot;</span> --default-queue-type <span class=\"string\">&quot;quorum&quot;</span> --description <span class=\"string\">&quot;Used to test&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 声明队列</span></span><br><span class=\"line\">rabbitmqadmin queues <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --name <span class=\"string\">&quot;target.classic.queue.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;classic&quot;</span> --durable <span class=\"literal\">true</span> --auto-delete <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 声明交换机</span></span><br><span class=\"line\">rabbitmqadmin exchanges <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --name <span class=\"string\">&quot;target.direct.exchange.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;direct&quot;</span> --durable <span class=\"literal\">true</span> --auto-delete <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 绑定队列和交换机</span></span><br><span class=\"line\">rabbitmqadmin bindings <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --<span class=\"built_in\">source</span> <span class=\"string\">&quot;target.direct.exchange.name&quot;</span> --destination <span class=\"string\">&quot;target.classic.queue.name&quot;</span> --destination-type <span class=\"string\">&quot;queue&quot;</span> --routing-key <span class=\"string\">&quot;target.routing.key&quot;</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>还有就是定期备份 RabbitMQ 的结构数据(不包括消息)</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导出</span></span><br><span class=\"line\">abbitmqadmin definitions <span class=\"built_in\">export</span> --file backup.json</span><br><span class=\"line\"><span class=\"comment\"># 导入</span></span><br><span class=\"line\">rabbitmqadmin definitions import --file backup.json</span><br></pre></td></tr></table></figure>\n<h2 id=\"RabbitMQ-需要开放哪些端口\">RabbitMQ 需要开放哪些端口</h2>\n<table>\n<thead>\n<tr>\n<th>端口号</th>\n<th>协议</th>\n<th>用途说明</th>\n<th>默认状态</th>\n<th>安全建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5672</td>\n<td>AMQP</td>\n<td>主客户端连接端口</td>\n<td>开放</td>\n<td>必须开放，限制IP</td>\n</tr>\n<tr>\n<td>5671</td>\n<td>AMQP/SSL</td>\n<td>TLS加密连接端口</td>\n<td>关闭</td>\n<td>如使用TLS则开放</td>\n</tr>\n<tr>\n<td>15672</td>\n<td>HTTP</td>\n<td>管理界面端口</td>\n<td>关闭</td>\n<td>建议内网访问</td>\n</tr>\n<tr>\n<td>15671</td>\n<td>HTTPS</td>\n<td>TLS管理界面端口</td>\n<td>关闭</td>\n<td>如使用HTTPS则开放</td>\n</tr>\n<tr>\n<td>25672</td>\n<td>Erlang Distribution</td>\n<td>集群节点通信</td>\n<td>开放</td>\n<td>集群内部使用</td>\n</tr>\n<tr>\n<td>35672-35682</td>\n<td>Erlang Distribution</td>\n<td>集群节点发现</td>\n<td>开放</td>\n<td>集群内部使用</td>\n</tr>\n<tr>\n<td>5552</td>\n<td>Stream Protocol</td>\n<td>流协议端口,RabbitMQ 3.9+</td>\n<td>关闭</td>\n<td>使用流功能时开放</td>\n</tr>\n<tr>\n<td>5551</td>\n<td>Stream Protocol/SSL</td>\n<td>流协议TLS端口,RabbitMQ 3.9+</td>\n<td>关闭</td>\n<td>如使用TLS则开放</td>\n</tr>\n<tr>\n<td>61613</td>\n<td>STOMP</td>\n<td>STOMP协议支持端口</td>\n<td>关闭</td>\n<td>如使用STOMP协议则开放</td>\n</tr>\n<tr>\n<td>61614</td>\n<td>STOMP/SSL</td>\n<td>STOMP TLS加密端口</td>\n<td>关闭</td>\n<td>如使用STOMP over TLS则开放</td>\n</tr>\n<tr>\n<td>1883</td>\n<td>MQTT</td>\n<td>MQTT协议支持端口</td>\n<td>关闭</td>\n<td>如使用MQTT协议则开放</td>\n</tr>\n<tr>\n<td>8883</td>\n<td>MQTT/SSL</td>\n<td>MQTT TLS加密端口</td>\n<td>关闭</td>\n<td>如使用MQTT over TLS则开放</td>\n</tr>\n<tr>\n<td>15674</td>\n<td>Web STOMP</td>\n<td>WebSocket STOMP支持端口</td>\n<td>关闭</td>\n<td>如使用Web STOMP则开放</td>\n</tr>\n<tr>\n<td>15675</td>\n<td>Web MQTT</td>\n<td>WebSocket MQTT支持端口</td>\n<td>关闭</td>\n<td>如使用Web MQTT则开放</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 CentOS9 中 RabbitMQ 的安装与使用。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 RabbitMQ 简介 RabbitMQ 是一个开源的 消息队列中间件，基于 AMQP（Advanced Message Queuing Protocol，高级消息队列协议） 实现，用于在分布式系统中 解耦、缓冲和异步处理消息。 它的主要作用是让 不同系统 或 应用 之间可靠地传递消息，即使发送方或接收方暂时不可用，也能保证消息不丢失。 RabbitMQ 的核心特点 核心特点 具体说明 可靠性 - 支持消息确认（ACK）机制- 消息持久化到磁盘- 支持事务或确认模式，保证消息不会丢失 灵活的路由 - 通过 交换机（Exchange） 将消息路由到不同的 队列（Queue）- 支持多种路由策略： • direct：直连，按队列名路由 • fanout：广播，所有队列都收到 • topic：主题匹配，类似订阅模式 • headers：按消息头匹配 高性能 - 内存队列快速处理消息- 支持异步 IO 和 Erlang 的并发模型 多语言支持 - 客户端库丰富：Java、Python、Go、C#、Node.js 等- 可在多种平台和框架中使用 集群与高可用 - 支持集群模式- 队列可以镜像到多个节点，保证高可用 RabbitMQ 的核心概念 概念 含义 作用范围 类比 Broker 一个 RabbitMQ 服务实例，包含整个 AMQP 服务、管理插件、队列、交换机等资源 运行在一台服务器上，或集群中的一个节点 类似于数据库的 实例 Vhost Broker 内部的 逻辑分区，用于隔离不同的队列、交换机、绑定等资源 一个 Broker 可以有多个 vhost，每个 vhost 彼此隔离 类似于数据库实例里的 schema，实际使用中建议为每个业务配置一个独立的 vhost，并为每个vhost单独配置一个管理用户 名称 说明 Producer 消息生产者，发送消息到 RabbitMQ Queue 队列，存储消息的地方 Consumer 消息消费者，从队列获取消息 Exchange 交换机，接收 Producer 的消息并根据规则路由到队列 Binding 绑定，定义 Exchange 与 Queue 的路由规则 Message 消息，RabbitMQ 传递的数据单元 Connection 连接，客户端与 RabbitMQ Broker 之间的 TCP 连接，是通信的物理通道 Channel 通道，Connection 内部的 逻辑连接，轻量级且多路复用，一个连接可开多个通道 1234567 ┌─ Broker (RabbitMQ 实例)──────────┐ │ │ │ ┌───── Virtual Host ─────┐ │ Producer ─── TCP ──────&gt; Exchange ──&gt; Queue ────────&gt; TCP ── Consumer(Connection ──&gt; Channel)│ └────────────────────────┘ │ │ │ └─────────────────────────────────┘ RabbitMQ 的典型应用场景 应用场景 说明 异步处理 用户请求不直接处理，消息入队后由后台异步消费，例如邮件发送、图片处理 削峰填谷 缓冲高峰流量，平滑系统压力 系统解耦 不同服务之间不直接调用，降低耦合 广播/通知 发布/订阅模式，实现多服务同时收到消息 日志收集 统一接收、分发日志到不同处理系统 RabbitMQ 4.0+ 有哪些升级 特性标志（Feature Flags）的优化与强制性要求 在升级到 4.0 之前，用户必须先升级到 3.13.x 版本并手动启用所有稳定的特性标志。 从 4.0+ 开始，如果集群中的所有节点都支持某个必需的特性标志，系统会在节点启动时自动启用该标志，无需人工干预。 AMQP 协议的增强 新增了对 AMQP 过滤表达式（AMQP Filter Expressions）Version 1.0 Working Draft 09 的支持。 MQTT 协议的改进 默认的 MQTT 最大包大小从之前的 256 MiB 降低到 16 MiB，同时仍允许用户通过配置项 mqtt.max_packet_size_authenticated 自定义该值 Classic队列的变化 删除了对 Classic队列 version1 的支持，默认就是 version2 不再支持 Classic队列 的镜像功能，官方推荐使用 Quorum 队列 ，未来会将 Quorum 队列 作为默认队列。 集群状态下创建 Quorum 队列 和 Stream 队列 会自动升级为 复制队列（镜像） RabbitMQ 单机安装 安装Erlang RabbitMQ是基于Erlang语言开发的，所以安装RabbitMQ之前需要安装Erlang语言环境。需要注意的是RabbitMQ与Erlang语言之间是有版本对应关系的。参考官方文档Erlang Version Requirements 目前RabbitMQ最新版本是4.1.4，Erlang版本可以选择 27.x，GitHub下载地址 123456789101112# 下载 el9 的版本，对应 CentOS 9wget https://github.com/rabbitmq/erlang-rpm/releases/download/v27.3.4.3/erlang-27.3.4.3-1.el9.x86_64.rpm# 安装sudo rpm -ivh erlang-27.3.4.3-1.el9.x86_64.rpm# 查看安装的版本erl# 输出类似于，这里 Erlang/OTP 27 就表示安装的是 27.x 版本Erlang/OTP 27 [erts-15.2.7.2] [source] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:1] [jit:ns]Eshell V15.2.7.2 (press Ctrl+G to abort, type help(). for help)1&gt; q(). # 退出命令，注意是括号后面还有一个点。输入 help(). 显示帮助信息ok 安装 RabbitMQ 目前RabbitMQ最新版本是4.1.4，GitHub下载地址] 123456789# 下载，noarch 表示架构无关，即 X86_64 和 ARM64 都可以# 因为没有对应的 el9 的包，所以只能用 el8 的包了，实际使用中没有问题。wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v4.1.4/rabbitmq-server-4.1.4-1.el8.noarch.rpm# 安装sudo rpm -ivh rabbitmq-server-4.1.4-1.el8.noarch.rpm# 查看版本信息rabbitmq-diagnostics version # 无需启动服务# RabbitMQ 服务启动后方可正确输出rabbitmqctl version RabbitMQ 启动与停止命令 Erlang VM 是 Erlang 语言运行环境，RabbitMQ 应用运行在 Erlang VM 下。 启动 RabbitMQ 服务(Erlang VM) + 应用 1234567# 启动 RabbitMQ 服务(Erlang VM) + 应用sudo systemctl start rabbitmq-server# 或者，--detached 后台运行，不加就是前台运行sudo rabbitmq-server -detached# 单独启动 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令sudo rabbitmqctl start_app 停止 RabbitMQ 服务(Erlang VM) + 应用 1234567# 停止 RabbitMQ 服务(Erlang VM) + 应用sudo systemctl stop rabbitmq-server# 或者，单机模式 stop，集群模式 shutdownsudo rabbitmqctl stop / shutdown# 单独停止 RabbitMQ 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令sudo rabbitmqctl stop_app 查看RabbitMQ 服务状态 123sudo systemctl status rabbitmq-server# 或者sudo rabbitmqctl status RabbitMQ 在 CentOS 9 (RPM 安装) 的目录结构 类型 目录路径 说明 配置文件 /etc/rabbitmq rabbitmq.conf、advanced.config 等配置 日志文件 /var/log/rabbitmq RabbitMQ 运行日志，默认存放在这里 数据目录 /var/lib/rabbitmq/mnesia 消息队列、元数据存储目录 Erlang Cookie /var/lib/rabbitmq/.erlang.cookie Erlang 节点间通信的 cookie 文件 可执行文件 /usr/lib/rabbitmq/bin rabbitmq-server、rabbitmqctl 等命令 启动脚本 /usr/lib/systemd/system/rabbitmq-server.service systemd 管理 RabbitMQ 的启动脚本 插件目录 /usr/lib/rabbitmq/lib/rabbitmq_server-&lt;version&gt;/plugins 所有插件文件存放路径 激活Web管理控制台插件 对于 RabbitMQ 所有的操作基本都可以通过命令行完成，但是使用起来并不方便，这时我们可以激活 rabbitmq_management 插件，该插件提供了 Web 管理控制台，我们可以通过 Web 管理控制台来管理 RabbitMQ rabbitmq_management 插件为 官方插件，默认已经安装，不需要下载，直接激活即可 12# 激活插件sudo rabbitmq-plugins enable rabbitmq_management 该插件除了提供了 Web 管理控制台 ，还提供 基于 HTTP 的 API 用于管理和监控 RabbitMQ 节点和集群，以及 命令行工具 rabbitmqadmin，这个后面会介绍。 设置远程访问帐号 插件激活后可以通过浏览器访问 http://&lt;ip&gt;:15672，rabbitmq_management 插件默认用户名和密码都是 guest，但是默认情况下其只能通过 127.0.0.1 访问，此时我们有两种方法可以解决 1. 允许 guest 账号远程访问 123456# 修改 /etc/rabbitmq/rabbitmq.conf 文件# 允许guest用户远程访问，`官方不推荐` 一直开启，建议开启后在 web 控制台中创建一个管理员账号，然后立刻关闭该配置loopback_users.guest = false# 默认的用户名和密码，注意这里 user 如果改成 admin，则上面的开启远程访问中的 guest 也要改成 admindefault_user = guestdefault_pass = guest 修改完成后，重启 RabbitMQ 服务 1sudo systemctl restart rabbitmq-server 2. 新创建一个可以远程访问的管理员账号 创建管理员账号，比如这里 用户名为 admin，密码为 rabbitmq 1sudo rabbitmqctl add_user admin rabbitmq 给管理员账号添加资源管理权限 1sudo rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 部分 解释 rabbitmqctl RabbitMQ 的命令行管理工具，用于管理用户、权限、队列、交换机等。 set_permissions 设置指定用户在某个虚拟主机（vhost）下的权限。 -p / 指定虚拟主机（vhost）。这里的 / 是默认虚拟主机。 admin 用户名，这里是为 admin 用户设置权限。 &quot;.*&quot;（配置权限） 第一个正则表达式，控制用户对资源配置的权限，比如创建交换机、队列、绑定等。&quot;.*&quot; 表示全部允许。 &quot;.*&quot;（写权限） 第二个正则表达式，控制用户向哪些资源发送消息。&quot;.*&quot; 表示全部允许。 &quot;.*&quot;（读权限） 第三个正则表达式，控制用户从哪些资源消费消息。&quot;.*&quot; 表示全部允许。 设置admin账号为控制台管理员 1sudo rabbitmqctl set_user_tags admin administrator 部分 解释 rabbitmqctl RabbitMQ 的命令行管理工具。 set_user_tags 用来为用户设置标签（tag），标签决定了用户在管理界面或 API 中的权限级别。 admin 用户名，这里是为 admin 用户设置标签。 administrator 标签名，表示给该用户赋予管理员权限。 常见的用户标签 标签 说明 administrator 管理员，拥有最高权限，可通过 Web 管理界面、CLI、API 管理 RabbitMQ 所有内容 monitoring 监控用户，可查看所有监控信息，但不能修改配置 management 普通管理用户，可以登录管理界面，但权限受限 policymaker 策略管理用户，可以管理策略和参数，但不能管理其他用户 无标签 普通用户，只能收发消息，不能登录管理界面 set_permissions 与 set_user_tags 总结对比 命令 控制范围 主要作用 set_permissions vhost 内的资源 发消息、收消息、创建队列、交换机 set_user_tags 管理界面、管理 API 用户管理、策略管理、集群管理 启用所有稳定的 Feature Flags 登录控制台后我们会看到一条告警信息，参考：Feature Flags 1⚠ All stable feature flags must be enabled after completing an upgrade. 它的意思是：RabbitMQ 在新版本中引入了一些 Feature Flags（特性标志），这些特性标志用于控制一些新的功能或行为是否启用。升级 RabbitMQ 后，有些功能会处于 未启用状态，需要你手动开启，确保集群完全运行在最新的功能模式下。 背景：为什么有 Feature Flags？ 向后兼容：RabbitMQ 升级时，可能引入了新的数据格式或内部机制，如果立即启用，旧版本节点可能无法理解。 滚动升级支持：升级集群时，可以先升级节点，再统一启用功能，避免中途出问题。 可控性：你可以选择在确认集群稳定后再启用新功能。 查看当前 Feature Flags 状态 1234567891011121314151617rabbitmqctl -q --formatter pretty_table list_feature_flags# 输出会类似这样：┌──────────────────────────────────────┬──────────┐│ name │ state │├──────────────────────────────────────┼──────────┤│ classic_mirrored_queue_version │ enabled │├──────────────────────────────────────┼──────────┤│ classic_queue_type_delivery_support │ enabled │├──────────────────────────────────────┼──────────┤│ detailed_queues_endpoint │ disabled │├──────────────────────────────────────┼──────────┤│ direct_exchange_routing_v2 │ enabled │├──────────────────────────────────────┼──────────┤&gt; enabled：特性已启用&gt; disabled：特性未启用 可以输出 其它 格式，显示更详细的信息 1234# jsonrabbitmqctl -q --formatter json list_feature_flags name state provided_by desc doc_url | jq# tablerabbitmqctl -q --formatter pretty_table list_feature_flags name state provided_by desc doc_url 启用所有已标记为 stable 的特性，建议升级下一个 RabbitMQ 版本 前一定要确保当前版本的 Feature Flags 都是启用的，避免升级后无法顺利启动服务。 1rabbitmqctl enable_feature_flag all 在控制台中也可以查看和开启这些 Feature Flags 的状态 这里要注意，Feature Flags 一旦开启就无法关闭。 RabbitMQ 配置文件 对于 RPM/YUM/DNF 安装的 RabbitMQ，配置文件默认路径是 文件类型 默认位置 作用 主配置文件（推荐） /etc/rabbitmq/rabbitmq.conf 使用 INI 格式，主要配置都在这里 环境变量配置 /etc/rabbitmq/rabbitmq-env.conf 定义节点名、Cookie 位置、数据/日志目录等 安装后 /etc/rabbitmq/ 目录可能是空的，你需要手动创建 rabbitmq.conf，详细的参数说明可以参看官网指南，rabbitmq.conf 示例 123456# /etc/rabbitmq/rabbitmq.conf# 监听端口listeners.tcp.default = 5672# 管理界面端口management.tcp.port = 15672 rabbitmq-env.conf 用来 定义节点名、Cookie 、数据/日志目录等的环境变量，RabbitMQ 启动时会自动读取该文件，以下是通过 RPM 安装的 RabbitMQ 的默认值 12345678910111213141516171819202122# /etc/rabbitmq/rabbitmq-env.conf# 节点名称，默认使用主机短名(hostname -s)，例如 rabbit@myhostNODENAME=rabbit@&lt;hostname&gt;# 绑定的 IP 地址，留空表示监听所有地址，等价于 0.0.0.0NODE_IP_ADDRESS=# AMQP 协议端口，默认 5672NODE_PORT=5672# RabbitMQ 数据库存储目录MNESIA_BASE=/var/lib/rabbitmq/mnesia# 日志存放目录LOG_BASE=/var/log/rabbitmq# 配置文件路径，不带 .conf 后缀CONFIG_FILE=/etc/rabbitmq/rabbitmq# 是否使用长主机名，true/false (长主机名 hostname -f)USE_LONGNAME=false 两个文件的作用 文件 作用范围 典型参数 何时加载 rabbitmq-env.conf 设置 RabbitMQ 启动时的 环境变量 NODENAME, NODE_IP_ADDRESS, NODE_PORT, LOG_BASE, MNESIA_BASE 在启动 RabbitMQ 服务前由 rabbitmq-env 脚本读取 rabbitmq.conf RabbitMQ 运行时配置（内部参数、插件配置等） listeners.tcp.default, log, cluster_formation 等 RabbitMQ 启动后由 Erlang VM 内部读取 rabbitmq-env.conf 决定 RabbitMQ 启动时的基本环境，比如节点名、数据目录、监听 IP 等，必须在启动前就确定。 rabbitmq.conf 决定运行时的功能，比如端口监听、日志等级、集群配置等，可以动态修改，重启应用后生效。 rabbitmq-env.conf 变量 rabbitmq.conf 对应配置 优先级 说明 NODE_IP_ADDRESS listeners.tcp.default = &lt;IP&gt; rabbitmq.conf 只要在 rabbitmq.conf 里配置，就覆盖环境变量 NODE_PORT listeners.tcp.default = &lt;Port&gt; rabbitmq.conf 同上，IP 和端口可以一起配置 NODENAME 无直接对应 rabbitmq-env.conf 节点名只能通过 rabbitmq-env.conf 或环境变量设定 MNESIA_BASE 无直接对应 rabbitmq-env.conf 数据目录只能在启动前设定 LOG_BASE log.dir = &lt;path&gt; rabbitmq.conf 运行时配置覆盖环境变量 CONFIG_FILE 无直接对应 rabbitmq-env.conf 这个只决定加载哪个 rabbitmq.conf 文件 USE_LONGNAME 无直接对应 rabbitmq-env.conf 节点名是否使用长主机名只能启动前决定 RabbitMQ 环境变量 rabbitmq-env.conf 文件就是用来定义环境变量的，但要注意，rabbitmq-env.conf 文件中定义的变量 去掉了 RABBITMQ_ 前缀，例如在环境中设置的变量名通常是 RABBITMQ_NODENAME，但在 rabbitmq-env.conf 中，设置变量时会去掉 RABBITMQ_ 前缀，直接使用 NODENAME。 123456789# 在 rabbitmq-env.conf 中配置NODENAME=rabbit@localhostNODE_PORT=5672LOG_BASE=/var/log/rabbitmq# 而在环境中，你实际设置的变量是export RABBITMQ_NODENAME=rabbit@localhostexport RABBITMQ_NODE_PORT=5672export RABBITMQ_LOG_BASE=/var/log/rabbitmq 环境变量名称 描述 Linux RPM 安装的默认值 RABBITMQ_BASE 只针对 Windows 系统。该基目录包含 RabbitMQ 服务器的数据库和日志文件的子目录。 无（仅适用于 Windows） RABBITMQ_CONFIG_FILE 配置文件的路径，没有 .config 扩展名。RabbitMQ 服务器使用该配置文件来配置组件。 默认配置文件路径：/etc/rabbitmq/rabbitmq.conf RABBITMQ_GENERATED_CONFIG_DIR RabbitMQ 写入其生成的配置文件的目录。 默认生成路径：/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_BASE RabbitMQ 服务器节点数据库、消息存储和集群状态文件的基目录，每个节点一个。通常会覆盖 RABBITMQ_MNESIA_DIR。 默认值：/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR 存储 RabbitMQ 节点数据的目录，包含模式数据库、消息存储、集群成员信息和其他持久节点状态。 默认值：/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt; RABBITMQ_SCHEMA_DIR RabbitMQ 保存新格式配置文件使用的配置模式的目录。 默认值：/etc/rabbitmq RABBITMQ_LOG_BASE 该基目录包含 RabbitMQ 服务器的日志文件。 默认值：/var/log/rabbitmq RABBITMQ_LOGS RabbitMQ 服务器的 Erlang 日志文件的路径。 默认值：/var/log/rabbitmq/rabbitmq.log RABBITMQ_PLUGINS_DIR RabbitMQ 的插件目录。路径由特定操作系统的分隔符定义（Unix 使用 :，Windows 使用 ;）。 默认值：/usr/lib/rabbitmq/plugins RABBITMQ_PLUGINS_EXPAND_DIR 用于展开启用的插件的工作目录。确保有效的 RabbitMQ 用户有足够权限读取和创建该目录中的文件。 默认值：/var/lib/rabbitmq/mnesia RABBITMQ_ENABLED_PLUGINS_FILE 显式记录启用的插件的文件，启用或禁用插件时会重新创建该文件。确保有效的 RabbitMQ 用户有足够权限随时读取、写入和创建该文件。 默认值：/var/lib/rabbitmq/.enabled_plugins RABBITMQ_PID_FILE 用于 rabbitmqctl 的进程 ID 文件。 默认值：/var/run/rabbitmq/rabbitmq.pid 小贴士 安装好 RabbitMQ 后，不要随便修改 hostname，因为默认情况下，RabbitMQ 的数据目录是基于 hostname 创建的，如果修改了 hostname，RabbitMQ 就会指向新的数据目录 数据目录默认是 /var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt; 如果修改了 hostname，但仍要使用原来的数据目录，可以设置 RABBITMQ_MNESIA_DIR 环境变量，指向原来的数据目录 RabbitMQ 相关命令 日常使用中，基本都是通过 Web 管理界面操作，这里仅对命令进行简要介绍。 命令 作用（简要） 常用示例（典型用法 + 中文说明） rabbitmq-defaults 定义/显示 RabbitMQ 安装默认目录和运行时前缀 编辑 sbin/rabbitmq-defaults 中 PREFIX/SYS_PREFIX（修改默认目录到系统目录） rabbitmq-diagnostics 健康检查 / 诊断工具，可用于监控 rabbitmq-diagnostics -q ping（检查节点是否可达）rabbitmq-diagnostics -q status（查看节点状态）rabbitmq-diagnostics -q check_running（确认节点运行中） rabbitmq-env rabbitmq-env 其实不是一个直接在命令行里单独使用的工具，而是 RabbitMQ 服务启动脚本 中用来加载 RabbitMQ 环境变量的脚本。 在 /etc/rabbitmq/rabbitmq-env.conf 中设置：RABBITMQ_NODENAME=myrabbit（设置节点名）或用 rabbitmq-env 输出查看实际环境 rabbitmq-plugins 插件管理：列出/启用/禁用插件 rabbitmq-plugins list（列出所有插件）rabbitmq-plugins enable rabbitmq_management（启用 Web 管理插件）rabbitmq-plugins disable --offline plugin（离线禁用插件） rabbitmq-queues 队列副本管理：rebalance/grow/shrink rabbitmq-queues rebalance all --vhost-pattern &quot;.*&quot; --queue-pattern &quot;.*&quot;（重平衡所有队列副本）rabbitmq-queues add_member --vhost / qname rabbit@node（为队列增加节点副本） rabbitmq-server 启动 RabbitMQ 节点（前台/后台） rabbitmq-server（前台启动）rabbitmq-server -detached（后台启动） rabbitmq-upgrade 升级相关操作：drain/恢复等 rabbitmq-upgrade drain（让节点进入维护模式，停止接收新连接）rabbitmq-upgrade post_upgrade（执行升级后收尾操作）rabbitmq-upgrade revive（恢复维护模式中的节点） rabbitmqctl 最常用管理命令：用户、队列、集群管理 rabbitmqctl status（查看节点状态）rabbitmqctl list_queues（列出所有队列）rabbitmqctl add_user bob s3cr3t（添加用户 bob，密码 s3cr3t） rabbitmq-streams 管理 Streams（流式队列） rabbitmq-streams stream_status --vhost / my-stream（查看 my-stream 状态）rabbitmq-streams add_replica --vhost / my-stream rabbit@node（为 my-stream 增加副本节点） 最常用的命令 rabbitmqctl 命令自动补全 rabbitmqctl 有一个 autocomplete 参数，可以自动完成命令参数，我们可以利用这个命令来实现命令自动补全 vim ~/.bashrc 添加如下内容： 12345678_rabbitmqctl_completion() &#123; local cur opts cur=&quot;$&#123;COMP_WORDS[COMP_CWORD]&#125;&quot; # 当前光标所在单词 opts=$(rabbitmqctl autocomplete &quot;$cur&quot;) # 只传当前单词作为前缀 COMPREPLY=( $(compgen -W &quot;$&#123;opts&#125;&quot; -- &quot;$cur&quot;) )&#125;complete -F _rabbitmqctl_completion rabbitmqctl 实际上 RabbitMQ 的大部分命令都有 autocomplete 参数，都可以自动完成命令参数 12345678910111213# 定义通用补全函数_rabbitmq_completion() &#123; local cur opts cur=&quot;$&#123;COMP_WORDS[COMP_CWORD]&#125;&quot; # 当前命令名，自动判断 local cmd=&quot;$&#123;COMP_WORDS[0]&#125;&quot; # 给对应命令传当前前缀 opts=$($cmd autocomplete &quot;$cur&quot; 2&gt;/dev/null) COMPREPLY=( $(compgen -W &quot;$&#123;opts&#125;&quot; -- &quot;$cur&quot;) )&#125;# 一次性绑定多个命令complete -F _rabbitmq_completion rabbitmqctl rabbitmq-plugins rabbitmq-diagnostics rabbitmq-queues rabbitmq-upgrade 测试 123456# 使补全生效source ~/.bashrc# tab 补全rabbitmqctl st&lt;TAB&gt;# 输出start_app status stop stop_app 常用命令参数 rabbitmqctl help 获取所有命令参数的简介 rabbitmqctl help &lt;command&gt; 获取指定命令的帮助 日常使用中基本都是通过 web 控制台 完成，这里只做了解。 1.节点管理 命令 功能 示例 status 查看节点状态，包括运行状态、版本、内存、队列数量等 rabbitmqctl status stop 停止 RabbitMQ 节点 rabbitmqctl stop stop_app 停止 RabbitMQ 应用（保留节点运行） rabbitmqctl stop_app start_app 启动 RabbitMQ 应用 rabbitmqctl start_app reset 重置 RabbitMQ 节点，删除所有队列和数据（慎用） rabbitmqctl reset force_reset 强制重置节点（即使在集群中也会重置） rabbitmqctl force_reset 2. 用户和权限管理 命令 功能 示例 list_users 列出所有用户 rabbitmqctl list_users add_user &lt;user&gt; &lt;password&gt; 添加新用户 rabbitmqctl add_user alice mypassword delete_user &lt;user&gt; 删除用户 rabbitmqctl delete_user alice change_password &lt;user&gt; &lt;password&gt; 修改用户密码 rabbitmqctl change_password alice newpass list_permissions &lt;user&gt; 查看某用户的权限 rabbitmqctl list_permissions alice set_permissions -p &lt;vhost&gt; &lt;user&gt; &quot;&lt;conf&gt;&quot; &quot;&lt;write&gt;&quot; &quot;&lt;read&gt;&quot; 设置用户在虚拟主机的权限 rabbitmqctl set_permissions -p / alice &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 3. 虚拟主机（vhost）管理 命令 功能 示例 list_vhosts 列出所有虚拟主机 rabbitmqctl list_vhosts add_vhost &lt;vhost&gt; 添加虚拟主机 rabbitmqctl add_vhost my_vhost delete_vhost &lt;vhost&gt; 删除虚拟主机 rabbitmqctl delete_vhost my_vhost 4. 队列管理 队列可以通过 web 控制台 创建， 也可以通过 客户端(比如Java) 创建，rabbitmqctl 只能查看和删除队列 命令 功能 示例 list_queues 列出队列 rabbitmqctl list_queues list_queues name messages consumers 列出队列及消息数、消费者数 rabbitmqctl list_queues name messages consumers purge_queue &lt;queue&gt; 清空队列消息 rabbitmqctl purge_queue my_queue delete_queue &lt;queue&gt; 删除队列 rabbitmqctl delete_queue my_queue 5. 交换机和绑定 交换机可以通过 web 控制台 创建， 也可以通过 客户端(比如Java) 创建，rabbitmqctl 只能查看 命令 功能 示例 list_exchanges 列出交换机 rabbitmqctl list_exchanges list_bindings 列出绑定关系 rabbitmqctl list_bindings 6. 集群管理 命令 功能 示例 cluster_status 查看集群状态 rabbitmqctl cluster_status join_cluster &lt;node&gt; 节点加入集群 rabbitmqctl join_cluster rabbit@node1 forget_cluster_node &lt;node&gt; 将节点从集群中移除 rabbitmqctl forget_cluster_node rabbit@node2 7. 日志和调试 命令 功能 示例 report 输出节点诊断报告 rabbitmqctl report eval &lt;expression&gt; 执行 Erlang 表达式 rabbitmqctl eval 'rabbit_mnesia:info().' 8. 其他命令 命令 功能 示例 help 查看帮助命令 rabbitmqctl help version 查看 RabbitMQ 版本 rabbitmqctl version authenticate_user &lt;user&gt; &lt;password&gt; 验证用户密码 rabbitmqctl authenticate_user alice mypassword RabbitMQ HTTP API RabbitMQ 的 HTTP API 是一个 基于 REST 的管理接口，主要用于对 RabbitMQ 的 资源管理和监控，它是 管理插件 rabbitmq_management 提供的功能。通过 HTTP API，你可以不用 rabbitmqctl 就能操作 RabbitMQ。 要使用 HTTP API，你需要在 RabbitMQ 节点上确保 rabbitmq_management 插件已经启动。前面我们介绍web 管理控制台时已经启动了该插件，所以你可以直接使用。 实际上 Web管理控制台 就是通过发送 AJAX 请求到 /api/… 接口来获取数据和执行操作。 这里有 HTTP API 的详细说明，本文不再赘述。 rabbitmqadmin rabbitmqadmin 是 管理插件 rabbitmq_management 提供的命令行工具，用于管理 RabbitMQ 的资源，如创建队列、交换机、绑定关系、查看队列、交换机、绑定关系等。 rabbitmqadmin 是一个使用 HTTP API 的命令行工具，所以底层实际上是调用了 HTTP API 。 下载地址 12345678910111213# 下载sudo wget -O /usr/local/bin/rabbitmqadmin https://github.com/rabbitmq/rabbitmqadmin-ng/releases/download/v2.10.0/rabbitmqadmin-2.10.0-x86_64-unknown-linux-gnu# 设置权限sudo chmod +x /usr/local/bin/rabbitmqadmin# 查看帮助rabbitmqadmin help# 查看子命令帮助rabbitmqadmin help &lt;command&gt;## 示例# 查看 队列 帮助rabbitmqadmin help queues# 查看 队列声明 帮助，子子命令rabbitmqadmin help queues declare rabbitmqadmin 的功能非常强大，但是因为HTTP API故意没有公开某些操作，所以其不能替代 rabbitmqctl 或 rabbitmq-plugins等命令。 因为实际使用中很少直接通过命令行，所以这里只做简单介绍。上文提到了 rabbitmqctl 不支持声明(创建) 交换机和队列，这个通过 rabbitmqadmin 实现 12345678# 创建虚拟主机rabbitmqadmin vhosts declare --name &quot;my-vhost&quot; --default-queue-type &quot;quorum&quot; --description &quot;Used to test&quot;# 声明队列rabbitmqadmin queues declare --vhost &quot;my-vhost&quot; --name &quot;target.classic.queue.name&quot; --type &quot;classic&quot; --durable true --auto-delete false# 声明交换机rabbitmqadmin exchanges declare --vhost &quot;my-vhost&quot; --name &quot;target.direct.exchange.name&quot; --type &quot;direct&quot; --durable true --auto-delete false# 绑定队列和交换机rabbitmqadmin bindings declare --vhost &quot;my-vhost&quot; --source &quot;target.direct.exchange.name&quot; --destination &quot;target.classic.queue.name&quot; --destination-type &quot;queue&quot; --routing-key &quot;target.routing.key&quot; 还有就是定期备份 RabbitMQ 的结构数据(不包括消息) 1234# 导出abbitmqadmin definitions export --file backup.json# 导入rabbitmqadmin definitions import --file backup.json RabbitMQ 需要开放哪些端口 端口号 协议 用途说明 默认状态 安全建议 5672 AMQP 主客户端连接端口 开放 必须开放，限制IP 5671 AMQP/SSL TLS加密连接端口 关闭 如使用TLS则开放 15672 HTTP 管理界面端口 关闭 建议内网访问 15671 HTTPS TLS管理界面端口 关闭 如使用HTTPS则开放 25672 Erlang Distribution 集群节点通信 开放 集群内部使用 35672-35682 Erlang Distribution 集群节点发现 开放 集群内部使用 5552 Stream Protocol 流协议端口,RabbitMQ 3.9+ 关闭 使用流功能时开放 5551 Stream Protocol/SSL 流协议TLS端口,RabbitMQ 3.9+ 关闭 如使用TLS则开放 61613 STOMP STOMP协议支持端口 关闭 如使用STOMP协议则开放 61614 STOMP/SSL STOMP TLS加密端口 关闭 如使用STOMP over TLS则开放 1883 MQTT MQTT协议支持端口 关闭 如使用MQTT协议则开放 8883 MQTT/SSL MQTT TLS加密端口 关闭 如使用MQTT over TLS则开放 15674 Web STOMP WebSocket STOMP支持端口 关闭 如使用Web STOMP则开放 15675 Web MQTT WebSocket MQTT支持端口 关闭 如使用Web MQTT则开放","summary":"摘要 本文介绍 CentOS9 中 RabbitMQ 的安装与使用。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-18T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/","url":"https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/","title":"Zookeeper 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Zookeeper 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://zookeeper.apache.org\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Zookeeper 版本为 3.8.4。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Zookeeper-简介\">Zookeeper 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 是一个集中式服务，用于：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>ZooKeeper 官方功能</th>\n<th>主要节点类型</th>\n<th>具体场景示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>配置中心 (Config Center)</td>\n<td>维护配置信息 (Configuration Management)</td>\n<td>持久节点（Persistent）</td>\n<td>把数据库连接信息、系统参数等放在 ZooKeeper 里，动态更新，像 Apollo、Spring Cloud Config 一样。</td>\n</tr>\n<tr>\n<td>注册中心 (Service Registry)</td>\n<td>提供命名服务 (Naming Service)</td>\n<td>临时节点（Ephemeral）</td>\n<td>服务实例启动时在 ZooKeeper 里注册自己的地址，客户端从 ZooKeeper 获取服务列表，类似于 Nacos、Eureka。</td>\n</tr>\n<tr>\n<td>分布式锁 (Distributed Lock)</td>\n<td>分布式同步 (Distributed Synchronization)</td>\n<td>临时顺序节点（Ephemeral Sequential）</td>\n<td>用临时顺序节点实现分布式锁，保证只有一个实例在执行关键任务，典型应用是分布式定时任务调度。</td>\n</tr>\n<tr>\n<td>消息队列 (Message Queue)</td>\n<td>集群管理服务 (Cluster Management)</td>\n<td>持久/临时节点 + Watch 机制</td>\n<td>通过 Watch 机制监听 ZNode 变化，节点间用数据变更当“信号”传递消息，早期 Kafka 用过这种方式。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。</p>\n</li>\n<li class=\"lvl-2\">\n<p>不同于文件系统，每个节点都可以保存数据，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识，每个节点都有一个版本(version)，版本从0开始计数。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QgdBSR.png\" alt=\"\"></p>\n</li>\n</ul>\n<h2 id=\"Zookeeper-安装\">Zookeeper 安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>运行 Zookeeper 需要安装 JDK1.8+。我这里使用 <a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">OpenJDK11</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mkdir</span> -p /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">ln</span> -s jdk-11.0.28+6 jdk11</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\">vim /etc/profile <span class=\"comment\"># 添加如下内容</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> JAVA_HOME=/usr/local/jdk/jdk11</span><br><span class=\"line\">  <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 立即生效</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看java版本</span></span><br><span class=\"line\">java -version</span><br><span class=\"line\">openjdk version <span class=\"string\">&quot;11.0.28&quot;</span> 2025-07-15</span><br><span class=\"line\">OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)</span><br><span class=\"line\">OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode)</span><br></pre></td></tr></table></figure>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://zookeeper.apache.org/releases.html\">下载 Zookeeper</a>，目前最新的稳定版本为 <code>3.8.4</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载</span></span><br><span class=\"line\">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class=\"line\"><span class=\"comment\"># 解压</span></span><br><span class=\"line\">tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class=\"line\"><span class=\"comment\"># 配置个软连接，方便以后升级</span></span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s apache-zookeeper-3.8.4-bin zookeeper</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改配置文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> zookeeper/conf</span><br><span class=\"line\"><span class=\"built_in\">cp</span> zoo_sample.cfg zoo.cfg</span><br><span class=\"line\"><span class=\"comment\"># 建议修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改为指定的data目录</span></span><br><span class=\"line\">vim zoo.cfg</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>zoo.cfg 参数说明</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>说明</th>\n<th>默认值</th>\n<th>单位 / 备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>tickTime</strong></td>\n<td>ZooKeeper 时间配置中的基本单位</td>\n<td>2000</td>\n<td>毫秒</td>\n</tr>\n<tr>\n<td><strong>initLimit</strong></td>\n<td>follower 初始化连接到 leader 的最大时长，单位为 tickTime 倍数</td>\n<td>10</td>\n<td>10 × tickTime = 20000 ms</td>\n</tr>\n<tr>\n<td><strong>syncLimit</strong></td>\n<td>follower 与 leader 数据同步的最大时长，单位为 tickTime 倍数</td>\n<td>5</td>\n<td>5 × tickTime = 10000 ms</td>\n</tr>\n<tr>\n<td><strong>dataDir</strong></td>\n<td>数据和日志存储目录（未指定 dataLogDir 时，日志也会保存在此目录）</td>\n<td>/tmp/zookeeper</td>\n<td>目录路径</td>\n</tr>\n<tr>\n<td><strong>clientPort</strong></td>\n<td>客户端连接 ZooKeeper 的端口号</td>\n<td>2181</td>\n<td>默认 2181</td>\n</tr>\n<tr>\n<td><strong>maxClientCnxns</strong></td>\n<td>单个客户端最大并发连接数</td>\n<td>60</td>\n<td>超过限制后新连接会被拒绝</td>\n</tr>\n<tr>\n<td><strong>autopurge.snapRetainCount</strong></td>\n<td>快照文件保留个数，超过数量的将会被清理</td>\n<td>3</td>\n<td>默认 3</td>\n</tr>\n<tr>\n<td><strong>autopurge.purgeInterval</strong></td>\n<td>清理任务执行间隔时间，单位小时，0 表示不自动清理</td>\n<td>1</td>\n<td>1 小时</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 zookeeper</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> zookeeper</span><br><span class=\"line\"><span class=\"comment\"># 启动</span></span><br><span class=\"line\">bin/zkServer.sh start</span><br><span class=\"line\"><span class=\"comment\"># 指定配置文件</span></span><br><span class=\"line\">bin/zkServer.sh start conf/zoo.cfg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止</span></span><br><span class=\"line\">bin/zkServer.sh stop</span><br><span class=\"line\"><span class=\"comment\"># 查看状态</span></span><br><span class=\"line\">bin/zkServer.sh status</span><br><span class=\"line\"><span class=\"comment\"># 查看版本</span></span><br><span class=\"line\">./bin/zkServer.sh version</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装\">集群安装</h3>\n<h4 id=\"ZooKeeper-集群角色\">ZooKeeper 集群角色</h4>\n<h5 id=\"1-Leader（领导者）\">1. Leader（领导者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性；</li>\n<li class=\"lvl-4\">集群内部各个服务器的调度者；</li>\n<li class=\"lvl-4\">对于 <code>create</code>、<code>setData</code>、<code>delete</code> 等写操作请求，统一转发给 Leader 处理；</li>\n<li class=\"lvl-4\">Leader 负责决定编号、执行操作，这个过程称为 <strong>事务</strong>。</li>\n</ul>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>三台虚拟机 zoo.cfg 文件末尾添加配置，启动时会自动选举出 Leader 角色，则其余就是 Follower 角色。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.1=10.250.0.229:2888:3888</span><br><span class=\"line\">server.2=10.250.0.152:2888:3888</span><br><span class=\"line\">server.3=10.250.0.36:2888:3888</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-Follower（跟随者）\">2. Follower（跟随者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">处理客户端非事务（读操作）请求（可以直接响应）；</li>\n<li class=\"lvl-4\">转发事务请求给 Leader；</li>\n<li class=\"lvl-4\">参与集群 Leader 选举投票。</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>leader节点可以处理读写请求，follower只可以处理读请求。follower在接到写请求时会把写请求转发给leader来处理。</p>\n</blockquote>\n<h5 id=\"3-Observer（观察者）\">3. Observer（观察者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">对于非事务请求（读操作）可以独立处理；</li>\n<li class=\"lvl-4\">对于事务请求会转发给 Leader 处理；</li>\n<li class=\"lvl-4\">接收来自 Leader 的 <code>inform</code> 信息，更新本地存储；</li>\n<li class=\"lvl-4\">不参与提交和选举投票；</li>\n<li class=\"lvl-4\">通常用于 <strong>提升集群非事务处理能力</strong>，不影响集群事务处理性能。</li>\n</ul>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置一个 ID 为 4 的观察者节点：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群搭建\">集群搭建</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>环境准备：4台服务器，按照 <code>单机安装</code> 的方式准备好 Zookeeper 环境</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.229</span><br><span class=\"line\">10.250.0.152</span><br><span class=\"line\">10.250.0.36</span><br><span class=\"line\">10.250.0.56</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>zoo.cfg</code> 文件末尾添加配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.1=10.250.0.229:2888:3888</span><br><span class=\"line\">server.2=10.250.0.152:2888:3888</span><br><span class=\"line\">server.3=10.250.0.36:2888:3888</span><br><span class=\"line\">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别在 <code>dataDir</code> 目录下创建 <code>myid</code> 文件，在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格）</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 注意 节点编号不能重复，而且要与 zoo.cfg 文件中的 server.id 一致</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; myid</span><br><span class=\"line\"><span class=\"comment\"># echo 2 &gt; myid</span></span><br><span class=\"line\"><span class=\"comment\"># echo 3 &gt; myid</span></span><br><span class=\"line\"><span class=\"comment\"># echo 4 &gt; myid</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别启动 Zookeeper 服务器</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别启动4个节点的zookeeper server</span></span><br><span class=\"line\">bin/zkServer.sh start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看状态，可以看到节点角色类型</span></span><br><span class=\"line\">bin/zkServer.sh status</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群最少节点要求和扩容规则\">集群最少节点要求和扩容规则</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 使用 多数派（quorum）机制 来保证数据一致性</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1.集群总节点数 N</span><br><span class=\"line\">2.容忍的宕机节点数 F = (N-1)/2（向下取整）</span><br><span class=\"line\">3.要保证集群可用，需要 大于 N/2 的节点存活</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群扩容规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1.节点总数必须是奇数</span><br><span class=\"line\">  奇数节点可以保证多数派投票机制正常</span><br><span class=\"line\">  偶数节点不推荐，容错能力不增加（比如 4 台，仍然只容忍 1 台宕机）</span><br><span class=\"line\"></span><br><span class=\"line\">2.每次扩容建议 +2 节点</span><br><span class=\"line\">  这样既保持奇数，又增加 quorum 容错能力</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>最少节点与容错能力表格</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>集群总节点数 N</th>\n<th>容忍宕机数 F</th>\n<th>可用 quorum 节点数</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>不推荐，无法容忍故障</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0</td>\n<td>2</td>\n<td>不推荐，1 台宕机就不可用</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n<td>最小可用生产集群</td>\n</tr>\n<tr>\n<td>5</td>\n<td>2</td>\n<td>3</td>\n<td>推荐生产集群规模</td>\n</tr>\n<tr>\n<td>7</td>\n<td>3</td>\n<td>4</td>\n<td>高可用大集群</td>\n</tr>\n<tr>\n<td>9</td>\n<td>4</td>\n<td>5</td>\n<td>更大集群，高容错</td>\n</tr>\n<tr>\n<td>11</td>\n<td>5</td>\n<td>6</td>\n<td>极高可用场景</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"ZooKeeper-默认端口说明\">ZooKeeper 默认端口说明</h2>\n<table>\n<thead>\n<tr>\n<th>端口</th>\n<th>用途</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2181</td>\n<td>客户端连接端口</td>\n<td>客户端通过这个端口访问 ZooKeeper</td>\n</tr>\n<tr>\n<td>2888</td>\n<td>集群内部通信</td>\n<td>follower 与 leader 之间同步数据</td>\n</tr>\n<tr>\n<td>3888</td>\n<td>leader 选举端口</td>\n<td>集群选举 leader 使用</td>\n</tr>\n<tr>\n<td>8080 (可选)</td>\n<td>admin/metrics web端口</td>\n<td>如果开启了 adminServer</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 永久开启端口</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=2181/tcp</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=2888/tcp</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=3888/tcp</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 adminServer</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=8080/tcp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新加载防火墙配置</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --reload</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看是否开放成功</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --list-all</span><br></pre></td></tr></table></figure>\n<h2 id=\"客户端连接\">客户端连接</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认连接 127.0.0.1:2181</span></span><br><span class=\"line\">bin/zkCli.sh</span><br><span class=\"line\"><span class=\"comment\"># 指定 -server ip:port，如果是集群，则连接任意一个节点，ZooKeeper 会自动处理与 Leader/Follower 的交互</span></span><br><span class=\"line\">bin/zkCli.sh -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>客户端命令简介：<a href=\"https://zookeeper.apache.org/doc/r3.8.4/zookeeperCLI.html\">参考官网</a></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>语法示例</th>\n<th>功能描述</th>\n<th>常用参数及说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>help</strong></td>\n<td><code>help</code></td>\n<td>显示所有操作命令</td>\n<td>无</td>\n<td><code>help</code></td>\n</tr>\n<tr>\n<td><strong>version</strong></td>\n<td><code>version</code></td>\n<td>查看客户端和服务器版本信息</td>\n<td>无</td>\n<td><code>version</code></td>\n</tr>\n<tr>\n<td><strong>connect</strong></td>\n<td><code>connect host:port</code></td>\n<td>连接到指定 ZooKeeper 服务器</td>\n<td><code>host:port</code>: 服务器地址</td>\n<td><code>connect 127.0.0.1:2181</code></td>\n</tr>\n<tr>\n<td><strong>close</strong></td>\n<td><code>close</code></td>\n<td>关闭当前会话 ,通过 <code>connect</code> 可重连</td>\n<td>无</td>\n<td><code>close</code></td>\n</tr>\n<tr>\n<td><strong>quit</strong></td>\n<td><code>quit</code></td>\n<td>退出客户端</td>\n<td>无</td>\n<td><code>quit</code></td>\n</tr>\n<tr>\n<td><strong>ls</strong></td>\n<td><code>ls [-s] [-w] [-R] path</code></td>\n<td>查看节点的子节点</td>\n<td>- <code>-w</code>: 监听子节点变化<br>- <code>-s</code>: 显示节点状态信息<br>- <code>-R</code>: 递归查看</td>\n<td><code>ls -s -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getAllChildrenNumber</strong></td>\n<td><code>getAllChildrenNumber path</code></td>\n<td>获取某节点所有子节点的总数</td>\n<td>无</td>\n<td><code>getAllChildrenNumber /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getEphemerals</strong></td>\n<td><code>getEphemerals path</code></td>\n<td>获取某路径下所有临时节点</td>\n<td>无</td>\n<td><code>getEphemerals /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>create</strong></td>\n<td><code>create [-s] [-e] [-c] [-t ttl] path [data] [acl]</code></td>\n<td>创建节点</td>\n<td>- <code>-s</code>: 顺序节点<br>- <code>-e</code>: 临时节点<br>- <code>-c</code>: 容器节点<br>- <code>-t ttl</code>: TTL节点，单位毫秒</td>\n<td><code>create -e /zk_test_ephemeral &quot;temp_data&quot;</code></td>\n</tr>\n<tr>\n<td><strong>get</strong></td>\n<td><code>get [-s] [-w] path</code></td>\n<td>获取节点数据信息</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-w</code>: 监听节点变化</td>\n<td><code>get -s -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>set</strong></td>\n<td><code>set [-s] [-v version] path data</code></td>\n<td>设置节点数据</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号</td>\n<td><code>set /zk_test &quot;new_data&quot;</code></td>\n</tr>\n<tr>\n<td><strong>stat</strong></td>\n<td><code>stat [-w] path</code></td>\n<td>查看节点状态信息</td>\n<td>- <code>-w</code>: 监听节点变化</td>\n<td><code>stat -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>sync</strong></td>\n<td><code>sync path</code></td>\n<td>同步指定节点数据</td>\n<td>无</td>\n<td><code>sync /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>delete</strong></td>\n<td><code>delete [-v version] path</code></td>\n<td>删除某一节点（无子节点）</td>\n<td>- <code>-v</code>: 节点版本号</td>\n<td><code>delete /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>deleteall</strong></td>\n<td><code>deleteall path</code></td>\n<td>递归删除某一节点及其子节点</td>\n<td>无</td>\n<td><code>deleteall /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getAcl</strong></td>\n<td><code>getAcl [-s] path</code></td>\n<td>获取节点访问控制信息</td>\n<td>- <code>-s</code>: 显示节点状态信息</td>\n<td><code>getAcl /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>setAcl</strong></td>\n<td><code>setAcl [-s] [-v version] [-R] path acl</code></td>\n<td>设置节点访问控制列表</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号<br>- <code>-R</code>: 递归设置</td>\n<td><code>setAcl /zk_test world:anyone:r</code></td>\n</tr>\n<tr>\n<td><strong>listquota</strong></td>\n<td><code>listquota path</code></td>\n<td>查看节点配额信息</td>\n<td>无</td>\n<td><code>listquota /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>setquota</strong></td>\n<td><code>setquota [-n] [-b] val path</code></td>\n<td>对节点增加限制</td>\n<td>- <code>-n</code>: 子节点最大个数<br>- <code>-b</code>: 数据值最大长度，-1 表示无限制</td>\n<td><code>setquota -n 5 /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>delquota</strong></td>\n<td><code>delquota [-n                                    | -b] path</code></td>\n<td>删除节点配额限制</td>\n<td>- <code>-n</code>: 删除子节点数限制<br>- <code>-b</code>: 删除数据值大小限制</td>\n<td><code>delquota -n /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>config</strong></td>\n<td><code>config</code></td>\n<td>查看服务器配置</td>\n<td>无</td>\n<td><code>config</code></td>\n</tr>\n<tr>\n<td><strong>whoami</strong></td>\n<td><code>whoami</code></td>\n<td>查看当前会话身份</td>\n<td>无</td>\n<td><code>whoami</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>GUI 工具</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>类型 / 运行方式</th>\n<th>优点</th>\n<th>注意事项</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>PrettyZoo</strong></td>\n<td>桌面应用（JavaFX）(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n<td>支持 Mac/Windows/Linux，界面友好；支持节点创建/删除/更新/查询，ACL 管理，多 ZK 实例管理，SSH 隧道等功能。(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n<td>项目已经 archived，维护可能不活跃。最新版可能在兼容性或 Bug 修复方面不如活跃项目。也可能需要自己构建或调试。(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n</tr>\n<tr>\n<td><strong>ZooNavigator</strong></td>\n<td>Web 界面 + 可 Docker 部署或本地启动(<a href=\"https://github.com/elkozmon/zoonavigator\" title=\"elkozmon/zoonavigator: Web-based ZooKeeper UI\">GitHub</a>)</td>\n<td>功能丰富；支持多个 Zookeeper 版本（如 3.5.x ～ 3.9.x）；浏览 / 编辑 /搜索节点；导入导出配置；支持浏览器访问，无需本地 heavy GUI。(<a href=\"https://github.com/elkozmon/zoonavigator\" title=\"elkozmon/zoonavigator: Web-based ZooKeeper UI\">GitHub</a>)</td>\n<td>因为 Web 应用，可能对浏览器安全策略与网络延迟敏感；需要部署自己版本或 Docker；如果要求本地脱机操作时，有些功能可能稍不如桌面应用。</td>\n</tr>\n<tr>\n<td><strong>ZooKeeper Assistant</strong></td>\n<td>桌面／管理员面板类型（支持监控界面等）(<a href=\"https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo\" title=\"An exciting Apache ZooKeeper Desktop GUI\">DEV Community</a>)</td>\n<td>除了浏览节点树以外，还提供健康状态监控（延迟、请求数等）、不同数据格式支持（JSON/XML 等）、导入/导出节点数据、命令行操作集成。(<a href=\"https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo\" title=\"An exciting Apache ZooKeeper Desktop GUI\">DEV Community</a>)</td>\n<td>有些功能可能在 Mac 上兼容性或视觉体验需要调试；具体版本支持情况要看最近更新。某些监控界面可能依赖于 ZK 的指标或插件。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Zookeeper-节点类型\">Zookeeper 节点类型</h2>\n<table>\n<thead>\n<tr>\n<th>节点类型</th>\n<th>生命周期说明</th>\n<th>创建命令示例</th>\n<th>特点说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>持久节点</strong> (Persistent)</td>\n<td>节点一直存在，除非手动删除，即使客户端会话关闭，节点也不会消失</td>\n<td><code>create /locks</code></td>\n<td>适合存储配置信息、元数据等持久数据</td>\n</tr>\n<tr>\n<td><strong>临时节点</strong> (Ephemeral)</td>\n<td>客户端会话关闭（异常或超时）时，节点自动被删除</td>\n<td><code>create -e /locks/DBLock</code></td>\n<td>常用于分布式锁、临时会话数据</td>\n</tr>\n<tr>\n<td><strong>有序节点</strong> (Sequential)</td>\n<td>在持久或临时节点基础上，增加有序编号，ZooKeeper 自动在节点名后加递增序号</td>\n<td><code>create -e -s /jobs/job</code></td>\n<td>常用于分布式锁、队列等需要顺序的场景</td>\n</tr>\n<tr>\n<td><strong>容器节点</strong> (Container)</td>\n<td>V3.5.3+，当容器节点下的最后一个子节点被删除后，容器节点也会自动删除</td>\n<td><code>create -c /work</code></td>\n<td>适合分布式任务临时目录、动态数据目录</td>\n</tr>\n<tr>\n<td><strong>TTL 节点</strong> (TTL)</td>\n<td>在指定 TTL 时间内未修改且无子节点，节点会被自动删除（需开启 <code>extendedTypesEnabled=true</code> 配置）</td>\n<td><code>create -t 3000 /ttl_node</code></td>\n<td>适合临时缓存、临时状态数据，过期自动清理</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注意</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">同一级节点 key 名称是唯一的</li>\n<li class=\"lvl-4\">创建节点时，必须要带上全路径</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>节点状态信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 16] <span class=\"built_in\">stat</span> /test</span><br><span class=\"line\">cZxid = 0x100000002                   <span class=\"comment\"># Znode创建的事务id</span></span><br><span class=\"line\">ctime = Mon Sep 15 09:44:51 UTC 2025  <span class=\"comment\"># 创建时间</span></span><br><span class=\"line\">mZxid = 0x100000004                   <span class=\"comment\"># 最后一次修改事务id</span></span><br><span class=\"line\">mtime = Mon Sep 15 09:47:12 UTC 2025  <span class=\"comment\"># 最后一次修改时间</span></span><br><span class=\"line\">pZxid = 0x400000004                   <span class=\"comment\"># 表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID（注意: 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）</span></span><br><span class=\"line\">cversion = 1                          <span class=\"comment\"># 子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。</span></span><br><span class=\"line\">dataVersion = 1                       <span class=\"comment\"># znode的数据版本号。每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据），可有效避免了数据更新时出现的先后顺序问题</span></span><br><span class=\"line\">aclVersion = 0                        <span class=\"comment\"># znode的ACL版本号。每次对节点进行ACL设置，aclVersion的值都会增加1</span></span><br><span class=\"line\">ephemeralOwner = 0x0                  <span class=\"comment\"># 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id。如果不是, ephemeralOwner值为0(持久节点)。</span></span><br><span class=\"line\">dataLength = 3                        <span class=\"comment\"># znode的数据长度</span></span><br><span class=\"line\">numChildren = 1                       <span class=\"comment\"># znode的子节点数量（只统计直接子节点的数量）</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Zookeeper-监听机制\">Zookeeper 监听机制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>watch机制，顾名思义是一个监听机制。Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发生时才会触发监听，通知给客户端。</p>\n</li>\n<li class=\"lvl-2\">\n<p>监听的对象是事件，支持的事件类型如下：</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- None: 连接建立事件</span><br><span class=\"line\">- NodeCreated： 节点创建</span><br><span class=\"line\">- NodeDeleted： 节点删除</span><br><span class=\"line\">- NodeDataChanged：节点数据变化</span><br><span class=\"line\">- NodeChildrenChanged：子节点列表变化</span><br><span class=\"line\">- DataWatchRemoved：节点监听被移除</span><br><span class=\"line\">- ChildWatchRemoved：子节点监听被移除</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>监听特性</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>一次性触发</strong></td>\n<td>Watch 是一次性的，一旦被触发就会被移除。再次使用时需要重新注册。</td>\n</tr>\n<tr>\n<td><strong>客户端顺序回调</strong></td>\n<td>Watch 回调是顺序串行执行的，客户端只有在回调完成后才能看到最新的数据状态。</td>\n</tr>\n<tr>\n<td><strong>轻量级</strong></td>\n<td>Watcher 回调逻辑不应过多，以免阻塞或影响其他 Watch 的执行。</td>\n</tr>\n<tr>\n<td><strong>最小通信单位</strong></td>\n<td><code>WatchEvent</code> 是最小的通信单位，只包含通知状态、事件类型和节点路径，不包含节点数据变化前后的具体内容。</td>\n</tr>\n<tr>\n<td><strong>时效性</strong></td>\n<td>Watcher 仅在当前 Session 完全失效时才无效。如果 Session 快速重连成功，Watcher 依然有效，可继续接收通知。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>可以开启监听的命令</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#监听节点数据的变化</span></span><br><span class=\"line\">get -w path</span><br><span class=\"line\"><span class=\"built_in\">stat</span> -w path</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#监听子节点增减的变化</span></span><br><span class=\"line\"><span class=\"built_in\">ls</span> -w path</span><br></pre></td></tr></table></figure>\n<h3 id=\"永久性-Watch\">永久性 Watch</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在被触发之后，仍然保留，可以继续监听ZNode上的变更，是Zookeeper 3.6.0版本新增的功能</p>\n</li>\n<li class=\"lvl-2\">\n<p>创建监听</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addWatch [-m mode] path</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mode:</span></span><br><span class=\"line\"><span class=\"comment\"># - PERSISTENT: 持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。</span></span><br><span class=\"line\"><span class=\"comment\"># - PERSISTENT_RECURSIVE: 持久化递归订阅(这个是默认值)，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性）</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除监听</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 普通一次性 Watch 不需要手动删除，触发后会自动移除；removewatches 主要用于持久 Watch（persistent watch）。</span></span><br><span class=\"line\">removewatches path [-c|-d|-a] [-l]</span><br><span class=\"line\"><span class=\"comment\"># -c: 仅删除当前客户端的 Watch</span></span><br><span class=\"line\"><span class=\"comment\"># -d: 删除指定节点的所有 Watch(包括其他客户端注册的)</span></span><br><span class=\"line\"><span class=\"comment\"># -a: 删除所有节点的所有 Watch（包括其他客户端的 Watch），慎用！！！</span></span><br><span class=\"line\"><span class=\"comment\"># -l: 显示被删除的 Watch 列表</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"监听器应用场景\">监听器应用场景</h3>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>特点</th>\n<th>应用场景举例</th>\n<th>适合的节点类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>临时监听</strong>（一次性 Watch）</td>\n<td>- 触发一次后自动移除<br>- 客户端需手动重新注册<br>- 轻量级，适合单次通知</td>\n<td>1. <strong>配置中心</strong>：配置变化时通知客户端，客户端收到通知后重新拉取最新配置 <br> 2. <strong>分布式锁</strong>：节点删除（锁释放）后通知等待的客户端重新竞争锁 <br> 3. <strong>主从选举</strong>：主节点宕机后，其他节点收到通知重新选主</td>\n<td><strong>持久节点</strong>（Persistent） <br><strong>临时节点</strong>（Ephemeral，用于锁和选主）</td>\n</tr>\n<tr>\n<td><strong>永久监听</strong>（Persistent Watch）</td>\n<td>- 注册后持续有效，直到客户端主动移除<br>- 支持子节点变化、数据变化的长期监听</td>\n<td>1. <strong>服务发现</strong>：客户端长期监听服务节点变化，节点上线/下线时自动更新本地服务列表 <br> 2. <strong>监控告警</strong>：监控重要节点状态，节点数据变化或被删除时自动触发告警 <br> 3. <strong>分布式缓存</strong>：缓存节点变化时，通知客户端刷新缓存</td>\n<td><strong>持久节点</strong>（Persistent）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"ACL权限控制\">ACL权限控制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 默认情况下，所有节点的权限都是 <code>OPEN_ACL_UNSAFE</code> ，任何客户端都可以读写任意节点数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>生产环境中，通常需要限制对节点的访问权限，即 <code>ACL</code> 权限控制。</p>\n</li>\n<li class=\"lvl-2\">\n<p>ZooKeeper 里的 ACL（Access Control List，访问控制列表） 主要用于控制 谁可以对某个节点做什么操作，它是 ZooKeeper 提供的安全机制之一。</p>\n</li>\n</ul>\n<h3 id=\"ACL-的作用\">ACL 的作用</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>限制访问：只允许授权用户或客户端对指定节点进行读、写、删除等操作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>防止误操作：保护重要节点不被未授权的客户端修改或删除。</p>\n</li>\n<li class=\"lvl-2\">\n<p>安全隔离：不同的应用或团队可以在同一 ZooKeeper 集群里安全共存。</p>\n</li>\n</ul>\n<h3 id=\"ACL-的组成\">ACL 的组成</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>zookeeper 的 acl 通过 <code>scheme:id:permissions</code> 来构成权限列表。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">scheme：授权的模式，代表采用的某种权限机制，包括 world、auth、digest、ip、super 几种。</li>\n<li class=\"lvl-4\">id：授权对象，代表允许访问的用户。如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。</li>\n<li class=\"lvl-4\">permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限， 创建权限 create©、删除权限 delete(d)、读权限 read®、写权限 write(w)、管理权限admin(a)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见的-scheme-类型\">常见的 scheme 类型</h3>\n<table>\n<thead>\n<tr>\n<th>Scheme</th>\n<th>说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>world</code></td>\n<td>开放给所有用户，仅可设置为 <code>anyone</code> 代表所有客户端</td>\n<td><code>world:anyone:r</code></td>\n</tr>\n<tr>\n<td><code>auth</code></td>\n<td>已通过 <code>addauth</code> 添加认证的客户端</td>\n<td><code>auth:user1:rw</code></td>\n</tr>\n<tr>\n<td><code>digest</code></td>\n<td>用户名+密码认证（常用），<code>user:pwd</code> 需要加密存储</td>\n<td><code>digest:user1:password:rw</code></td>\n</tr>\n<tr>\n<td><code>ip</code></td>\n<td>基于 IP 地址控制访问</td>\n<td><code>ip:192.168.1.10:r</code></td>\n</tr>\n<tr>\n<td><code>super</code></td>\n<td>超级用户，拥有所有权限</td>\n<td><code>super:admin:secret</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"权限类型\">权限类型</h3>\n<table>\n<thead>\n<tr>\n<th>权限字符</th>\n<th>权限名称</th>\n<th>允许的操作/命令示例</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>r</code></strong></td>\n<td>读取(Read)</td>\n<td><code>get /node</code> <br> <code>ls /node</code> <br> <code>getAcl /node</code></td>\n<td>允许读取节点数据和子节点列表</td>\n</tr>\n<tr>\n<td><strong><code>w</code></strong></td>\n<td>写入(Write)</td>\n<td><code>set /node data</code></td>\n<td>允许修改节点数据</td>\n</tr>\n<tr>\n<td><strong><code>c</code></strong></td>\n<td>创建(Create)</td>\n<td><code>create /node/sub &quot;data&quot;</code></td>\n<td>允许在当前节点下创建子节点</td>\n</tr>\n<tr>\n<td><strong><code>d</code></strong></td>\n<td>删除(Delete)</td>\n<td><code>delete /node/sub</code></td>\n<td>允许删除当前节点的子节点</td>\n</tr>\n<tr>\n<td><strong><code>a</code></strong></td>\n<td>管理(Admin)</td>\n<td><code>setAcl /node acl</code></td>\n<td>允许修改 ACL 权限</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"典型应用场景\">典型应用场景</h3>\n<table>\n<thead>\n<tr>\n<th>认证方式（scheme）</th>\n<th>权限类型（permissions）</th>\n<th>典型 ACL 配置示例</th>\n<th>应用场景</th>\n<th>特点说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>world</strong></td>\n<td><code>r</code>（只读）</td>\n<td><code>world:anyone:r</code></td>\n<td>公共配置节点，所有客户端都可读取</td>\n<td>简单、无认证，适合对安全性要求不高的只读场景</td>\n</tr>\n<tr>\n<td><strong>auth</strong></td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>auth:user:rwcd</code></td>\n<td>内部应用共享节点，需客户端认证</td>\n<td>需先 <code>addauth digest user1:password</code> 添加认证，适合多客户端共享</td>\n</tr>\n<tr>\n<td><strong>digest</strong>（常用）</td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>digest:user:secret:crwda</code></td>\n<td>高安全节点，配置中心，分布式锁</td>\n<td>用户名+密码认证，需加密存储密码，灵活安全</td>\n</tr>\n<tr>\n<td><strong>ip</strong></td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>ip:192.168.1.100:r</code></td>\n<td>基于 IP 限制访问的场景</td>\n<td>快速控制某些固定 IP 可访问，适合内部网络应用</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"ACL-相关命令\">ACL 相关命令</h3>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>语法</th>\n<th>功能说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>getAcl</strong></td>\n<td><code>getAcl path</code></td>\n<td>读取指定节点的 ACL</td>\n<td><code>getAcl /my_node</code></td>\n</tr>\n<tr>\n<td><strong>setAcl</strong></td>\n<td><code>setAcl path acl</code></td>\n<td>设置指定节点的 ACL</td>\n<td><code>setAcl /my_node world:anyone:crdwa</code></td>\n</tr>\n<tr>\n<td><strong>create</strong></td>\n<td><code>create path data [acl]</code></td>\n<td>创建节点时指定 ACL</td>\n<td><code>create /secure_node &quot;secret_data&quot; digest:user1:pwd:crwa</code></td>\n</tr>\n<tr>\n<td><strong>addAuth</strong></td>\n<td><code>addauth scheme auth</code></td>\n<td>添加认证用户（类似登录）</td>\n<td><code>addauth digest user1:password</code></td>\n</tr>\n<tr>\n<td><strong>deleteAcl(不存在)</strong></td>\n<td><code>setAcl path world:anyone:</code></td>\n<td>删除节点 ACL（设为空或全开放）</td>\n<td><code>setAcl /my_node world:anyone:</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"auth-与-digest-的区别\"><code>auth</code> 与 <code>digest</code> 的区别</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用 <code>auth</code> 时，需先 <code>addauth digest user1:password</code> 添加认证，<code>setAcl</code> 时，使用 <code>auth:user1:rw</code>，这里是为已经登录的用户设置节点权限，所以不需要设置密码</p>\n</li>\n<li class=\"lvl-2\">\n<p>使用 <code>digest</code> 时，无需进行登录认证，所以需要指定密码，即<code>setAcl</code> 时，使用 <code>digest:user1:password:rw</code></p>\n</li>\n<li class=\"lvl-2\">\n<p><code>digest</code> 的密码是经过加密的，所以不能直接使用明文密码</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 加密密码</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -n user:123456 | openssl dgst -binary -sha1 | openssl <span class=\"built_in\">base64</span></span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">6DY5WhzOfGsWQ1XFuIyzxkpwdPo=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># zookeeper客户端中设置权限</span></span><br><span class=\"line\">setAcl /name digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:cdrwa</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 登录时密码是明文</span></span><br><span class=\"line\">addauth digest user:123456</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论使用 <code>digest</code> 还是 <code>auth</code>，在需要访问节点前，都需要先登录。</p>\n</li>\n</ul>\n<h3 id=\"super-超级管理员\"><code>super</code> 超级管理员</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>拥有全部节点的所有权限: <code>crwda</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>设置超级管理员</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 加密密码，用户和密码可以随意设置</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -n admin:123456 | openssl dgst -binary -sha1 | openssl <span class=\"built_in\">base64</span></span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打开 conf/zoo.cfg 文件并编辑，在文件中添加下面内容</span></span><br><span class=\"line\">DigestAuthenticationProvider.superDigest=admin:0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重新启动服务后登录客户端进行测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建节点并设置权限，这里将节点授权给用户user</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 10] create /testNode 666 digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:rw</span><br><span class=\"line\">Created /testNode</span><br><span class=\"line\"><span class=\"comment\"># 查看节点内容被拒绝</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 11] get /testNode</span><br><span class=\"line\">Insufficient permission : /testNode</span><br><span class=\"line\"><span class=\"comment\"># 登录super用户，验证超级用户是否有权限访问节点</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 12] addauth digest admin:123456</span><br><span class=\"line\"><span class=\"comment\"># 此时查看节点内容就可以了</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 13] get /testNode</span><br><span class=\"line\">666</span><br></pre></td></tr></table></figure>\n<h2 id=\"4字母命令\">4字母命令</h2>\n<h3 id=\"什么是-4-字母命令\">什么是 <code>4 字母命令</code>?</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 提供了一组简短的 <code>4个字母的管理命令</code>(Four Letter Words Commands, 4lw)，可以通过 TCP 连接 ZooKeeper 端口（默认 2181）发送这些命令，快速查看或管理 ZooKeeper 状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>常用的 <code>4字母命令</code></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>引入版本</th>\n<th>功能描述</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>conf</code></td>\n<td>3.3.0</td>\n<td>打印服务相关配置的详细信息</td>\n<td><code>echo conf | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>cons</code></td>\n<td>3.3.0</td>\n<td>列出所有连接到该服务器的客户端连接/会话详细信息，包括接收/发送的包数量、会话ID、操作延迟、最后操作执行时间等</td>\n<td><code>echo cons | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>crst</code></td>\n<td>3.3.0</td>\n<td>重置所有连接的连接和会话统计信息</td>\n<td><code>echo crst | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>dump</code></td>\n<td>-</td>\n<td>列出重要的会话和临时节点信息，仅在 Leader 节点上有效</td>\n<td><code>echo dump | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>envi</code></td>\n<td>-</td>\n<td>打印服务环境的详细信息</td>\n<td><code>echo envi | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>reqs</code></td>\n<td>-</td>\n<td>列出未经处理的请求</td>\n<td><code>echo reqs | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>ruok</code></td>\n<td>-</td>\n<td>测试服务是否处于正常状态；正常返回 <code>imok</code></td>\n<td><code>echo ruok | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>stat</code></td>\n<td>-</td>\n<td>输出关于性能和客户端连接的列表信息</td>\n<td><code>echo stat | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>srst</code></td>\n<td>-</td>\n<td>重置服务器统计信息</td>\n<td><code>echo srst | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>srvr</code></td>\n<td>3.3.0</td>\n<td>列出连接服务器的详细信息</td>\n<td><code>echo srvr | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchs</code></td>\n<td>3.3.0</td>\n<td>列出服务器 Watch 的详细信息</td>\n<td><code>echo wchs | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchc</code></td>\n<td>3.3.0</td>\n<td>通过会话列出服务器 Watch 的详细信息，输出与 Watch 相关的会话列表</td>\n<td><code>echo wchc | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchp</code></td>\n<td>3.3.0</td>\n<td>通过路径列出服务器 Watch 的详细信息，输出与会话相关的路径</td>\n<td><code>echo wchp | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>mntr</code></td>\n<td>3.4.0</td>\n<td>输出可用于检测集群健康状态的关键指标变量列表</td>\n<td><code>echo mntr | nc 127.0.0.1 2181</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"开启-4字母命令\">开启 <code>4字母命令</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 ZooKeeper 3.5.0 及之后的版本，4lw 命令默认是禁用的，必须在配置文件(zoo.cfg)中显式开启。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 表示允许所有 4lw 命令都能用（风险最大）</span></span><br><span class=\"line\">4lw.commands.whitelist=*</span><br><span class=\"line\"><span class=\"comment\"># 这样只允许执行 stat、conf、ruok 这几个命令。</span></span><br><span class=\"line\">4lw.commands.whitelist=<span class=\"built_in\">stat</span>,conf,ruok</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用方法</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 如果没有安装 nc，可以使用 yum 安装</span></span><br><span class=\"line\">yum install nc -y</span><br><span class=\"line\"><span class=\"comment\"># 查看节点状态</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"built_in\">stat</span> | nc 127.0.0.1 2181</span><br></pre></td></tr></table></figure>\n<h2 id=\"Zookeeper-Java-Client\">Zookeeper Java Client</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>项目示例：<a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/zookeeper-demo/\">Github地址</a>，单元测试。</p>\n</li>\n</ul>\n<h3 id=\"Zookeeper-官方Java客户端\">Zookeeper 官方Java客户端</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper官方的客户端API提供了基本的操作。例如，创建会话、创建节点、读取节点、更新数据、删除节点和检查节点是否存在等。不过，对于实际开发来说，ZooKeeper官方API有一些不足之处，具体如下：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">ZooKeeper的Watcher监测是一次性的，每次触发之后都需要重新进行注册。</li>\n<li class=\"lvl-4\">会话超时之后没有实现重连机制。</li>\n<li class=\"lvl-4\">异常处理烦琐，ZooKeeper提供了很多异常，对于开发人员来说可能根本不知道应该如何处理这些抛出的异常。</li>\n<li class=\"lvl-4\">仅提供了简单的byte[]数组类型的接口，没有提供Java POJO级别的序列化数据处理接口。</li>\n<li class=\"lvl-4\">创建节点时如果抛出异常，需要自行检查节点是否存在。</li>\n<li class=\"lvl-4\">无法实现级联删除。</li>\n<li class=\"lvl-4\">总之，ZooKeeper官方API功能比较简单，在实际开发过程中比较笨重，一般不推荐使用。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>项目引入依赖时，最好保持与服务端版本一致，否则可能会有一些兼容性的问题</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- zookeeper client --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.4<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Zookeeper-第三方Java客户端-Curator\">Zookeeper 第三方Java客户端 Curator</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://curator.apache.org/docs/about\">Curator</a>是Netflix公司开源的一套ZooKeeper客户端框架，和ZkClient一样它解决了非常底层的细节开发工作，包括连接、重连、反复注册Watcher的问题以及NodeExistsException异常等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Curator是Apache基金会的顶级项目之一，Curator具有更加完善的文档，另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Curator还为ZooKeeper客户端框架提供了一些比较普遍的、开箱即用的、分布式开发用的解决方案，例如Recipe、共享锁服务、Master选举机制和分布式计算器等，帮助开发者避免了“重复造轮子”的无效开发工作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在实际的开发场景中，使用Curator客户端就足以应付日常的ZooKeeper集群操作的需求。</p>\n</li>\n<li class=\"lvl-2\">\n<p>引入依赖说明：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>模块</th>\n<th>依赖关系</th>\n<th>功能定位</th>\n<th>典型功能举例</th>\n<th>常用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>curator-client</strong></td>\n<td>依赖 zookeeper</td>\n<td>连接管理、重试策略、底层 API</td>\n<td>连接会话管理、RetryPolicy</td>\n<td>需要最轻量的 ZooKeeper 客户端</td>\n</tr>\n<tr>\n<td><strong>curator-framework</strong></td>\n<td>依赖 curator-client</td>\n<td>高层 API 封装，简化 ZK 操作</td>\n<td>创建节点、Watcher 管理、自动重连</td>\n<td>通用 ZooKeeper 客户端开发</td>\n</tr>\n<tr>\n<td><strong>curator-recipes</strong></td>\n<td>依赖 curator-framework → curator-client</td>\n<td>分布式模式现成实现</td>\n<td>分布式锁、Leader 选举、队列、Barrier</td>\n<td>直接用分布式工具，无需自己实现</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>使用建议</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p>如果你只想轻量访问 ZooKeeper → <code>curator-client</code> 就够了，但几乎没人单独用。</p>\n</li>\n<li class=\"lvl-4\">\n<p>如果你想方便操作 ZooKeeper API → <code>curator-framework</code>，大部分情况都适用。</p>\n</li>\n<li class=\"lvl-4\">\n<p>如果你想用分布式锁、选举、Barrier → <code>curator-recipes</code>（它会自动引入前两个）。</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- zookeeper client --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.4<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!--curator--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.curator<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>curator-recipes<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.9.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">exclusions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">exclusion</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">exclusion</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">exclusions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 CentOS9 中 Zookeeper 的安装与使用。 Zookeeper官网 本文使用的 Zookeeper 版本为 3.8.4。 Zookeeper 简介 ZooKeeper 是一个集中式服务，用于： 场景 ZooKeeper 官方功能 主要节点类型 具体场景示例 配置中心 (Config Center) 维护配置信息 (Configuration Management) 持久节点（Persistent） 把数据库连接信息、系统参数等放在 ZooKeeper 里，动态更新，像 Apollo、Spring Cloud Config 一样。 注册中心 (Service Registry) 提供命名服务 (Naming Service) 临时节点（Ephemeral） 服务实例启动时在 ZooKeeper 里注册自己的地址，客户端从 ZooKeeper 获取服务列表，类似于 Nacos、Eureka。 分布式锁 (Distributed Lock) 分布式同步 (Distributed Synchronization) 临时顺序节点（Ephemeral Sequential） 用临时顺序节点实现分布式锁，保证只有一个实例在执行关键任务，典型应用是分布式定时任务调度。 消息队列 (Message Queue) 集群管理服务 (Cluster Management) 持久/临时节点 + Watch 机制 通过 Watch 机制监听 ZNode 变化，节点间用数据变更当“信号”传递消息，早期 Kafka 用过这种方式。 ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。 不同于文件系统，每个节点都可以保存数据，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识，每个节点都有一个版本(version)，版本从0开始计数。 Zookeeper 安装 运行 Zookeeper 需要安装 JDK1.8+。我这里使用 OpenJDK11 12345678910111213141516sudo mkdir -p /usr/local/jdkcd /usr/local/jdksudo wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzsudo tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzsudo ln -s jdk-11.0.28+6 jdk11# 配置环境变量vim /etc/profile # 添加如下内容 export JAVA_HOME=/usr/local/jdk/jdk11 export PATH=$JAVA_HOME/bin:$PATH# 立即生效source /etc/profile# 查看java版本java -versionopenjdk version &quot;11.0.28&quot; 2025-07-15OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode) 单机安装 下载 Zookeeper，目前最新的稳定版本为 3.8.4 123456# 下载wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz# 解压tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz# 配置个软连接，方便以后升级ln -s apache-zookeeper-3.8.4-bin zookeeper 修改配置文件 1234cd zookeeper/confcp zoo_sample.cfg zoo.cfg# 建议修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改为指定的data目录vim zoo.cfg zoo.cfg 参数说明 配置项 说明 默认值 单位 / 备注 tickTime ZooKeeper 时间配置中的基本单位 2000 毫秒 initLimit follower 初始化连接到 leader 的最大时长，单位为 tickTime 倍数 10 10 × tickTime = 20000 ms syncLimit follower 与 leader 数据同步的最大时长，单位为 tickTime 倍数 5 5 × tickTime = 10000 ms dataDir 数据和日志存储目录（未指定 dataLogDir 时，日志也会保存在此目录） /tmp/zookeeper 目录路径 clientPort 客户端连接 ZooKeeper 的端口号 2181 默认 2181 maxClientCnxns 单个客户端最大并发连接数 60 超过限制后新连接会被拒绝 autopurge.snapRetainCount 快照文件保留个数，超过数量的将会被清理 3 默认 3 autopurge.purgeInterval 清理任务执行间隔时间，单位小时，0 表示不自动清理 1 1 小时 启动 zookeeper 123456789101112cd zookeeper# 启动bin/zkServer.sh start# 指定配置文件bin/zkServer.sh start conf/zoo.cfg# 停止bin/zkServer.sh stop# 查看状态bin/zkServer.sh status# 查看版本./bin/zkServer.sh version 集群安装 ZooKeeper 集群角色 1. Leader（领导者） 职责： 事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性； 集群内部各个服务器的调度者； 对于 create、setData、delete 等写操作请求，统一转发给 Leader 处理； Leader 负责决定编号、执行操作，这个过程称为 事务。 三台虚拟机 zoo.cfg 文件末尾添加配置，启动时会自动选举出 Leader 角色，则其余就是 Follower 角色。 123server.1=10.250.0.229:2888:3888server.2=10.250.0.152:2888:3888server.3=10.250.0.36:2888:3888 2. Follower（跟随者） 职责： 处理客户端非事务（读操作）请求（可以直接响应）； 转发事务请求给 Leader； 参与集群 Leader 选举投票。 leader节点可以处理读写请求，follower只可以处理读请求。follower在接到写请求时会把写请求转发给leader来处理。 3. Observer（观察者） 职责： 对于非事务请求（读操作）可以独立处理； 对于事务请求会转发给 Leader 处理； 接收来自 Leader 的 inform 信息，更新本地存储； 不参与提交和选举投票； 通常用于 提升集群非事务处理能力，不影响集群事务处理性能。 配置一个 ID 为 4 的观察者节点： 1server.4=10.250.0.56:2888:3888:observer 集群搭建 环境准备：4台服务器，按照 单机安装 的方式准备好 Zookeeper 环境 123410.250.0.22910.250.0.15210.250.0.3610.250.0.56 zoo.cfg 文件末尾添加配置 1234server.1=10.250.0.229:2888:3888server.2=10.250.0.152:2888:3888server.3=10.250.0.36:2888:3888server.4=10.250.0.56:2888:3888:observer 分别在 dataDir 目录下创建 myid 文件，在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格） 12345# 注意 节点编号不能重复，而且要与 zoo.cfg 文件中的 server.id 一致echo 1 &gt; myid# echo 2 &gt; myid# echo 3 &gt; myid# echo 4 &gt; myid 分别启动 Zookeeper 服务器 12345# 分别启动4个节点的zookeeper serverbin/zkServer.sh start# 查看状态，可以看到节点角色类型bin/zkServer.sh status 集群最少节点要求和扩容规则 ZooKeeper 使用 多数派（quorum）机制 来保证数据一致性 1231.集群总节点数 N2.容忍的宕机节点数 F = (N-1)/2（向下取整）3.要保证集群可用，需要 大于 N/2 的节点存活 集群扩容规则 1234561.节点总数必须是奇数 奇数节点可以保证多数派投票机制正常 偶数节点不推荐，容错能力不增加（比如 4 台，仍然只容忍 1 台宕机）2.每次扩容建议 +2 节点 这样既保持奇数，又增加 quorum 容错能力 最少节点与容错能力表格 集群总节点数 N 容忍宕机数 F 可用 quorum 节点数 备注 1 0 1 不推荐，无法容忍故障 2 0 2 不推荐，1 台宕机就不可用 3 1 2 最小可用生产集群 5 2 3 推荐生产集群规模 7 3 4 高可用大集群 9 4 5 更大集群，高容错 11 5 6 极高可用场景 ZooKeeper 默认端口说明 端口 用途 说明 2181 客户端连接端口 客户端通过这个端口访问 ZooKeeper 2888 集群内部通信 follower 与 leader 之间同步数据 3888 leader 选举端口 集群选举 leader 使用 8080 (可选) admin/metrics web端口 如果开启了 adminServer 123456789101112# 永久开启端口sudo firewall-cmd --permanent --add-port=2181/tcpsudo firewall-cmd --permanent --add-port=2888/tcpsudo firewall-cmd --permanent --add-port=3888/tcp# 如果使用 adminServersudo firewall-cmd --permanent --add-port=8080/tcp# 重新加载防火墙配置sudo firewall-cmd --reload# 查看是否开放成功sudo firewall-cmd --list-all 客户端连接 命令行 1234# 默认连接 127.0.0.1:2181bin/zkCli.sh# 指定 -server ip:port，如果是集群，则连接任意一个节点，ZooKeeper 会自动处理与 Leader/Follower 的交互bin/zkCli.sh -server 127.0.0.1:2181 客户端命令简介：参考官网 命令 语法示例 功能描述 常用参数及说明 示例 help help 显示所有操作命令 无 help version version 查看客户端和服务器版本信息 无 version connect connect host:port 连接到指定 ZooKeeper 服务器 host:port: 服务器地址 connect 127.0.0.1:2181 close close 关闭当前会话 ,通过 connect 可重连 无 close quit quit 退出客户端 无 quit ls ls [-s] [-w] [-R] path 查看节点的子节点 - -w: 监听子节点变化- -s: 显示节点状态信息- -R: 递归查看 ls -s -w /zk_test getAllChildrenNumber getAllChildrenNumber path 获取某节点所有子节点的总数 无 getAllChildrenNumber /zk_test getEphemerals getEphemerals path 获取某路径下所有临时节点 无 getEphemerals /zk_test create create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 - -s: 顺序节点- -e: 临时节点- -c: 容器节点- -t ttl: TTL节点，单位毫秒 create -e /zk_test_ephemeral &quot;temp_data&quot; get get [-s] [-w] path 获取节点数据信息 - -s: 显示节点状态信息- -w: 监听节点变化 get -s -w /zk_test set set [-s] [-v version] path data 设置节点数据 - -s: 显示节点状态信息- -v: 指定版本号 set /zk_test &quot;new_data&quot; stat stat [-w] path 查看节点状态信息 - -w: 监听节点变化 stat -w /zk_test sync sync path 同步指定节点数据 无 sync /zk_test delete delete [-v version] path 删除某一节点（无子节点） - -v: 节点版本号 delete /zk_test deleteall deleteall path 递归删除某一节点及其子节点 无 deleteall /zk_test getAcl getAcl [-s] path 获取节点访问控制信息 - -s: 显示节点状态信息 getAcl /zk_test setAcl setAcl [-s] [-v version] [-R] path acl 设置节点访问控制列表 - -s: 显示节点状态信息- -v: 指定版本号- -R: 递归设置 setAcl /zk_test world:anyone:r listquota listquota path 查看节点配额信息 无 listquota /zk_test setquota setquota [-n] [-b] val path 对节点增加限制 - -n: 子节点最大个数- -b: 数据值最大长度，-1 表示无限制 setquota -n 5 /zk_test delquota delquota [-n | -b] path 删除节点配额限制 - -n: 删除子节点数限制- -b: 删除数据值大小限制 delquota -n /zk_test config config 查看服务器配置 无 config whoami whoami 查看当前会话身份 无 whoami GUI 工具 名称 类型 / 运行方式 优点 注意事项 PrettyZoo 桌面应用（JavaFX）(GitHub) 支持 Mac/Windows/Linux，界面友好；支持节点创建/删除/更新/查询，ACL 管理，多 ZK 实例管理，SSH 隧道等功能。(GitHub) 项目已经 archived，维护可能不活跃。最新版可能在兼容性或 Bug 修复方面不如活跃项目。也可能需要自己构建或调试。(GitHub) ZooNavigator Web 界面 + 可 Docker 部署或本地启动(GitHub) 功能丰富；支持多个 Zookeeper 版本（如 3.5.x ～ 3.9.x）；浏览 / 编辑 /搜索节点；导入导出配置；支持浏览器访问，无需本地 heavy GUI。(GitHub) 因为 Web 应用，可能对浏览器安全策略与网络延迟敏感；需要部署自己版本或 Docker；如果要求本地脱机操作时，有些功能可能稍不如桌面应用。 ZooKeeper Assistant 桌面／管理员面板类型（支持监控界面等）(DEV Community) 除了浏览节点树以外，还提供健康状态监控（延迟、请求数等）、不同数据格式支持（JSON/XML 等）、导入/导出节点数据、命令行操作集成。(DEV Community) 有些功能可能在 Mac 上兼容性或视觉体验需要调试；具体版本支持情况要看最近更新。某些监控界面可能依赖于 ZK 的指标或插件。 Zookeeper 节点类型 节点类型 生命周期说明 创建命令示例 特点说明 持久节点 (Persistent) 节点一直存在，除非手动删除，即使客户端会话关闭，节点也不会消失 create /locks 适合存储配置信息、元数据等持久数据 临时节点 (Ephemeral) 客户端会话关闭（异常或超时）时，节点自动被删除 create -e /locks/DBLock 常用于分布式锁、临时会话数据 有序节点 (Sequential) 在持久或临时节点基础上，增加有序编号，ZooKeeper 自动在节点名后加递增序号 create -e -s /jobs/job 常用于分布式锁、队列等需要顺序的场景 容器节点 (Container) V3.5.3+，当容器节点下的最后一个子节点被删除后，容器节点也会自动删除 create -c /work 适合分布式任务临时目录、动态数据目录 TTL 节点 (TTL) 在指定 TTL 时间内未修改且无子节点，节点会被自动删除（需开启 extendedTypesEnabled=true 配置） create -t 3000 /ttl_node 适合临时缓存、临时状态数据，过期自动清理 注意 同一级节点 key 名称是唯一的 创建节点时，必须要带上全路径 节点状态信息 123456789101112[zk: localhost:2181(CONNECTED) 16] stat /testcZxid = 0x100000002 # Znode创建的事务idctime = Mon Sep 15 09:44:51 UTC 2025 # 创建时间mZxid = 0x100000004 # 最后一次修改事务idmtime = Mon Sep 15 09:47:12 UTC 2025 # 最后一次修改时间pZxid = 0x400000004 # 表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID（注意: 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）cversion = 1 # 子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。dataVersion = 1 # znode的数据版本号。每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据），可有效避免了数据更新时出现的先后顺序问题aclVersion = 0 # znode的ACL版本号。每次对节点进行ACL设置，aclVersion的值都会增加1ephemeralOwner = 0x0 # 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id。如果不是, ephemeralOwner值为0(持久节点)。dataLength = 3 # znode的数据长度numChildren = 1 # znode的子节点数量（只统计直接子节点的数量） Zookeeper 监听机制 watch机制，顾名思义是一个监听机制。Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发生时才会触发监听，通知给客户端。 监听的对象是事件，支持的事件类型如下： 1234567- None: 连接建立事件- NodeCreated： 节点创建- NodeDeleted： 节点删除- NodeDataChanged：节点数据变化- NodeChildrenChanged：子节点列表变化- DataWatchRemoved：节点监听被移除- ChildWatchRemoved：子节点监听被移除 监听特性 特性 说明 一次性触发 Watch 是一次性的，一旦被触发就会被移除。再次使用时需要重新注册。 客户端顺序回调 Watch 回调是顺序串行执行的，客户端只有在回调完成后才能看到最新的数据状态。 轻量级 Watcher 回调逻辑不应过多，以免阻塞或影响其他 Watch 的执行。 最小通信单位 WatchEvent 是最小的通信单位，只包含通知状态、事件类型和节点路径，不包含节点数据变化前后的具体内容。 时效性 Watcher 仅在当前 Session 完全失效时才无效。如果 Session 快速重连成功，Watcher 依然有效，可继续接收通知。 可以开启监听的命令 123456#监听节点数据的变化get -w pathstat -w path#监听子节点增减的变化ls -w path 永久性 Watch 在被触发之后，仍然保留，可以继续监听ZNode上的变更，是Zookeeper 3.6.0版本新增的功能 创建监听 12345addWatch [-m mode] path# mode:# - PERSISTENT: 持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。# - PERSISTENT_RECURSIVE: 持久化递归订阅(这个是默认值)，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性） 删除监听 123456# 普通一次性 Watch 不需要手动删除，触发后会自动移除；removewatches 主要用于持久 Watch（persistent watch）。removewatches path [-c|-d|-a] [-l]# -c: 仅删除当前客户端的 Watch# -d: 删除指定节点的所有 Watch(包括其他客户端注册的)# -a: 删除所有节点的所有 Watch（包括其他客户端的 Watch），慎用！！！# -l: 显示被删除的 Watch 列表 监听器应用场景 类型 特点 应用场景举例 适合的节点类型 临时监听（一次性 Watch） - 触发一次后自动移除- 客户端需手动重新注册- 轻量级，适合单次通知 1. 配置中心：配置变化时通知客户端，客户端收到通知后重新拉取最新配置 2. 分布式锁：节点删除（锁释放）后通知等待的客户端重新竞争锁 3. 主从选举：主节点宕机后，其他节点收到通知重新选主 持久节点（Persistent） 临时节点（Ephemeral，用于锁和选主） 永久监听（Persistent Watch） - 注册后持续有效，直到客户端主动移除- 支持子节点变化、数据变化的长期监听 1. 服务发现：客户端长期监听服务节点变化，节点上线/下线时自动更新本地服务列表 2. 监控告警：监控重要节点状态，节点数据变化或被删除时自动触发告警 3. 分布式缓存：缓存节点变化时，通知客户端刷新缓存 持久节点（Persistent） ACL权限控制 ZooKeeper 默认情况下，所有节点的权限都是 OPEN_ACL_UNSAFE ，任何客户端都可以读写任意节点数据。 生产环境中，通常需要限制对节点的访问权限，即 ACL 权限控制。 ZooKeeper 里的 ACL（Access Control List，访问控制列表） 主要用于控制 谁可以对某个节点做什么操作，它是 ZooKeeper 提供的安全机制之一。 ACL 的作用 限制访问：只允许授权用户或客户端对指定节点进行读、写、删除等操作。 防止误操作：保护重要节点不被未授权的客户端修改或删除。 安全隔离：不同的应用或团队可以在同一 ZooKeeper 集群里安全共存。 ACL 的组成 zookeeper 的 acl 通过 scheme:id:permissions 来构成权限列表。 scheme：授权的模式，代表采用的某种权限机制，包括 world、auth、digest、ip、super 几种。 id：授权对象，代表允许访问的用户。如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。 permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限， 创建权限 create©、删除权限 delete(d)、读权限 read®、写权限 write(w)、管理权限admin(a)。 常见的 scheme 类型 Scheme 说明 示例 world 开放给所有用户，仅可设置为 anyone 代表所有客户端 world:anyone:r auth 已通过 addauth 添加认证的客户端 auth:user1:rw digest 用户名+密码认证（常用），user:pwd 需要加密存储 digest:user1:password:rw ip 基于 IP 地址控制访问 ip:192.168.1.10:r super 超级用户，拥有所有权限 super:admin:secret 权限类型 权限字符 权限名称 允许的操作/命令示例 说明 r 读取(Read) get /node ls /node getAcl /node 允许读取节点数据和子节点列表 w 写入(Write) set /node data 允许修改节点数据 c 创建(Create) create /node/sub &quot;data&quot; 允许在当前节点下创建子节点 d 删除(Delete) delete /node/sub 允许删除当前节点的子节点 a 管理(Admin) setAcl /node acl 允许修改 ACL 权限 典型应用场景 认证方式（scheme） 权限类型（permissions） 典型 ACL 配置示例 应用场景 特点说明 world r（只读） world:anyone:r 公共配置节点，所有客户端都可读取 简单、无认证，适合对安全性要求不高的只读场景 auth r,w,c,d,a（可组合） auth:user:rwcd 内部应用共享节点，需客户端认证 需先 addauth digest user1:password 添加认证，适合多客户端共享 digest（常用） r,w,c,d,a（可组合） digest:user:secret:crwda 高安全节点，配置中心，分布式锁 用户名+密码认证，需加密存储密码，灵活安全 ip r,w,c,d,a（可组合） ip:192.168.1.100:r 基于 IP 限制访问的场景 快速控制某些固定 IP 可访问，适合内部网络应用 ACL 相关命令 命令 语法 功能说明 示例 getAcl getAcl path 读取指定节点的 ACL getAcl /my_node setAcl setAcl path acl 设置指定节点的 ACL setAcl /my_node world:anyone:crdwa create create path data [acl] 创建节点时指定 ACL create /secure_node &quot;secret_data&quot; digest:user1:pwd:crwa addAuth addauth scheme auth 添加认证用户（类似登录） addauth digest user1:password deleteAcl(不存在) setAcl path world:anyone: 删除节点 ACL（设为空或全开放） setAcl /my_node world:anyone: auth 与 digest 的区别 使用 auth 时，需先 addauth digest user1:password 添加认证，setAcl 时，使用 auth:user1:rw，这里是为已经登录的用户设置节点权限，所以不需要设置密码 使用 digest 时，无需进行登录认证，所以需要指定密码，即setAcl 时，使用 digest:user1:password:rw digest 的密码是经过加密的，所以不能直接使用明文密码 12345678910# 加密密码echo -n user:123456 | openssl dgst -binary -sha1 | openssl base64# 输出6DY5WhzOfGsWQ1XFuIyzxkpwdPo=# zookeeper客户端中设置权限setAcl /name digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:cdrwa# 登录时密码是明文addauth digest user:123456 无论使用 digest 还是 auth，在需要访问节点前，都需要先登录。 super 超级管理员 拥有全部节点的所有权限: crwda 设置超级管理员 1234567# 加密密码，用户和密码可以随意设置echo -n admin:123456 | openssl dgst -binary -sha1 | openssl base64# 输出0uek/hZ/V9fgiM35b0Z2226acMQ=# 打开 conf/zoo.cfg 文件并编辑，在文件中添加下面内容DigestAuthenticationProvider.superDigest=admin:0uek/hZ/V9fgiM35b0Z2226acMQ= 重新启动服务后登录客户端进行测试 1234567891011# 创建节点并设置权限，这里将节点授权给用户user[zk: localhost:2181(CONNECTED) 10] create /testNode 666 digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:rwCreated /testNode# 查看节点内容被拒绝[zk: localhost:2181(CONNECTED) 11] get /testNodeInsufficient permission : /testNode# 登录super用户，验证超级用户是否有权限访问节点[zk: localhost:2181(CONNECTED) 12] addauth digest admin:123456# 此时查看节点内容就可以了[zk: localhost:2181(CONNECTED) 13] get /testNode666 4字母命令 什么是 4 字母命令? ZooKeeper 提供了一组简短的 4个字母的管理命令(Four Letter Words Commands, 4lw)，可以通过 TCP 连接 ZooKeeper 端口（默认 2181）发送这些命令，快速查看或管理 ZooKeeper 状态。 常用的 4字母命令 命令 引入版本 功能描述 示例 conf 3.3.0 打印服务相关配置的详细信息 echo conf | nc 127.0.0.1 2181 cons 3.3.0 列出所有连接到该服务器的客户端连接/会话详细信息，包括接收/发送的包数量、会话ID、操作延迟、最后操作执行时间等 echo cons | nc 127.0.0.1 2181 crst 3.3.0 重置所有连接的连接和会话统计信息 echo crst | nc 127.0.0.1 2181 dump - 列出重要的会话和临时节点信息，仅在 Leader 节点上有效 echo dump | nc 127.0.0.1 2181 envi - 打印服务环境的详细信息 echo envi | nc 127.0.0.1 2181 reqs - 列出未经处理的请求 echo reqs | nc 127.0.0.1 2181 ruok - 测试服务是否处于正常状态；正常返回 imok echo ruok | nc 127.0.0.1 2181 stat - 输出关于性能和客户端连接的列表信息 echo stat | nc 127.0.0.1 2181 srst - 重置服务器统计信息 echo srst | nc 127.0.0.1 2181 srvr 3.3.0 列出连接服务器的详细信息 echo srvr | nc 127.0.0.1 2181 wchs 3.3.0 列出服务器 Watch 的详细信息 echo wchs | nc 127.0.0.1 2181 wchc 3.3.0 通过会话列出服务器 Watch 的详细信息，输出与 Watch 相关的会话列表 echo wchc | nc 127.0.0.1 2181 wchp 3.3.0 通过路径列出服务器 Watch 的详细信息，输出与会话相关的路径 echo wchp | nc 127.0.0.1 2181 mntr 3.4.0 输出可用于检测集群健康状态的关键指标变量列表 echo mntr | nc 127.0.0.1 2181 开启 4字母命令 在 ZooKeeper 3.5.0 及之后的版本，4lw 命令默认是禁用的，必须在配置文件(zoo.cfg)中显式开启。 1234# 表示允许所有 4lw 命令都能用（风险最大）4lw.commands.whitelist=*# 这样只允许执行 stat、conf、ruok 这几个命令。4lw.commands.whitelist=stat,conf,ruok 使用方法 1234# 如果没有安装 nc，可以使用 yum 安装yum install nc -y# 查看节点状态echo stat | nc 127.0.0.1 2181 Zookeeper Java Client 项目示例：Github地址，单元测试。 Zookeeper 官方Java客户端 ZooKeeper官方的客户端API提供了基本的操作。例如，创建会话、创建节点、读取节点、更新数据、删除节点和检查节点是否存在等。不过，对于实际开发来说，ZooKeeper官方API有一些不足之处，具体如下： ZooKeeper的Watcher监测是一次性的，每次触发之后都需要重新进行注册。 会话超时之后没有实现重连机制。 异常处理烦琐，ZooKeeper提供了很多异常，对于开发人员来说可能根本不知道应该如何处理这些抛出的异常。 仅提供了简单的byte[]数组类型的接口，没有提供Java POJO级别的序列化数据处理接口。 创建节点时如果抛出异常，需要自行检查节点是否存在。 无法实现级联删除。 总之，ZooKeeper官方API功能比较简单，在实际开发过程中比较笨重，一般不推荐使用。 项目引入依赖时，最好保持与服务端版本一致，否则可能会有一些兼容性的问题 123456&lt;!-- zookeeper client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.8.4&lt;/version&gt;&lt;/dependency&gt; Zookeeper 第三方Java客户端 Curator Curator是Netflix公司开源的一套ZooKeeper客户端框架，和ZkClient一样它解决了非常底层的细节开发工作，包括连接、重连、反复注册Watcher的问题以及NodeExistsException异常等。 Curator是Apache基金会的顶级项目之一，Curator具有更加完善的文档，另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。 Curator还为ZooKeeper客户端框架提供了一些比较普遍的、开箱即用的、分布式开发用的解决方案，例如Recipe、共享锁服务、Master选举机制和分布式计算器等，帮助开发者避免了“重复造轮子”的无效开发工作。 在实际的开发场景中，使用Curator客户端就足以应付日常的ZooKeeper集群操作的需求。 引入依赖说明： 模块 依赖关系 功能定位 典型功能举例 常用场景 curator-client 依赖 zookeeper 连接管理、重试策略、底层 API 连接会话管理、RetryPolicy 需要最轻量的 ZooKeeper 客户端 curator-framework 依赖 curator-client 高层 API 封装，简化 ZK 操作 创建节点、Watcher 管理、自动重连 通用 ZooKeeper 客户端开发 curator-recipes 依赖 curator-framework → curator-client 分布式模式现成实现 分布式锁、Leader 选举、队列、Barrier 直接用分布式工具，无需自己实现 使用建议 如果你只想轻量访问 ZooKeeper → curator-client 就够了，但几乎没人单独用。 如果你想方便操作 ZooKeeper API → curator-framework，大部分情况都适用。 如果你想用分布式锁、选举、Barrier → curator-recipes（它会自动引入前两个）。 12345678910111213141516171819&lt;!-- zookeeper client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.8.4&lt;/version&gt;&lt;/dependency&gt;&lt;!--curator--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;","summary":"摘要 本文介绍 CentOS9 中 Zookeeper 的安装与使用。 Zookeeper官网 本文使用的 Zookeeper 版本为 3.8.4。","date_published":"2025-09-15T13:30:05.000Z","tags":["技术","zookeeper","分布式","zookeeper"]},{"id":"https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/","url":"https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/","title":"ShardingSphere-Proxy5.5.2 DistSQL","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"DistSQL\">DistSQL</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a>（Distributed SQL）是 Apache ShardingSphere 特有的操作语言。 它与标准 SQL 的使用方式完全一致，用于提供增量功能的 SQL 级别操作能力。</p>\n</li>\n<li class=\"lvl-2\">\n<p>灵活的规则配置和资源管控能力是 Apache ShardingSphere 的特点之一。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在使用 4.x 及其之前版本时，开发者虽然可以像使用原生数据库一样操作数据，但却需要通过本地文件或注册中心配置资源和规则。然而，操作习惯变更，对于运维工程师并不友好。</p>\n</li>\n<li class=\"lvl-2\">\n<p>从 5.x 版本开始，DistSQL（Distributed SQL）让用户可以像操作数据库一样操作 Apache ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的数据库产品。</p>\n</li>\n<li class=\"lvl-2\">\n<p>DistSQL 细分为 RDL、RQL、RAL 和 RUL 四种类型。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">RDL: Resource &amp; Rule Definition Language，负责资源和规则的创建、修改和删除。</li>\n<li class=\"lvl-4\">RQL: Resource &amp; Rule Query Language，负责资源和规则的查询和展现。</li>\n<li class=\"lvl-4\">RAL: Resource &amp; Rule Administration Language，负责强制路由、熔断、配置导入导出、数据迁移控制等管理功能。</li>\n<li class=\"lvl-4\">RUL: Resource &amp; Rule Utility Language，负责 SQL 解析、SQL 格式化、执行计划预览等功能。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>DistSQL 仅可以在 ShardingSphere-Proxy 中使用，不能在 ShardingSphere-JDBC 中使用。</p>\n</li>\n</ul>\n<h2 id=\"示例准备\">示例准备</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>具体的语法，官网介绍的很详细，这里基于 <a href=\"/2025/09/04/springboot3-shardingsphere-proxy/\" title=\"SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表\">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 中的配置进行示例说明。</p>\n</li>\n<li class=\"lvl-2\">\n<p>为了尽可能多的使用 DistSQL 语法，这里仅在 <code>global.yaml</code> 中配置如下内容:</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置为基于 zookeeper 集群模式，为了演示 DistSQL 语法，这里需要将配置持久化，使用 JDBC 的单机模式也可以</span></span><br><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置用户和权限，因为 DistSQL 暂不支持 用户和权限管理，所以这里需要先配置用户和权限</span></span><br><span class=\"line\"><span class=\"attr\">authority:</span></span><br><span class=\"line\">  <span class=\"attr\">users:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">root@127.0.0.1</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">admin:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">sharding@%</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">sharding</span></span><br><span class=\"line\">  <span class=\"attr\">privilege:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">DATABASE_PERMITTED</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">user-database-mappings:</span> <span class=\"string\">root@127.0.0.1=*,sharding@%=sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 ShardingSphere-Proxy 服务，并登录</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 ShardingSphere-Proxy</span></span><br><span class=\"line\">./shardingsphere-proxy-bin/bin/start.sh</span><br><span class=\"line\"><span class=\"comment\"># 使用管理员登录</span></span><br><span class=\"line\">mysql -h127.0.0.1 -uroot -proot -P3307</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看当前用户权限</span></span><br><span class=\"line\">mysql&gt; SHOW AUTHORITY RULE;</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">| <span class=\"built_in\">users</span>                      | provider           | props                                                                |</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">| root@127.0.0.1; sharding@% | DATABASE_PERMITTED | &#123;<span class=\"string\">&quot;user-database-mappings&quot;</span>:<span class=\"string\">&quot;root@127.0.0.1=*,sharding@%=sharding_db&quot;</span>&#125; |</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">1 row <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.49 sec)</span><br></pre></td></tr></table></figure>\n<h2 id=\"全局配置，即global-yaml中的配置\">全局配置，即<code>global.yaml</code>中的配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>全局配置对所有逻辑数据库有效</p>\n</li>\n</ul>\n<h3 id=\"属性配置\">属性配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">props:</span></span><br><span class=\"line\">  <span class=\"attr\">sql-show:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>设置属性，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/set-dist-vairable/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里要注意，属性名需要使用下划线格式</span></span><br><span class=\"line\">SET DIST VARIABLE sql_show = <span class=\"literal\">true</span>;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看属性，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/show-dist-variable/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; SHOW DIST VARIABLES;</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br><span class=\"line\">| variable_name                           | variable_value  |</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br><span class=\"line\">| agent_plugins_enabled                   | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">| cached_connections                      | 0               |</span><br><span class=\"line\">| cdc_server_port                         | 33071           |</span><br><span class=\"line\">| check_table_metadata_enabled            | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| kernel_executor_size                    | 0               |</span><br><span class=\"line\">| load_table_metadata_batch_size          | 1000            |</span><br><span class=\"line\">| max_connections_size_per_query          | 1               |</span><br><span class=\"line\">| proxy_backend_query_fetch_size          | -1              |</span><br><span class=\"line\">| proxy_default_port                      | 3307            |</span><br><span class=\"line\">| proxy_frontend_database_protocol_type   |                 |</span><br><span class=\"line\">| proxy_frontend_executor_size            | 0               |</span><br><span class=\"line\">| proxy_frontend_flush_threshold          | 128             |</span><br><span class=\"line\">| proxy_frontend_max_connections          | 0               |</span><br><span class=\"line\">| proxy_frontend_ssl_cipher               |                 |</span><br><span class=\"line\">| proxy_frontend_ssl_enabled              | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| proxy_frontend_ssl_version              | TLSv1.2,TLSv1.3 |</span><br><span class=\"line\">| proxy_meta_data_collector_enabled       | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| proxy_netty_backlog                     | 1024            |</span><br><span class=\"line\">| sql_show                                | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">| sql_simple                              | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| system_log_level                        | INFO            |</span><br><span class=\"line\">| system_schema_metadata_assembly_enabled | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br></pre></td></tr></table></figure>\n<h3 id=\"分布式事务配置\">分布式事务配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">transaction:</span></span><br><span class=\"line\">  <span class=\"attr\">defaultType:</span> <span class=\"string\">XA</span></span><br><span class=\"line\">  <span class=\"attr\">providerType:</span> <span class=\"string\">Atomikos</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-2\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看事务规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/show-transaction-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW TRANSACTION RULE;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改事务规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/alter-transaction-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER TRANSACTION RULE(</span><br><span class=\"line\">  DEFAULT=<span class=\"string\">&quot;XA&quot;</span>, TYPE(NAME=<span class=\"string\">&quot;Atomikos&quot;</span>)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h2 id=\"规则配置，即database-xxx-yaml中的配置\">规则配置，即<code>database-xxx.yaml</code>中的配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>以下 DistSQL 仅可以在逻辑库中执行，所以需要先创建一个逻辑数据库</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; CREATE DATABASE sharding_db;</span><br><span class=\"line\">Query OK, 0 rows affected (0.03 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; use sharding_db;</span><br><span class=\"line\">Database changed</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据源配置\">数据源配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 DistSQL中，官方将数据源叫做<code>存储单元(STORAGE UNIT)</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span>  <span class=\"comment\"># 注意这里属性为 url</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-3\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注册存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/register-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">REGISTER STORAGE UNIT ds_0 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">REGISTER STORAGE UNIT ds_1 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/storage-unit-query/show-storage-units/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW STORAGE UNITS FROM sharding_db \\G;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/alter-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER STORAGE UNIT ds_1 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span>,</span><br><span class=\"line\">    PROPERTIES(<span class=\"string\">&quot;maximumPoolSize&quot;</span>=10,<span class=\"string\">&quot;idleTimeout&quot;</span>=30000)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>取消注册存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/unregister-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 无法移除已经被规则使用的存储单元</span></span><br><span class=\"line\">UNREGISTER STORAGE UNIT ds_0;</span><br></pre></td></tr></table></figure>\n<h3 id=\"单表配置\">单表配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SINGLE</span> <span class=\"comment\"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"comment\"># MySQL 风格</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">ds_0.t_address</span> <span class=\"comment\"># 加载指定单表</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-4\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>加载单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/load-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/single-table/show-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW SINGLE TABLES;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>卸载单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/unload-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">UNLOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure>\n<h3 id=\"广播表配置\">广播表配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>广播表，即所有数据源都包含的表，比如字典表</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!BROADCAST</span>  <span class=\"comment\"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">dict</span>    <span class=\"comment\"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-5\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/create-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/drop-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/broadcast-table/show-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中具有广播规则的表</span></span><br><span class=\"line\">SHOW BROADCAST TABLE RULES;</span><br><span class=\"line\"><span class=\"comment\"># 查询指定数据库中具有广播规则的表</span></span><br><span class=\"line\">SHOW BROADCAST TABLE RULES FROM sharding_db;</span><br></pre></td></tr></table></figure>\n<h3 id=\"分库分表配置\">分库分表配置</h3>\n<h4 id=\"单分片键，Long-类型\">单分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">course:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class=\"comment\"># 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">cid</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_inline</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">cid</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">course_inline:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span> <span class=\"comment\"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 属性</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">course_$&#123;cid</span> <span class=\"string\">%</span> <span class=\"number\">2</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class=\"line\">          <span class=\"attr\">allow-range-query-with-inline-sharding:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 允许范围查询</span></span><br><span class=\"line\">      <span class=\"attr\">course_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表示 ds_0, ds_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-6\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/create-sharding-table-rule/#1%E6%A0%87%E5%87%86%E5%88%86%E7%89%87%E8%A7%84%E5%88%99\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE course (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.course_<span class=\"variable\">$&#123;1..2&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=cid,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;course_<span class=\"variable\">$&#123;cid % 2 + 1&#125;</span>&quot;</span>,<span class=\"string\">&quot;allow-range-query-with-inline-sharding&quot;</span>=<span class=\"literal\">true</span> )))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=cid,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"单分片键，String-类型\">单分片键，String 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span>  <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">id</span> <span class=\"comment\"># 自增列名称，字符串类型</span></span><br><span class=\"line\"><span class=\"comment\">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">custom_snowflake_string</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span> <span class=\"comment\"># 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span> <span class=\"comment\"># 分表，t_user_0, t_user_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式序列算法</span></span><br><span class=\"line\">      <span class=\"attr\">uuid:</span>    <span class=\"comment\"># 定义名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">UUID</span> <span class=\"comment\"># 字符串主键，String</span></span><br><span class=\"line\">      <span class=\"attr\">custom_snowflake_string:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CUSTOM_SNOWFLAKE_STRING</span> <span class=\"comment\"># 自定义雪花算法，String，spi</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">workerId:</span> <span class=\"number\">2</span></span><br><span class=\"line\">          <span class=\"attr\">datacenterId:</span> <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-7\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_user (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_user_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class=\"built_in\">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;Math.abs(id.hashCode()%2)&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class=\"built_in\">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;t_user_<span class=\"variable\">$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=<span class=\"built_in\">id</span>,TYPE(NAME=<span class=\"string\">&quot;CUSTOM_SNOWFLAKE_STRING&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"多分片键，Long-类型\">多分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order-complex-algorithm</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span>  <span class=\"comment\"># 分片列名称,多个逗号分隔</span></span><br><span class=\"line\"><span class=\"comment\">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_item-class-based-algorithm_spi</span> <span class=\"comment\"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order-complex-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">COMPLEX_INLINE</span> <span class=\"comment\"># 基于行表达式的复合分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_order_complex_$&#123;(user_id</span> <span class=\"string\">+</span> <span class=\"string\">order_id</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">)</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm_spi:</span> <span class=\"comment\"># SPI</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">T_ORDER_ITEM_COMPLEX</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-8\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_order_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;complex_inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;t_order_complex_<span class=\"variable\">$&#123;(user_id + order_id + 1) % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE SHARDING TABLE RULE t_order_item_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_item_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;SNOWFLAKE&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"自动分片规则\">自动分片规则</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">   <span class=\"comment\"># 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致</span></span><br><span class=\"line\">    <span class=\"attr\">bindingTables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">t_order,t_order_item</span></span><br><span class=\"line\">    <span class=\"attr\">autoTables:</span> <span class=\"comment\"># 自动分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">mod_2:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MOD</span> <span class=\"comment\"># 基于 MOD 的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">sharding-count:</span> <span class=\"number\">2</span> <span class=\"comment\"># 分片数量，即 对 2 进行取余</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-9\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_order (</span><br><span class=\"line\">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class=\"line\">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class=\"string\">&quot;mod&quot;</span>,PROPERTIES(<span class=\"string\">&quot;sharding-count&quot;</span>=<span class=\"string\">&quot;2&quot;</span>)),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE SHARDING TABLE RULE t_order_item (</span><br><span class=\"line\">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class=\"line\">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class=\"string\">&quot;mod&quot;</span>,PROPERTIES(<span class=\"string\">&quot;sharding-count&quot;</span>=<span class=\"string\">&quot;2&quot;</span>)),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"其它分片操作语句\">其它分片操作语句</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/sharding/show-sharding-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看当前逻辑库下的所有分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULES \\G;</span><br><span class=\"line\"><span class=\"comment\"># 查看指定逻辑库下的分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULES FROM sharding_db; \\G;</span><br><span class=\"line\"><span class=\"comment\"># 查看指定分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULE t_user \\G;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/alter-sharding-table-rule/\">官网文档</a>，与创建分片规则类似，将<code>CREATE</code>改为<code>ALTER</code>即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER SHARDING TABLE RULE t_order_item_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_item_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;SNOWFLAKE&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/drop-sharding-table-rule/\">官网文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP SHARDING TABLE RULE t_order;</span><br><span class=\"line\"><span class=\"comment\"># 删除多个表</span></span><br><span class=\"line\">DROP SHARDING TABLE RULE t_order,t_order_item;</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据加密规则\">数据加密规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!ENCRYPT</span>    <span class=\"comment\"># 数据加密配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 加密表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 加密列名称</span></span><br><span class=\"line\">            <span class=\"attr\">cipher:</span></span><br><span class=\"line\">              <span class=\"attr\">name:</span> <span class=\"string\">password</span> <span class=\"comment\"># 密文列名称</span></span><br><span class=\"line\">              <span class=\"attr\">encryptorName:</span> <span class=\"string\">aes_encryptor</span> <span class=\"comment\"># 密文列加密算法名称</span></span><br><span class=\"line\">    <span class=\"comment\"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class=\"line\">    <span class=\"attr\">encryptors:</span></span><br><span class=\"line\">      <span class=\"attr\">aes_encryptor:</span> <span class=\"comment\"># 加解密算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">AES</span> <span class=\"comment\"># 加解密算法类型</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 加解密算法属性配置</span></span><br><span class=\"line\">          <span class=\"attr\">aes-key-value:</span> <span class=\"string\">123456abc</span>     <span class=\"comment\"># AES 使用的 KEY</span></span><br><span class=\"line\">          <span class=\"attr\">digest-algorithm-name:</span> <span class=\"string\">SHA-1</span> <span class=\"comment\"># AES KEY 的摘要算法</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-10\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建加密规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/encrypt/create-encrypt-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE ENCRYPT RULE t_user (</span><br><span class=\"line\">COLUMNS(</span><br><span class=\"line\">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class=\"string\">&#x27;AES&#x27;</span>,PROPERTIES(<span class=\"string\">&#x27;aes-key-value&#x27;</span>=<span class=\"string\">&#x27;123456abc&#x27;</span>, <span class=\"string\">&#x27;digest-algorithm-name&#x27;</span>=<span class=\"string\">&#x27;SHA-1&#x27;</span>))))</span><br><span class=\"line\">));</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改加密规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER ENCRYPT RULE t_user (</span><br><span class=\"line\">COLUMNS(</span><br><span class=\"line\">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class=\"string\">&#x27;AES&#x27;</span>,PROPERTIES(<span class=\"string\">&#x27;aes-key-value&#x27;</span>=<span class=\"string\">&#x27;123456abc&#x27;</span>, <span class=\"string\">&#x27;digest-algorithm-name&#x27;</span>=<span class=\"string\">&#x27;SHA-1&#x27;</span>))))</span><br><span class=\"line\">));</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除加密规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP ENCRYPT RULE t_user;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询加密规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/encrypt/show-encrypt-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中所有加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULES \\G;</span><br><span class=\"line\"><span class=\"comment\"># 获取指定逻辑库中的加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULES FROM sharding_db \\G;</span><br><span class=\"line\"><span class=\"comment\"># 获取指定逻辑表中的加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULE t_user \\G;</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据脱敏规则\">数据脱敏规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!MASK</span>  <span class=\"comment\"># 数据脱敏配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 脱敏表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span>  <span class=\"comment\"># 脱敏列配置</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 脱敏列名称</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">md5_mask</span> <span class=\"comment\"># 脱敏算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">email:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">mask_before_special_chars_mask</span></span><br><span class=\"line\">          <span class=\"attr\">telephone:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">keep_first_n_last_m_mask</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">my_mask</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">maskAlgorithms:</span> <span class=\"comment\"># 脱敏算法配置</span></span><br><span class=\"line\">      <span class=\"attr\">md5_mask:</span> <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span>  <span class=\"comment\"># 脱敏算法类型，md5加密后展示</span></span><br><span class=\"line\">      <span class=\"attr\">mask_before_special_chars_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MASK_BEFORE_SPECIAL_CHARS</span> <span class=\"comment\"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">special-chars:</span> <span class=\"string\">&#x27;@&#x27;</span>  <span class=\"comment\"># 遇到 @ 之前的部分做脱敏</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span>   <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">keep_first_n_last_m_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">KEEP_FIRST_N_LAST_M</span> <span class=\"comment\"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">first-n:</span> <span class=\"number\">3</span>     <span class=\"comment\"># 保留前 3 位</span></span><br><span class=\"line\">          <span class=\"attr\">last-m:</span> <span class=\"number\">4</span>      <span class=\"comment\"># 保留后 4 位</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span> <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">my_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MY_CUSTOM_MASK</span>  <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&quot;#&quot;</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-11\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建脱敏规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/mask/create-mask-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE MASK RULE t_user (</span><br><span class=\"line\">  COLUMNS(</span><br><span class=\"line\">    (NAME=password, TYPE(NAME=<span class=\"string\">&#x27;MD5&#x27;</span>)),</span><br><span class=\"line\">    (NAME=email, TYPE(NAME=<span class=\"string\">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;special-chars&quot;</span>=<span class=\"string\">&quot;@&quot;</span>,  <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=telephone, TYPE(NAME=<span class=\"string\">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;first-n&quot;</span>=3, <span class=\"string\">&quot;last-m&quot;</span>=4, <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=`name`, TYPE(NAME=<span class=\"string\">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;#&quot;</span>)))</span><br><span class=\"line\">  )</span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"comment\"># 这里注意 name 是关键字，所以需要用 `` 包起来</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改脱敏规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER MASK RULE t_user (</span><br><span class=\"line\">  COLUMNS(</span><br><span class=\"line\">    (NAME=password, TYPE(NAME=<span class=\"string\">&#x27;MD5&#x27;</span>)),</span><br><span class=\"line\">    (NAME=email, TYPE(NAME=<span class=\"string\">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;special-chars&quot;</span>=<span class=\"string\">&quot;@&quot;</span>,  <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=telephone, TYPE(NAME=<span class=\"string\">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;first-n&quot;</span>=3, <span class=\"string\">&quot;last-m&quot;</span>=4, <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=`name`, TYPE(NAME=<span class=\"string\">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;#&quot;</span>)))</span><br><span class=\"line\">  )</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除脱敏规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP MASK RULE t_user;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询脱敏规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/mask/show-mask-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中所有脱敏规则</span></span><br><span class=\"line\">SHOW MASK RULES;</span><br><span class=\"line\"><span class=\"comment\"># 仅查询指定逻辑库中的脱敏规则</span></span><br><span class=\"line\">SHOW MASK RULES FROM sharding_db;</span><br><span class=\"line\"><span class=\"comment\"># 查询指定规则</span></span><br><span class=\"line\">mysql&gt; SHOW MASK RULE t_user;</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class=\"line\">| table  | column    | algorithm_type            | algorithm_props                                 |</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class=\"line\">| t_user | password  | MD5                       |                                                 |</span><br><span class=\"line\">| t_user | email     | MASK_BEFORE_SPECIAL_CHARS | &#123;<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;*&quot;</span>,<span class=\"string\">&quot;special-chars&quot;</span>:<span class=\"string\">&quot;@&quot;</span>&#125;        |</span><br><span class=\"line\">| t_user | telephone | KEEP_FIRST_N_LAST_M       | &#123;<span class=\"string\">&quot;first-n&quot;</span>:<span class=\"string\">&quot;3&quot;</span>,<span class=\"string\">&quot;last-m&quot;</span>:<span class=\"string\">&quot;4&quot;</span>,<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;*&quot;</span>&#125; |</span><br><span class=\"line\">| t_user | name      | MY_CUSTOM_MASK            | &#123;<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;#&quot;</span>&#125;                            |</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。 ShardingSphere官网 DistSQL DistSQL（Distributed SQL）是 Apache ShardingSphere 特有的操作语言。 它与标准 SQL 的使用方式完全一致，用于提供增量功能的 SQL 级别操作能力。 灵活的规则配置和资源管控能力是 Apache ShardingSphere 的特点之一。 在使用 4.x 及其之前版本时，开发者虽然可以像使用原生数据库一样操作数据，但却需要通过本地文件或注册中心配置资源和规则。然而，操作习惯变更，对于运维工程师并不友好。 从 5.x 版本开始，DistSQL（Distributed SQL）让用户可以像操作数据库一样操作 Apache ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的数据库产品。 DistSQL 细分为 RDL、RQL、RAL 和 RUL 四种类型。 RDL: Resource &amp; Rule Definition Language，负责资源和规则的创建、修改和删除。 RQL: Resource &amp; Rule Query Language，负责资源和规则的查询和展现。 RAL: Resource &amp; Rule Administration Language，负责强制路由、熔断、配置导入导出、数据迁移控制等管理功能。 RUL: Resource &amp; Rule Utility Language，负责 SQL 解析、SQL 格式化、执行计划预览等功能。 DistSQL 仅可以在 ShardingSphere-Proxy 中使用，不能在 ShardingSphere-JDBC 中使用。 示例准备 具体的语法，官网介绍的很详细，这里基于 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 中的配置进行示例说明。 为了尽可能多的使用 DistSQL 语法，这里仅在 global.yaml 中配置如下内容: 12345678910111213141516171819202122232425# 配置为基于 zookeeper 集群模式，为了演示 DistSQL 语法，这里需要将配置持久化，使用 JDBC 的单机模式也可以mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型 props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。# 配置用户和权限，因为 DistSQL 暂不支持 用户和权限管理，所以这里需要先配置用户和权限authority: users: - user: root@127.0.0.1 password: root admin: true - user: sharding@% password: sharding privilege: type: DATABASE_PERMITTED props: user-database-mappings: root@127.0.0.1=*,sharding@%=sharding_db 启动 ShardingSphere-Proxy 服务，并登录 12345678910111213# 启动 ShardingSphere-Proxy./shardingsphere-proxy-bin/bin/start.sh# 使用管理员登录mysql -h127.0.0.1 -uroot -proot -P3307# 查看当前用户权限mysql&gt; SHOW AUTHORITY RULE;+----------------------------+--------------------+----------------------------------------------------------------------+| users | provider | props |+----------------------------+--------------------+----------------------------------------------------------------------+| root@127.0.0.1; sharding@% | DATABASE_PERMITTED | &#123;&quot;user-database-mappings&quot;:&quot;root@127.0.0.1=*,sharding@%=sharding_db&quot;&#125; |+----------------------------+--------------------+----------------------------------------------------------------------+1 row in set (0.49 sec) 全局配置，即global.yaml中的配置 全局配置对所有逻辑数据库有效 属性配置 配置文件中的配置 12props: sql-show: true # 控制台打印改写后的 SQL，便于排错，默认为 false DistSQL 语法 设置属性，官方文档 12# 这里要注意，属性名需要使用下划线格式SET DIST VARIABLE sql_show = true; 查看属性，官方文档 123456789101112131415161718192021222324252627mysql&gt; SHOW DIST VARIABLES;+-----------------------------------------+-----------------+| variable_name | variable_value |+-----------------------------------------+-----------------+| agent_plugins_enabled | true || cached_connections | 0 || cdc_server_port | 33071 || check_table_metadata_enabled | false || kernel_executor_size | 0 || load_table_metadata_batch_size | 1000 || max_connections_size_per_query | 1 || proxy_backend_query_fetch_size | -1 || proxy_default_port | 3307 || proxy_frontend_database_protocol_type | || proxy_frontend_executor_size | 0 || proxy_frontend_flush_threshold | 128 || proxy_frontend_max_connections | 0 || proxy_frontend_ssl_cipher | || proxy_frontend_ssl_enabled | false || proxy_frontend_ssl_version | TLSv1.2,TLSv1.3 || proxy_meta_data_collector_enabled | false || proxy_netty_backlog | 1024 || sql_show | true || sql_simple | false || system_log_level | INFO || system_schema_metadata_assembly_enabled | true |+-----------------------------------------+-----------------+ 分布式事务配置 配置文件中的配置 123transaction: defaultType: XA providerType: Atomikos DistSQL 语法 查看事务规则，官方文档 1SHOW TRANSACTION RULE; 修改事务规则，官方文档 123ALTER TRANSACTION RULE( DEFAULT=&quot;XA&quot;, TYPE(NAME=&quot;Atomikos&quot;)); 规则配置，即database-xxx.yaml中的配置 以下 DistSQL 仅可以在逻辑库中执行，所以需要先创建一个逻辑数据库 12345mysql&gt; CREATE DATABASE sharding_db;Query OK, 0 rows affected (0.03 sec)mysql&gt; use sharding_db;Database changed 数据源配置 在 DistSQL中，官方将数据源叫做存储单元(STORAGE UNIT) 配置文件中的配置 12345678910dataSources: ds_0: # 逻辑数据源名称 url: jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 # 注意这里属性为 url username: root password: newpwd ds_1: url: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd DistSQL 语法 注册存储单元，官方文档 1234567891011REGISTER STORAGE UNIT ds_0 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;);REGISTER STORAGE UNIT ds_1 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;); 查询存储单元，官方文档 1SHOW STORAGE UNITS FROM sharding_db \\G; 修改存储单元，官方文档 123456ALTER STORAGE UNIT ds_1 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;, PROPERTIES(&quot;maximumPoolSize&quot;=10,&quot;idleTimeout&quot;=30000)); 取消注册存储单元，官方文档 12# 无法移除已经被规则使用的存储单元UNREGISTER STORAGE UNIT ds_0; 单表配置 配置文件中的配置 12345rules: - !SINGLE # 单表规则配置，单表规则优先级高于分库分表规则 tables: # MySQL 风格 - ds_0.t_address # 加载指定单表 DistSQL 语法 加载单表，官方文档 1LOAD SINGLE TABLE ds_0.t_address; 查询单表，官方文档 1SHOW SINGLE TABLES; 卸载单表，官方文档 1UNLOAD SINGLE TABLE ds_0.t_address; 广播表配置 广播表，即所有数据源都包含的表，比如字典表 1234rules: - !BROADCAST # 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个 tables: - dict # 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。 DistSQL 语法 创建广播表，官方文档 1CREATE BROADCAST TABLE RULE dict; 删除广播表，官方文档 1DROP BROADCAST TABLE RULE dict; 查询广播表，官方文档 1234# 查询当前逻辑库中具有广播规则的表SHOW BROADCAST TABLE RULES;# 查询指定数据库中具有广播规则的表SHOW BROADCAST TABLE RULES FROM sharding_db; 分库分表配置 单分片键，Long 类型 12345678910111213141516171819202122232425262728293031rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 course: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.course_$&#123;1..2&#125; # 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: course_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: cid shardingAlgorithmName: course_inline keyGenerateStrategy: # 分布式序列策略 column: cid # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 course_inline: # 定义名称，在上面引用 type: INLINE # 基于行表达式的分片算法，这里使用 MOD 会报错 props: # 属性 algorithm-expression: course_$&#123;cid % 2 + 1&#125; # 表达式，这是因为表名称为 course_1, course_2 allow-range-query-with-inline-sharding: true # 允许范围查询 course_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; # 表示 ds_0, ds_1 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则，官方文档 123456CREATE SHARDING TABLE RULE course ( DATANODES(&quot;ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=cid,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;course_$&#123;cid % 2 + 1&#125;&quot;,&quot;allow-range-query-with-inline-sharding&quot;=true )))), KEY_GENERATE_STRATEGY(COLUMN=cid,TYPE(NAME=&quot;snowflake&quot;))); 单分片键，String 类型 123456789101112131415161718192021222324252627282930313233343536rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_user: actualDataNodes: ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_inline # 分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: id # 自增列名称，字符串类型# keyGeneratorName: uuid # 分布式序列算法名称 keyGeneratorName: custom_snowflake_string # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_user_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;Math.abs(id.hashCode()%2)&#125; # 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算 t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125; # 分表，t_user_0, t_user_1 keyGenerators: # 分布式序列算法 uuid: # 定义名称 type: UUID # 字符串主键，String custom_snowflake_string: type: CUSTOM_SNOWFLAKE_STRING # 自定义雪花算法，String，spi props: workerId: 2 datacenterId: 2 DistSQL 语法 创建分片规则 123456CREATE SHARDING TABLE RULE t_user ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;Math.abs(id.hashCode()%2)&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;&quot;)))), KEY_GENERATE_STRATEGY(COLUMN=id,TYPE(NAME=&quot;CUSTOM_SNOWFLAKE_STRING&quot;))); 多分片键，Long 类型 12345678910111213141516171819202122232425262728293031323334353637383940414243444546rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_order_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id shardingAlgorithmName: t_order-complex-algorithm keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id # 分片列名称,多个逗号分隔# shardingAlgorithmName: t_order_item-class-based-algorithm # 基于自定义类的分片算法 shardingAlgorithmName: t_order_item-class-based-algorithm_spi # 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_order_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; t_order-complex-algorithm: type: COMPLEX_INLINE # 基于行表达式的复合分片算法 props: algorithm-expression: t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125; t_order_item-class-based-algorithm_spi: # SPI type: T_ORDER_ITEM_COMPLEX # 基于自定义类的分片算法 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则 12345678910111213CREATE SHARDING TABLE RULE t_order_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;complex_inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125;&quot;)))), KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=&quot;snowflake&quot;)));CREATE SHARDING TABLE RULE t_order_item_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;T_ORDER_ITEM_COMPLEX&quot;))), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;SNOWFLAKE&quot;))); 自动分片规则 上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则 12345678910111213141516171819202122232425262728293031323334rules: - !SHARDING # 分片规则配置 # 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致 bindingTables: - t_order,t_order_item autoTables: # 自动分片规则配置 t_order: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 mod_2: type: MOD # 基于 MOD 的分片算法 props: sharding-count: 2 # 分片数量，即 对 2 进行取余 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则 1234567891011CREATE SHARDING TABLE RULE t_order ( STORAGE_UNITS(ds_0,ds_1), SHARDING_COLUMN=user_id,TYPE(NAME=&quot;mod&quot;,PROPERTIES(&quot;sharding-count&quot;=&quot;2&quot;)), KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=&quot;snowflake&quot;)));CREATE SHARDING TABLE RULE t_order_item ( STORAGE_UNITS(ds_0,ds_1), SHARDING_COLUMN=user_id,TYPE(NAME=&quot;mod&quot;,PROPERTIES(&quot;sharding-count&quot;=&quot;2&quot;)), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;snowflake&quot;))); 其它分片操作语句 查询分片规则，官方文档 123456# 查看当前逻辑库下的所有分片规则SHOW SHARDING TABLE RULES \\G;# 查看指定逻辑库下的分片规则SHOW SHARDING TABLE RULES FROM sharding_db; \\G;# 查看指定分片规则SHOW SHARDING TABLE RULE t_user \\G; 修改分片规则，官网文档，与创建分片规则类似，将CREATE改为ALTER即可 123456ALTER SHARDING TABLE RULE t_order_item_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;T_ORDER_ITEM_COMPLEX&quot;))), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;SNOWFLAKE&quot;))); 删除分片规则，官网文档 123DROP SHARDING TABLE RULE t_order;# 删除多个表DROP SHARDING TABLE RULE t_order,t_order_item; 数据加密规则 12345678910111213141516rules: - !ENCRYPT # 数据加密配置 tables: t_user: # 加密表名称 columns: password: # 加密列名称 cipher: name: password # 密文列名称 encryptorName: aes_encryptor # 密文列加密算法名称 # 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/ encryptors: aes_encryptor: # 加解密算法名称 type: AES # 加解密算法类型 props: # 加解密算法属性配置 aes-key-value: 123456abc # AES 使用的 KEY digest-algorithm-name: SHA-1 # AES KEY 的摘要算法 DistSQL 语法 创建加密规则，官方文档 1234CREATE ENCRYPT RULE t_user (COLUMNS( (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=&#x27;AES&#x27;,PROPERTIES(&#x27;aes-key-value&#x27;=&#x27;123456abc&#x27;, &#x27;digest-algorithm-name&#x27;=&#x27;SHA-1&#x27;)))))); 修改加密规则 1234ALTER ENCRYPT RULE t_user (COLUMNS( (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=&#x27;AES&#x27;,PROPERTIES(&#x27;aes-key-value&#x27;=&#x27;123456abc&#x27;, &#x27;digest-algorithm-name&#x27;=&#x27;SHA-1&#x27;)))))); 删除加密规则 1DROP ENCRYPT RULE t_user; 查询加密规则，官方文档 123456# 查询当前逻辑库中所有加密规则SHOW ENCRYPT RULES \\G;# 获取指定逻辑库中的加密规则SHOW ENCRYPT RULES FROM sharding_db \\G;# 获取指定逻辑表中的加密规则SHOW ENCRYPT RULE t_user \\G; 数据脱敏规则 1234567891011121314151617181920212223242526272829303132rules: - !MASK # 数据脱敏配置 tables: t_user: # 脱敏表名称 columns: # 脱敏列配置 password: # 脱敏列名称 maskAlgorithm: md5_mask # 脱敏算法名称 email: maskAlgorithm: mask_before_special_chars_mask telephone: maskAlgorithm: keep_first_n_last_m_mask name: maskAlgorithm: my_mask maskAlgorithms: # 脱敏算法配置 md5_mask: # 自定义脱敏算法名称 type: MD5 # 脱敏算法类型，md5加密后展示 mask_before_special_chars_mask: type: MASK_BEFORE_SPECIAL_CHARS # 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com props: special-chars: &#x27;@&#x27; # 遇到 @ 之前的部分做脱敏 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 keep_first_n_last_m_mask: type: KEEP_FIRST_N_LAST_M # 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678 props: first-n: 3 # 保留前 3 位 last-m: 4 # 保留后 4 位 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 my_mask: type: MY_CUSTOM_MASK # 自定义脱敏算法名称 props: replace-char: &quot;#&quot; DistSQL 语法 创建脱敏规则，官方文档 123456789CREATE MASK RULE t_user ( COLUMNS( (NAME=password, TYPE(NAME=&#x27;MD5&#x27;)), (NAME=email, TYPE(NAME=&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;, PROPERTIES(&quot;special-chars&quot;=&quot;@&quot;, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=telephone, TYPE(NAME=&#x27;KEEP_FIRST_N_LAST_M&#x27;, PROPERTIES(&quot;first-n&quot;=3, &quot;last-m&quot;=4, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=`name`, TYPE(NAME=&#x27;MY_CUSTOM_MASK&#x27;, PROPERTIES(&quot;replace-char&quot;=&quot;#&quot;))) ));# 这里注意 name 是关键字，所以需要用 `` 包起来 修改脱敏规则 12345678ALTER MASK RULE t_user ( COLUMNS( (NAME=password, TYPE(NAME=&#x27;MD5&#x27;)), (NAME=email, TYPE(NAME=&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;, PROPERTIES(&quot;special-chars&quot;=&quot;@&quot;, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=telephone, TYPE(NAME=&#x27;KEEP_FIRST_N_LAST_M&#x27;, PROPERTIES(&quot;first-n&quot;=3, &quot;last-m&quot;=4, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=`name`, TYPE(NAME=&#x27;MY_CUSTOM_MASK&#x27;, PROPERTIES(&quot;replace-char&quot;=&quot;#&quot;))) )); 删除脱敏规则 1DROP MASK RULE t_user; 查询脱敏规则，官方文档 1234567891011121314# 查询当前逻辑库中所有脱敏规则SHOW MASK RULES;# 仅查询指定逻辑库中的脱敏规则SHOW MASK RULES FROM sharding_db;# 查询指定规则mysql&gt; SHOW MASK RULE t_user;+--------+-----------+---------------------------+-------------------------------------------------+| table | column | algorithm_type | algorithm_props |+--------+-----------+---------------------------+-------------------------------------------------+| t_user | password | MD5 | || t_user | email | MASK_BEFORE_SPECIAL_CHARS | &#123;&quot;replace-char&quot;:&quot;*&quot;,&quot;special-chars&quot;:&quot;@&quot;&#125; || t_user | telephone | KEEP_FIRST_N_LAST_M | &#123;&quot;first-n&quot;:&quot;3&quot;,&quot;last-m&quot;:&quot;4&quot;,&quot;replace-char&quot;:&quot;*&quot;&#125; || t_user | name | MY_CUSTOM_MASK | &#123;&quot;replace-char&quot;:&quot;#&quot;&#125; |+--------+-----------+---------------------------+-------------------------------------------------+","summary":"摘要 本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。 ShardingSphere官网","date_published":"2025-09-11T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/","url":"https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/","title":"SpringBoot3 + ShardingSphere-Proxy5.5.2 运行模式","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文在 <a href=\"/2025/09/04/springboot3-shardingsphere-proxy/\" title=\"SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表\">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 的基础上进行修改。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"运行模式说明\">运行模式说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/dev-manual/mode/\">运行模式</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 运行模式分为两种：单机模式(Standalone) 和 集群模式(Cluster)。</p>\n</li>\n<li class=\"lvl-2\">\n<p>运行模式就是指定将<code>元数据</code>(认证、数据源、分片规则等等)持久化的存储方式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>默认运行模式为单机模式，使用<code>H2</code>的内存方式。</p>\n</li>\n</ul>\n<h2 id=\"单机模式-Standalone\">单机模式(Standalone)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>单机模式能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知。 通过某一实例更新元数据之后，会导致其他实例由于获取不到最新的元数据而产生不一致的错误。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用于工程师在本地搭建 Apache ShardingSphere 环境。</p>\n</li>\n<li class=\"lvl-2\">\n<p>单机模式目前仅支持一种：JDBC，即数据库持久化。以下为默认值(<code>JDBCRepositoryPropertyKey</code>)。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>数据类型</th>\n<th>说明</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provider</td>\n<td>String</td>\n<td>元数据存储类型，可选值为 <code>H2</code>、<code>MySQL</code> 、<code>EmbeddedDerby</code>、<code>DerbyNetworkServer</code>、<code>HSQLDB</code></td>\n<td>H2</td>\n</tr>\n<tr>\n<td>jdbc_url</td>\n<td>String</td>\n<td>JDBC URL</td>\n<td><code>jdbc:h2:mem:config;DB_CLOSE_DELAY=0;DATABASE_TO_UPPER=false;MODE=MYSQL</code></td>\n</tr>\n<tr>\n<td>username</td>\n<td>String</td>\n<td>账号</td>\n<td>sa</td>\n</tr>\n<tr>\n<td>password</td>\n<td>String</td>\n<td>密码</td>\n<td>空（无默认值）</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里以 Mysql 存储元数据为例，相关属性参考<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#jdbc-%E6%8C%81%E4%B9%85%E5%8C%96\">官网说明</a></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">JDBC</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">provider:</span> <span class=\"string\">MySQL</span></span><br><span class=\"line\">      <span class=\"attr\">jdbc_url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">      <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时需要将 mysql 的驱动 jar 包 添加到 <code>ext-lib</code> 目录下</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动 ShardingSphere Proxy 成功后会自动在上面的数据库中创建一张表，并将配置文件的中的元数据存储进去</p>\n</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `repository` (</span><br><span class=\"line\">  `id` <span class=\"type\">varchar</span>(<span class=\"number\">36</span>) <span class=\"keyword\">COLLATE</span> utf8mb4_bin <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `key` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  `<span class=\"keyword\">value</span>` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  `parent` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB <span class=\"keyword\">DEFAULT</span> CHARSET<span class=\"operator\">=</span>utf8mb4 <span class=\"keyword\">COLLATE</span><span class=\"operator\">=</span>utf8mb4_bin;</span><br></pre></td></tr></table></figure>\n<h3 id=\"重点说明\">重点说明</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当数据库中不存在该表时，会自动创建该表，并将配置文件的元数据插入该表中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当数据库中已存在该表时，会读取该表中的数据并将其加载到内存，而不会读取配置文件中的元数据。即此时配置文件中的元数据不会生效。</p>\n</li>\n<li class=\"lvl-2\">\n<p>若此时想修改配置规则，有三种方法：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">1.删除该表，修改配置文件后重新启动Proxy，此时会重新创建该表并加载配置文件中的元数据。</li>\n<li class=\"lvl-4\">2.手工修改数据表中的元数据，但修改后需要重新启动Proxy才会加载新的元数据。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li>\n<li class=\"lvl-4\">3.<code>[推荐]</code>登录逻辑数据库后，使用 <a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a> 动态修改配置，修改后的配置会被保存在该表中，并立即生效，无需重启Proxy。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>开发和测试环境可以直接使用默认的 H2 内存数据库，生产环境可以使用 MySQL等数据库对元数据进行持久化保存或者使用下面的集群模式。</p>\n</li>\n</ul>\n<h2 id=\"集群模式-Cluster\">集群模式(Cluster)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群模式提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调的能力。 它能够提供计算能力水平扩展和高可用等分布式系统必备的能力，集群环境需要通过独立部署的注册中心来存储元数据和协调节点状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在生产环境建议使用集群模式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>这里以 zookeeper 集群模式为例，相关属性参考<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#zookeeper-%E6%8C%81%E4%B9%85%E5%8C%96\">官网说明</a></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型，当前版本仅支持 ZooKeeper 和 etcd</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"重点说明-2\">重点说明</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>不要手工修改 Zookeeper 集群中的 namespace 下的配置信息!</p>\n</li>\n<li class=\"lvl-2\">\n<p>既然是集群，就需要多个 ShardingSphere-Proxy 实例。 当第一个 ShardingSphere-Proxy 实例 启动后，其它相同配置的 ShardingSphere-Proxy 实例仅需要一个 <code>global.yaml</code> 全局配置文件即可，并仅需在其中配置上面的<code>运行模式</code>信息，而不需要再配置其它配置，比如认证、数据源、分片规则等信息，这些信息会通过 Zookeeper 集群中的 namespace 获取并保存到本地内存中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>每个 ShardingSphere-Proxy 实例启动时，都会自动将自己注册到 Zookeeper 集群中指定的 namespace 下，并自动获取该 namespace 下的配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中不存在指定的 namespace 时，此时第一次启动 ShardingSphere-Proxy 会自动在 Zookeeper 中创建 namespace，并写入配置文件中的配置信息到 Zookeeper 中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中已存在指定的 namespace 时，此时再启动 ShardingSphere-Proxy 会自动从 Zookeeper 中读取 namespace 下的配置信息，并将其加载到内存中，不会再读取本地配置文件中的配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中已存在指定的 namespace 时，根据上面的规则，此时修改本地的配置文件中的分片规则后重启ShardingSphere-Proxy 并不会生效。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">此时有三种方法：\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">\n<ol>\n<li class=\"lvl-9\">删除 Zookeeper 集群中指定的 namespace，然后重启 ShardingSphere-Proxy。这种方法有个弊端，即会导致连接到相同 ZooKeeper 集群的 namespace 的其它 ShardingSphere-Proxy 实例数据丢失(完全不可用)，也需要重启才能重新获取到数据。</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"2\">\n<li class=\"lvl-9\">手工修改 Zookeeper 集群中指定的 namespace 下的分片规则，修改后会立即同步到所有 ShardingSphere-Proxy 实例。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"3\">\n<li class=\"lvl-9\"><code>[推荐]</code>登录逻辑数据库后，使用 <a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a> 动态修改配置，此时会自动同步到所有 ShardingSphere-Proxy 实例。所以，灵活掌握 <code>DistSQL</code> 是维护 ShardingSphere-Proxy 集群的关键。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>多个 ShardingSphere-Proxy 实例 可以通过负载均衡器，比如 Nginx，将请求路由到不同的 ShardingSphere-Proxy 实例。比如：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream&#123;</span><br><span class=\"line\">    upstream shardingsphere_proxy&#123;</span><br><span class=\"line\">        server  10.10.21.35:3307;</span><br><span class=\"line\">        server  10.10.21.36:3307;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 3310;</span><br><span class=\"line\">        proxy_connect_timeout 20s;</span><br><span class=\"line\">        proxy_timeout 5m;</span><br><span class=\"line\">        proxy_pass shardingsphere_proxy;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"与-Spring-Boot3-整合\">与 Spring Boot3 整合</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论是 <code>单机模式</code> 还是 <code>集群模式</code>，其目的都是将 <code>配置</code> 保存到独立的 <code>配置中心(数据库 或 Zookeeper)</code>中，并让其它 <code>ShardingSphere-Proxy</code> 实例从该配置中心中读取配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>前文我们介绍过 <code>Spring Boot3</code> + <code>ShardingSphere-Proxy</code> 就相当于是集成普通的MySql数据库，而 <code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code> 就需要单独在本地配置各种规则。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 <code>ShardingSphere-JDBC</code> 也可以从 <code>配置中心</code> 中读取配置信息，这样我们就不需要在本地配置任何规则了，我们仅需要在 <code>sharding.yaml</code> 中配置好<code>运行模式</code>，并配置好 <code>databaseName</code> 的名称即可。注意，此时配置中心的的事务不能是 <code>XA</code>，因为<code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code>目前不支持 <code>XA</code> 事务。</p>\n</li>\n<li class=\"lvl-2\">\n<p>此时，springboot项目启动后会拉取<code>配置中心</code>中的配置信息并将其保存到本地内存，本地配置文件中的其它配置信息会被忽略。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/G3kESF.png\" alt=\"\"></p>\n</li>\n</ul>\n<h3 id=\"单机模式\">单机模式</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-03\">代码示例</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 DistSQL 改规则后，必须重启应用才能生效</p>\n</li>\n<li class=\"lvl-2\">\n<p>sharding.yaml</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">JDBC</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">provider:</span> <span class=\"string\">MySQL</span></span><br><span class=\"line\">      <span class=\"attr\">jdbc_url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">      <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"><span class=\"comment\"># 数据库名称，默认值：logic_db</span></span><br><span class=\"line\"><span class=\"attr\">databaseName:</span> <span class=\"string\">sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Maven 依赖</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mysql<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mysql-connector-j<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.baomidou<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.5.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-jdbc<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.hanqf<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>algorithm-swapper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"集群模式\">集群模式</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-04\">代码示例</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 DistSQL 改规则后，立即推送到所有实例，无需重启应用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>sharding.yaml，注意这里一定要配置 <code>databaseName</code></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># # 开启集群模式</span></span><br><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class=\"line\"><span class=\"comment\"># 数据库名称，默认值：logic_db</span></span><br><span class=\"line\"><span class=\"attr\">databaseName:</span> <span class=\"string\">sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Maven 依赖，注意要加上 <code>shardingsphere-cluster-mode-repository-zookeeper</code> 的依赖</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mysql<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mysql-connector-j<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.baomidou<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.5.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-jdbc<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.hanqf<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>algorithm-swapper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- shardingsphere-cluster-mode-repository-zookeeper --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-cluster-mode-repository-zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"如何选择\">如何选择</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当我使用<code>springboot3+shardingSphere-JDBC5.5.2</code>时，我应该使用本地<code>配置文件</code>的方式还是使用<code>配置中心</code>（比如：zookeeper）的方式呢？</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>方式</th>\n<th>部署复杂度</th>\n<th>配置动态更新</th>\n<th>多实例共享配置</th>\n<th>热更新支持</th>\n<th>适用环境</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>本地配置文件</td>\n<td>简单</td>\n<td>不支持</td>\n<td>不支持</td>\n<td>否</td>\n<td>开发/测试/小型项目</td>\n</tr>\n<tr>\n<td>配置中心（ZooKeeper/etcd）</td>\n<td>略高</td>\n<td>支持</td>\n<td>支持</td>\n<td>是</td>\n<td>生产/分布式环境</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注意</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">DistSQL 目前确实只支持在 ShardingSphere-Proxy 上执行，并且 Proxy 只支持 MySQL 和 PostgreSQL 协议。</li>\n<li class=\"lvl-4\">如果你在 Spring Boot + ShardingSphere-JDBC 里用 其它数据库（比如 SQL Server、Oracle、DB2 等），就无法直接通过 DistSQL 去动态改配置。</li>\n<li class=\"lvl-4\">此时你可以选择通过 Zookeeper 的客户端直接修改或配置规则，也可以不选择 <code>配置中心</code> 的方式，直接使用 <code>本地配置文件</code>。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"什么时候需要分库分表\">什么时候需要分库分表</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分库分表的主要目的是 <strong>解决数据量大带来的性能、可用性和可扩展性问题</strong>。通常需要考虑的几个关键指标：</p>\n</li>\n</ul>\n<h3 id=\"1-数据量指标\">1. 数据量指标</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>单表数据量过大</strong>：一般来说，单表数据量在 <strong>千万级</strong> 以上时，查询、写入和索引的性能会明显下降。</p>\n</li>\n<li class=\"lvl-2\">\n<p>例如：一个订单表一天有上百万条数据，一年下来可能有上亿条，单表性能会成为瓶颈。</p>\n</li>\n</ul>\n<h3 id=\"2-访问量指标\">2. 访问量指标</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>高并发写入或查询</strong>：数据库连接、事务锁、IO 等资源会成为瓶颈。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果你的系统每天有上千万的请求，数据库可能无法承受。</p>\n</li>\n</ul>\n<h3 id=\"3-业务隔离需求\">3. 业务隔离需求</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>不同业务的数据分离，避免单个业务影响整个数据库的稳定性。</p>\n</li>\n<li class=\"lvl-2\">\n<p>例如：电商系统中的订单和日志数据，日志量非常大，和订单分开存储更合理。</p>\n</li>\n</ul>\n<h3 id=\"4-运营与成本因素\">4. 运营与成本因素</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分库分表后，可以分布到多个数据库实例上，支持 <strong>水平扩展</strong>，而不必依赖昂贵的单机数据库。</p>\n</li>\n</ul>\n<h2 id=\"使用-ShardingSphere-可能带来的问题\">使用 ShardingSphere 可能带来的问题</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用 <strong>ShardingSphere</strong> 可以方便地解决分库分表问题，但在实际生产中，它会带来一些新的复杂性和潜在问题，主要体现在性能、运维、功能限制等方面。</p>\n</li>\n</ul>\n<h3 id=\"1-性能与延迟\">1. 性能与延迟</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>跨库 JOIN 性能差</strong><br>\n分库分表后，跨库的 <code>JOIN</code> 查询会在各个分片上分别执行，然后在 ShardingSphere 层合并结果，性能明显下降。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">例如：订单表在多个库，查询订单 + 用户信息时必须跨库 JOIN，执行效率比单库低很多。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p><strong>分页查询慢</strong><br>\n分库分表后，如果要全局排序 + 分页，需要所有分片查出数据再合并，代价非常大。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">解决方式：使用分片键范围分页，或引入 ElasticSearch/ClickHouse 做搜索和统计。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p><strong>广播表压力</strong><br>\n配置了广播表（每个库一份完整数据）后，更新需要同步所有库，写入性能下降。</p>\n</li>\n</ul>\n<h3 id=\"2-SQL-兼容性限制\">2. SQL 兼容性限制</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>复杂 SQL 支持不完整</strong><br>\nShardingSphere 对某些复杂 SQL（如子查询、窗口函数）支持有限，可能报错或性能极差。</p>\n</li>\n<li class=\"lvl-2\">\n<p><strong>存储过程、触发器受限</strong><br>\n分库分表后，存储过程、触发器在分片数据库执行可能不一致，维护成本高。</p>\n</li>\n</ul>\n<h3 id=\"3-分布式事务问题\">3. 分布式事务问题</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere 支持 <strong>XA 分布式事务</strong>，但性能不如单机事务，出现网络抖动时可能会卡住。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果业务需要强一致性，必须结合可靠消息或 TCC、SAGA 等分布式事务模式，架构会更复杂。</p>\n</li>\n</ul>\n<h3 id=\"4-运维与管理复杂度\">4. 运维与管理复杂度</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>分片规则变更困难</strong><br>\n例如，最初按 <code>user_id % 2</code> 分成两个库，后续想增加到 4 个库，需要迁移数据，非常麻烦。</p>\n</li>\n<li class=\"lvl-2\">\n<p><strong>监控与调优</strong><br>\nShardingSphere 增加了中间层，SQL 路由、执行计划、数据节点状态都需要额外的监控工具支持。</p>\n</li>\n</ul>\n<h3 id=\"5-成本与学习曲线\">5. 成本与学习曲线</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置相对复杂：分片规则、读写分离、分布式事务、弹性扩容都需要仔细设计。</p>\n</li>\n<li class=\"lvl-2\">\n<p>学习曲线较陡：开发和运维人员必须了解 ShardingSphere 的工作机制，否则定位问题很困难。</p>\n</li>\n</ul>\n<h3 id=\"6-高可用与扩展问题\">6. 高可用与扩展问题</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere-JDBC 是应用内库，无法独立扩展，需要依赖应用扩容。</p>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 支持集群，但需要自己搭建高可用架构，涉及负载均衡、故障切换等问题。</p>\n</li>\n</ul>\n<h2 id=\"其它技术方案：分布式数据库\">其它技术方案：分布式数据库</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>开源产品: 核心功能完全开源，企业版提供额外商业特性</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>数据库</th>\n<th>架构类型</th>\n<th>SQL 兼容性</th>\n<th>分布式事务支持</th>\n<th>数据存储模型</th>\n<th>主要特点</th>\n<th>典型应用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><a href=\"https://www.pingcap.com/\">TiDB</a></strong></td>\n<td>分布式 HTAP</td>\n<td>MySQL 协议兼容</td>\n<td>支持（Percolator 模型）</td>\n<td>行存 + 列存混合</td>\n<td>开源、云原生、强一致性、弹性扩展</td>\n<td>在线事务处理 + 实时分析</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://en.oceanbase.com/\">OceanBase</a></strong></td>\n<td>分布式关系型数据库</td>\n<td>MySQL/Oracle 兼容</td>\n<td>支持（两阶段提交）</td>\n<td>行存</td>\n<td>高性能、金融级事务、阿里蚂蚁金服核心系统使用</td>\n<td>金融、电商、核心交易系统</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.cockroachlabs.com/\">CockroachDB</a></strong></td>\n<td>分布式 NewSQL</td>\n<td>PostgreSQL 兼容</td>\n<td>支持（分布式事务）</td>\n<td>行存</td>\n<td>类 Spanner 架构，全球分布，强一致性</td>\n<td>全球化分布式应用</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.citusdata.com/\">Citus</a> (PostgreSQL)</strong></td>\n<td>PostgreSQL 扩展</td>\n<td>PostgreSQL 兼容</td>\n<td>部分支持（基于逻辑分片）</td>\n<td>行存</td>\n<td>基于 PostgreSQL 的分布式扩展，支持大规模 OLAP</td>\n<td>大数据实时分析、BI 场景</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://vitess.io/\">Vitess</a></strong></td>\n<td>分布式中间件 + 存储</td>\n<td>MySQL 协议兼容</td>\n<td>弱事务（最终一致性）</td>\n<td>行存</td>\n<td>YouTube 开源，K8s 友好，分库分表自动化</td>\n<td>大规模 Web 应用，在线服务</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.yugabyte.com/\">YugabyteDB</a></strong></td>\n<td>分布式 SQL + NoSQL</td>\n<td>PostgreSQL 兼容</td>\n<td>支持（两阶段提交）</td>\n<td>行存 + 列存混合</td>\n<td>融合 NewSQL 和 NoSQL，强一致性，跨区域部署</td>\n<td>金融级事务 + 分析混合场景</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>商业产品</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>数据库</th>\n<th>架构类型</th>\n<th>SQL 兼容性</th>\n<th>分布式事务支持</th>\n<th>数据存储模型</th>\n<th>主要特点</th>\n<th>典型应用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><a href=\"https://www.alibabacloud.com/product/polardb\">PolarDB</a></strong></td>\n<td>云原生分布式数据库</td>\n<td>MySQL/PostgreSQL 兼容</td>\n<td>支持（云端分布式事务）</td>\n<td>行存</td>\n<td>阿里云产品，弹性扩容，存储计算分离</td>\n<td>云上企业数据库解决方案</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.huaweicloud.com/product/gaussdb.html\">GaussDB</a></strong></td>\n<td>分布式关系型数据库</td>\n<td>MySQL/Oracle 兼容</td>\n<td>支持（分布式事务）</td>\n<td>行存 + 列存混合</td>\n<td>华为推出，分布式 HTAP，云原生架构</td>\n<td>企业级 OLTP + OLAP 混合负载</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://cloud.google.com/spanner\">Spanner</a></strong></td>\n<td>全球分布式数据库</td>\n<td>类 SQL</td>\n<td>支持（TrueTime 协议）</td>\n<td>行存</td>\n<td>Google 云产品，全球分布式强一致事务</td>\n<td>全球化分布式事务，金融场景</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://aws.amazon.com/rds/aurora/\">Amazon Aurora</a></strong></td>\n<td>云原生分布式关系型数据库</td>\n<td>MySQL/PostgreSQL 兼容</td>\n<td>支持（单实例事务，多 AZ 高可用）</td>\n<td>行存</td>\n<td>AWS 托管，自动扩展存储，多可用区高可用</td>\n<td>OLTP、企业级业务</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。 ShardingSphere官网 本文在 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 的基础上进行修改。 运行模式说明 运行模式 ShardingSphere-Proxy 运行模式分为两种：单机模式(Standalone) 和 集群模式(Cluster)。 运行模式就是指定将元数据(认证、数据源、分片规则等等)持久化的存储方式。 默认运行模式为单机模式，使用H2的内存方式。 单机模式(Standalone) 单机模式能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知。 通过某一实例更新元数据之后，会导致其他实例由于获取不到最新的元数据而产生不一致的错误。 适用于工程师在本地搭建 Apache ShardingSphere 环境。 单机模式目前仅支持一种：JDBC，即数据库持久化。以下为默认值(JDBCRepositoryPropertyKey)。 名称 数据类型 说明 默认值 provider String 元数据存储类型，可选值为 H2、MySQL 、EmbeddedDerby、DerbyNetworkServer、HSQLDB H2 jdbc_url String JDBC URL jdbc:h2:mem:config;DB_CLOSE_DELAY=0;DATABASE_TO_UPPER=false;MODE=MYSQL username String 账号 sa password String 密码 空（无默认值） 这里以 Mysql 存储元数据为例，相关属性参考官网说明 123456789mode: type: Standalone repository: type: JDBC props: provider: MySQL jdbc_url: jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd 此时需要将 mysql 的驱动 jar 包 添加到 ext-lib 目录下 启动 ShardingSphere Proxy 成功后会自动在上面的数据库中创建一张表，并将配置文件的中的元数据存储进去 1234567CREATE TABLE `repository` ( `id` varchar(36) COLLATE utf8mb4_bin NOT NULL, `key` text COLLATE utf8mb4_bin, `value` text COLLATE utf8mb4_bin, `parent` text COLLATE utf8mb4_bin, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 重点说明 当数据库中不存在该表时，会自动创建该表，并将配置文件的元数据插入该表中。 当数据库中已存在该表时，会读取该表中的数据并将其加载到内存，而不会读取配置文件中的元数据。即此时配置文件中的元数据不会生效。 若此时想修改配置规则，有三种方法： 1.删除该表，修改配置文件后重新启动Proxy，此时会重新创建该表并加载配置文件中的元数据。 2.手工修改数据表中的元数据，但修改后需要重新启动Proxy才会加载新的元数据。但手工修改需要对数据的组织形式非常清楚，否则极易出错。 3.[推荐]登录逻辑数据库后，使用 DistSQL 动态修改配置，修改后的配置会被保存在该表中，并立即生效，无需重启Proxy。 开发和测试环境可以直接使用默认的 H2 内存数据库，生产环境可以使用 MySQL等数据库对元数据进行持久化保存或者使用下面的集群模式。 集群模式(Cluster) 集群模式提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调的能力。 它能够提供计算能力水平扩展和高可用等分布式系统必备的能力，集群环境需要通过独立部署的注册中心来存储元数据和协调节点状态。 在生产环境建议使用集群模式。 这里以 zookeeper 集群模式为例，相关属性参考官网说明 1234567891011mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型，当前版本仅支持 ZooKeeper 和 etcd props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。 重点说明 不要手工修改 Zookeeper 集群中的 namespace 下的配置信息! 既然是集群，就需要多个 ShardingSphere-Proxy 实例。 当第一个 ShardingSphere-Proxy 实例 启动后，其它相同配置的 ShardingSphere-Proxy 实例仅需要一个 global.yaml 全局配置文件即可，并仅需在其中配置上面的运行模式信息，而不需要再配置其它配置，比如认证、数据源、分片规则等信息，这些信息会通过 Zookeeper 集群中的 namespace 获取并保存到本地内存中。 每个 ShardingSphere-Proxy 实例启动时，都会自动将自己注册到 Zookeeper 集群中指定的 namespace 下，并自动获取该 namespace 下的配置信息。 当 Zookeeper 集群中不存在指定的 namespace 时，此时第一次启动 ShardingSphere-Proxy 会自动在 Zookeeper 中创建 namespace，并写入配置文件中的配置信息到 Zookeeper 中。 当 Zookeeper 集群中已存在指定的 namespace 时，此时再启动 ShardingSphere-Proxy 会自动从 Zookeeper 中读取 namespace 下的配置信息，并将其加载到内存中，不会再读取本地配置文件中的配置信息。 当 Zookeeper 集群中已存在指定的 namespace 时，根据上面的规则，此时修改本地的配置文件中的分片规则后重启ShardingSphere-Proxy 并不会生效。 此时有三种方法： 删除 Zookeeper 集群中指定的 namespace，然后重启 ShardingSphere-Proxy。这种方法有个弊端，即会导致连接到相同 ZooKeeper 集群的 namespace 的其它 ShardingSphere-Proxy 实例数据丢失(完全不可用)，也需要重启才能重新获取到数据。 手工修改 Zookeeper 集群中指定的 namespace 下的分片规则，修改后会立即同步到所有 ShardingSphere-Proxy 实例。但手工修改需要对数据的组织形式非常清楚，否则极易出错。 [推荐]登录逻辑数据库后，使用 DistSQL 动态修改配置，此时会自动同步到所有 ShardingSphere-Proxy 实例。所以，灵活掌握 DistSQL 是维护 ShardingSphere-Proxy 集群的关键。 多个 ShardingSphere-Proxy 实例 可以通过负载均衡器，比如 Nginx，将请求路由到不同的 ShardingSphere-Proxy 实例。比如： 123456789101112stream&#123; upstream shardingsphere_proxy&#123; server 10.10.21.35:3307; server 10.10.21.36:3307; &#125; server&#123; listen 3310; proxy_connect_timeout 20s; proxy_timeout 5m; proxy_pass shardingsphere_proxy; &#125;&#125; 与 Spring Boot3 整合 无论是 单机模式 还是 集群模式，其目的都是将 配置 保存到独立的 配置中心(数据库 或 Zookeeper)中，并让其它 ShardingSphere-Proxy 实例从该配置中心中读取配置信息。 前文我们介绍过 Spring Boot3 + ShardingSphere-Proxy 就相当于是集成普通的MySql数据库，而 Spring Boot3 + ShardingSphere-JDBC 就需要单独在本地配置各种规则。 实际上 ShardingSphere-JDBC 也可以从 配置中心 中读取配置信息，这样我们就不需要在本地配置任何规则了，我们仅需要在 sharding.yaml 中配置好运行模式，并配置好 databaseName 的名称即可。注意，此时配置中心的的事务不能是 XA，因为Spring Boot3 + ShardingSphere-JDBC目前不支持 XA 事务。 此时，springboot项目启动后会拉取配置中心中的配置信息并将其保存到本地内存，本地配置文件中的其它配置信息会被忽略。 单机模式 代码示例 通过 DistSQL 改规则后，必须重启应用才能生效 sharding.yaml 1234567891011mode: type: Standalone repository: type: JDBC props: provider: MySQL jdbc_url: jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd# 数据库名称，默认值：logic_dbdatabaseName: sharding_db Maven 依赖 123456789101112131415161718192021222324&lt;!-- MySQL Connector/J --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mybatis plus，本项目用到，非必须 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 自定义 的 SPI --&gt;&lt;dependency&gt; &lt;groupId&gt;com.hanqf&lt;/groupId&gt; &lt;artifactId&gt;algorithm-swapper&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 集群模式 代码示例 通过 DistSQL 改规则后，立即推送到所有实例，无需重启应用。 sharding.yaml，注意这里一定要配置 databaseName 1234567891011121314# # 开启集群模式mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型 props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。# 数据库名称，默认值：logic_dbdatabaseName: sharding_db Maven 依赖，注意要加上 shardingsphere-cluster-mode-repository-zookeeper 的依赖 123456789101112131415161718192021222324252627282930&lt;!-- MySQL Connector/J --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mybatis plus，本项目用到，非必须 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 自定义 的 SPI --&gt;&lt;dependency&gt; &lt;groupId&gt;com.hanqf&lt;/groupId&gt; &lt;artifactId&gt;algorithm-swapper&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- shardingsphere-cluster-mode-repository-zookeeper --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-cluster-mode-repository-zookeeper&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt; 如何选择 当我使用springboot3+shardingSphere-JDBC5.5.2时，我应该使用本地配置文件的方式还是使用配置中心（比如：zookeeper）的方式呢？ 方式 部署复杂度 配置动态更新 多实例共享配置 热更新支持 适用环境 本地配置文件 简单 不支持 不支持 否 开发/测试/小型项目 配置中心（ZooKeeper/etcd） 略高 支持 支持 是 生产/分布式环境 注意 DistSQL 目前确实只支持在 ShardingSphere-Proxy 上执行，并且 Proxy 只支持 MySQL 和 PostgreSQL 协议。 如果你在 Spring Boot + ShardingSphere-JDBC 里用 其它数据库（比如 SQL Server、Oracle、DB2 等），就无法直接通过 DistSQL 去动态改配置。 此时你可以选择通过 Zookeeper 的客户端直接修改或配置规则，也可以不选择 配置中心 的方式，直接使用 本地配置文件。 什么时候需要分库分表 分库分表的主要目的是 解决数据量大带来的性能、可用性和可扩展性问题。通常需要考虑的几个关键指标： 1. 数据量指标 单表数据量过大：一般来说，单表数据量在 千万级 以上时，查询、写入和索引的性能会明显下降。 例如：一个订单表一天有上百万条数据，一年下来可能有上亿条，单表性能会成为瓶颈。 2. 访问量指标 高并发写入或查询：数据库连接、事务锁、IO 等资源会成为瓶颈。 如果你的系统每天有上千万的请求，数据库可能无法承受。 3. 业务隔离需求 不同业务的数据分离，避免单个业务影响整个数据库的稳定性。 例如：电商系统中的订单和日志数据，日志量非常大，和订单分开存储更合理。 4. 运营与成本因素 分库分表后，可以分布到多个数据库实例上，支持 水平扩展，而不必依赖昂贵的单机数据库。 使用 ShardingSphere 可能带来的问题 使用 ShardingSphere 可以方便地解决分库分表问题，但在实际生产中，它会带来一些新的复杂性和潜在问题，主要体现在性能、运维、功能限制等方面。 1. 性能与延迟 跨库 JOIN 性能差 分库分表后，跨库的 JOIN 查询会在各个分片上分别执行，然后在 ShardingSphere 层合并结果，性能明显下降。 例如：订单表在多个库，查询订单 + 用户信息时必须跨库 JOIN，执行效率比单库低很多。 分页查询慢 分库分表后，如果要全局排序 + 分页，需要所有分片查出数据再合并，代价非常大。 解决方式：使用分片键范围分页，或引入 ElasticSearch/ClickHouse 做搜索和统计。 广播表压力 配置了广播表（每个库一份完整数据）后，更新需要同步所有库，写入性能下降。 2. SQL 兼容性限制 复杂 SQL 支持不完整 ShardingSphere 对某些复杂 SQL（如子查询、窗口函数）支持有限，可能报错或性能极差。 存储过程、触发器受限 分库分表后，存储过程、触发器在分片数据库执行可能不一致，维护成本高。 3. 分布式事务问题 ShardingSphere 支持 XA 分布式事务，但性能不如单机事务，出现网络抖动时可能会卡住。 如果业务需要强一致性，必须结合可靠消息或 TCC、SAGA 等分布式事务模式，架构会更复杂。 4. 运维与管理复杂度 分片规则变更困难 例如，最初按 user_id % 2 分成两个库，后续想增加到 4 个库，需要迁移数据，非常麻烦。 监控与调优 ShardingSphere 增加了中间层，SQL 路由、执行计划、数据节点状态都需要额外的监控工具支持。 5. 成本与学习曲线 配置相对复杂：分片规则、读写分离、分布式事务、弹性扩容都需要仔细设计。 学习曲线较陡：开发和运维人员必须了解 ShardingSphere 的工作机制，否则定位问题很困难。 6. 高可用与扩展问题 ShardingSphere-JDBC 是应用内库，无法独立扩展，需要依赖应用扩容。 ShardingSphere-Proxy 支持集群，但需要自己搭建高可用架构，涉及负载均衡、故障切换等问题。 其它技术方案：分布式数据库 开源产品: 核心功能完全开源，企业版提供额外商业特性 数据库 架构类型 SQL 兼容性 分布式事务支持 数据存储模型 主要特点 典型应用场景 TiDB 分布式 HTAP MySQL 协议兼容 支持（Percolator 模型） 行存 + 列存混合 开源、云原生、强一致性、弹性扩展 在线事务处理 + 实时分析 OceanBase 分布式关系型数据库 MySQL/Oracle 兼容 支持（两阶段提交） 行存 高性能、金融级事务、阿里蚂蚁金服核心系统使用 金融、电商、核心交易系统 CockroachDB 分布式 NewSQL PostgreSQL 兼容 支持（分布式事务） 行存 类 Spanner 架构，全球分布，强一致性 全球化分布式应用 Citus (PostgreSQL) PostgreSQL 扩展 PostgreSQL 兼容 部分支持（基于逻辑分片） 行存 基于 PostgreSQL 的分布式扩展，支持大规模 OLAP 大数据实时分析、BI 场景 Vitess 分布式中间件 + 存储 MySQL 协议兼容 弱事务（最终一致性） 行存 YouTube 开源，K8s 友好，分库分表自动化 大规模 Web 应用，在线服务 YugabyteDB 分布式 SQL + NoSQL PostgreSQL 兼容 支持（两阶段提交） 行存 + 列存混合 融合 NewSQL 和 NoSQL，强一致性，跨区域部署 金融级事务 + 分析混合场景 商业产品 数据库 架构类型 SQL 兼容性 分布式事务支持 数据存储模型 主要特点 典型应用场景 PolarDB 云原生分布式数据库 MySQL/PostgreSQL 兼容 支持（云端分布式事务） 行存 阿里云产品，弹性扩容，存储计算分离 云上企业数据库解决方案 GaussDB 分布式关系型数据库 MySQL/Oracle 兼容 支持（分布式事务） 行存 + 列存混合 华为推出，分布式 HTAP，云原生架构 企业级 OLTP + OLAP 混合负载 Spanner 全球分布式数据库 类 SQL 支持（TrueTime 协议） 行存 Google 云产品，全球分布式强一致事务 全球化分布式事务，金融场景 Amazon Aurora 云原生分布式关系型数据库 MySQL/PostgreSQL 兼容 支持（单实例事务，多 AZ 高可用） 行存 AWS 托管，自动扩展存储，多可用区高可用 OLTP、企业级业务","summary":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。 ShardingSphere官网 本文在 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 的基础上进行修改。","date_published":"2025-09-10T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/","url":"https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/","title":"Maven 私服 Nexus 升级实录","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Mavne 私服 Nexus 升级的全过程，从 <code>3.29.2-02</code> 升级到 <code>3.83.2-01</code></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://help.sonatype.com/en/sonatype-nexus-repository.html\">Nexus官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">OpenJdk下载地址</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://help.sonatype.com/en/sonatype-nexus-repository-system-requirements.html\">Nexus系统配置要求</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"升级过程说明\">升级过程说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Nexus 从 <code>3.71.x</code> 开始，不再支持 <code>OrientDB</code>，后续版本仅支持 <code>H2</code> 和 <code>PostgreSQL</code> ，根据<a href=\"https://help.sonatype.com/en/upgrading-to-nexus-repository-3-71-0-and-beyond.html\">官网说明</a>，<code>3.70.x</code> 以下的版本需要将 Nexus 先升级到 <code>3.70.x</code> 的最新版本，然后使用官方提供的数据库迁移工具，将数据库迁移到 <code>H2</code> 后，再升级到 <code>3.71.x</code> 以后的版本</p>\n</li>\n</ul>\n<h2 id=\"从-3-29-2-02-升级到-nexus-3-70-4-02\">从 <code>3.29.2-02</code> 升级到 <code>nexus-3.70.4-02</code></h2>\n<h3 id=\"安装-OpenJDK\">安装 <code>OpenJDK</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>需要先安装好 <code>OpenJDK</code>，原因是<code>Nexus的数据库迁移工具</code>仅支持 <code>OpenJDK</code>，不支持 <code>Oracle JDK</code>，我这里选择安装 <code>OpenJDK11</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local</span><br><span class=\"line\">curl -O https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\">tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s /usr/local/jdk-11.0.28+6/bin/java /usr/bin/java</span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/local/jdk-11.0.28+6</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"安装-nexus-3-70-x\">安装 <code>nexus-3.70.x</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>目前官网发布的<code>nexus-3.70.x</code>的最新版本为 <code>nexus-3.70.4-02</code>，<a href=\"https://help.sonatype.com/en/orientdb-downloads.html\">下载页面</a>，其对应的数据库迁移工具也可以从该页面下载。</p>\n</li>\n<li class=\"lvl-2\">\n<p>这里我们选择 <a href=\"https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz\">Java 11 的版本</a>，升级安装与第一次安装方式一样。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 切换到 nexus 用户，原 nexus-3.29.2-02 就安装在 该用户的 `home` 目录下</span></span><br><span class=\"line\">su - nexus</span><br><span class=\"line\"><span class=\"comment\"># 关闭 原 nexus 服务，关于如何将 Nexus 配置为系统服务，可以参考：https://help.sonatype.com/en/run-as-a-service.html</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\">#~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 需要科学上网</span></span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class=\"line\">tar -zxvf nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">rm</span> -f ~/nexus3</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s /usr/local/nexus-3.70.4-02 ~/nexus3</span><br><span class=\"line\"><span class=\"comment\"># 启动 nexus</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"迁移数据到-H2\">迁移数据到 H2</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>下载数据库迁移工具</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> ~/backup</span><br><span class=\"line\"><span class=\"built_in\">cd</span> ~/backup</span><br><span class=\"line\"><span class=\"comment\"># 与 nexus 版本一致</span></span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/nxrm3-migrator/nexus-db-migrator-3.70.4-02.jar</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录 Nexus 导出数据: 设置 -&gt; System -&gt; Tasks -&gt; Create task -&gt; Admin - Export databases for backup<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MS26e5.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>任务创建后点击<code>Run</code>，即可在 <code>/home/nexus/backup</code> 目录下看到备份文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ll /home/nexus/backup</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   121066 Sep  8 07:25 analytics-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus 19349428 Sep  8 07:25 component-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   266208 Sep  8 07:25 config-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-r--r-- 1 nexus nexus 56809625 Sep  8 06:41 nexus-db-migrator-3.70.4-02.jar</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   132802 Sep  8 07:25 security-2025-09-08-07-25-57-3.70.4-02.bak</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用迁移工具生成H2数据库文件，官网参考资料: <a href=\"https://help.sonatype.com/en/migrating-to-a-new-database.html#migrating-from-orientdb-to-h2\">Migrating From OrientDB to H2</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开始迁移前需要先关闭 nexus 服务</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"><span class=\"comment\"># 进入备份目录</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /home/nexus/backup</span><br><span class=\"line\"><span class=\"comment\"># 这里要使用 OpenJDK 11 运行，根据需要适当调整内存参数</span></span><br><span class=\"line\">java -Xmx2G -Xms2G -XX:+UseG1GC -jar nexus-db-migrator-3.70.4-02.jar --migration_type=h2</span><br><span class=\"line\"><span class=\"comment\"># 运行后会提示你迁移数据库前需要先关闭 nexus 服务，我们输入 y 继续</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>运行成功后会生成 <code>nexus.mv.db</code>，将其移动到 <code>/home/nexus/sonatype-work/nexus3/db/</code> 目录下</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mv</span> nexus.mv.db /home/nexus/sonatype-work/nexus3/db/</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编辑<code>/home/nexus/sonatype-work/nexus3/etc/nexus.properties</code> 文件，添加如下内容</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># enable db h2</span></span><br><span class=\"line\">nexus.datastore.enabled=<span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 nexus，此时我们就完成了 从 <code>3.29.2-02</code> 到 <code>nexus-3.70.4-02</code> 的升级</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"从-nexus-3-70-4-02-升级到-nexus-3-83-2-01\">从 <code>nexus-3.70.4-02</code> 升级到 <code>nexus-3.83.2-01</code></h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这个升级就比较简单了，和我们此前的升级方式是一样的，下载解压后替换安装目录即可，这里要注意，从<code>nexus-3.71.0+</code>开始仅支持<code>jdk17</code>，所以需要提前安装好<code>jdk17</code>，另外从<code>nexus-3.78.0</code>开始，Nexus 内置了<code>openjdk17</code>，所以不需要再额外安装jdk。</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>nexus-3.83.2-01</code> 是目前的最新版，<a href=\"https://help.sonatype.com/en/download.html\">最新版下载页面</a>，<a href=\"https://help.sonatype.com/en/download-archives---repository-manager-3.html\">历史版本下载页面地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 Nexus 服务</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> ~</span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/3/nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class=\"line\">tar -zxvf nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">rm</span> -f nexus3</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s nexus-3.83.2-01 nexus3</span><br><span class=\"line\"><span class=\"comment\"># 启动 Nexus，nexus-3.83.2-01 自带 openjdk17，所以不需要单独安装 openjdk</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/rgLwWf.png\" alt=\"\"><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/mdWh22.png\" alt=\"\" width=\"1400\" height=\"1000\"><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/56aOWz.png\" alt=\"\"></p>\n","content_text":"摘要 本文介绍 Mavne 私服 Nexus 升级的全过程，从 3.29.2-02 升级到 3.83.2-01 Nexus官网 OpenJdk下载地址 Nexus系统配置要求 升级过程说明 Nexus 从 3.71.x 开始，不再支持 OrientDB，后续版本仅支持 H2 和 PostgreSQL ，根据官网说明，3.70.x 以下的版本需要将 Nexus 先升级到 3.70.x 的最新版本，然后使用官方提供的数据库迁移工具，将数据库迁移到 H2 后，再升级到 3.71.x 以后的版本 从 3.29.2-02 升级到 nexus-3.70.4-02 安装 OpenJDK 需要先安装好 OpenJDK，原因是Nexus的数据库迁移工具仅支持 OpenJDK，不支持 Oracle JDK，我这里选择安装 OpenJDK11 123456cd /usr/localcurl -O https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gztar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzln -s /usr/local/jdk-11.0.28+6/bin/java /usr/bin/javaexport JAVA_HOME=/usr/local/jdk-11.0.28+6export PATH=$JAVA_HOME/bin:$PATH 安装 nexus-3.70.x 目前官网发布的nexus-3.70.x的最新版本为 nexus-3.70.4-02，下载页面，其对应的数据库迁移工具也可以从该页面下载。 这里我们选择 Java 11 的版本，升级安装与第一次安装方式一样。 1234567891011121314# 切换到 nexus 用户，原 nexus-3.29.2-02 就安装在 该用户的 `home` 目录下su - nexus# 关闭 原 nexus 服务，关于如何将 Nexus 配置为系统服务，可以参考：https://help.sonatype.com/en/run-as-a-service.htmlsudo systemctl stop nexus#~/nexus3/bin/nexus stop# 需要科学上网curl -O https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gztar -zxvf nexus-3.70.4-02-java11-unix.tar.gzrm -f ~/nexus3ln -s /usr/local/nexus-3.70.4-02 ~/nexus3# 启动 nexussudo systemctl start nexus# ~/nexus3/bin/nexus start 迁移数据到 H2 下载数据库迁移工具 1234mkdir ~/backupcd ~/backup# 与 nexus 版本一致curl -O https://download.sonatype.com/nexus/nxrm3-migrator/nexus-db-migrator-3.70.4-02.jar 登录 Nexus 导出数据: 设置 -&gt; System -&gt; Tasks -&gt; Create task -&gt; Admin - Export databases for backup 任务创建后点击Run，即可在 /home/nexus/backup 目录下看到备份文件 123456ll /home/nexus/backup-rw-rw-r-- 1 nexus nexus 121066 Sep 8 07:25 analytics-2025-09-08-07-25-57-3.70.4-02.bak-rw-rw-r-- 1 nexus nexus 19349428 Sep 8 07:25 component-2025-09-08-07-25-57-3.70.4-02.bak-rw-rw-r-- 1 nexus nexus 266208 Sep 8 07:25 config-2025-09-08-07-25-57-3.70.4-02.bak-rw-r--r-- 1 nexus nexus 56809625 Sep 8 06:41 nexus-db-migrator-3.70.4-02.jar-rw-rw-r-- 1 nexus nexus 132802 Sep 8 07:25 security-2025-09-08-07-25-57-3.70.4-02.bak 使用迁移工具生成H2数据库文件，官网参考资料: Migrating From OrientDB to H2 12345678# 开始迁移前需要先关闭 nexus 服务sudo systemctl stop nexus# ~/nexus3/bin/nexus stop# 进入备份目录cd /home/nexus/backup# 这里要使用 OpenJDK 11 运行，根据需要适当调整内存参数java -Xmx2G -Xms2G -XX:+UseG1GC -jar nexus-db-migrator-3.70.4-02.jar --migration_type=h2# 运行后会提示你迁移数据库前需要先关闭 nexus 服务，我们输入 y 继续 运行成功后会生成 nexus.mv.db，将其移动到 /home/nexus/sonatype-work/nexus3/db/ 目录下 1mv nexus.mv.db /home/nexus/sonatype-work/nexus3/db/ 编辑/home/nexus/sonatype-work/nexus3/etc/nexus.properties 文件，添加如下内容 12# enable db h2nexus.datastore.enabled=true 启动 nexus，此时我们就完成了 从 3.29.2-02 到 nexus-3.70.4-02 的升级 12sudo systemctl start nexus# ~/nexus3/bin/nexus start 从 nexus-3.70.4-02 升级到 nexus-3.83.2-01 这个升级就比较简单了，和我们此前的升级方式是一样的，下载解压后替换安装目录即可，这里要注意，从nexus-3.71.0+开始仅支持jdk17，所以需要提前安装好jdk17，另外从nexus-3.78.0开始，Nexus 内置了openjdk17，所以不需要再额外安装jdk。 nexus-3.83.2-01 是目前的最新版，最新版下载页面，历史版本下载页面地址 1234567891011# 关闭 Nexus 服务sudo systemctl stop nexus# ~/nexus3/bin/nexus stopcd ~curl -O https://download.sonatype.com/nexus/3/nexus-3.83.2-01-linux-x86_64.tar.gztar -zxvf nexus-3.83.2-01-linux-x86_64.tar.gzrm -f nexus3ln -s nexus-3.83.2-01 nexus3# 启动 Nexus，nexus-3.83.2-01 自带 openjdk17，所以不需要单独安装 openjdksudo systemctl start nexus# ~/nexus3/bin/nexus start","summary":"摘要 本文介绍 Mavne 私服 Nexus 升级的全过程，从 3.29.2-02 升级到 3.83.2-01 Nexus官网 OpenJdk下载地址 Nexus系统配置要求","date_published":"2025-09-08T13:30:05.000Z","tags":["技术","maven","nexus","mavne","nexus"]}]}