{"version":"https://jsonfeed.org/version/1","name":"飘逸峰的博客","home_page_url":"https://blog.hanqunfeng.com","feed_url":"https://blog.hanqunfeng.com/feed.json","author":{"name":"飘逸峰"},"items":[{"id":"https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/","url":"https://blog.hanqunfeng.com/2025/10/24/rocketmq-02-dashboard/","title":"RocketMQ Dashboard 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RocketMQ-Dashboard-简介\">RocketMQ Dashboard 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/04Dashboard\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>RocketMQ Dashboard 是 RocketMQ 的管控利器，为用户提供客户端和应用程序的各种事件、性能的统计信息，支持以可视化工具代替 Topic 配置、Broker 管理等命令行操作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>功能概览</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>面板</th>\n<th>功能说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>运维</strong></td>\n<td>修改 <strong>NameServer 地址</strong>；选择 <strong>VIPChannel</strong> 等运维配置。</td>\n</tr>\n<tr>\n<td><strong>驾驶舱</strong></td>\n<td>查看 <strong>Broker、Topic 消息量</strong> 等运行总览信息。</td>\n</tr>\n<tr>\n<td><strong>集群</strong></td>\n<td>查看 <strong>集群分布</strong>、Broker 配置、运行状态及详细信息。</td>\n</tr>\n<tr>\n<td><strong>主题（Topic）</strong></td>\n<td>搜索、筛选、删除、更新/新增主题；查看 <strong>消息路由</strong>；执行 <strong>发送消息</strong>、<strong>重置消费位点</strong> 等操作。</td>\n</tr>\n<tr>\n<td><strong>消费者（Consumer）</strong></td>\n<td>搜索、删除、新增/更新消费者组；查看 <strong>终端信息、消费详情、配置项</strong>。</td>\n</tr>\n<tr>\n<td><strong>消息（Message）</strong></td>\n<td>查看 <strong>消息记录、死信消息、消息轨迹</strong> 等消息级详情。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>系统要求 与 网络配置</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>项目</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>系统要求</strong></td>\n<td>操作系统</td>\n<td>Linux / Unix / macOS</td>\n</tr>\n<tr>\n<td></td>\n<td>JDK</td>\n<td>64 位 JDK, 1.x 版本需要<strong>1.8+</strong>，2.x版本需要 <strong>17+</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>构建工具</td>\n<td><strong>Maven 3.2.x</strong> 或更高版本</td>\n</tr>\n<tr>\n<td></td>\n<td>启动项</td>\n<td>启动 <strong>RocketMQ</strong>（包括 NameServer 与 Broker）</td>\n</tr>\n<tr>\n<td><strong>网络配置</strong></td>\n<td>网络访问</td>\n<td>云服务器需可远程访问，或本地虚拟机需可 <strong>PING 通外网</strong></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RocketMQ-Dashboard-的安装\">RocketMQ Dashboard 的安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>部署 RocketMQ Dashboard 2.x，需要安装 JDK17</p>\n</li>\n<li class=\"lvl-2\">\n<p>源码安装，<a href=\"https://github.com/apache/rocketmq-dashboard\">源码下载</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载源码</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq</span><br><span class=\"line\">wget https://github.com/apache/rocketmq-dashboard/archive/refs/tags/rocketmq-dashboard-2.1.0.tar.gz</span><br><span class=\"line\">tar -zxvf rocketmq-dashboard-2.1.0.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s rocketmq-dashboard-rocketmq-dashboard-2.1.0 rocketmq-dashboard</span><br><span class=\"line\"><span class=\"built_in\">cd</span> rocketmq-dashboard</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>bug 修复，当前<code>2.1.0</code>版本存在bug，只能通过<code>http://localhost:8082</code>访问，如果需要ip或域名访问，则需要修改源码</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> frontend-new/src/api/remoteApi</span><br><span class=\"line\">sed -i <span class=\"string\">&#x27;s|apiBaseUrl: &#x27;</span>\\&#x27;<span class=\"string\">&#x27;http://localhost:8082&#x27;</span>\\&#x27;<span class=\"string\">&#x27;|apiBaseUrl: process.env.REACT_APP_API_BASE_URL \\|\\| window.location.origin|&#x27;</span> remoteApi.js.bck</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 替换前：</span></span><br><span class=\"line\">const appConfig = &#123;</span><br><span class=\"line\">    apiBaseUrl: <span class=\"string\">&#x27;http://localhost:8082&#x27;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"comment\"># 替换后：</span></span><br><span class=\"line\">const appConfig = &#123;</span><br><span class=\"line\">    apiBaseUrl: process.env.REACT_APP_API_BASE_URL || window.location.origin</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>环境</th>\n<th>环境变量值</th>\n<th>结果 (<code>appConfig.apiBaseUrl</code>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>开发环境</td>\n<td><code>REACT_APP_API_BASE_URL=http://localhost:8080</code></td>\n<td><code>http://localhost:8080</code></td>\n</tr>\n<tr>\n<td>测试环境</td>\n<td><code>REACT_APP_API_BASE_URL=https://api.test.example.com</code></td>\n<td><code>https://api.test.example.com</code></td>\n</tr>\n<tr>\n<td>未设置变量</td>\n<td><em>(无该环境变量)</em> 则使用默认的 <code>window.location.origin</code>，其表示 当前网页的 协议 + 域名 + 端口号</td>\n<td>自动使用当前网站地址，如 <code>https://myapp.example.com</code></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>目前<code>2.1.0</code>版本的bug还比较多，GitHub仓库中的代码已经修复了包括该bug在内的部分bug，不过还没有发布到 release。<br>\n着急的小伙伴可以通过 <code>git clone</code> 项目，编译并运行，或者等待作者发布新版本。</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编译</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq/rocketmq-dashboard</span><br><span class=\"line\"><span class=\"comment\"># 编译</span></span><br><span class=\"line\">JAVA_HOME=/usr/local/jdk/jdk17 mvn clean package -Dmaven.test.skip=<span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># 将jar包复制到run目录下，以避免重新编译时被覆盖</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> run</span><br><span class=\"line\"><span class=\"built_in\">cp</span> target/rocketmq-dashboard-2.1.0.jar run/</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>按需替换配置，</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># vim run/application.yaml # 按需替换配置</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">rocketmq:</span></span><br><span class=\"line\">  <span class=\"attr\">config:</span></span><br><span class=\"line\">    <span class=\"attr\">namesrvAddrs:</span>                <span class=\"comment\"># 填写NameServer地址列表</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.175</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.188</span><span class=\"string\">:9876</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.131</span><span class=\"string\">:9876</span></span><br><span class=\"line\">    <span class=\"attr\">proxyAddrs:</span>                  <span class=\"comment\"># 填写Proxy地址列表</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.175</span><span class=\"string\">:8080</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.188</span><span class=\"string\">:8080</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"number\">10.250</span><span class=\"number\">.0</span><span class=\"number\">.131</span><span class=\"string\">:8080</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> run</span><br><span class=\"line\"><span class=\"comment\"># 启动，默认会加载与jar包同级目录下的application.yaml文件</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> /usr/local/jdk/jdk17/bin/java -jar rocketmq-dashboard-2.1.0.jar 1&gt;dashboard.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看日志</span></span><br><span class=\"line\"><span class=\"built_in\">tail</span> -f dashboard.log</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/9F26eh.png\" alt=\"\" width=\"1400\" height=\"800\"></p>\n","content_text":"摘要 本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 RocketMQ Dashboard 简介 官方文档 RocketMQ Dashboard 是 RocketMQ 的管控利器，为用户提供客户端和应用程序的各种事件、性能的统计信息，支持以可视化工具代替 Topic 配置、Broker 管理等命令行操作。 功能概览 面板 功能说明 运维 修改 NameServer 地址；选择 VIPChannel 等运维配置。 驾驶舱 查看 Broker、Topic 消息量 等运行总览信息。 集群 查看 集群分布、Broker 配置、运行状态及详细信息。 主题（Topic） 搜索、筛选、删除、更新/新增主题；查看 消息路由；执行 发送消息、重置消费位点 等操作。 消费者（Consumer） 搜索、删除、新增/更新消费者组；查看 终端信息、消费详情、配置项。 消息（Message） 查看 消息记录、死信消息、消息轨迹 等消息级详情。 系统要求 与 网络配置 类别 项目 说明 系统要求 操作系统 Linux / Unix / macOS JDK 64 位 JDK, 1.x 版本需要1.8+，2.x版本需要 17+ 构建工具 Maven 3.2.x 或更高版本 启动项 启动 RocketMQ（包括 NameServer 与 Broker） 网络配置 网络访问 云服务器需可远程访问，或本地虚拟机需可 PING 通外网 RocketMQ Dashboard 的安装 部署 RocketMQ Dashboard 2.x，需要安装 JDK17 源码安装，源码下载 123456# 下载源码cd /usr/local/soft/rocketmqwget https://github.com/apache/rocketmq-dashboard/archive/refs/tags/rocketmq-dashboard-2.1.0.tar.gztar -zxvf rocketmq-dashboard-2.1.0.tar.gzln -s rocketmq-dashboard-rocketmq-dashboard-2.1.0 rocketmq-dashboardcd rocketmq-dashboard bug 修复，当前2.1.0版本存在bug，只能通过http://localhost:8082访问，如果需要ip或域名访问，则需要修改源码 1234567891011cd frontend-new/src/api/remoteApised -i &#x27;s|apiBaseUrl: &#x27;\\&#x27;&#x27;http://localhost:8082&#x27;\\&#x27;&#x27;|apiBaseUrl: process.env.REACT_APP_API_BASE_URL \\|\\| window.location.origin|&#x27; remoteApi.js.bck# 替换前：const appConfig = &#123; apiBaseUrl: &#x27;http://localhost:8082&#x27;&#125;;# 替换后：const appConfig = &#123; apiBaseUrl: process.env.REACT_APP_API_BASE_URL || window.location.origin&#125;; 环境 环境变量值 结果 (appConfig.apiBaseUrl) 开发环境 REACT_APP_API_BASE_URL=http://localhost:8080 http://localhost:8080 测试环境 REACT_APP_API_BASE_URL=https://api.test.example.com https://api.test.example.com 未设置变量 (无该环境变量) 则使用默认的 window.location.origin，其表示 当前网页的 协议 + 域名 + 端口号 自动使用当前网站地址，如 https://myapp.example.com 目前2.1.0版本的bug还比较多，GitHub仓库中的代码已经修复了包括该bug在内的部分bug，不过还没有发布到 release。 着急的小伙伴可以通过 git clone 项目，编译并运行，或者等待作者发布新版本。 编译 123456cd /usr/local/soft/rocketmq/rocketmq-dashboard# 编译JAVA_HOME=/usr/local/jdk/jdk17 mvn clean package -Dmaven.test.skip=true# 将jar包复制到run目录下，以避免重新编译时被覆盖mkdir runcp target/rocketmq-dashboard-2.1.0.jar run/ 按需替换配置， 123456789101112# vim run/application.yaml # 按需替换配置rocketmq: config: namesrvAddrs: # 填写NameServer地址列表 - 10.250.0.175:9876 - 10.250.0.188:9876 - 10.250.0.131:9876 proxyAddrs: # 填写Proxy地址列表 - 10.250.0.175:8080 - 10.250.0.188:8080 - 10.250.0.131:8080 启动 123456cd run# 启动，默认会加载与jar包同级目录下的application.yaml文件nohup /usr/local/jdk/jdk17/bin/java -jar rocketmq-dashboard-2.1.0.jar 1&gt;dashboard.log 2&gt;&amp;1 &amp;# 查看日志tail -f dashboard.log","summary":"摘要 本文介绍 CentOS9 中 RocketMQ Dashboard 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-24T13:30:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/","url":"https://blog.hanqunfeng.com/2025/10/23/rocketmq-01-install/","title":"RocketMQ 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RocketMQ 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/\">RocketMQ官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RocketMQ 版本为 5.3.2。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Apache-RocketMQ-简介\">Apache RocketMQ 简介</h2>\n<h3 id=\"一、RocketMQ-是什么？\">一、RocketMQ 是什么？</h3>\n<p>RocketMQ 是一个<strong>分布式、队列模型的消息中间件</strong>。它由阿里巴巴在2012年开源，并于2017年正式成为 Apache 基金会的顶级项目。</p>\n<p>你可以把它想象成一个在分布式系统中负责可靠传递消息的“邮局”或“快递系统”。当系统A需要发送数据给系统B，但它们之间不直接通信时，就可以通过 RocketMQ 来中转，确保消息不丢失、不重复，并且能按顺序送达。</p>\n<p><strong>RocketMQ 是一个高性能、高可靠、高实时的分布式消息中间件</strong>。它就像分布式系统的“中枢神经系统”，负责在各个服务之间可靠、高效地传递数据，是现代互联网架构中不可或缺的基础组件之一。</p>\n<p><strong>RocketMQ 5.x 通过引入 Proxy 模式，极大地提升了架构的灵活性、多语言支持能力和云原生亲和力</strong>，是其在消息中间件领域持续演进的重要里程碑。</p>\n<p>它与 Kafka、RabbitMQ 等都是业界顶级的消息队列，但各有侧重。RocketMQ 在事务消息、顺序消息和对在线业务的稳定性支持方面表现尤为出色。</p>\n<hr>\n<h3 id=\"二、核心特点与优势\">二、核心特点与优势</h3>\n<p>RocketMQ 之所以流行，主要归功于以下几个核心特点：</p>\n<ol>\n<li class=\"lvl-4\">\n<p><strong>削峰填谷</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\"><strong>场景</strong>：电商秒杀活动时，瞬时会有海量下单请求涌来，后端处理系统可能无法承受。</li>\n<li class=\"lvl-8\"><strong>作用</strong>：RocketMQ 可以将这些突发的请求消息先缓存起来，然后让后端系统按照自己能处理的速率慢慢消费，避免了系统被冲垮。这就好比用一个大水库先拦住洪水，再平稳地向下游放水。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>异步解耦</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\"><strong>场景</strong>：用户注册后，需要发送欢迎邮件、发放优惠券、初始化积分等。</li>\n<li class=\"lvl-8\"><strong>作用</strong>：主注册流程只需要向 RocketMQ 发送一个“用户已注册”的消息，而不需要等待所有后续操作完成。负责邮件、优惠券的系统会自己去 RocketMQ 取消息并处理。这样，系统之间的依赖关系就变弱了，提高了整体的灵活性和可维护性。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>顺序消息</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\"><strong>场景</strong>：一个订单的状态必须严格按照 <code>创建 -&gt; 付款 -&gt; 发货 -&gt; 确认收货</code> 的顺序来变更。</li>\n<li class=\"lvl-8\"><strong>作用</strong>：RocketMQ 可以保证同一个订单ID的消息被存储在同一个队列中，并按照发送顺序被消费，确保了业务逻辑的正确性。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>持久性与高可靠</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\">RocketMQ 会将所有消息持久化到磁盘，即使服务器重启，消息也不会丢失。</li>\n<li class=\"lvl-8\">它本身采用分布式集群架构，支持主从复制，提供了极高的可用性。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>消息回溯</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\">消费者可以重置消费位点，重新消费过去某个时间点的消息。这在业务逻辑出错、需要重新处理时非常有用。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>海量消息堆积能力</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\">能够支持万亿级别的消息堆积，不会因为大量未消费消息而导致性能急剧下降。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"三、核心架构与概念\">三、核心架构与概念</h3>\n<p>要理解 RocketMQ，需要知道几个关键角色：</p>\n<h4 id=\"3-1-经典核心组件-RocketMQ-4-x\">3.1 经典核心组件 (RocketMQ 4.x)</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><strong>Producer（生产者）</strong>：发送消息的客户端。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>Consumer（消费者）</strong>：接收消息的客户端。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>Broker</strong>：消息服务器，负责存储和转发消息。它是 RocketMQ 的核心。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>Topic（主题）</strong>：消息的分类，生产者向指定的 Topic 发送消息，消费者订阅指定的 Topic 来消费消息。例如，可以有一个 “Order_Topic” 专门用来处理所有订单相关的消息。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>Name Server（名字服务）</strong>：一个轻量级的注册中心，负责管理所有 Broker 的地址信息，帮助生产者和消费者找到对应的 Broker。</p>\n</li>\n</ul>\n<h4 id=\"3-2-RocketMQ-5-的新核心：Proxy\">3.2 RocketMQ 5 的新核心：Proxy</h4>\n<p>在 RocketMQ 5.x 版本中，引入了一个新的关键组件——<strong>Proxy</strong>。</p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><strong>Proxy（代理）</strong>：一个无状态的网络代理层，可以独立部署。</p>\n</li>\n</ul>\n<p><strong>引入 Proxy 主要有两种模式：</strong></p>\n<ol>\n<li class=\"lvl-4\">\n<p><strong>集群部署模式 (Cluster Mode)</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\">这是经典的部署方式。生产者和消费者直接与 Broker 通信。</li>\n<li class=\"lvl-8\"><strong>架构</strong>：<code>Producer/Consumer &lt;--&gt; Broker &lt;--&gt; Name Server</code></li>\n</ul>\n</li>\n<li class=\"lvl-4\">\n<p><strong>Proxy 部署模式</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-8\">这是 RocketMQ 5.x 推荐的新模式。所有客户端的请求都先经过 Proxy，由 Proxy 代理与 Broker 和 Name Server 进行交互。</li>\n<li class=\"lvl-8\"><strong>架构</strong>：<code>Producer/Consumer &lt;--&gt; Proxy &lt;--&gt; Broker &lt;--&gt; Name Server</code></li>\n</ul>\n</li>\n</ol>\n<p><strong>引入 Proxy 模式的优势：</strong></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><strong>架构解耦与语言无关</strong>：Proxy 作为通用代理，将复杂的 Broker 协议封装成更简单的接口（如 gRPC），使得用不同编程语言（如 Go, Python, C++ 等）开发的客户端更容易接入，而无需实现复杂的原生协议。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>简化客户端</strong>：客户端不再需要感知 Name Server 和 Broker 的地址变化，只需连接固定的 Proxy 地址即可，大大降低了客户端的复杂度。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>增强安全性</strong>：可以在 Proxy 层统一实现安全认证、限流、审计等策略，作为Broker集群的安全屏障。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>云原生友好</strong>：无状态的 Proxy 非常适合在 Kubernetes 等容器化环境中进行部署和弹性伸缩。</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"四、典型应用场景\">四、典型应用场景</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><strong>电商/金融交易系统</strong>：保证交易核心流程的可靠、顺序和最终一致性。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>大数据采集</strong>：将大量日志、行为数据先写入消息队列，再由后端的大数据处理系统（如 Flink, Spark）消费。</p>\n</li>\n<li class=\"lvl-4\">\n<p><strong>微服务间的异步通信</strong>：在微服务架构中，作为服务之间的通信总线。</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"RocketMQ-的安装\">RocketMQ 的安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RocketMQ 5.x 依赖 JDK 1.8+。</p>\n</li>\n</ul>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/quickStart/01quickstart\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>下载RocketMQ</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> -p /usr/local/soft/rocketmq/</span><br><span class=\"line\">wget https://dist.apache.org/repos/dist/release/rocketmq/5.3.2/rocketmq-all-5.3.2-bin-release.zip</span><br><span class=\"line\">unzip rocketmq-all-5.3.2-bin-release.zip</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s rocketmq-all-5.3.2-bin-release rocketmq5</span><br><span class=\"line\"><span class=\"built_in\">cd</span> rocketmq5</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>小贴士</strong></em><br>\n默认脚本中，NameServer需要4G内存，Broker 需要8G内存，如果内存不够，可以进入bin目录，对其中的<code>runserver.sh</code>和<code>runbroker.sh</code>两个脚本进行一下修改</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用vi runserver.sh指令，编辑这个脚本，找到下面的一行配置，调整Java进程的内存大小。</span></span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms4g -Xmx4g -Xmn2G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class=\"line\">修改为：</span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms1g -Xmx1g -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 接下来，同样调整runbroker.sh中的内存大小。</span></span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g&quot;</span></span><br><span class=\"line\">修改为：</span><br><span class=\"line\">JAVA_OPT=<span class=\"string\">&quot;<span class=\"variable\">$&#123;JAVA_OPT&#125;</span> -server -Xms2g -Xmx2g&quot;</span></span><br></pre></td></tr></table></figure>\n</div>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 NameServer</p>\n</li>\n</ul>\n<blockquote>\n<p>安装完RocketMQ包后，我们启动NameServer</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 启动namesrv</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqnamesrv &amp;</span><br><span class=\"line\"><span class=\"comment\">## 指定配置文件</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqnamesrv -c namesrv.conf &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 验证namesrv是否启动成功</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -f ~/logs/rocketmqlogs/namesrv.log</span><br><span class=\"line\"><span class=\"comment\"># 我们可以在namesrv.log 中看到 &#x27;The Name Server boot success..&#x27;， 表示NameServer 已成功启动。</span></span><br><span class=\"line\">The Name Server boot success. serializeType=JSON, address 0.0.0.0:9876</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>namesrv.conf 示例</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The port of nameserver</span></span><br><span class=\"line\">listenPort = 9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Broker+Proxy</p>\n</li>\n</ul>\n<blockquote>\n<p>NameServer成功启动后，我们启动Broker和Proxy。这里我们使用 Local 模式部署，即 Broker 和 Proxy 同进程部署。5.x 版本也支持 Broker 和 Proxy 分离部署以实现更灵活的集群能力。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 先启动broker</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqbroker -n localhost:9876 --enable-proxy &amp;</span><br><span class=\"line\"><span class=\"comment\"># 指定配置文件</span></span><br><span class=\"line\">$ <span class=\"built_in\">nohup</span> sh bin/mqbroker -n localhost:9876 -c conf/broker.conf --enable-proxy &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 验证broker是否启动成功, 比如, broker的ip是192.168.1.2 然后名字是broker-a</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -f ~/logs/rocketmqlogs/proxy.log</span><br><span class=\"line\"><span class=\"comment\"># 我们可以在 proxy.log 中看到“The broker[brokerName,ip:port] boot success..”，这表明 broker 已成功启动。</span></span><br><span class=\"line\">The broker[broker-a, 10.250.0.175:10911] boot success. serializeType=JSON and name server is localhost:9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关闭服务器</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 先停止 Broker</span></span><br><span class=\"line\">$ sh bin/mqshutdown broker</span><br><span class=\"line\"><span class=\"comment\"># 停止 NameServer</span></span><br><span class=\"line\">$ sh bin/mqshutdown namesrv</span><br></pre></td></tr></table></figure>\n<h4 id=\"日志及数据存储路径\">日志及数据存储路径</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RocketMQ 5 主要有三类服务组件需要关注它们的存储目录</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>组件</th>\n<th>功能</th>\n<th>默认存储内容</th>\n<th>默认路径（Linux 环境）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>NameServer</strong></td>\n<td>路由服务</td>\n<td>日志配置文件： <code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.namesrv.logback.xml</code></td>\n<td><code>~/logs/rocketmqlogs/namesrv.log</code></td>\n</tr>\n<tr>\n<td><strong>Broker</strong></td>\n<td>核心消息存储服务</td>\n<td>消息数据（CommitLog、ConsumeQueue、Index、Config）</td>\n<td><strong>数据目录</strong>：<br><code>~/store</code><br>├── <code>commitlog/</code> → 消息物理文件<br>├── <code>consumequeue/</code> → 消费队列索引<br>├── <code>index/</code> → 消息索引<br>├── <code>config/</code> → topic、consumer offset、subscription 信息<br>├── <code>checkpoint</code> → 存储校验点<br>├── <code>abort</code> → 异常退出标志</td>\n</tr>\n<tr>\n<td></td>\n<td>运行日志</td>\n<td>日志配置文件：<code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.broker.logback.xml</code></td>\n<td><code>~/logs/rocketmqlogs/broker.log</code></td>\n</tr>\n<tr>\n<td></td>\n<td>配置文件</td>\n<td>broker配置文件</td>\n<td><code>$&#123;ROCKETMQ_HOME&#125;/conf/broker.conf</code></td>\n</tr>\n<tr>\n<td><strong>Proxy</strong></td>\n<td>客户端访问入口（可选）</td>\n<td>访问日志、转发日志：  <code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq.proxy.logback.xml</code></td>\n<td><code>~/logs/rocketmqlogs/proxy.log</code></td>\n</tr>\n<tr>\n<td></td>\n<td>配置文件</td>\n<td>代理配置文件</td>\n<td><code>$&#123;ROCKETMQ_HOME&#125;/conf/rmq-proxy.json</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>NameServer 和 Proxy 都是无状态（stateless）组件，不会持久化业务数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>修改 Broker 数据路径，比如 <code>conf/broker.conf</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 消息存储根目录</span></span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># CommitLog 存储路径</span></span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ConsumeQueue 存储路径</span></span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 消息索引文件存储路径</span></span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 运行时配置存储路径</span></span><br><span class=\"line\">storePathConfig=/data/rocketmq/store/config</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># checkpoint 文件路径</span></span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># abort 文件路径</span></span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装\">集群安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://rocketmq.apache.org/zh/docs/deploymentOperations/01deploy\">官网文档</a> 对集群安装的方式介绍了多种，本文仅实战一种：<code>多节点（集群）多副本模式-异步复制</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>每个Master配置一个Slave，有多组 Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；</li>\n<li class=\"lvl-6\">缺点：Master宕机，磁盘损坏情况下会丢失少量消息。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>该模式下，Master 节点和 Slave 节点之间是异步复制的，Master 节点挂掉后，Slave 节点不会自动切换为 Master 节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>集群规划</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># NameServer 3 台</span></span><br><span class=\"line\">NameServer1 10.250.0.175</span><br><span class=\"line\">NameServer2 10.250.0.188</span><br><span class=\"line\">NameServer3 10.250.0.31</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broker 2 Master 2 Replicas</span></span><br><span class=\"line\">Broker1 10.250.0.188 broker-a,broker-b-s</span><br><span class=\"line\">Broker2 10.250.0.31  broker-b,broker-a-s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Proxy 3 台</span></span><br><span class=\"line\">Proxy1 10.250.0.175</span><br><span class=\"line\">Proxy2 10.250.0.188</span><br><span class=\"line\">Proxy3 10.250.0.31</span><br></pre></td></tr></table></figure>\n<h4 id=\"部署-NameServer\">部署 NameServer</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在三台服务器上分别启动RocketMQ NameServer</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/soft/rocketmq/rocketmq5</span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqnamesrv &amp;</span><br></pre></td></tr></table></figure>\n<h4 id=\"部署Broker\">部署Broker</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>部署前需要先清除掉之前的存储数据</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认路径</span></span><br><span class=\"line\"><span class=\"built_in\">rm</span> -rf ~/store/*</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-a.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-a              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=0                       <span class=\"comment\"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class=\"line\">deleteWhen=04                    <span class=\"comment\"># 表示凌晨 4 点清理</span></span><br><span class=\"line\">fileReservedTime=48              <span class=\"comment\"># 表示保存 48 小时的数据</span></span><br><span class=\"line\">brokerRole=ASYNC_MASTER          <span class=\"comment\"># 角色，表示异步复制的主节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH        <span class=\"comment\"># 表示异步刷盘</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=10911</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-a-s.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-a              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=1                       <span class=\"comment\"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE                 <span class=\"comment\"># 角色，表示异步复制的从节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-a</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-a/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-a/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-a/abort</span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=11011</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-b.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-b              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=0                       <span class=\"comment\"># brokerId 必须唯一 ，且 master 的 brokerId 必须为 0</span></span><br><span class=\"line\">deleteWhen=04                    <span class=\"comment\"># 表示凌晨 4 点清理</span></span><br><span class=\"line\">fileReservedTime=48              <span class=\"comment\"># 表示保存 48 小时的数据</span></span><br><span class=\"line\">brokerRole=ASYNC_MASTER          <span class=\"comment\"># 角色，表示异步复制的主节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH        <span class=\"comment\"># 表示异步刷盘</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=10911</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>broker-b-s.properties</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brokerClusterName=DefaultCluster <span class=\"comment\"># 集群名称必须一致</span></span><br><span class=\"line\">brokerName=broker-b              <span class=\"comment\"># broker 名称，master 和 slave 的 brokerName 必须一致</span></span><br><span class=\"line\">brokerId=1                       <span class=\"comment\"># brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0</span></span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE                 <span class=\"comment\"># 角色，表示异步复制的从节点</span></span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口</span></span><br><span class=\"line\"><span class=\"comment\"># 存储数据路径</span></span><br><span class=\"line\">storePathRootDir=/usr/local/soft/rocketmq/data/store-b</span><br><span class=\"line\">storePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlog</span><br><span class=\"line\">storePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeue</span><br><span class=\"line\">storePathIndex=/usr/local/soft/rocketmq/data/store-b/index</span><br><span class=\"line\">storePathConfig=/usr/local/soft/rocketmq/data/store-b/config</span><br><span class=\"line\">storeCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpoint</span><br><span class=\"line\">abortFile=/usr/local/soft/rocketmq/data/store-b/abort</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口</span></span><br><span class=\"line\">listenPort=11011</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Broker1 10.250.0.188 上启动 broker-a 和 broker-b-s</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 broker-a</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a.properties &amp;</span><br><span class=\"line\"><span class=\"comment\"># 启动 broker-b-s</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b-s.properties &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## nohup.out 中的输出类似与下面这种就表示启动成功</span></span><br><span class=\"line\">The broker[broker-a, 10.250.0.31:11011] boot success. serializeType=JSON and name server is 10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Broker2 10.250.0.31 上启动 broker-b 和 broker-a-s</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 broker-b</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-b.properties &amp;</span><br><span class=\"line\"><span class=\"comment\"># 启动 broker-a-s</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqbroker -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -c conf/2m-2s-async/broker-a-s.properties &amp;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动成功后，可以通过如下命令检查机器状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）</span></span><br><span class=\"line\">sh bin/mqadmin clusterList -n 10.250.0.175:9876</span><br><span class=\"line\"><span class=\"comment\">## 输出类似如下</span></span><br><span class=\"line\"><span class=\"comment\">#Cluster Name           #Broker Name            #BID  #Addr                  #Version              #InTPS(LOAD)                   #OutTPS(LOAD)  #Timer(Progress)        #PCWait(ms)  #Hour         #SPACE    #ACTIVATED</span></span><br><span class=\"line\">DefaultCluster          broker-a                0     10.250.0.188:10911     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-a                1     10.250.0.31:11011      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600         <span class=\"literal\">false</span></span><br><span class=\"line\">DefaultCluster          broker-b                0     10.250.0.31:10911      V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  0-0(0.0w, 0.0, 0.0)               0  489250.72     0.2600          <span class=\"literal\">true</span></span><br><span class=\"line\">DefaultCluster          broker-b                1     10.250.0.188:11011     V5_3_2                 0.00(0,0ms)               0.00(0,0ms|0,0ms)  3-0(0.0w, 0.0, 0.0)               0  489250.72     0.2900         <span class=\"literal\">false</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"配置-Proxy\">配置 Proxy</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在三台服务器上分别启动RocketMQ NameServer</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqproxy -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 指定配置文件，这里要注意，集群的名称要与 conf/proxy.conf 中配置的集群名称必须一致，默认是 DefaultCluster</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> sh bin/mqproxy -n <span class=\"string\">&quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot;</span> -pc conf/proxy.conf &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看日志，输出如下内容就表示启动成功，tail -f nohup.out</span></span><br><span class=\"line\">rocketmq-proxy startup successfully</span><br></pre></td></tr></table></figure>\n<h2 id=\"端口说明\">端口说明</h2>\n<table>\n<thead>\n<tr>\n<th>端口号</th>\n<th>协议</th>\n<th>组件/服务</th>\n<th>作用说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>9876</strong></td>\n<td>TCP</td>\n<td><strong>NameServer</strong></td>\n<td>RocketMQ 集群的 <strong>NameServer</strong> 服务端口。<br>用于 Broker 注册、客户端路由发现。<br>Producer/Consumer 连接此端口以获取 Broker 地址。</td>\n</tr>\n<tr>\n<td><strong>8080</strong></td>\n<td>TCP</td>\n<td><strong>Proxy (gRPC / HTTP)</strong></td>\n<td>RocketMQ 5 引入的 <strong>Proxy 服务</strong> 默认端口之一。<br>用于 <strong>HTTP/gRPC 客户端接入</strong>，例如 RocketMQ Proxy REST API、异步消息接口等。</td>\n</tr>\n<tr>\n<td><strong>8081</strong></td>\n<td>TCP</td>\n<td><strong>Proxy Admin / Dashboard / gRPC Alt</strong></td>\n<td>通常是 Proxy 的 <strong>管理接口</strong> 或 <strong>gRPC 辅助端口</strong>（依配置而定）。<br>也可能是控制面接口，用于与 Console 或控制工具通信。</td>\n</tr>\n<tr>\n<td><strong>10909</strong></td>\n<td>TCP</td>\n<td><strong>Broker HA (High Availability)</strong></td>\n<td>Broker <strong>主从同步端口</strong>（Master ↔ Slave 之间的数据复制）。<br>用于消息数据与元数据的同步。</td>\n</tr>\n<tr>\n<td><strong>10911</strong></td>\n<td>TCP</td>\n<td><strong>Broker 服务端口</strong></td>\n<td>Broker 的 <strong>主通信端口</strong>，客户端连接发送消息、消费消息、心跳等。<br>Producer 和 Consumer 通过 NameServer 获取该端口地址后进行通信。</td>\n</tr>\n<tr>\n<td><strong>10912</strong></td>\n<td>TCP</td>\n<td><strong>Broker HA 客户端端口</strong></td>\n<td>Broker <strong>主从复制中的 Slave 连接 Master</strong> 时使用的 <strong>客户端监听端口</strong>。<br>通常与 10909 配合使用，一主多从模式中 Slave 主动连接 Master。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"安装过程中遇到的问题\">安装过程中遇到的问题</h2>\n<h3 id=\"1-启动-Proxy-失败\">1.启动 Proxy 失败</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论是 <code>Broker+Proxy</code> 启动，还是 单独启动 <code>Proxy</code>，都报如下错误：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 错误会在 nohup.out 中输出</span></span><br><span class=\"line\">Exception <span class=\"keyword\">in</span> thread <span class=\"string\">&quot;main&quot;</span> java.lang.UnsatisfiedLinkError: failed to load the required native library</span><br><span class=\"line\"></span><br><span class=\"line\">Caused by: java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_x86_64_fedora, netty_tcnative_linux_x86_64, netty_tcnative_x86_64, netty_tcnative]</span><br><span class=\"line\"></span><br><span class=\"line\">Suppressed: java.lang.UnsatisfiedLinkError: /tmp/libnetty_tcnative_linux_x86_642308675901892111861.so: libcrypt.so.1: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>原因分析</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">\n<ol>\n<li class=\"lvl-7\">Netty-tcnative 的编译依赖：RocketMQ 使用的 Netty 的 tcnative 模块是在较旧的环境中编译的，而动态链接的版本锁定：编译时链接的是 libcrypt.so.1，运行时必须找到相同主版本号的库</li>\n</ol>\n</li>\n<li class=\"lvl-4\">\n<ol start=\"2\">\n<li class=\"lvl-7\">而我当前使用的系统为 Amazon Linux 2023，基于更新的 glibc，其加密功能已经迁移到 libcrypt.so.2。（Amazon Linux 2：基于较旧的 glibc 版本，libcrypt.so.1 是主要的加密库）</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 检查 libcrypt 是否存在</span></span><br><span class=\"line\">$ ldconfig -p | grep libcrypt</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class=\"line\">\tlibcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class=\"line\">\tlibcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class=\"line\">\tlibcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class=\"line\">\tlibcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>解决办法</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装兼容性包</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> yum install libxcrypt-compat</span><br><span class=\"line\"><span class=\"comment\"># 检查 libcrypt 是否存在</span></span><br><span class=\"line\">$ ldconfig -p | grep libcrypt</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">  libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12</span><br><span class=\"line\">\tlibcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3</span><br><span class=\"line\">\tlibcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so</span><br><span class=\"line\">\tlibcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2</span><br><span class=\"line\">\tlibcrypt.so.1 (libc6,x86-64) =&gt; /lib64/libcrypt.so.1</span><br><span class=\"line\">\tlibcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-写入消息失败，并报如下错误\">2.写入消息失败，并报如下错误</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Caused by: org.apache.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now. It may be caused by one of the following reasons: the broker<span class=\"string\">&#x27;s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00], messages are put to the slave, message store has been shut down, etc. BROKER: 10.250.0.175:10911</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>错误原因</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">RocketMQ 返回的 CODE: 14 表示：Broker 当前 不接受消息写入（服务暂不可用）。</li>\n<li class=\"lvl-4\">the broker’s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00]: Broker 的磁盘已满</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CL: 0.95 → CommitLog 95% 已使用</span><br><span class=\"line\">CQ: 0.95 → ConsumeQueue 95% 已使用</span><br><span class=\"line\">INDEX: -1.00 → 索引异常或未采集</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>含义</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>diskMaxUsedSpaceRatio</code></td>\n<td>Broker 磁盘最大可用比例（超过后禁止写入）</td>\n<td><strong>75%</strong></td>\n</tr>\n<tr>\n<td><code>storePathCommitLog</code></td>\n<td>消息存储路径（CommitLog）</td>\n<td><code>~/store/commitlog</code></td>\n</tr>\n<tr>\n<td><code>storePathConsumeQueue</code></td>\n<td>消费队列路径（ConsumeQueue）</td>\n<td><code>~/store/consumequeue</code></td>\n</tr>\n<tr>\n<td><code>storePathIndex</code></td>\n<td>索引路径</td>\n<td><code>~/store/index</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p>总结：可以确认是 磁盘使用率过高 导致 Broker 自动进入 “写保护” 模式。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>解决方法</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">\n<ol>\n<li class=\"lvl-9\">清理磁盘：确认磁盘使用率过高，并清理磁盘空间，既降低磁盘使用率</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"2\">\n<li class=\"lvl-9\">磁盘扩容：如果清理磁盘空间后，磁盘使用率依然过高，则需要扩容磁盘</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"3\">\n<li class=\"lvl-9\">配置调整：调整 Broker 配置(<code>broker.conf</code>)，将 <code>diskMaxUsedSpaceRatio</code> 配置适当提高，如 96%(<code>diskMaxUsedSpaceRatio=96</code>)，调整后重启 Broker。仅建议在紧急情况下临时解决。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 CentOS9 中 RocketMQ 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。 Apache RocketMQ 简介 一、RocketMQ 是什么？ RocketMQ 是一个分布式、队列模型的消息中间件。它由阿里巴巴在2012年开源，并于2017年正式成为 Apache 基金会的顶级项目。 你可以把它想象成一个在分布式系统中负责可靠传递消息的“邮局”或“快递系统”。当系统A需要发送数据给系统B，但它们之间不直接通信时，就可以通过 RocketMQ 来中转，确保消息不丢失、不重复，并且能按顺序送达。 RocketMQ 是一个高性能、高可靠、高实时的分布式消息中间件。它就像分布式系统的“中枢神经系统”，负责在各个服务之间可靠、高效地传递数据，是现代互联网架构中不可或缺的基础组件之一。 RocketMQ 5.x 通过引入 Proxy 模式，极大地提升了架构的灵活性、多语言支持能力和云原生亲和力，是其在消息中间件领域持续演进的重要里程碑。 它与 Kafka、RabbitMQ 等都是业界顶级的消息队列，但各有侧重。RocketMQ 在事务消息、顺序消息和对在线业务的稳定性支持方面表现尤为出色。 二、核心特点与优势 RocketMQ 之所以流行，主要归功于以下几个核心特点： 削峰填谷 场景：电商秒杀活动时，瞬时会有海量下单请求涌来，后端处理系统可能无法承受。 作用：RocketMQ 可以将这些突发的请求消息先缓存起来，然后让后端系统按照自己能处理的速率慢慢消费，避免了系统被冲垮。这就好比用一个大水库先拦住洪水，再平稳地向下游放水。 异步解耦 场景：用户注册后，需要发送欢迎邮件、发放优惠券、初始化积分等。 作用：主注册流程只需要向 RocketMQ 发送一个“用户已注册”的消息，而不需要等待所有后续操作完成。负责邮件、优惠券的系统会自己去 RocketMQ 取消息并处理。这样，系统之间的依赖关系就变弱了，提高了整体的灵活性和可维护性。 顺序消息 场景：一个订单的状态必须严格按照 创建 -&gt; 付款 -&gt; 发货 -&gt; 确认收货 的顺序来变更。 作用：RocketMQ 可以保证同一个订单ID的消息被存储在同一个队列中，并按照发送顺序被消费，确保了业务逻辑的正确性。 持久性与高可靠 RocketMQ 会将所有消息持久化到磁盘，即使服务器重启，消息也不会丢失。 它本身采用分布式集群架构，支持主从复制，提供了极高的可用性。 消息回溯 消费者可以重置消费位点，重新消费过去某个时间点的消息。这在业务逻辑出错、需要重新处理时非常有用。 海量消息堆积能力 能够支持万亿级别的消息堆积，不会因为大量未消费消息而导致性能急剧下降。 三、核心架构与概念 要理解 RocketMQ，需要知道几个关键角色： 3.1 经典核心组件 (RocketMQ 4.x) Producer（生产者）：发送消息的客户端。 Consumer（消费者）：接收消息的客户端。 Broker：消息服务器，负责存储和转发消息。它是 RocketMQ 的核心。 Topic（主题）：消息的分类，生产者向指定的 Topic 发送消息，消费者订阅指定的 Topic 来消费消息。例如，可以有一个 “Order_Topic” 专门用来处理所有订单相关的消息。 Name Server（名字服务）：一个轻量级的注册中心，负责管理所有 Broker 的地址信息，帮助生产者和消费者找到对应的 Broker。 3.2 RocketMQ 5 的新核心：Proxy 在 RocketMQ 5.x 版本中，引入了一个新的关键组件——Proxy。 Proxy（代理）：一个无状态的网络代理层，可以独立部署。 引入 Proxy 主要有两种模式： 集群部署模式 (Cluster Mode) 这是经典的部署方式。生产者和消费者直接与 Broker 通信。 架构：Producer/Consumer &lt;--&gt; Broker &lt;--&gt; Name Server Proxy 部署模式 这是 RocketMQ 5.x 推荐的新模式。所有客户端的请求都先经过 Proxy，由 Proxy 代理与 Broker 和 Name Server 进行交互。 架构：Producer/Consumer &lt;--&gt; Proxy &lt;--&gt; Broker &lt;--&gt; Name Server 引入 Proxy 模式的优势： 架构解耦与语言无关：Proxy 作为通用代理，将复杂的 Broker 协议封装成更简单的接口（如 gRPC），使得用不同编程语言（如 Go, Python, C++ 等）开发的客户端更容易接入，而无需实现复杂的原生协议。 简化客户端：客户端不再需要感知 Name Server 和 Broker 的地址变化，只需连接固定的 Proxy 地址即可，大大降低了客户端的复杂度。 增强安全性：可以在 Proxy 层统一实现安全认证、限流、审计等策略，作为Broker集群的安全屏障。 云原生友好：无状态的 Proxy 非常适合在 Kubernetes 等容器化环境中进行部署和弹性伸缩。 四、典型应用场景 电商/金融交易系统：保证交易核心流程的可靠、顺序和最终一致性。 大数据采集：将大量日志、行为数据先写入消息队列，再由后端的大数据处理系统（如 Flink, Spark）消费。 微服务间的异步通信：在微服务架构中，作为服务之间的通信总线。 RocketMQ 的安装 RocketMQ 5.x 依赖 JDK 1.8+。 单机安装 官方文档 下载RocketMQ 12345mkdir -p /usr/local/soft/rocketmq/wget https://dist.apache.org/repos/dist/release/rocketmq/5.3.2/rocketmq-all-5.3.2-bin-release.zipunzip rocketmq-all-5.3.2-bin-release.zipln -s rocketmq-all-5.3.2-bin-release rocketmq5cd rocketmq5 小贴士 默认脚本中，NameServer需要4G内存，Broker 需要8G内存，如果内存不够，可以进入bin目录，对其中的runserver.sh和runbroker.sh两个脚本进行一下修改 123456789# 使用vi runserver.sh指令，编辑这个脚本，找到下面的一行配置，调整Java进程的内存大小。JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;修改为：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms1g -Xmx1g -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;# 接下来，同样调整runbroker.sh中的内存大小。JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g&quot;修改为：JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms2g -Xmx2g&quot; 启动 NameServer 安装完RocketMQ包后，我们启动NameServer 123456789### 启动namesrv$ nohup sh bin/mqnamesrv &amp;## 指定配置文件$ nohup sh bin/mqnamesrv -c namesrv.conf &amp;### 验证namesrv是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.log# 我们可以在namesrv.log 中看到 &#x27;The Name Server boot success..&#x27;， 表示NameServer 已成功启动。The Name Server boot success. serializeType=JSON, address 0.0.0.0:9876 namesrv.conf 示例 12# The port of nameserverlistenPort = 9876 启动 Broker+Proxy NameServer成功启动后，我们启动Broker和Proxy。这里我们使用 Local 模式部署，即 Broker 和 Proxy 同进程部署。5.x 版本也支持 Broker 和 Proxy 分离部署以实现更灵活的集群能力。 123456789### 先启动broker$ nohup sh bin/mqbroker -n localhost:9876 --enable-proxy &amp;# 指定配置文件$ nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf --enable-proxy &amp;### 验证broker是否启动成功, 比如, broker的ip是192.168.1.2 然后名字是broker-a$ tail -f ~/logs/rocketmqlogs/proxy.log# 我们可以在 proxy.log 中看到“The broker[brokerName,ip:port] boot success..”，这表明 broker 已成功启动。The broker[broker-a, 10.250.0.175:10911] boot success. serializeType=JSON and name server is localhost:9876 关闭服务器 1234# 先停止 Broker$ sh bin/mqshutdown broker# 停止 NameServer$ sh bin/mqshutdown namesrv 日志及数据存储路径 RocketMQ 5 主要有三类服务组件需要关注它们的存储目录 组件 功能 默认存储内容 默认路径（Linux 环境） NameServer 路由服务 日志配置文件： $&#123;ROCKETMQ_HOME&#125;/conf/rmq.namesrv.logback.xml ~/logs/rocketmqlogs/namesrv.log Broker 核心消息存储服务 消息数据（CommitLog、ConsumeQueue、Index、Config） 数据目录：~/store├── commitlog/ → 消息物理文件├── consumequeue/ → 消费队列索引├── index/ → 消息索引├── config/ → topic、consumer offset、subscription 信息├── checkpoint → 存储校验点├── abort → 异常退出标志 运行日志 日志配置文件：$&#123;ROCKETMQ_HOME&#125;/conf/rmq.broker.logback.xml ~/logs/rocketmqlogs/broker.log 配置文件 broker配置文件 $&#123;ROCKETMQ_HOME&#125;/conf/broker.conf Proxy 客户端访问入口（可选） 访问日志、转发日志： $&#123;ROCKETMQ_HOME&#125;/conf/rmq.proxy.logback.xml ~/logs/rocketmqlogs/proxy.log 配置文件 代理配置文件 $&#123;ROCKETMQ_HOME&#125;/conf/rmq-proxy.json NameServer 和 Proxy 都是无状态（stateless）组件，不会持久化业务数据。 修改 Broker 数据路径，比如 conf/broker.conf 1234567891011121314151617181920# 消息存储根目录storePathRootDir=/data/rocketmq/store# CommitLog 存储路径storePathCommitLog=/data/rocketmq/store/commitlog# ConsumeQueue 存储路径storePathConsumeQueue=/data/rocketmq/store/consumequeue# 消息索引文件存储路径storePathIndex=/data/rocketmq/store/index# 运行时配置存储路径storePathConfig=/data/rocketmq/store/config# checkpoint 文件路径storeCheckpoint=/data/rocketmq/store/checkpoint# abort 文件路径abortFile=/data/rocketmq/store/abort 集群安装 官网文档 对集群安装的方式介绍了多种，本文仅实战一种：多节点（集群）多副本模式-异步复制 每个Master配置一个Slave，有多组 Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样； 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 该模式下，Master 节点和 Slave 节点之间是异步复制的，Master 节点挂掉后，Slave 节点不会自动切换为 Master 节点。 集群规划 12345678910111213# NameServer 3 台NameServer1 10.250.0.175NameServer2 10.250.0.188NameServer3 10.250.0.31# Broker 2 Master 2 ReplicasBroker1 10.250.0.188 broker-a,broker-b-sBroker2 10.250.0.31 broker-b,broker-a-s# Proxy 3 台Proxy1 10.250.0.175Proxy2 10.250.0.188Proxy3 10.250.0.31 部署 NameServer 在三台服务器上分别启动RocketMQ NameServer 12cd /usr/local/soft/rocketmq/rocketmq5nohup sh bin/mqnamesrv &amp; 部署Broker 部署前需要先清除掉之前的存储数据 12# 默认路径rm -rf ~/store/* broker-a.properties 12345678910111213141516171819brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-a # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=0 # brokerId 必须唯一 ，且 master 的 brokerId 必须为 0deleteWhen=04 # 表示凌晨 4 点清理fileReservedTime=48 # 表示保存 48 小时的数据brokerRole=ASYNC_MASTER # 角色，表示异步复制的主节点flushDiskType=ASYNC_FLUSH # 表示异步刷盘# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-astorePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-a/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-a/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpointabortFile=/usr/local/soft/rocketmq/data/store-a/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=10911 broker-a-s.properties 12345678910111213141516171819brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-a # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=1 # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0deleteWhen=04fileReservedTime=48brokerRole=SLAVE # 角色，表示异步复制的从节点flushDiskType=ASYNC_FLUSH# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-astorePathCommitLog=/usr/local/soft/rocketmq/data/store-a/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-a/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-a/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-a/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-a/checkpointabortFile=/usr/local/soft/rocketmq/data/store-a/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=11011 broker-b.properties 1234567891011121314151617181920brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-b # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=0 # brokerId 必须唯一 ，且 master 的 brokerId 必须为 0deleteWhen=04 # 表示凌晨 4 点清理fileReservedTime=48 # 表示保存 48 小时的数据brokerRole=ASYNC_MASTER # 角色，表示异步复制的主节点flushDiskType=ASYNC_FLUSH # 表示异步刷盘# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-bstorePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-b/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-b/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpointabortFile=/usr/local/soft/rocketmq/data/store-b/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=10911 broker-b-s.properties 1234567891011121314151617181920brokerClusterName=DefaultCluster # 集群名称必须一致brokerName=broker-b # broker 名称，master 和 slave 的 brokerName 必须一致brokerId=1 # brokerId 必须唯一 ，且 slave 的 brokerId 必须大于 0deleteWhen=04fileReservedTime=48brokerRole=SLAVE # 角色，表示异步复制的从节点flushDiskType=ASYNC_FLUSH# 因为同一台服务器上启动多个 Broker，所以需要指定不同的存储路径和端口# 存储数据路径storePathRootDir=/usr/local/soft/rocketmq/data/store-bstorePathCommitLog=/usr/local/soft/rocketmq/data/store-b/commitlogstorePathConsumeQueue=/usr/local/soft/rocketmq/data/store-b/consumequeuestorePathIndex=/usr/local/soft/rocketmq/data/store-b/indexstorePathConfig=/usr/local/soft/rocketmq/data/store-b/configstoreCheckpoint=/usr/local/soft/rocketmq/data/store-b/checkpointabortFile=/usr/local/soft/rocketmq/data/store-b/abort#Broker 对外服务的监听端口，同一台机器上启动多个Broker，需要指定不同的端口listenPort=11011 在 Broker1 10.250.0.188 上启动 broker-a 和 broker-b-s 1234567# 启动 broker-anohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-a.properties &amp;# 启动 broker-b-snohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-b-s.properties &amp;## nohup.out 中的输出类似与下面这种就表示启动成功The broker[broker-a, 10.250.0.31:11011] boot success. serializeType=JSON and name server is 10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876 在 Broker2 10.250.0.31 上启动 broker-b 和 broker-a-s 1234# 启动 broker-bnohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-b.properties &amp;# 启动 broker-a-snohup sh bin/mqbroker -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -c conf/2m-2s-async/broker-a-s.properties &amp; 启动成功后，可以通过如下命令检查机器状态 12345678# 确认 Broker 是否已经成功注册到 Nameserver，执行以下命令（在任意一台机器上）sh bin/mqadmin clusterList -n 10.250.0.175:9876## 输出类似如下#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #Timer(Progress) #PCWait(ms) #Hour #SPACE #ACTIVATEDDefaultCluster broker-a 0 10.250.0.188:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489250.72 0.2900 trueDefaultCluster broker-a 1 10.250.0.31:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 489250.72 0.2600 falseDefaultCluster broker-b 0 10.250.0.31:10911 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 0-0(0.0w, 0.0, 0.0) 0 489250.72 0.2600 trueDefaultCluster broker-b 1 10.250.0.188:11011 V5_3_2 0.00(0,0ms) 0.00(0,0ms|0,0ms) 3-0(0.0w, 0.0, 0.0) 0 489250.72 0.2900 false 配置 Proxy 在三台服务器上分别启动RocketMQ NameServer 1234567nohup sh bin/mqproxy -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; &amp;## 指定配置文件，这里要注意，集群的名称要与 conf/proxy.conf 中配置的集群名称必须一致，默认是 DefaultClusternohup sh bin/mqproxy -n &quot;10.250.0.175:9876;10.250.0.188:9876;10.250.0.31:9876&quot; -pc conf/proxy.conf &amp;## 查看日志，输出如下内容就表示启动成功，tail -f nohup.outrocketmq-proxy startup successfully 端口说明 端口号 协议 组件/服务 作用说明 9876 TCP NameServer RocketMQ 集群的 NameServer 服务端口。用于 Broker 注册、客户端路由发现。Producer/Consumer 连接此端口以获取 Broker 地址。 8080 TCP Proxy (gRPC / HTTP) RocketMQ 5 引入的 Proxy 服务 默认端口之一。用于 HTTP/gRPC 客户端接入，例如 RocketMQ Proxy REST API、异步消息接口等。 8081 TCP Proxy Admin / Dashboard / gRPC Alt 通常是 Proxy 的 管理接口 或 gRPC 辅助端口（依配置而定）。也可能是控制面接口，用于与 Console 或控制工具通信。 10909 TCP Broker HA (High Availability) Broker 主从同步端口（Master ↔ Slave 之间的数据复制）。用于消息数据与元数据的同步。 10911 TCP Broker 服务端口 Broker 的 主通信端口，客户端连接发送消息、消费消息、心跳等。Producer 和 Consumer 通过 NameServer 获取该端口地址后进行通信。 10912 TCP Broker HA 客户端端口 Broker 主从复制中的 Slave 连接 Master 时使用的 客户端监听端口。通常与 10909 配合使用，一主多从模式中 Slave 主动连接 Master。 安装过程中遇到的问题 1.启动 Proxy 失败 无论是 Broker+Proxy 启动，还是 单独启动 Proxy，都报如下错误： 123456# 错误会在 nohup.out 中输出Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: failed to load the required native libraryCaused by: java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_x86_64_fedora, netty_tcnative_linux_x86_64, netty_tcnative_x86_64, netty_tcnative]Suppressed: java.lang.UnsatisfiedLinkError: /tmp/libnetty_tcnative_linux_x86_642308675901892111861.so: libcrypt.so.1: cannot open shared object file: No such file or directory 原因分析 Netty-tcnative 的编译依赖：RocketMQ 使用的 Netty 的 tcnative 模块是在较旧的环境中编译的，而动态链接的版本锁定：编译时链接的是 libcrypt.so.1，运行时必须找到相同主版本号的库 而我当前使用的系统为 Amazon Linux 2023，基于更新的 glibc，其加密功能已经迁移到 libcrypt.so.2。（Amazon Linux 2：基于较旧的 glibc 版本，libcrypt.so.1 是主要的加密库） 12345678# 检查 libcrypt 是否存在$ ldconfig -p | grep libcrypt## 输出 libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12 libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3 libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2 libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so 解决办法 1234567891011# 安装兼容性包sudo yum install libxcrypt-compat# 检查 libcrypt 是否存在$ ldconfig -p | grep libcrypt## 输出 libcryptsetup.so.12 (libc6,x86-64) =&gt; /lib64/libcryptsetup.so.12 libcrypto.so.3 (libc6,x86-64) =&gt; /lib64/libcrypto.so.3 libcrypto.so (libc6,x86-64) =&gt; /lib64/libcrypto.so libcrypt.so.2 (libc6,x86-64) =&gt; /lib64/libcrypt.so.2 libcrypt.so.1 (libc6,x86-64) =&gt; /lib64/libcrypt.so.1 libcrypt.so (libc6,x86-64) =&gt; /lib64/libcrypt.so 2.写入消息失败，并报如下错误 1Caused by: org.apache.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now. It may be caused by one of the following reasons: the broker&#x27;s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00], messages are put to the slave, message store has been shut down, etc. BROKER: 10.250.0.175:10911 错误原因 RocketMQ 返回的 CODE: 14 表示：Broker 当前 不接受消息写入（服务暂不可用）。 the broker’s disk is full [CL: 0.95 CQ: 0.95 INDEX: -1.00]: Broker 的磁盘已满 123CL: 0.95 → CommitLog 95% 已使用CQ: 0.95 → ConsumeQueue 95% 已使用INDEX: -1.00 → 索引异常或未采集 配置项 含义 默认值 diskMaxUsedSpaceRatio Broker 磁盘最大可用比例（超过后禁止写入） 75% storePathCommitLog 消息存储路径（CommitLog） ~/store/commitlog storePathConsumeQueue 消费队列路径（ConsumeQueue） ~/store/consumequeue storePathIndex 索引路径 ~/store/index 总结：可以确认是 磁盘使用率过高 导致 Broker 自动进入 “写保护” 模式。 解决方法 清理磁盘：确认磁盘使用率过高，并清理磁盘空间，既降低磁盘使用率 磁盘扩容：如果清理磁盘空间后，磁盘使用率依然过高，则需要扩容磁盘 配置调整：调整 Broker 配置(broker.conf)，将 diskMaxUsedSpaceRatio 配置适当提高，如 96%(diskMaxUsedSpaceRatio=96)，调整后重启 Broker。仅建议在紧急情况下临时解决。","summary":"摘要 本文介绍 CentOS9 中 RocketMQ 的安装与使用。 RocketMQ官网 本文使用的 RocketMQ 版本为 5.3.2。","date_published":"2025-10-23T13:30:05.000Z","tags":["技术","rocketmq","分布式","rocketmq"]},{"id":"https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/","url":"https://blog.hanqunfeng.com/2025/10/16/kafka-06-zk-to-kraft/","title":"Kafka 从 Zookeeper 迁移到 KRaft","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org/39/documentation.html#kraft_zk_migration\">官方文档：ZooKeeper到KRaft迁移</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"从-Zookeeper-模式迁移到-KRaft-模式（平滑迁移）\">从 Zookeeper 模式迁移到 KRaft 模式（平滑迁移）</h2>\n<p><em><strong>！！！迁移后将无法再恢复到 ZooKeeper 模式！！！</strong></em></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 官方在 3.4+ 引入了完整的 Zookeeper → KRaft 平滑迁移机制，称为 <code>ZK to KRaft (ZkMigration)</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>迁移背景与前提</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">项目</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">支持版本</td>\n<td style=\"text-align:left\">Kafka <strong>3.4.0+</strong>（建议至少使用 <strong>3.6.x ，目前最新版为 3.9.x</strong>）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">迁移目的</td>\n<td style=\"text-align:left\">摆脱 ZooKeeper，完全切换为 KRaft 自管理模式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">迁移模式</td>\n<td style=\"text-align:left\"><strong>在线迁移</strong>（无停机或最小停机）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">最终目标</td>\n<td style=\"text-align:left\">Kafka 的控制器与元数据完全由 KRaft 管理，不再依赖 ZooKeeper。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>整体迁移流程概览</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>阶段</th>\n<th>控制器类型</th>\n<th>Broker 模式</th>\n<th>ZooKeeper 角色</th>\n<th>KRaft 角色</th>\n<th>特征说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>初始阶段</strong></td>\n<td>ZooKeeper 控制器</td>\n<td>全部为 ZK 模式</td>\n<td>管理所有元数据</td>\n<td>尚未启用</td>\n<td>所有 Broker 都运行在 ZK 模式下，由 ZK 控制器管理集群。</td>\n</tr>\n<tr>\n<td><strong>初始元数据加载阶段</strong></td>\n<td>KRaft 控制器开始加载</td>\n<td>部分（或全部）仍为 ZK 模式</td>\n<td>提供元数据源</td>\n<td>从 ZK 加载元数据</td>\n<td>KRaft 法定节点（controller.quorum.voters）从 ZK 中读取并同步当前集群元数据。</td>\n</tr>\n<tr>\n<td><strong>混合阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>部分 ZK 模式，部分 KRaft 模式</td>\n<td>保留只读元数据</td>\n<td>管理并更新元数据</td>\n<td>KRaft 控制器成为主控，ZK 仍存在但只提供读取，Broker 可处于不同模式（混合状态）。</td>\n</tr>\n<tr>\n<td><strong>双写阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>全部为 KRaft 模式</td>\n<td>接收 KRaft 同步写入</td>\n<td>管理元数据并写入 ZK</td>\n<td>所有 Broker 都运行在 KRaft 模式，控制器将元数据同时写入 ZK 和 KRaft 日志。</td>\n</tr>\n<tr>\n<td><strong>迁移完成阶段</strong></td>\n<td>KRaft 控制器</td>\n<td>全部为 KRaft 模式</td>\n<td>不再使用</td>\n<td>独立运行</td>\n<td>停止向 ZK 写入元数据，ZK 可安全关闭，Kafka 完全运行在无 Zookeeper 的 KRaft 模式下。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"开始迁移\">开始迁移</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里以前文 <a href=\"/2025/10/13/kafka-01-install-zookeeper/\" title=\"Kafka 的安装：基于 Zookeeper\">Kafka 的安装：基于 Zookeeper</a> 中的3个节点的集群为例。</p>\n</li>\n</ul>\n<h3 id=\"启动一个-Controller-节点\">启动一个 Controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在任意一个节点上启动一个 Controller 节点，这里为 worker1</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动前需要先获取当前 Kafka 集群的 Cluster ID</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ zookeeper-shell.sh localhost:2181 get /cluster/id</span><br><span class=\"line\">Connecting to localhost:2181</span><br><span class=\"line\"></span><br><span class=\"line\">WATCHER::</span><br><span class=\"line\"></span><br><span class=\"line\">WatchedEvent state:SyncConnected <span class=\"built_in\">type</span>:None path:null</span><br><span class=\"line\">&#123;<span class=\"string\">&quot;version&quot;</span>:<span class=\"string\">&quot;1&quot;</span>,<span class=\"string\">&quot;id&quot;</span>:<span class=\"string\">&quot;hp_Q0pihQ0ORcIvXlfHobQ&quot;</span>&#125;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>准备好 Controller 节点的配置文件，这里可以用 <code>config/kraft/controller.properties</code> 为模板进行修改</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色，这里只能是controller</span></span><br><span class=\"line\">process.roles=controller</span><br><span class=\"line\"><span class=\"comment\"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class=\"line\">node.id=3000</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点，因为我们当前只启动了一个controller节点，所以只能配置一个投票节点</span></span><br><span class=\"line\">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class=\"line\"><span class=\"comment\"># 配置监听器，注意端口不能重复</span></span><br><span class=\"line\">listeners=CONTROLLER://:9098</span><br><span class=\"line\">advertised.listeners=CONTROLLER://worker1:9098</span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录，这里存放的是元数据，在格式化时这个目录必须为空目录</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\">zookeeper.metadata.migration.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ZooKeeper client 连接</span></span><br><span class=\"line\">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 其它参数尽量保持与旧集群的配置一致</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Controller 节点</p>\n</li>\n</ul>\n<blockquote>\n<p>千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 <a href=\"http://kafka-storage.sh\">kafka-storage.sh</a> format ，那会把原有数据结构重置或踩坏。<br>\n必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 格式化元数据目录，log.dirs 参数指定元数据存放目录，首次运行前必须为空目录</span></span><br><span class=\"line\"><span class=\"comment\"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class=\"line\">kafka-storage.sh format --standalone -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br><span class=\"line\"><span class=\"comment\"># 启动，这里没有后台启动是为了方便观察日志输出</span></span><br><span class=\"line\">kafka-server-start.sh /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>模式</th>\n<th>format 命令</th>\n<th>quorum 状态</th>\n<th>是否从 ZK 加载</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>迁移阶段（standalone）</td>\n<td><code>--standalone</code></td>\n<td>无（单节点）</td>\n<td>✅ 是</td>\n</tr>\n<tr>\n<td>正式 KRaft 模式</td>\n<td>无 <code>--standalone</code></td>\n<td>✅ 多节点</td>\n<td>❌ 否（独立运行）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"将原先的三个节点作为-Broker-节点重新启动\">将原先的三个节点作为 Broker 节点重新启动</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改原先的配置文件 <code>server.properties</code>，只需要修改如下内容即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在最后加入 CONTROLLER:PLAINTEXT</span></span><br><span class=\"line\">listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,CONTROLLER:PLAINTEXT</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 以下是新加入的 配置项</span></span><br><span class=\"line\"><span class=\"comment\"># Set the IBP，当前 kafka 版本是 3.9.1，所以这里设置为 3.9</span></span><br><span class=\"line\">inter.broker.protocol.version=3.9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\">zookeeper.metadata.migration.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># KRaft controller quorum configuration，因为目前只启动了一个 controller 节点，所以只能配置一个投票节点</span></span><br><span class=\"line\">controller.quorum.bootstrap.servers=worker1:9098</span><br><span class=\"line\"><span class=\"comment\"># 控制器监听器名称，要与 contreller 节点配置文件 controller.properties 中的配置一致</span></span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别重新启动三个节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 kafka</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br><span class=\"line\"><span class=\"comment\"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class=\"line\">ps -ef | grep kafka | grep  <span class=\"string\">&quot;server\\.properties&quot;</span> | grep -v grep | awk <span class=\"string\">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class=\"built_in\">kill</span> -9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新启动 kafka</span></span><br><span class=\"line\">kafka-server-start.sh /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当三个节点都以必要的配置重新启动后，迁移将自动开始。迁移完成后，可以在 Controller(worker1)节点 上看到类似如下日志：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ✅ 意味：从 ZooKeeper 到 KRaft 的初始元数据迁移已成功，共写入 62 条记录，当前 KRaft metadata offset 为 3179。这是迁移成功的明确证据。</span></span><br><span class=\"line\">Completed migration of metadata from ZooKeeper to KRaft. 62 records were generated <span class=\"keyword\">in</span> 300 ms across 1 batches. The average time spent waiting on a batch was 97.00 ms. The record types were &#123;TOPIC_RECORD=3, PARTITION_RECORD=56, CONFIG_RECORD=3&#125;. The current metadata offset is now 3179 with an epoch of 2. Saw 3 brokers <span class=\"keyword\">in</span> the migrated metadata [1, 2, 3]. (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：控制器已加载并生效新元数据与 feature set（与 offset 3179 对应）。</span></span><br><span class=\"line\">Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures=&#123;metadata.version=21&#125;, finalizedFeaturesEpoch=3179). (org.apache.kafka.metadata.publisher.FeaturesPublisher)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：内部迁移状态已更新，KRaft 上有了写入位置记录。</span></span><br><span class=\"line\">Finished initial migration of ZK metadata to KRaft <span class=\"keyword\">in</span> 3486479 ns. Transitioned migration state from ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=-1, kraftMetadataEpoch=-1, lastUpdatedTimeMs=1760682050169, migrationZkVersion=1, controllerZkEpoch=3, controllerZkVersion=3&#125; to ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=3179, kraftMetadataEpoch=2, lastUpdatedTimeMs=1760682050169, migrationZkVersion=2, controllerZkEpoch=3, controllerZkVersion=3&#125; (org.apache.kafka.metadata.migration.KRaftMigrationDriver)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ✅ 意味：迁移流程按预期推进：先把 KRaft 的元数据与 ZK 对齐（sync），然后与 brokers 建立通信，最终进入 DUAL_WRITE（双写）。DUAL_WRITE 阶段表示控制器在写入 KRaft metadata log 的同时，仍然会把必要的写操作也写回 ZooKeeper（双写）——直到迁移完全完成并确认可以停止写 ZK 为止。</span></span><br><span class=\"line\">3000 transitioning from ZK_MIGRATION to SYNC_KRAFT_TO_ZK state</span><br><span class=\"line\">...</span><br><span class=\"line\">Performing a full metadata <span class=\"built_in\">sync</span> from KRaft to ZK.</span><br><span class=\"line\">Did not make any ZK writes when reconciling with KRaft state.</span><br><span class=\"line\">3000 transitioning ... to KRAFT_CONTROLLER_TO_BROKER_COMM</span><br><span class=\"line\">...</span><br><span class=\"line\">Sending RPCs to broker before moving to dual-write mode using at offset and epoch OffsetAndEpoch(offset=3179, epoch=2)</span><br><span class=\"line\">...</span><br><span class=\"line\">3000 transitioning ... to DUAL_WRITE state</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面的日志总体上表明，元数据迁移已成功完成并且控制器进入了双写（DUAL_WRITE）阶段。</p>\n</li>\n</ul>\n<h3 id=\"将三个Broker节点的配置修改为-KRaft-模式的-broker-节点\">将三个Broker节点的配置修改为 KRaft 模式的 broker 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改三个节点的配置文件 <code>server.properties</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 添加process.roles=broker</span></span><br><span class=\"line\">process.roles=broker</span><br><span class=\"line\"><span class=\"comment\"># 用 node.id 替换 broker.id，注意，node.id 需要与 broker.id 一致</span></span><br><span class=\"line\"><span class=\"comment\"># broker.id=1</span></span><br><span class=\"line\">node.id=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 去掉 zookeeper 相关配置</span></span><br><span class=\"line\"><span class=\"comment\"># Don&#x27;t set the IBP, KRaft uses &quot;metadata.version&quot; feature flag</span></span><br><span class=\"line\"><span class=\"comment\"># inter.broker.protocol.version=3.9</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove the migration enabled flag</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.metadata.migration.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove ZooKeeper client configuration</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别重新启动三个节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 kafka</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br><span class=\"line\"><span class=\"comment\"># 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.properties</span></span><br><span class=\"line\">ps -ef | grep kafka | grep  <span class=\"string\">&quot;server\\.properties&quot;</span> | grep -v grep | awk <span class=\"string\">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class=\"built_in\">kill</span> -9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新启动 kafka</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<h3 id=\"将-Controller-节点的配置修改为-KRaft-模式的-controller-节点\">将 Controller 节点的配置修改为 KRaft 模式的 controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改 controller 节点的配置文件 <code>controller.properties</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 去掉去下内容</span></span><br><span class=\"line\"><span class=\"comment\"># 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.metadata.migration.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ZooKeeper client 连接</span></span><br><span class=\"line\"><span class=\"comment\"># zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重启启动 controller 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭后重新启动</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时你可以关闭 zookeeper 集群了，新的 kafka 集群将不再使用 ZooKeeper，也无法在恢复到 ZooKeeper 模式。</p>\n</li>\n</ul>\n<h3 id=\"加入新的-Controller-节点\">加入新的 Controller 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Controller 尽量保持 奇数个节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>之前已经在 <code>worker1</code> 节点上启动了 controller ，现在 <code>worker2</code> 和 <code>worker3</code> 上也来启动 controller 节点，并将它们加入到 kafka 集群中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在开始配置前，先将上面的 controller 节点 和 三个 broker 节点 的如下配置进行修改，并重启启动。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将 controller.quorum.bootstrap.servers 替换为 controller.quorum.voters</span></span><br><span class=\"line\">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.bootstrap.servers=worker1:9098</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.voters = 谁是正式投票成员（固定配置）</span></span><br><span class=\"line\"><span class=\"comment\"># controller.quorum.bootstrap.servers = 临时找谁引导连接（迁移或初始化用）</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>作用</th>\n<th>适用阶段</th>\n<th>是否必需</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>controller.quorum.voters</code></strong></td>\n<td>定义 <strong>正式的 KRaft 控制器投票成员列表（voter set）</strong></td>\n<td>集群正常运行时</td>\n<td>✅ 是</td>\n<td>所有节点必须配置相同的值</td>\n</tr>\n<tr>\n<td><strong><code>controller.quorum.bootstrap.servers</code></strong></td>\n<td>定义 <strong>迁移阶段或初始化阶段的控制器连接地址（bootstrap controller endpoint）</strong></td>\n<td><strong>ZK → KRaft 迁移阶段</strong> 或 <strong>KRaft 集群初次启动</strong></td>\n<td>⚙️ 可选（仅特定阶段）</td>\n<td>用于在 controller quorum 尚未形成时的临时发现</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>参考 worker1 上的 controller 节点的配置文件 <code>controller.properties</code>，配置 woker2 的 controller 节点配置文件<code>controller.properties</code> ，worker3 也是类似的。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色，这里只能是controller</span></span><br><span class=\"line\">process.roles=controller</span><br><span class=\"line\"><span class=\"comment\"># 节点ID，不能与现有Broker节点的ID一致</span></span><br><span class=\"line\">node.id=3001</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点</span></span><br><span class=\"line\">controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># 配置监听器，注意端口不能重复</span></span><br><span class=\"line\">listeners=CONTROLLER://:9098</span><br><span class=\"line\">advertised.listeners=CONTROLLER://worker2:9098</span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录，这里存放的是元数据</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-meta</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意这里要与原先的 server.properties 中配置的监听器名称一致</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>初始化日志目录</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 只有 Controller 节点才需要初始化日志目录</span></span><br><span class=\"line\"><span class=\"comment\"># -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster ID</span></span><br><span class=\"line\">kafka-storage.sh format -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别启动 worker2 和 worker3 上的 controller 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时新的 controller 节点不会立刻加入选举队列，新节点初始状态默认是 observer，需要执行下面的命令将节点加入选举队列</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别在 worker2 和 worker3 上执行</span></span><br><span class=\"line\">kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config /usr/local/kafka/kafka3/config/kraft/controller.properties add-controller</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看集群节点状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --replication</span><br><span class=\"line\">NodeId\tDirectoryId           \tLogEndOffset\tLag\tLastFetchTimestamp\tLastCaughtUpTimestamp\tStatus</span><br><span class=\"line\">3000  \tRJ4oOPGgTw-KxHFNn4SmiQ\t27820       \t0  \t1760696136345     \t1760696136345        \tLeader</span><br><span class=\"line\">3001  \tzGnWA7zYmRHG6bcTlFV2qA\t27820       \t0  \t1760696136259     \t1760696136259        \tFollower</span><br><span class=\"line\">3002  \tgIDkhOQJEHqg-GJBdezU1Q\t27820       \t0  \t1760696136257     \t1760696136257        \tFollower</span><br><span class=\"line\">2     \t9KeeAYKEQHT92DxqNSwYuA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\">1     \tQ8lr8JQ2vrDS35_DrI1MxA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\">3     \trgQR5wd_i5hLgU97dCKIvA\t27820       \t0  \t1760696136257     \t1760696136257        \tObserver</span><br><span class=\"line\"></span><br><span class=\"line\">$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --status</span><br><span class=\"line\">ClusterId:              hp_Q0pihQ0ORcIvXlfHobQ</span><br><span class=\"line\">LeaderId:               3000</span><br><span class=\"line\">LeaderEpoch:            5</span><br><span class=\"line\">HighWatermark:          30094</span><br><span class=\"line\">MaxFollowerLag:         0</span><br><span class=\"line\">MaxFollowerLagTimeMs:   0</span><br><span class=\"line\">CurrentVoters:          [&#123;<span class=\"string\">&quot;id&quot;</span>: 3000, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;RJ4oOPGgTw-KxHFNn4SmiQ&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker1:9098&quot;</span>]&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3001, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;zGnWA7zYmRHG6bcTlFV2qA&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker2:9098&quot;</span>]&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3002, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;gIDkhOQJEHqg-GJBdezU1Q&quot;</span>, <span class=\"string\">&quot;endpoints&quot;</span>: [<span class=\"string\">&quot;CONTROLLER://worker3:9098&quot;</span>]&#125;]</span><br><span class=\"line\">CurrentObservers:       [&#123;<span class=\"string\">&quot;id&quot;</span>: 2, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;9KeeAYKEQHT92DxqNSwYuA&quot;</span>&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 1, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;Q8lr8JQ2vrDS35_DrI1MxA&quot;</span>&#125;, &#123;<span class=\"string\">&quot;id&quot;</span>: 3, <span class=\"string\">&quot;directoryId&quot;</span>: <span class=\"string\">&quot;rgQR5wd_i5hLgU97dCKIvA&quot;</span>&#125;]</span><br></pre></td></tr></table></figure>\n<h3 id=\"加入-新的-Broker-节点\">加入 新的 Broker 节点</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建新的 Broker 节点时，参考其它 Broker 节点 配置好配置文件 <code>server.properties</code>，并启动 Broker 节点即可。</p>\n</li>\n<li class=\"lvl-2\">\n<p>无需运行日志目录初始化命令，因为 Broker 节点只存放 消息 数据。</p>\n</li>\n</ul>\n<h2 id=\"迁移后注意事项\">迁移后注意事项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>迁移完成后，Kafka 客户端（Producer / Consumer / AdminClient）依然连接的是 Broker 节点，而不是 Controller 节点。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 在 ZooKeeper 模式与 KRaft 模式下的区别主要在于：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">控制平面（Control Plane）：ZK 模式下由 ZooKeeper + Controller Broker 共同管理；KRaft 模式下由 独立的 Controller 进程或角色 管理（通过 Raft 协议同步元数据）。</li>\n<li class=\"lvl-4\">数据平面（Data Plane）：无论是哪个模式，客户端发送、消费消息仍然是通过 Broker 节点 完成的。</li>\n<li class=\"lvl-4\">也就是说，Controller 管理集群元数据（主题、分区、副本、Leader 选举等），而 Broker 节点处理实际的消息流。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 官方文档：ZooKeeper到KRaft迁移 从 Zookeeper 模式迁移到 KRaft 模式（平滑迁移） ！！！迁移后将无法再恢复到 ZooKeeper 模式！！！ Kafka 官方在 3.4+ 引入了完整的 Zookeeper → KRaft 平滑迁移机制，称为 ZK to KRaft (ZkMigration)。 迁移背景与前提 项目 说明 支持版本 Kafka 3.4.0+（建议至少使用 3.6.x ，目前最新版为 3.9.x） 迁移目的 摆脱 ZooKeeper，完全切换为 KRaft 自管理模式 迁移模式 在线迁移（无停机或最小停机） 最终目标 Kafka 的控制器与元数据完全由 KRaft 管理，不再依赖 ZooKeeper。 整体迁移流程概览 阶段 控制器类型 Broker 模式 ZooKeeper 角色 KRaft 角色 特征说明 初始阶段 ZooKeeper 控制器 全部为 ZK 模式 管理所有元数据 尚未启用 所有 Broker 都运行在 ZK 模式下，由 ZK 控制器管理集群。 初始元数据加载阶段 KRaft 控制器开始加载 部分（或全部）仍为 ZK 模式 提供元数据源 从 ZK 加载元数据 KRaft 法定节点（controller.quorum.voters）从 ZK 中读取并同步当前集群元数据。 混合阶段 KRaft 控制器 部分 ZK 模式，部分 KRaft 模式 保留只读元数据 管理并更新元数据 KRaft 控制器成为主控，ZK 仍存在但只提供读取，Broker 可处于不同模式（混合状态）。 双写阶段 KRaft 控制器 全部为 KRaft 模式 接收 KRaft 同步写入 管理元数据并写入 ZK 所有 Broker 都运行在 KRaft 模式，控制器将元数据同时写入 ZK 和 KRaft 日志。 迁移完成阶段 KRaft 控制器 全部为 KRaft 模式 不再使用 独立运行 停止向 ZK 写入元数据，ZK 可安全关闭，Kafka 完全运行在无 Zookeeper 的 KRaft 模式下。 开始迁移 这里以前文 Kafka 的安装：基于 Zookeeper 中的3个节点的集群为例。 启动一个 Controller 节点 在任意一个节点上启动一个 Controller 节点，这里为 worker1 启动前需要先获取当前 Kafka 集群的 Cluster ID 1234567$ zookeeper-shell.sh localhost:2181 get /cluster/idConnecting to localhost:2181WATCHER::WatchedEvent state:SyncConnected type:None path:null&#123;&quot;version&quot;:&quot;1&quot;,&quot;id&quot;:&quot;hp_Q0pihQ0ORcIvXlfHobQ&quot;&#125; 准备好 Controller 节点的配置文件，这里可以用 config/kraft/controller.properties 为模板进行修改 123456789101112131415161718192021222324# 配置当前节点的角色，这里只能是controllerprocess.roles=controller# 节点ID，不能与现有Broker节点的ID一致node.id=3000# 配置集群的投票节点，因为我们当前只启动了一个controller节点，所以只能配置一个投票节点controller.quorum.bootstrap.servers=worker1:9098# 配置监听器，注意端口不能重复listeners=CONTROLLER://:9098advertised.listeners=CONTROLLER://worker1:9098controller.listener.names=CONTROLLER# 日志存放目录，这里存放的是元数据，在格式化时这个目录必须为空目录log.dirs=/usr/local/kafka/dataDir/kraft-meta# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程zookeeper.metadata.migration.enable=true# ZooKeeper client 连接zookeeper.connect=worker1:2181,worker2:2181,worker3:2181# 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。# 注意这里要与原先的 server.properties 中配置的监听器名称一致inter.broker.listener.name=PLAINTEXT# 其它参数尽量保持与旧集群的配置一致 启动 Controller 节点 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。 12345# 格式化元数据目录，log.dirs 参数指定元数据存放目录，首次运行前必须为空目录# -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster IDkafka-storage.sh format --standalone -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties# 启动，这里没有后台启动是为了方便观察日志输出kafka-server-start.sh /usr/local/kafka/kafka3/config/kraft/controller.properties 模式 format 命令 quorum 状态 是否从 ZK 加载 迁移阶段（standalone） --standalone 无（单节点） ✅ 是 正式 KRaft 模式 无 --standalone ✅ 多节点 ❌ 否（独立运行） 将原先的三个节点作为 Broker 节点重新启动 修改原先的配置文件 server.properties，只需要修改如下内容即可 1234567891011121314# 在最后加入 CONTROLLER:PLAINTEXTlistener.security.protocol.map=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,CONTROLLER:PLAINTEXT## 以下是新加入的 配置项# Set the IBP，当前 kafka 版本是 3.9.1，所以这里设置为 3.9inter.broker.protocol.version=3.9# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程zookeeper.metadata.migration.enable=true# KRaft controller quorum configuration，因为目前只启动了一个 controller 节点，所以只能配置一个投票节点controller.quorum.bootstrap.servers=worker1:9098# 控制器监听器名称，要与 contreller 节点配置文件 controller.properties 中的配置一致controller.listener.names=CONTROLLER 分别重新启动三个节点 1234567# 关闭 kafkakafka-server-stop.sh# 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.propertiesps -ef | grep kafka | grep &quot;server\\.properties&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9# 重新启动 kafkakafka-server-start.sh /usr/local/kafka/kafka3/config/server.properties 当三个节点都以必要的配置重新启动后，迁移将自动开始。迁移完成后，可以在 Controller(worker1)节点 上看到类似如下日志： 1234567891011121314151617181920# ✅ 意味：从 ZooKeeper 到 KRaft 的初始元数据迁移已成功，共写入 62 条记录，当前 KRaft metadata offset 为 3179。这是迁移成功的明确证据。Completed migration of metadata from ZooKeeper to KRaft. 62 records were generated in 300 ms across 1 batches. The average time spent waiting on a batch was 97.00 ms. The record types were &#123;TOPIC_RECORD=3, PARTITION_RECORD=56, CONFIG_RECORD=3&#125;. The current metadata offset is now 3179 with an epoch of 2. Saw 3 brokers in the migrated metadata [1, 2, 3]. (org.apache.kafka.metadata.migration.KRaftMigrationDriver)# ✅ 意味：控制器已加载并生效新元数据与 feature set（与 offset 3179 对应）。Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures=&#123;metadata.version=21&#125;, finalizedFeaturesEpoch=3179). (org.apache.kafka.metadata.publisher.FeaturesPublisher)# ✅ 意味：内部迁移状态已更新，KRaft 上有了写入位置记录。Finished initial migration of ZK metadata to KRaft in 3486479 ns. Transitioned migration state from ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=-1, kraftMetadataEpoch=-1, lastUpdatedTimeMs=1760682050169, migrationZkVersion=1, controllerZkEpoch=3, controllerZkVersion=3&#125; to ZkMigrationLeadershipState&#123;kraftControllerId=3000, kraftControllerEpoch=2, kraftMetadataOffset=3179, kraftMetadataEpoch=2, lastUpdatedTimeMs=1760682050169, migrationZkVersion=2, controllerZkEpoch=3, controllerZkVersion=3&#125; (org.apache.kafka.metadata.migration.KRaftMigrationDriver)# ✅ 意味：迁移流程按预期推进：先把 KRaft 的元数据与 ZK 对齐（sync），然后与 brokers 建立通信，最终进入 DUAL_WRITE（双写）。DUAL_WRITE 阶段表示控制器在写入 KRaft metadata log 的同时，仍然会把必要的写操作也写回 ZooKeeper（双写）——直到迁移完全完成并确认可以停止写 ZK 为止。3000 transitioning from ZK_MIGRATION to SYNC_KRAFT_TO_ZK state...Performing a full metadata sync from KRaft to ZK.Did not make any ZK writes when reconciling with KRaft state.3000 transitioning ... to KRAFT_CONTROLLER_TO_BROKER_COMM...Sending RPCs to broker before moving to dual-write mode using at offset and epoch OffsetAndEpoch(offset=3179, epoch=2)...3000 transitioning ... to DUAL_WRITE state 上面的日志总体上表明，元数据迁移已成功完成并且控制器进入了双写（DUAL_WRITE）阶段。 将三个Broker节点的配置修改为 KRaft 模式的 broker 节点 修改三个节点的配置文件 server.properties 123456789101112131415# 添加process.roles=brokerprocess.roles=broker# 用 node.id 替换 broker.id，注意，node.id 需要与 broker.id 一致# broker.id=1node.id=1# 去掉 zookeeper 相关配置# Don&#x27;t set the IBP, KRaft uses &quot;metadata.version&quot; feature flag# inter.broker.protocol.version=3.9# Remove the migration enabled flag# zookeeper.metadata.migration.enable=true# Remove ZooKeeper client configuration# zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 分别重新启动三个节点 1234567# 关闭 kafkakafka-server-stop.sh# 这里要注意 worker1 上不要使用 kafka-server-stop.sh 进行关闭，因为 worker1 上的 controller 节点 也在运行，会有两个 kafka 进程运行，可以用如下命令进行关闭；因为 controller 节点 启动使用的是 controller.propertiesps -ef | grep kafka | grep &quot;server\\.properties&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9# 重新启动 kafkakafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 将 Controller 节点的配置修改为 KRaft 模式的 controller 节点 修改 controller 节点的配置文件 controller.properties 123456## 去掉去下内容# 控制是否启用 ZooKeeper → KRaft 的元数据迁移过程# zookeeper.metadata.migration.enable=true# ZooKeeper client 连接# zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 重启启动 controller 节点 12# 关闭后重新启动kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties 此时你可以关闭 zookeeper 集群了，新的 kafka 集群将不再使用 ZooKeeper，也无法在恢复到 ZooKeeper 模式。 加入新的 Controller 节点 Controller 尽量保持 奇数个节点。 之前已经在 worker1 节点上启动了 controller ，现在 worker2 和 worker3 上也来启动 controller 节点，并将它们加入到 kafka 集群中。 在开始配置前，先将上面的 controller 节点 和 三个 broker 节点 的如下配置进行修改，并重启启动。 123456# 将 controller.quorum.bootstrap.servers 替换为 controller.quorum.voterscontroller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098# controller.quorum.bootstrap.servers=worker1:9098# controller.quorum.voters = 谁是正式投票成员（固定配置）# controller.quorum.bootstrap.servers = 临时找谁引导连接（迁移或初始化用） 配置项 作用 适用阶段 是否必需 说明 controller.quorum.voters 定义 正式的 KRaft 控制器投票成员列表（voter set） 集群正常运行时 ✅ 是 所有节点必须配置相同的值 controller.quorum.bootstrap.servers 定义 迁移阶段或初始化阶段的控制器连接地址（bootstrap controller endpoint） ZK → KRaft 迁移阶段 或 KRaft 集群初次启动 ⚙️ 可选（仅特定阶段） 用于在 controller quorum 尚未形成时的临时发现 参考 worker1 上的 controller 节点的配置文件 controller.properties，配置 woker2 的 controller 节点配置文件controller.properties ，worker3 也是类似的。 12345678910111213141516# 配置当前节点的角色，这里只能是controllerprocess.roles=controller# 节点ID，不能与现有Broker节点的ID一致node.id=3001# 配置集群的投票节点controller.quorum.voters=3000@worker1:9098,3001@worker2:9098,3002@worker3:9098# 配置监听器，注意端口不能重复listeners=CONTROLLER://:9098advertised.listeners=CONTROLLER://worker2:9098controller.listener.names=CONTROLLER# 日志存放目录，这里存放的是元数据log.dirs=/usr/local/kafka/dataDir/kraft-meta# 指定 Kafka 集群内部（broker 与 broker、KRaft 控制器与 broker）通信所使用的监听器（listener）名称。# 注意这里要与原先的 server.properties 中配置的监听器名称一致inter.broker.listener.name=PLAINTEXT 初始化日志目录 123# 只有 Controller 节点才需要初始化日志目录# -t 参数指定集群的 Cluster ID，就是前面获取的 Cluster IDkafka-storage.sh format -t hp_Q0pihQ0ORcIvXlfHobQ -c /usr/local/kafka/kafka3/config/kraft/controller.properties 分别启动 worker2 和 worker3 上的 controller 节点 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/controller.properties 此时新的 controller 节点不会立刻加入选举队列，新节点初始状态默认是 observer，需要执行下面的命令将节点加入选举队列 12# 分别在 worker2 和 worker3 上执行kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config /usr/local/kafka/kafka3/config/kraft/controller.properties add-controller 查看集群节点状态 123456789101112131415161718$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --replicationNodeId DirectoryId LogEndOffset Lag LastFetchTimestamp LastCaughtUpTimestamp Status3000 RJ4oOPGgTw-KxHFNn4SmiQ 27820 0 1760696136345 1760696136345 Leader3001 zGnWA7zYmRHG6bcTlFV2qA 27820 0 1760696136259 1760696136259 Follower3002 gIDkhOQJEHqg-GJBdezU1Q 27820 0 1760696136257 1760696136257 Follower2 9KeeAYKEQHT92DxqNSwYuA 27820 0 1760696136257 1760696136257 Observer1 Q8lr8JQ2vrDS35_DrI1MxA 27820 0 1760696136257 1760696136257 Observer3 rgQR5wd_i5hLgU97dCKIvA 27820 0 1760696136257 1760696136257 Observer$ kafka-metadata-quorum.sh --bootstrap-server worker1:9092 describe --statusClusterId: hp_Q0pihQ0ORcIvXlfHobQLeaderId: 3000LeaderEpoch: 5HighWatermark: 30094MaxFollowerLag: 0MaxFollowerLagTimeMs: 0CurrentVoters: [&#123;&quot;id&quot;: 3000, &quot;directoryId&quot;: &quot;RJ4oOPGgTw-KxHFNn4SmiQ&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker1:9098&quot;]&#125;, &#123;&quot;id&quot;: 3001, &quot;directoryId&quot;: &quot;zGnWA7zYmRHG6bcTlFV2qA&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker2:9098&quot;]&#125;, &#123;&quot;id&quot;: 3002, &quot;directoryId&quot;: &quot;gIDkhOQJEHqg-GJBdezU1Q&quot;, &quot;endpoints&quot;: [&quot;CONTROLLER://worker3:9098&quot;]&#125;]CurrentObservers: [&#123;&quot;id&quot;: 2, &quot;directoryId&quot;: &quot;9KeeAYKEQHT92DxqNSwYuA&quot;&#125;, &#123;&quot;id&quot;: 1, &quot;directoryId&quot;: &quot;Q8lr8JQ2vrDS35_DrI1MxA&quot;&#125;, &#123;&quot;id&quot;: 3, &quot;directoryId&quot;: &quot;rgQR5wd_i5hLgU97dCKIvA&quot;&#125;] 加入 新的 Broker 节点 创建新的 Broker 节点时，参考其它 Broker 节点 配置好配置文件 server.properties，并启动 Broker 节点即可。 无需运行日志目录初始化命令，因为 Broker 节点只存放 消息 数据。 迁移后注意事项 迁移完成后，Kafka 客户端（Producer / Consumer / AdminClient）依然连接的是 Broker 节点，而不是 Controller 节点。 Kafka 在 ZooKeeper 模式与 KRaft 模式下的区别主要在于： 控制平面（Control Plane）：ZK 模式下由 ZooKeeper + Controller Broker 共同管理；KRaft 模式下由 独立的 Controller 进程或角色 管理（通过 Raft 协议同步元数据）。 数据平面（Data Plane）：无论是哪个模式，客户端发送、消费消息仍然是通过 Broker 节点 完成的。 也就是说，Controller 管理集群元数据（主题、分区、副本、Leader 选举等），而 Broker 节点处理实际的消息流。","summary":"摘要 本文介绍 如何将 Kafka 集群从 Zookeeper 模式迁移到 KRaft 模式 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 官方文档：ZooKeeper到KRaft迁移","date_published":"2025-10-16T14:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/","url":"https://blog.hanqunfeng.com/2025/10/16/kafka-05-install-kraft/","title":"Kafka 的安装：基于 KRaft 模式","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p>本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"KRaft-简介\">KRaft 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kraft 是 Kafka 从 2.8.0 版本 开始⽀持的⼀种新的集群架构⽅式。其⽬的主要是为了摆脱Kafka对Zookeeper的依赖。因为以往基于Zookeeper搭建的集群，增加了Kafka演进与运维的难度，逐渐开始成为Kakfa拥抱云原⽣的⼀种障碍。使⽤Kraft集群后，Kafka集群就不再需要依赖Zookeeper，将之前基于Zookeeper管理的集群数据，转为由Kafka集群⾃⼰管理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>传统的Kafka集群，会将每个节点的状态信息统一保存在Zookeeper中，并通过Zookeeper动态选举产生一个Controller节点，通过Controller节点来管理Kafka集群，比如触发Partition的选举。而在Kraft集群中，会固定配置几台Broker节点来共同担任Controller的角色，各组Partition的Leader节点就会由这些Controller选举产生。原本保存在Zookeeper中的元数据也转而保存到Controller节点中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>🧭 Kafka KRaft 模式 vs Zookeeper 模式 对比表</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">对比项</th>\n<th style=\"text-align:left\"><strong>KRaft 模式（Kafka Raft 模式）</strong></th>\n<th style=\"text-align:left\"><strong>Zookeeper 模式（传统模式）</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>架构结构</strong></td>\n<td style=\"text-align:left\">去中心化架构，Kafka 自身内置控制平面，不依赖外部 Zookeeper。</td>\n<td style=\"text-align:left\">控制平面依赖外部 Zookeeper 集群，Kafka Broker 只负责数据平面。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>组件数量</strong></td>\n<td style=\"text-align:left\">无需部署 Zookeeper，只有 Kafka Broker 节点。</td>\n<td style=\"text-align:left\">需要单独维护 Zookeeper 集群。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>元数据存储</strong></td>\n<td style=\"text-align:left\">元数据存储在 Kafka 自身的内置日志中（<code>__cluster_metadata</code> topic）。</td>\n<td style=\"text-align:left\">元数据存储在 Zookeeper 的 znode 树结构中。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>一致性协议</strong></td>\n<td style=\"text-align:left\">使用 Kafka 自己实现的 Raft 协议（KRaft）来保证元数据一致性。</td>\n<td style=\"text-align:left\">使用 ZAB（Zookeeper Atomic Broadcast）协议保证一致性。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>启动速度</strong></td>\n<td style=\"text-align:left\">更快，控制器内嵌于 Broker 中，不需要等待外部 Zookeeper 启动。</td>\n<td style=\"text-align:left\">启动依赖 Zookeeper，启动顺序和连通性要求更严格。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>容错性</strong></td>\n<td style=\"text-align:left\">Raft 控制器具备日志复制机制，容错性与 Kafka 数据副本一致。</td>\n<td style=\"text-align:left\">容错性由 Zookeeper 决定，Zookeeper 挂掉可能导致 Kafka 控制面不可用。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>扩展性</strong></td>\n<td style=\"text-align:left\">元数据存储在 Kafka 主题中，水平扩展能力更强。</td>\n<td style=\"text-align:left\">Zookeeper 在高分区数场景下易成为性能瓶颈。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>运维复杂度</strong></td>\n<td style=\"text-align:left\">无需维护 Zookeeper 集群，统一运维 Kafka 即可。</td>\n<td style=\"text-align:left\">需要额外维护 Zookeeper 集群（监控、扩容、升级）。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>数据恢复</strong></td>\n<td style=\"text-align:left\">元数据恢复与 Kafka 主题一致，可通过日志回放恢复。</td>\n<td style=\"text-align:left\">Zookeeper 数据恢复相对复杂，依赖快照和事务日志。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>安全机制</strong></td>\n<td style=\"text-align:left\">统一 Kafka 的安全机制（SASL、SSL、ACL 等）。</td>\n<td style=\"text-align:left\">Zookeeper 有独立的安全配置体系，需单独管理。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>性能表现</strong></td>\n<td style=\"text-align:left\">元数据操作延迟更低（控制器与 Broker 本地通信）。</td>\n<td style=\"text-align:left\">元数据操作需要跨进程网络通信，延迟更高。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>控制器角色</strong></td>\n<td style=\"text-align:left\">由 Broker 中的控制器 quorum 选举产生（支持多控制器候选）。</td>\n<td style=\"text-align:left\">由 Zookeeper 选举控制器（单点控制器）。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>分区与副本管理</strong></td>\n<td style=\"text-align:left\">全部元数据存储在 Kafka 自身，可实现更快的分区变更和扩容。</td>\n<td style=\"text-align:left\">分区、副本元数据同步依赖 Zookeeper，性能相对较低。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>版本支持</strong></td>\n<td style=\"text-align:left\">从 Kafka 2.8 开始引入，Kafka 3.3+ 已经非常稳定，Kafka 3.5+ 默认推荐。</td>\n<td style=\"text-align:left\">Kafka 3.5 开始标记为“Legacy”，未来版本计划移除支持。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>兼容性</strong></td>\n<td style=\"text-align:left\">可通过元数据迁移工具从 Zookeeper 模式平滑迁移。</td>\n<td style=\"text-align:left\">不能直接迁移到 KRaft，需要工具辅助。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>运维监控</strong></td>\n<td style=\"text-align:left\">单一系统可监控（Kafka 自带的 JMX、Prometheus 等）。</td>\n<td style=\"text-align:left\">Kafka 与 Zookeeper 各自需要独立监控体系。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>未来发展方向</strong></td>\n<td style=\"text-align:left\">官方推荐和默认模式（Zookeeper 模式将逐步淘汰）。</td>\n<td style=\"text-align:left\">官方已不再建议新集群使用。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Kafka-的-KRaft-集群配置\">Kafka 的 KRaft 集群配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在Kafka的config目录下，提供了一个kraft的文件夹，在这里面提供了三个Kraft协议的参考配置文件</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">broker.properties: 数据节点，client连接时只连接broker数据节点</li>\n<li class=\"lvl-4\">controller.properties: Controller控制节点</li>\n<li class=\"lvl-4\">server.properties: 即可以是数据节点，又可以是Controller控制节点。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>实际上这些配置文件中的配置项基本与 serrver.properties 一致，只是去除了与 zookeeper 相关的配置项，同时增加了一些 Kraft 模式下的配置项。关于 server.properties 的配置项，请参考 <a href=\"https://kafka.apache.org/39/documentation/#brokerconfigs\">Kafka 官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里以 <code>kraft/serrver.properties</code> 为例进行修改，配置三个节点的Kafka集群，每个节点即是 controller 节点，也可以是 broker 节点</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下面这四个配置项是 kraft 模式下新增加的</span></span><br><span class=\"line\"><span class=\"comment\"># 配置当前节点的角色。Controller相当于Zookeeper的功能，负责集群管理。Broker提供具体的消息转发服务。</span></span><br><span class=\"line\"><span class=\"comment\"># 一个节点可以即是 Controller 又是 Broker，也可以只是 Controller 或 Broker。</span></span><br><span class=\"line\">process.roles=broker,controller</span><br><span class=\"line\"><span class=\"comment\"># 配置当前节点的id。与普通集群一样，要求集群内每个节点的ID不能重复。</span></span><br><span class=\"line\">node.id=1</span><br><span class=\"line\"><span class=\"comment\"># 配置集群的投票节点。其中@前面的是节点的id，后面是节点的地址和端口，这个端口跟客户端访问的端口是不一样的，要与 CONTROLLER 协议对应的端口一致，这里配置为 9098</span></span><br><span class=\"line\"><span class=\"comment\"># 通常将集群内的所有Controllor节点都配置进去。</span></span><br><span class=\"line\">controller.quorum.voters=1@worker1:9098,2@worker2:9098,3@worker3:9098</span><br><span class=\"line\"><span class=\"comment\"># Controller服务协议的别名。默认就是CONTROLLER</span></span><br><span class=\"line\">controller.listener.names=CONTROLLER</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 以下配置项与之前一样，按需进行配置即可</span></span><br><span class=\"line\"><span class=\"comment\"># 集群间通信仍使用内网</span></span><br><span class=\"line\">inter.broker.listener.name=PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 配置监听服务。不同的服务可以绑定不同的接口。这种配置方式在端口前面是省略了一个主机IP的，主机IP默认是使用的java.net.InetAddress.getCanonicalHostName()，这里同时开启外网访问，关于 sasl_plaintext 、sasl_ssl协议 的配置方式参考前文 kafka 通信协议</span></span><br><span class=\"line\">listeners=PLAINTEXT://:9092,CONTROLLER://:9098,EXTERNAL://0.0.0.0:9093</span><br><span class=\"line\"><span class=\"comment\"># Broker对客户端暴露的服务地址。基于PLAINTEXT协议。这里要替换为各个节点的IP地址</span></span><br><span class=\"line\">advertised.listeners=PLAINTEXT://worker1:9092,CONTROLLER://worker1:9098,EXTERNAL://161.189.227.200:9093</span><br><span class=\"line\"><span class=\"comment\"># 将监听器名称映射到安全协议类型，这里 CONTROLLER 协议对应的安全协议类型为 PLAINTEXT</span></span><br><span class=\"line\">listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 数据文件地址。默认配置在/tmp目录下。</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kraft-logs</span><br><span class=\"line\"><span class=\"comment\"># topic默认的partition分区数。</span></span><br><span class=\"line\">num.partitions=2</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动Kafka集群\">启动Kafka集群</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动前要对日志目录进行格式化</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在worker1节点上生成集群ID</span></span><br><span class=\"line\">$ kafka-storage.sh random-uuid</span><br><span class=\"line\">oGwJsVANRDKYwE7Lhn2zIA</span><br><span class=\"line\"><span class=\"comment\"># 然后在集群的每个节点上执行如下命令，格式化日志目录，注意 --cluster-id 必须一致</span></span><br><span class=\"line\"><span class=\"comment\"># 必须在第一次启动前执行</span></span><br><span class=\"line\"><span class=\"comment\"># 不可以重复执行，否则会清空数据目录并破坏已有元数据</span></span><br><span class=\"line\"><span class=\"comment\"># 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。</span></span><br><span class=\"line\"><span class=\"comment\"># 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。</span></span><br><span class=\"line\">$ kafka-storage.sh format --cluster-id oGwJsVANRDKYwE7Lhn2zIA --config /usr/local/kafka/kafka3/config/kraft/server.properties</span><br><span class=\"line\"><span class=\"comment\">## 格式化后会在日志目录下生成两个文件</span></span><br><span class=\"line\"><span class=\"comment\"># bootstrap.checkpoint # 存储元数据日志（Metadata Log）对应的初始快照偏移量（snapshot offset）。用于控制器在启动时恢复状态的起点。</span></span><br><span class=\"line\"><span class=\"comment\"># meta.properties # 存储节点元信息：cluster.id、node.id、version 等</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动集群，所以节点启动 kafka 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/server.properties</span><br></pre></td></tr></table></figure>\n<h2 id=\"注意事项\">注意事项</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 集群的启动顺序不能乱，必须先启动 Controller 节点，再启动 Broker 节点，我们这里是将节点同时做为Controller 和 Broker ，实际生产环境建议分开。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Controller 节点至少3个，建议配置为奇数个。Broker 节点数量任意，但建议至少2个以上，以保证分区的备份可以分开存储。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Client 仅能与 Broker 节点通信，不能与 Controller 节点通信。</p>\n</li>\n</ul>\n<h2 id=\"Kafka-4-0-的新特性\">Kafka 4.0 的新特性</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>彻底以 KRaft（Kafka Raft）取代 ZooKeeper（KRaft 成为默认且唯一的元数据管理）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：4.x 系列标志性变化是完全移除 ZooKeeper，元数据由 KRaft 管理（Controller 与 Broker 更紧密集成）。对运维而言：不再部署/维护 ZooKeeper 集群、元数据迁移/格式化步骤是升级时的关键。</li>\n<li class=\"lvl-4\">影响/提示：必须按官方迁移流程把元数据从 ZK 导入 KRaft（若从旧版本升级）。测试迁移/备份元数据是必须项。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>新的 consumer-group 协议（更高效的 rebalance/群组管理）与消费模型改进（包括“Queues/Shared Group”支持）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：引入/稳定了新的 Consumer Group 协议（相关 KIP），显著改善大群组下的重平衡延迟与稳定性；同时引入了类似“队列/共享组（Queues for Kafka）”的消费模式（用例：点对点消费），允许多消费者同时处理同一分区消息。</li>\n<li class=\"lvl-4\">影响/提示：如果你有大规模消费者群组或依赖旧 rebalance 行为，需要测试新协议行为；某些客户端配置/行为可能需要调整。</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>指标类别</th>\n<th>旧协议（Eager Rebalance）</th>\n<th>新协议（Incremental / Cooperative Rebalance）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>重平衡延迟（大规模群组）</td>\n<td>约 <strong>60 秒</strong>（万级消费者规模）</td>\n<td>小于 <strong>1 秒</strong>（测试显示在千级任务时可在一分钟内完成） (<a href=\"https://www.confluent.io/blog/incremental-cooperative-rebalancing-in-kafka/?utm_source=chatgpt.com\" title=\"Incremental Cooperative Rebalancing in Apache Kafka\">Confluent</a>)</td>\n</tr>\n<tr>\n<td>资源消耗（CPU）</td>\n<td>较高（在重平衡期间系统停止或大规模迁移资源）</td>\n<td>据称可降低约 <strong>70%</strong> 的 CPU／系统中断负荷（社区经验）</td>\n</tr>\n<tr>\n<td>消费者群组扩展上限</td>\n<td>适用于“千级消费者”规模</td>\n<td>可扩展至“十万级消费者”规模（理论/社区宣称）</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>传统消费者组（Consumer Group）</strong></th>\n<th><strong>共享组（Shared Group / Queues for Kafka）</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>并行消费模型</strong></td>\n<td>分区数 = 消费者数（一个分区只能被一个消费者消费）</td>\n<td>消费者数 &gt; 分区数（同一分区可由多个消费者并行处理）</td>\n</tr>\n<tr>\n<td><strong>消息确认机制</strong></td>\n<td>通过提交偏移量（Offset Commit）实现确认</td>\n<td>每条消息单独确认（ACK/NACK 机制）</td>\n</tr>\n<tr>\n<td><strong>投递语义</strong></td>\n<td><strong>At-Least-Once</strong>（至少一次投递）</td>\n<td><strong>Exactly-Once（可选）</strong>，支持精确一次处理</td>\n</tr>\n<tr>\n<td><strong>典型场景</strong></td>\n<td>流式日志、监控、顺序性要求高的场景</td>\n<td>任务队列、并行计算、高吞吐任务处理</td>\n</tr>\n<tr>\n<td><strong>实现方式</strong></td>\n<td>基于 Topic-Partition 分配与偏移管理</td>\n<td>基于共享队列模型，允许多消费者竞争消费同一分区</td>\n</tr>\n<tr>\n<td><strong>Kafka 版本支持</strong></td>\n<td>Kafka ≤ 3.x</td>\n<td>Kafka 4.x 引入（KIP-932 “Queues for Kafka”）</td>\n</tr>\n<tr>\n<td><strong>优势</strong></td>\n<td>顺序保证强、模型成熟稳定</td>\n<td>并行能力强、吞吐提升、支持精确一次语义</td>\n</tr>\n<tr>\n<td><strong>劣势</strong></td>\n<td>分区限制吞吐，扩展受限</td>\n<td>顺序性可能减弱，实现更复杂</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除长期弃用的旧 API / 协议（向后不兼容的清理）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：4.x 移除了那些已弃用 ≥12 个月的接口/协议，旨在简化代码库并鼓励采用新功能。</li>\n<li class=\"lvl-4\">影响/提示：升级前务必检查你使用到的 Broker/Client/Streams/Connect API 是否依赖被移除的功能；测试客户端与第三方 Connector/插件兼容性。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Java 运行环境最低版本更新：Clients/Streams 与 Broker/Tools 的 JDK 要求提高</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：Kafka 4.x 将客户端（Kafka Clients、Kafka Streams）与 Broker/Connect/工具分别提出了更高的 Java baseline（Clients/Streams 最低 Java 11，Broker/Connect/Tools 最低 Java 17 等）。</li>\n<li class=\"lvl-4\">影响/提示：升级集群前先统一平台 JDK 版本，CI/CD/容器镜像也要对应更新。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>许多新的 KIP（功能增强）与性能/可观测性改进</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">说明：包含改进的 Streams rebalance、更多 Admin/运维命令、节点注册/列举能力、插件/指标扩展点等（多项 KIP 在 4.0/4.1 陆续落地）。这些改进覆盖 Broker、Controller、Producer、Consumer、Admin 和 Streams 子系统。</li>\n<li class=\"lvl-4\">影响/提示：运维与监控面板可能受益（新增可观测指标/API）；如果你有自定义插件或监控接入，需要检查新的插件/metrics 注册机制。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。 KRaft 简介 Kraft 是 Kafka 从 2.8.0 版本 开始⽀持的⼀种新的集群架构⽅式。其⽬的主要是为了摆脱Kafka对Zookeeper的依赖。因为以往基于Zookeeper搭建的集群，增加了Kafka演进与运维的难度，逐渐开始成为Kakfa拥抱云原⽣的⼀种障碍。使⽤Kraft集群后，Kafka集群就不再需要依赖Zookeeper，将之前基于Zookeeper管理的集群数据，转为由Kafka集群⾃⼰管理。 传统的Kafka集群，会将每个节点的状态信息统一保存在Zookeeper中，并通过Zookeeper动态选举产生一个Controller节点，通过Controller节点来管理Kafka集群，比如触发Partition的选举。而在Kraft集群中，会固定配置几台Broker节点来共同担任Controller的角色，各组Partition的Leader节点就会由这些Controller选举产生。原本保存在Zookeeper中的元数据也转而保存到Controller节点中。 🧭 Kafka KRaft 模式 vs Zookeeper 模式 对比表 对比项 KRaft 模式（Kafka Raft 模式） Zookeeper 模式（传统模式） 架构结构 去中心化架构，Kafka 自身内置控制平面，不依赖外部 Zookeeper。 控制平面依赖外部 Zookeeper 集群，Kafka Broker 只负责数据平面。 组件数量 无需部署 Zookeeper，只有 Kafka Broker 节点。 需要单独维护 Zookeeper 集群。 元数据存储 元数据存储在 Kafka 自身的内置日志中（__cluster_metadata topic）。 元数据存储在 Zookeeper 的 znode 树结构中。 一致性协议 使用 Kafka 自己实现的 Raft 协议（KRaft）来保证元数据一致性。 使用 ZAB（Zookeeper Atomic Broadcast）协议保证一致性。 启动速度 更快，控制器内嵌于 Broker 中，不需要等待外部 Zookeeper 启动。 启动依赖 Zookeeper，启动顺序和连通性要求更严格。 容错性 Raft 控制器具备日志复制机制，容错性与 Kafka 数据副本一致。 容错性由 Zookeeper 决定，Zookeeper 挂掉可能导致 Kafka 控制面不可用。 扩展性 元数据存储在 Kafka 主题中，水平扩展能力更强。 Zookeeper 在高分区数场景下易成为性能瓶颈。 运维复杂度 无需维护 Zookeeper 集群，统一运维 Kafka 即可。 需要额外维护 Zookeeper 集群（监控、扩容、升级）。 数据恢复 元数据恢复与 Kafka 主题一致，可通过日志回放恢复。 Zookeeper 数据恢复相对复杂，依赖快照和事务日志。 安全机制 统一 Kafka 的安全机制（SASL、SSL、ACL 等）。 Zookeeper 有独立的安全配置体系，需单独管理。 性能表现 元数据操作延迟更低（控制器与 Broker 本地通信）。 元数据操作需要跨进程网络通信，延迟更高。 控制器角色 由 Broker 中的控制器 quorum 选举产生（支持多控制器候选）。 由 Zookeeper 选举控制器（单点控制器）。 分区与副本管理 全部元数据存储在 Kafka 自身，可实现更快的分区变更和扩容。 分区、副本元数据同步依赖 Zookeeper，性能相对较低。 版本支持 从 Kafka 2.8 开始引入，Kafka 3.3+ 已经非常稳定，Kafka 3.5+ 默认推荐。 Kafka 3.5 开始标记为“Legacy”，未来版本计划移除支持。 兼容性 可通过元数据迁移工具从 Zookeeper 模式平滑迁移。 不能直接迁移到 KRaft，需要工具辅助。 运维监控 单一系统可监控（Kafka 自带的 JMX、Prometheus 等）。 Kafka 与 Zookeeper 各自需要独立监控体系。 未来发展方向 官方推荐和默认模式（Zookeeper 模式将逐步淘汰）。 官方已不再建议新集群使用。 Kafka 的 KRaft 集群配置 在Kafka的config目录下，提供了一个kraft的文件夹，在这里面提供了三个Kraft协议的参考配置文件 broker.properties: 数据节点，client连接时只连接broker数据节点 controller.properties: Controller控制节点 server.properties: 即可以是数据节点，又可以是Controller控制节点。 实际上这些配置文件中的配置项基本与 serrver.properties 一致，只是去除了与 zookeeper 相关的配置项，同时增加了一些 Kraft 模式下的配置项。关于 server.properties 的配置项，请参考 Kafka 官方文档 这里以 kraft/serrver.properties 为例进行修改，配置三个节点的Kafka集群，每个节点即是 controller 节点，也可以是 broker 节点 12345678910111213141516171819202122232425# 下面这四个配置项是 kraft 模式下新增加的# 配置当前节点的角色。Controller相当于Zookeeper的功能，负责集群管理。Broker提供具体的消息转发服务。# 一个节点可以即是 Controller 又是 Broker，也可以只是 Controller 或 Broker。process.roles=broker,controller# 配置当前节点的id。与普通集群一样，要求集群内每个节点的ID不能重复。node.id=1# 配置集群的投票节点。其中@前面的是节点的id，后面是节点的地址和端口，这个端口跟客户端访问的端口是不一样的，要与 CONTROLLER 协议对应的端口一致，这里配置为 9098# 通常将集群内的所有Controllor节点都配置进去。controller.quorum.voters=1@worker1:9098,2@worker2:9098,3@worker3:9098# Controller服务协议的别名。默认就是CONTROLLERcontroller.listener.names=CONTROLLER# 以下配置项与之前一样，按需进行配置即可# 集群间通信仍使用内网inter.broker.listener.name=PLAINTEXT# 配置监听服务。不同的服务可以绑定不同的接口。这种配置方式在端口前面是省略了一个主机IP的，主机IP默认是使用的java.net.InetAddress.getCanonicalHostName()，这里同时开启外网访问，关于 sasl_plaintext 、sasl_ssl协议 的配置方式参考前文 kafka 通信协议listeners=PLAINTEXT://:9092,CONTROLLER://:9098,EXTERNAL://0.0.0.0:9093# Broker对客户端暴露的服务地址。基于PLAINTEXT协议。这里要替换为各个节点的IP地址advertised.listeners=PLAINTEXT://worker1:9092,CONTROLLER://worker1:9098,EXTERNAL://161.189.227.200:9093# 将监听器名称映射到安全协议类型，这里 CONTROLLER 协议对应的安全协议类型为 PLAINTEXTlistener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT# 数据文件地址。默认配置在/tmp目录下。log.dirs=/usr/local/kafka/dataDir/kraft-logs# topic默认的partition分区数。num.partitions=2 启动Kafka集群 启动前要对日志目录进行格式化 123456789101112# 在worker1节点上生成集群ID$ kafka-storage.sh random-uuidoGwJsVANRDKYwE7Lhn2zIA# 然后在集群的每个节点上执行如下命令，格式化日志目录，注意 --cluster-id 必须一致# 必须在第一次启动前执行# 不可以重复执行，否则会清空数据目录并破坏已有元数据# 千万不要在已有 broker 的数据目录（包含消息数据的 log.dirs）上运行 kafka-storage.sh format ，那会把原有数据结构重置或踩坏。# 必须明确：格式化只针对 新 controller 的 metadata 目录（且该目录必须为空）。$ kafka-storage.sh format --cluster-id oGwJsVANRDKYwE7Lhn2zIA --config /usr/local/kafka/kafka3/config/kraft/server.properties## 格式化后会在日志目录下生成两个文件# bootstrap.checkpoint # 存储元数据日志（Metadata Log）对应的初始快照偏移量（snapshot offset）。用于控制器在启动时恢复状态的起点。# meta.properties # 存储节点元信息：cluster.id、node.id、version 等 启动集群，所以节点启动 kafka 服务 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/kraft/server.properties 注意事项 Kafka 集群的启动顺序不能乱，必须先启动 Controller 节点，再启动 Broker 节点，我们这里是将节点同时做为Controller 和 Broker ，实际生产环境建议分开。 Controller 节点至少3个，建议配置为奇数个。Broker 节点数量任意，但建议至少2个以上，以保证分区的备份可以分开存储。 Client 仅能与 Broker 节点通信，不能与 Controller 节点通信。 Kafka 4.0 的新特性 彻底以 KRaft（Kafka Raft）取代 ZooKeeper（KRaft 成为默认且唯一的元数据管理） 说明：4.x 系列标志性变化是完全移除 ZooKeeper，元数据由 KRaft 管理（Controller 与 Broker 更紧密集成）。对运维而言：不再部署/维护 ZooKeeper 集群、元数据迁移/格式化步骤是升级时的关键。 影响/提示：必须按官方迁移流程把元数据从 ZK 导入 KRaft（若从旧版本升级）。测试迁移/备份元数据是必须项。 新的 consumer-group 协议（更高效的 rebalance/群组管理）与消费模型改进（包括“Queues/Shared Group”支持） 说明：引入/稳定了新的 Consumer Group 协议（相关 KIP），显著改善大群组下的重平衡延迟与稳定性；同时引入了类似“队列/共享组（Queues for Kafka）”的消费模式（用例：点对点消费），允许多消费者同时处理同一分区消息。 影响/提示：如果你有大规模消费者群组或依赖旧 rebalance 行为，需要测试新协议行为；某些客户端配置/行为可能需要调整。 指标类别 旧协议（Eager Rebalance） 新协议（Incremental / Cooperative Rebalance） 重平衡延迟（大规模群组） 约 60 秒（万级消费者规模） 小于 1 秒（测试显示在千级任务时可在一分钟内完成） (Confluent) 资源消耗（CPU） 较高（在重平衡期间系统停止或大规模迁移资源） 据称可降低约 70% 的 CPU／系统中断负荷（社区经验） 消费者群组扩展上限 适用于“千级消费者”规模 可扩展至“十万级消费者”规模（理论/社区宣称） 特性 传统消费者组（Consumer Group） 共享组（Shared Group / Queues for Kafka） 并行消费模型 分区数 = 消费者数（一个分区只能被一个消费者消费） 消费者数 &gt; 分区数（同一分区可由多个消费者并行处理） 消息确认机制 通过提交偏移量（Offset Commit）实现确认 每条消息单独确认（ACK/NACK 机制） 投递语义 At-Least-Once（至少一次投递） Exactly-Once（可选），支持精确一次处理 典型场景 流式日志、监控、顺序性要求高的场景 任务队列、并行计算、高吞吐任务处理 实现方式 基于 Topic-Partition 分配与偏移管理 基于共享队列模型，允许多消费者竞争消费同一分区 Kafka 版本支持 Kafka ≤ 3.x Kafka 4.x 引入（KIP-932 “Queues for Kafka”） 优势 顺序保证强、模型成熟稳定 并行能力强、吞吐提升、支持精确一次语义 劣势 分区限制吞吐，扩展受限 顺序性可能减弱，实现更复杂 删除长期弃用的旧 API / 协议（向后不兼容的清理） 说明：4.x 移除了那些已弃用 ≥12 个月的接口/协议，旨在简化代码库并鼓励采用新功能。 影响/提示：升级前务必检查你使用到的 Broker/Client/Streams/Connect API 是否依赖被移除的功能；测试客户端与第三方 Connector/插件兼容性。 Java 运行环境最低版本更新：Clients/Streams 与 Broker/Tools 的 JDK 要求提高 说明：Kafka 4.x 将客户端（Kafka Clients、Kafka Streams）与 Broker/Connect/工具分别提出了更高的 Java baseline（Clients/Streams 最低 Java 11，Broker/Connect/Tools 最低 Java 17 等）。 影响/提示：升级集群前先统一平台 JDK 版本，CI/CD/容器镜像也要对应更新。 许多新的 KIP（功能增强）与性能/可观测性改进 说明：包含改进的 Streams rebalance、更多 Admin/运维命令、节点注册/列举能力、插件/指标扩展点等（多项 KIP 在 4.0/4.1 陆续落地）。这些改进覆盖 Broker、Controller、Producer、Consumer、Admin 和 Streams 子系统。 影响/提示：运维与监控面板可能受益（新增可观测指标/API）；如果你有自定义插件或监控接入，需要检查新的插件/metrics 注册机制。","summary":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 KRaft 模式。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 本文的安装方法同样适用于 Kafka 4.x 版本，只不过 Kafka 4.x 中已经不再包含 ZooKeeper 相关的配置文件以及相关的命令，另外要求JDK17+。","date_published":"2025-10-16T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/","url":"https://blog.hanqunfeng.com/2025/10/15/kafka-04-command/","title":"Kafka 的 常用命令","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 常用命令</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/kafka-3-demo\">Java-Client 代码示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"topic\">topic</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --partitions 3 --replication-factor 2</span><br><span class=\"line\"><span class=\"comment\"># --bootstrap-server 指定 kafka 集群地址</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 创建的 topic 名称</span></span><br><span class=\"line\"><span class=\"comment\"># --partitions 指定分区数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class=\"line\"><span class=\"comment\"># --replication-factor 指定副本数，不设置则默认使用 server.properties 中设置的默认值</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 列出 topic</span></span><br><span class=\"line\">kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class=\"line\"><span class=\"comment\"># 查看 topic 详情</span></span><br><span class=\"line\">kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">Topic: <span class=\"built_in\">test</span>\tTopicId: Ru0tWQJ4RMWcjjGsKAdWQg\tPartitionCount: 3\tReplicationFactor: 3\tConfigs:</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 0\tLeader: 3\tReplicas: 3,1,2\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 1\tLeader: 1\tReplicas: 1,2,3\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: <span class=\"built_in\">test</span>\tPartition: 2\tLeader: 2\tReplicas: 2,3,1\tIsr: 3,2,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\"><span class=\"comment\">## 输出说明</span></span><br><span class=\"line\"><span class=\"comment\"># 总体信息（Topic 概览）Topic: test\tTopicId: Ru0tWQJ4RMWcjjGsKAdWQg\tPartitionCount: 3\tReplicationFactor: 3\tConfigs:</span></span><br><span class=\"line\">| 字段                                  | 含义                                                            |</span><br><span class=\"line\">| ----------------------------------- | ------------------------------------------------------------- |</span><br><span class=\"line\">| **Topic: disTopic**                 | Topic 名称，即当前描述的主题。                                            |</span><br><span class=\"line\">| **TopicId: VUK7Mc9oQdS1mjGG7OhQzQ** | Kafka 内部自动生成的唯一标识符（UUID），Kafka 3.x 之后引入，用于区分同名但不同生命周期的 topic。 |</span><br><span class=\"line\">| **PartitionCount: 3**               | 该主题有 3 个分区（partition）。每个分区存储一部分消息。                            |</span><br><span class=\"line\">| **ReplicationFactor:**              | 副本因子。这里虽然输出中没显示具体值，但可从每行分区配置推断是 **3**（每个分区有 3 个副本）。           |</span><br><span class=\"line\">| **Configs:**                        | topic 的配置项（例如清理策略、压缩类型等），如果为空，说明使用默认配置。                       |</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分区详情（每个 Partition 一行）</span></span><br><span class=\"line\"></span><br><span class=\"line\">| 字段                                | 含义                                                          |</span><br><span class=\"line\">| --------------------------------- | ----------------------------------------------------------- |</span><br><span class=\"line\">| **Partition: 0**                  | 第 0 号分区。                                                    |</span><br><span class=\"line\">| **Leader: 2**                     | 该分区当前的 **Leader Broker 是 broker ID = 2**，只有 Leader 才处理读写请求。 |</span><br><span class=\"line\">| **Replicas: 2,3,1**               | 该分区的所有副本存放在哪些 Broker 上（即副本分布,AR），分别是 broker 2、3、1。             |</span><br><span class=\"line\">| **Isr (In-Sync Replicas): 2,3,1** | 当前与 Leader 保持同步的副本集合。这里所有副本都在同步中（健康状态 👍）。                  |</span><br><span class=\"line\">| **Elr / LastKnownElr**            | Kafka 新版本中引入的 <span class=\"string\">&quot;Enhanced Leader Replica&quot;</span> 状态，目前未启用（N/A）。      |</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 删除 topic</span></span><br><span class=\"line\">kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"consumer\">consumer</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 consumer</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --group <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 指定 topic</span></span><br><span class=\"line\"><span class=\"comment\"># --group 指定 consumer 组</span></span><br><span class=\"line\"></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span>  --from-beginning</span><br><span class=\"line\"><span class=\"comment\"># --from-beginning 从 topic 的最开始消费</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"consumer-group\">consumer-group</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 列出 consumer 组</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span><br><span class=\"line\"><span class=\"comment\"># --bootstrap-server 集群地址</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 consumer 组详情</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">GROUP  TOPIC  PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                             HOST         CLIENT-ID</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   0          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   1          2               2               0    console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1  /10.250.0.7   console-consumer</span><br><span class=\"line\"><span class=\"built_in\">test</span>   <span class=\"built_in\">test</span>   2          1               1               0    console-consumer-9ac45b29-d8f3-4649-ab09-7b567aa2ba53  /10.250.0.108 console-consumer</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 输出说明</span></span><br><span class=\"line\"><span class=\"comment\"># GROUP       消费组名称</span></span><br><span class=\"line\"><span class=\"comment\"># TOPIC       topic 名称</span></span><br><span class=\"line\"><span class=\"comment\"># PARTITION   分区编号</span></span><br><span class=\"line\"><span class=\"comment\"># CURRENT-OFFSET  当前消费的 offset</span></span><br><span class=\"line\"><span class=\"comment\"># LOG-END-OFFSET   topic 中最大的 offset</span></span><br><span class=\"line\"><span class=\"comment\"># LAG         当前消费的 offset 与 topic 中最大的 offset 的差值，即剩余未消费的 消息数量</span></span><br><span class=\"line\"><span class=\"comment\"># CONSUMER-ID  当前消费的 consumer 的 id</span></span><br><span class=\"line\"><span class=\"comment\"># HOST        当前消费的 consumer 的主机名</span></span><br><span class=\"line\"><span class=\"comment\"># CLIENT-ID   当前消费的 consumer 的客户端名称</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 删除 consumer 组</span></span><br><span class=\"line\">kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"producer\">producer</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 producer</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># --topic 指定 topic</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"手动触发-Kafka-Partitoin-的-Leader-选举-自平衡\">手动触发 Kafka Partitoin 的 Leader 选举(自平衡)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>kafka的自平衡默认开启，每隔 300秒扫描一次，如果需要平衡的比例高于 10%，则会触发一次</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开启自动平衡</span></span><br><span class=\"line\">auto.leader.rebalance.enable=<span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"comment\"># 间隔扫描时间 默认 300 秒</span></span><br><span class=\"line\">eader.imbalance.check.interval.seconds=300</span><br><span class=\"line\"><span class=\"comment\"># 触发比例，即扫描的 broker 上需要平衡的 partition 占当前 broker 全部 partition 的比例，默认 10%</span></span><br><span class=\"line\">leader.imbalance.per.broker.percentage=10</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>建议关闭，改为业务低峰时手动触发</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 自动平衡</span></span><br><span class=\"line\">kafka-leader-election.sh --bootstrap-server localhost:9092  --election-type preferred --topic <span class=\"built_in\">test</span> --partition 0</span><br><span class=\"line\"><span class=\"comment\"># --topic 指定要触发的 topic</span></span><br><span class=\"line\"><span class=\"comment\"># --partition 0 触发 partition 0 的 leader 选举</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>🧩 参数说明：–election-type</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数值</th>\n<th>含义</th>\n<th>触发条件</th>\n<th>典型使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>preferred</code></strong></td>\n<td><strong>首选 Leader 选举</strong>（Preferred Leader Election）<br>Kafka 会尝试将分区的 leader 重新切换为「首选副本」（通常是第一个副本）。</td>\n<td>只有当前 leader <strong>不是</strong> 首选副本时才执行。</td>\n<td>某些副本被自动选举成 leader 后，希望恢复原有「首选 leader」结构，以实现负载均衡。</td>\n</tr>\n<tr>\n<td><strong><code>unclean</code></strong></td>\n<td><strong>非干净 Leader 选举</strong>（Unclean Leader Election）<br>允许从不同步的副本中选举新的 leader。</td>\n<td>仅在分区 <strong>没有可用 leader</strong> 时执行。</td>\n<td>在紧急恢复场景下（比如所有 ISR 副本都下线），为了恢复服务可用性，即使会导致数据丢失。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Leader Partition⾃动平衡机制</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-6\">Leader Partitoin选举机制能够保证每⼀个Partition同⼀时刻有且仅有⼀个Leader Partition。但是，是不是只要分配好了Leader Partition就够了呢？</li>\n<li class=\"lvl-6\">在⼀组Partiton中，Leader Partition通常是⽐较繁忙的节点，因为他要负责与客户端的数据交互，以及向Follower同步数据。默认情况下，Kafka会尽量将Leader Partition分配到不同的Broker节点上，⽤以保证整个集群的性能压⼒能够⽐较平均。</li>\n<li class=\"lvl-6\">但是，经过Leader Partition选举后，这种平衡就有可能会被打破，让Leader Partition过多的集中到同⼀个Broker上。这样，这个Broker的压⼒就会明显⾼于其他Broker，从⽽影响到集群的整体性能。</li>\n<li class=\"lvl-6\">为此，Kafka设计了Leader Partition⾃动平衡机制，当发现Leader分配不均衡时，⾃动进⾏Leader Partition调整。</li>\n<li class=\"lvl-6\">Kafka在进⾏Leader Partition⾃平衡时的逻辑是这样的：他会认为AR(Replicas副本集)当中的第⼀个节点就应该是Leader节点。这种选举结果成为preferred election 理想选举结果。</li>\n<li class=\"lvl-6\">Controller会定期检测集群的Partition平衡情况，在开始检测时，Controller会依次检查所有的Broker。当发现这个Broker上的不平衡的Partition⽐例⾼于<code>leader.imbalance.per.broker.percentage</code>阈值时，就会触发⼀次Leader Partiton的⾃平衡。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 Kafka 的 常用命令 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Java-Client 代码示例 topic 12345678910111213141516171819202122232425262728293031323334353637383940# 创建 topickafka-topics.sh --create --bootstrap-server localhost:9092 --topic test --partitions 3 --replication-factor 2# --bootstrap-server 指定 kafka 集群地址# --topic 创建的 topic 名称# --partitions 指定分区数，不设置则默认使用 server.properties 中设置的默认值# --replication-factor 指定副本数，不设置则默认使用 server.properties 中设置的默认值# 列出 topickafka-topics.sh --list --bootstrap-server localhost:9092# 查看 topic 详情kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test## 输出Topic: test TopicId: Ru0tWQJ4RMWcjjGsKAdWQg PartitionCount: 3 ReplicationFactor: 3 Configs: Topic: test Partition: 0 Leader: 3 Replicas: 3,1,2 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A Topic: test Partition: 1 Leader: 1 Replicas: 1,2,3 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A Topic: test Partition: 2 Leader: 2 Replicas: 2,3,1 Isr: 3,2,1 Elr: N/A LastKnownElr: N/A## 输出说明# 总体信息（Topic 概览）Topic: test TopicId: Ru0tWQJ4RMWcjjGsKAdWQg PartitionCount: 3 ReplicationFactor: 3 Configs:| 字段 | 含义 || ----------------------------------- | ------------------------------------------------------------- || **Topic: disTopic** | Topic 名称，即当前描述的主题。 || **TopicId: VUK7Mc9oQdS1mjGG7OhQzQ** | Kafka 内部自动生成的唯一标识符（UUID），Kafka 3.x 之后引入，用于区分同名但不同生命周期的 topic。 || **PartitionCount: 3** | 该主题有 3 个分区（partition）。每个分区存储一部分消息。 || **ReplicationFactor:** | 副本因子。这里虽然输出中没显示具体值，但可从每行分区配置推断是 **3**（每个分区有 3 个副本）。 || **Configs:** | topic 的配置项（例如清理策略、压缩类型等），如果为空，说明使用默认配置。 |# 分区详情（每个 Partition 一行）| 字段 | 含义 || --------------------------------- | ----------------------------------------------------------- || **Partition: 0** | 第 0 号分区。 || **Leader: 2** | 该分区当前的 **Leader Broker 是 broker ID = 2**，只有 Leader 才处理读写请求。 || **Replicas: 2,3,1** | 该分区的所有副本存放在哪些 Broker 上（即副本分布,AR），分别是 broker 2、3、1。 || **Isr (In-Sync Replicas): 2,3,1** | 当前与 Leader 保持同步的副本集合。这里所有副本都在同步中（健康状态 👍）。 || **Elr / LastKnownElr** | Kafka 新版本中引入的 &quot;Enhanced Leader Replica&quot; 状态，目前未启用（N/A）。 |# 删除 topickafka-topics.sh --delete --bootstrap-server localhost:9092 --topic test consumer 1234567# 创建 consumerkafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --group test# --topic 指定 topic# --group 指定 consumer 组kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning# --from-beginning 从 topic 的最开始消费 consumer-group 12345678910111213141516171819202122232425# 列出 consumer 组kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# --bootstrap-server 集群地址# 查看 consumer 组详情kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test## 输出GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDtest test 0 2 2 0 console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1 /10.250.0.7 console-consumertest test 1 2 2 0 console-consumer-2102b86e-895c-4ee3-8304-6df83523d1c1 /10.250.0.7 console-consumertest test 2 1 1 0 console-consumer-9ac45b29-d8f3-4649-ab09-7b567aa2ba53 /10.250.0.108 console-consumer## 输出说明# GROUP 消费组名称# TOPIC topic 名称# PARTITION 分区编号# CURRENT-OFFSET 当前消费的 offset# LOG-END-OFFSET topic 中最大的 offset# LAG 当前消费的 offset 与 topic 中最大的 offset 的差值，即剩余未消费的 消息数量# CONSUMER-ID 当前消费的 consumer 的 id# HOST 当前消费的 consumer 的主机名# CLIENT-ID 当前消费的 consumer 的客户端名称# 删除 consumer 组kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group test producer 123# 创建 producerkafka-console-producer.sh --bootstrap-server localhost:9092 --topic test# --topic 指定 topic 手动触发 Kafka Partitoin 的 Leader 选举(自平衡) kafka的自平衡默认开启，每隔 300秒扫描一次，如果需要平衡的比例高于 10%，则会触发一次 123456# 开启自动平衡auto.leader.rebalance.enable=true# 间隔扫描时间 默认 300 秒eader.imbalance.check.interval.seconds=300# 触发比例，即扫描的 broker 上需要平衡的 partition 占当前 broker 全部 partition 的比例，默认 10%leader.imbalance.per.broker.percentage=10 建议关闭，改为业务低峰时手动触发 1234# 自动平衡kafka-leader-election.sh --bootstrap-server localhost:9092 --election-type preferred --topic test --partition 0# --topic 指定要触发的 topic# --partition 0 触发 partition 0 的 leader 选举 🧩 参数说明：–election-type 参数值 含义 触发条件 典型使用场景 preferred 首选 Leader 选举（Preferred Leader Election）Kafka 会尝试将分区的 leader 重新切换为「首选副本」（通常是第一个副本）。 只有当前 leader 不是 首选副本时才执行。 某些副本被自动选举成 leader 后，希望恢复原有「首选 leader」结构，以实现负载均衡。 unclean 非干净 Leader 选举（Unclean Leader Election）允许从不同步的副本中选举新的 leader。 仅在分区 没有可用 leader 时执行。 在紧急恢复场景下（比如所有 ISR 副本都下线），为了恢复服务可用性，即使会导致数据丢失。 Leader Partition⾃动平衡机制 Leader Partitoin选举机制能够保证每⼀个Partition同⼀时刻有且仅有⼀个Leader Partition。但是，是不是只要分配好了Leader Partition就够了呢？ 在⼀组Partiton中，Leader Partition通常是⽐较繁忙的节点，因为他要负责与客户端的数据交互，以及向Follower同步数据。默认情况下，Kafka会尽量将Leader Partition分配到不同的Broker节点上，⽤以保证整个集群的性能压⼒能够⽐较平均。 但是，经过Leader Partition选举后，这种平衡就有可能会被打破，让Leader Partition过多的集中到同⼀个Broker上。这样，这个Broker的压⼒就会明显⾼于其他Broker，从⽽影响到集群的整体性能。 为此，Kafka设计了Leader Partition⾃动平衡机制，当发现Leader分配不均衡时，⾃动进⾏Leader Partition调整。 Kafka在进⾏Leader Partition⾃平衡时的逻辑是这样的：他会认为AR(Replicas副本集)当中的第⼀个节点就应该是Leader节点。这种选举结果成为preferred election 理想选举结果。 Controller会定期检测集群的Partition平衡情况，在开始检测时，Controller会依次检查所有的Broker。当发现这个Broker上的不平衡的Partition⽐例⾼于leader.imbalance.per.broker.percentage阈值时，就会触发⼀次Leader Partiton的⾃平衡。","summary":"摘要 本文介绍 Kafka 的 常用命令 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Java-Client 代码示例","date_published":"2025-10-15T12:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/","url":"https://blog.hanqunfeng.com/2025/10/14/kafka-01-server-config/","title":"Kafka 的 server.properties 配置项","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-3-x-server-properties-主要配置项清单\">Kafka 3.x server.properties 主要配置项清单</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关于 server.properties 的配置项，请参考 <a href=\"https://kafka.apache.org/39/documentation/#brokerconfigs\">Kafka 官方文档</a></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>分类</th>\n<th>参数名</th>\n<th>默认值</th>\n<th>说明</th>\n<th>推荐/备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>🗂️ <strong>基本信息</strong></td>\n<td><code>broker.id</code></td>\n<td>0</td>\n<td>Broker 唯一标识</td>\n<td>集群中必须唯一</td>\n</tr>\n<tr>\n<td></td>\n<td><code>node.id</code></td>\n<td>-</td>\n<td>Raft 模式（KRaft）下使用</td>\n<td>ZK 模式忽略</td>\n</tr>\n<tr>\n<td></td>\n<td><code>process.roles</code></td>\n<td>-</td>\n<td>KRaft 模式角色（controller, broker）</td>\n<td>ZK 模式不配置</td>\n</tr>\n<tr>\n<td>🔌 <strong>网络与监听配置</strong></td>\n<td><code>listeners</code></td>\n<td>PLAINTEXT://:9092</td>\n<td>Broker 监听地址</td>\n<td>可用多个协议，如 SASL_PLAINTEXT, SSL</td>\n</tr>\n<tr>\n<td></td>\n<td><code>advertised.listeners</code></td>\n<td>-</td>\n<td>客户端连接时看到的地址</td>\n<td>外网访问需配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>listener.security.protocol.map</code></td>\n<td>PLAINTEXT:PLAINTEXT</td>\n<td>映射监听器协议</td>\n<td>多协议时配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>inter.broker.listener.name</code></td>\n<td>-（Kafka 2.4+ 默认第一个 listener）</td>\n<td>指定 broker 间通信使用哪个 listener（如 INTERNAL）</td>\n<td>集群内部通信必须一致；常配合多 listener 使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.network.threads</code></td>\n<td>3</td>\n<td>网络线程数</td>\n<td>一般不需修改</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.io.threads</code></td>\n<td>8</td>\n<td>处理请求的 IO 线程数</td>\n<td>根据 CPU 调整</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.send.buffer.bytes</code></td>\n<td>102400</td>\n<td>发送缓冲区大小</td>\n<td>网络优化参数</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.receive.buffer.bytes</code></td>\n<td>102400</td>\n<td>接收缓冲区大小</td>\n<td>网络优化参数</td>\n</tr>\n<tr>\n<td></td>\n<td><code>socket.request.max.bytes</code></td>\n<td>104857600</td>\n<td>单请求最大大小 (100MB)</td>\n<td>大消息需调大</td>\n</tr>\n<tr>\n<td>⚙️ <strong>集群与元数据</strong></td>\n<td><code>log.dirs</code></td>\n<td>/tmp/kafka-logs</td>\n<td>数据存储路径</td>\n<td>多目录可提升性能</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.recovery.threads.per.data.dir</code></td>\n<td>1</td>\n<td>每个数据目录的恢复线程数</td>\n<td>多磁盘时可增加</td>\n</tr>\n<tr>\n<td></td>\n<td><code>auto.create.topics.enable</code></td>\n<td>true</td>\n<td>是否允许自动创建 Topic</td>\n<td>生产建议禁用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controlled.shutdown.enable</code></td>\n<td>true</td>\n<td>优雅关闭 Broker</td>\n<td>建议开启</td>\n</tr>\n<tr>\n<td></td>\n<td><code>delete.topic.enable</code></td>\n<td>true</td>\n<td>是否允许删除 Topic</td>\n<td>生产慎用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>auto.leader.rebalance.enable</code></td>\n<td>true</td>\n<td>是否自动均衡 Leader</td>\n<td>建议开启</td>\n</tr>\n<tr>\n<td></td>\n<td><code>leader.imbalance.check.interval.seconds</code></td>\n<td>300</td>\n<td>检查 leader 失衡间隔</td>\n<td>与上配合使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>leader.imbalance.per.broker.percentage</code></td>\n<td>10</td>\n<td>触发 leader 重平衡的阈值</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td>🧱 <strong>副本与复制机制</strong></td>\n<td><code>default.replication.factor</code></td>\n<td>1</td>\n<td>新 Topic 默认副本数</td>\n<td>生产建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>offsets.topic.replication.factor</code></td>\n<td>1</td>\n<td>消费组偏移主题副本数</td>\n<td>建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>transaction.state.log.replication.factor</code></td>\n<td>1</td>\n<td>事务状态主题副本数</td>\n<td>建议 3</td>\n</tr>\n<tr>\n<td></td>\n<td><code>transaction.state.log.min.isr</code></td>\n<td>1</td>\n<td>事务状态日志最小 ISR 数</td>\n<td>建议 2</td>\n</tr>\n<tr>\n<td></td>\n<td><code>min.insync.replicas</code></td>\n<td>1</td>\n<td>Leader 写入时要求的最小 ISR 副本数</td>\n<td>建议 <code>replication.factor - 1</code></td>\n</tr>\n<tr>\n<td></td>\n<td><code>unclean.leader.election.enable</code></td>\n<td>false</td>\n<td>是否允许非同步副本选为 leader</td>\n<td>生产建议 false</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.replica.fetchers</code></td>\n<td>1</td>\n<td>follower 拉取线程数</td>\n<td>可提升复制性能</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.max.bytes</code></td>\n<td>1048576 (1MB)</td>\n<td>follower 拉取单分区最大数据量</td>\n<td>增大可提速</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.response.max.bytes</code></td>\n<td>10485760 (10MB)</td>\n<td>follower 一次拉取响应总量</td>\n<td>可调大</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.wait.max.ms</code></td>\n<td>500</td>\n<td>follower 等待新数据的最大时长</td>\n<td>延迟与吞吐折中</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.backoff.ms</code></td>\n<td>1000</td>\n<td>拉取失败后退避时间</td>\n<td>网络不稳时调整</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.socket.timeout.ms</code></td>\n<td>30000</td>\n<td>follower 与 leader 通信超时</td>\n<td>≥ <a href=\"http://fetch.wait.ms\">fetch.wait.ms</a></td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.socket.receive.buffer.bytes</code></td>\n<td>65536</td>\n<td>拉取 socket 缓冲区</td>\n<td>调大可提速</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.lag.time.max.ms</code></td>\n<td>10000</td>\n<td>follower 落后 leader 的最大时间</td>\n<td>影响 ISR</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.high.watermark.checkpoint.interval.ms</code></td>\n<td>5000</td>\n<td>高水位写入 checkpoint 周期</td>\n<td>影响恢复速度</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.selector.class</code></td>\n<td>-</td>\n<td>自定义副本选择类</td>\n<td>一般保持默认</td>\n</tr>\n<tr>\n<td>🧮 <strong>日志与段文件</strong></td>\n<td><code>log.segment.bytes</code></td>\n<td>1073741824 (1GB)</td>\n<td>单日志段文件大小</td>\n<td>调小便于删除</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.segment.ms</code></td>\n<td>604800000 (7天)</td>\n<td>强制滚动日志的时间</td>\n<td>适用于时间控制</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.hours</code></td>\n<td>168</td>\n<td>日志保留时间（小时）</td>\n<td>与磁盘空间相关</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.bytes</code></td>\n<td>-1</td>\n<td>日志总大小限制</td>\n<td>-1 表示不限制</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.retention.check.interval.ms</code></td>\n<td>300000</td>\n<td>检查日志保留策略间隔</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.enable</code></td>\n<td>true</td>\n<td>是否启用日志压缩</td>\n<td>compact 主题需启用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.threads</code></td>\n<td>1</td>\n<td>清理线程数</td>\n<td>大集群可增加</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.cleaner.io.max.bytes.per.second</code></td>\n<td>None</td>\n<td>限制清理 IO 带宽</td>\n<td>控制磁盘负载</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.flush.interval.messages</code></td>\n<td>Long.MAX_VALUE</td>\n<td>累计消息数达到后强制 flush</td>\n<td>通常保持默认</td>\n</tr>\n<tr>\n<td></td>\n<td><code>log.flush.interval.ms</code></td>\n<td>None</td>\n<td>每隔多久强制 flush</td>\n<td>SSD 可调大</td>\n</tr>\n<tr>\n<td></td>\n<td><code>num.partitions</code></td>\n<td>1</td>\n<td>新 Topic 默认分区数</td>\n<td>通常 3~6 起步</td>\n</tr>\n<tr>\n<td>🧵 <strong>生产与消费相关</strong></td>\n<td><code>message.max.bytes</code></td>\n<td>1048576</td>\n<td>允许的最大消息大小</td>\n<td>与 Producer <code>max.request.size</code> 对齐</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetch.max.bytes</code></td>\n<td>1048576</td>\n<td>与 Producer/Consumer 对应的限制</td>\n<td>防止大消息卡死</td>\n</tr>\n<tr>\n<td></td>\n<td><code>compression.type</code></td>\n<td>producer</td>\n<td>压缩算法（none, gzip, snappy, lz4, zstd）</td>\n<td>建议 zstd</td>\n</tr>\n<tr>\n<td></td>\n<td><code>queued.max.requests</code></td>\n<td>500</td>\n<td>Broker 最大排队请求数</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td>🛠️ <strong>控制器与协调器</strong></td>\n<td><code>controller.socket.timeout.ms</code></td>\n<td>30000</td>\n<td>控制器通信超时</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controller.quorum.voters</code></td>\n<td>-</td>\n<td>KRaft 模式选举成员</td>\n<td>ZK 模式不需</td>\n</tr>\n<tr>\n<td></td>\n<td><code>controller.listener.names</code></td>\n<td>-</td>\n<td>控制器监听名</td>\n<td>ZK 模式忽略</td>\n</tr>\n<tr>\n<td>📈 <strong>监控与指标</strong></td>\n<td><code>metric.reporters</code></td>\n<td>空</td>\n<td>指标上报类</td>\n<td>可接 Prometheus</td>\n</tr>\n<tr>\n<td></td>\n<td><code>metrics.num.samples</code></td>\n<td>2</td>\n<td>指标采样数</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>metrics.sample.window.ms</code></td>\n<td>30000</td>\n<td>指标采样窗口</td>\n<td>默认即可</td>\n</tr>\n<tr>\n<td></td>\n<td><code>replica.fetchers.metrics.enabled</code></td>\n<td>true</td>\n<td>是否启用副本拉取指标</td>\n<td>Kafka 3.x 新增</td>\n</tr>\n<tr>\n<td>🔒 <strong>安全</strong></td>\n<td><code>authorizer.class.name</code></td>\n<td>空</td>\n<td>授权类实现</td>\n<td>开启 ACL 时配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>super.users</code></td>\n<td>空</td>\n<td>超级用户列表</td>\n<td>ACL 模式下配置</td>\n</tr>\n<tr>\n<td></td>\n<td><code>ssl.keystore.location</code></td>\n<td>-</td>\n<td>SSL 证书路径</td>\n<td>启用 SSL 时使用</td>\n</tr>\n<tr>\n<td></td>\n<td><code>ssl.truststore.location</code></td>\n<td>-</td>\n<td>信任证书路径</td>\n<td>启用 SSL 时使用</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参数使用建议总结\">参数使用建议总结</h2>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>推荐配置</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>高可靠性集群</strong></td>\n<td><code>default.replication.factor=3</code>, <code>min.insync.replicas=2</code>, <code>unclean.leader.election.enable=false</code></td>\n</tr>\n<tr>\n<td><strong>吞吐优先</strong></td>\n<td>提高 <code>num.replica.fetchers</code>、<code>replica.fetch.max.bytes</code></td>\n</tr>\n<tr>\n<td><strong>快速恢复</strong></td>\n<td>减少 <code>replica.high.watermark.checkpoint.interval.ms</code></td>\n</tr>\n<tr>\n<td><strong>节省磁盘</strong></td>\n<td>启用 <code>log.cleaner.enable</code> 并设置 <code>log.retention.hours</code></td>\n</tr>\n<tr>\n<td><strong>事务或精确一次语义</strong></td>\n<td>设置 <code>transaction.state.log.replication.factor=3</code>、<code>transaction.state.log.min.isr=2</code></td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 3.x server.properties 主要配置项清单 关于 server.properties 的配置项，请参考 Kafka 官方文档 分类 参数名 默认值 说明 推荐/备注 🗂️ 基本信息 broker.id 0 Broker 唯一标识 集群中必须唯一 node.id - Raft 模式（KRaft）下使用 ZK 模式忽略 process.roles - KRaft 模式角色（controller, broker） ZK 模式不配置 🔌 网络与监听配置 listeners PLAINTEXT://:9092 Broker 监听地址 可用多个协议，如 SASL_PLAINTEXT, SSL advertised.listeners - 客户端连接时看到的地址 外网访问需配置 listener.security.protocol.map PLAINTEXT:PLAINTEXT 映射监听器协议 多协议时配置 inter.broker.listener.name -（Kafka 2.4+ 默认第一个 listener） 指定 broker 间通信使用哪个 listener（如 INTERNAL） 集群内部通信必须一致；常配合多 listener 使用 num.network.threads 3 网络线程数 一般不需修改 num.io.threads 8 处理请求的 IO 线程数 根据 CPU 调整 socket.send.buffer.bytes 102400 发送缓冲区大小 网络优化参数 socket.receive.buffer.bytes 102400 接收缓冲区大小 网络优化参数 socket.request.max.bytes 104857600 单请求最大大小 (100MB) 大消息需调大 ⚙️ 集群与元数据 log.dirs /tmp/kafka-logs 数据存储路径 多目录可提升性能 num.recovery.threads.per.data.dir 1 每个数据目录的恢复线程数 多磁盘时可增加 auto.create.topics.enable true 是否允许自动创建 Topic 生产建议禁用 controlled.shutdown.enable true 优雅关闭 Broker 建议开启 delete.topic.enable true 是否允许删除 Topic 生产慎用 auto.leader.rebalance.enable true 是否自动均衡 Leader 建议开启 leader.imbalance.check.interval.seconds 300 检查 leader 失衡间隔 与上配合使用 leader.imbalance.per.broker.percentage 10 触发 leader 重平衡的阈值 默认即可 🧱 副本与复制机制 default.replication.factor 1 新 Topic 默认副本数 生产建议 3 offsets.topic.replication.factor 1 消费组偏移主题副本数 建议 3 transaction.state.log.replication.factor 1 事务状态主题副本数 建议 3 transaction.state.log.min.isr 1 事务状态日志最小 ISR 数 建议 2 min.insync.replicas 1 Leader 写入时要求的最小 ISR 副本数 建议 replication.factor - 1 unclean.leader.election.enable false 是否允许非同步副本选为 leader 生产建议 false num.replica.fetchers 1 follower 拉取线程数 可提升复制性能 replica.fetch.max.bytes 1048576 (1MB) follower 拉取单分区最大数据量 增大可提速 replica.fetch.response.max.bytes 10485760 (10MB) follower 一次拉取响应总量 可调大 replica.fetch.wait.max.ms 500 follower 等待新数据的最大时长 延迟与吞吐折中 replica.fetch.backoff.ms 1000 拉取失败后退避时间 网络不稳时调整 replica.socket.timeout.ms 30000 follower 与 leader 通信超时 ≥ fetch.wait.ms replica.socket.receive.buffer.bytes 65536 拉取 socket 缓冲区 调大可提速 replica.lag.time.max.ms 10000 follower 落后 leader 的最大时间 影响 ISR replica.high.watermark.checkpoint.interval.ms 5000 高水位写入 checkpoint 周期 影响恢复速度 replica.selector.class - 自定义副本选择类 一般保持默认 🧮 日志与段文件 log.segment.bytes 1073741824 (1GB) 单日志段文件大小 调小便于删除 log.segment.ms 604800000 (7天) 强制滚动日志的时间 适用于时间控制 log.retention.hours 168 日志保留时间（小时） 与磁盘空间相关 log.retention.bytes -1 日志总大小限制 -1 表示不限制 log.retention.check.interval.ms 300000 检查日志保留策略间隔 默认即可 log.cleaner.enable true 是否启用日志压缩 compact 主题需启用 log.cleaner.threads 1 清理线程数 大集群可增加 log.cleaner.io.max.bytes.per.second None 限制清理 IO 带宽 控制磁盘负载 log.flush.interval.messages Long.MAX_VALUE 累计消息数达到后强制 flush 通常保持默认 log.flush.interval.ms None 每隔多久强制 flush SSD 可调大 num.partitions 1 新 Topic 默认分区数 通常 3~6 起步 🧵 生产与消费相关 message.max.bytes 1048576 允许的最大消息大小 与 Producer max.request.size 对齐 replica.fetch.max.bytes 1048576 与 Producer/Consumer 对应的限制 防止大消息卡死 compression.type producer 压缩算法（none, gzip, snappy, lz4, zstd） 建议 zstd queued.max.requests 500 Broker 最大排队请求数 默认即可 🛠️ 控制器与协调器 controller.socket.timeout.ms 30000 控制器通信超时 默认即可 controller.quorum.voters - KRaft 模式选举成员 ZK 模式不需 controller.listener.names - 控制器监听名 ZK 模式忽略 📈 监控与指标 metric.reporters 空 指标上报类 可接 Prometheus metrics.num.samples 2 指标采样数 默认即可 metrics.sample.window.ms 30000 指标采样窗口 默认即可 replica.fetchers.metrics.enabled true 是否启用副本拉取指标 Kafka 3.x 新增 🔒 安全 authorizer.class.name 空 授权类实现 开启 ACL 时配置 super.users 空 超级用户列表 ACL 模式下配置 ssl.keystore.location - SSL 证书路径 启用 SSL 时使用 ssl.truststore.location - 信任证书路径 启用 SSL 时使用 参数使用建议总结 场景 推荐配置 高可靠性集群 default.replication.factor=3, min.insync.replicas=2, unclean.leader.election.enable=false 吞吐优先 提高 num.replica.fetchers、replica.fetch.max.bytes 快速恢复 减少 replica.high.watermark.checkpoint.interval.ms 节省磁盘 启用 log.cleaner.enable 并设置 log.retention.hours 事务或精确一次语义 设置 transaction.state.log.replication.factor=3、transaction.state.log.min.isr=2","summary":"摘要 本文介绍 CentOS9 中 Kafka 的 server.properties 的配置项，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-14T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-03-webui/","title":"Kafka 的 Web UI 之 Kafbat UI","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 Web UI 之 Kafbat UI</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafbat.io\">Kafbat UI 官网</a>，<a href=\"https://github.com/kafbat/kafka-ui\">Kafbat UI Github</a>，<a href=\"https://ui.docs.kafbat.io\">Kafbat UI 文档</a>，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。</p>\n</li>\n<li class=\"lvl-2\">\n<p>与 Kafbat UI 类似的 Kafka Web UI 还有一个 <a href=\"https://github.com/obsidiandynamics/kafdrop\">kafdrop</a>，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafbat-UI-简介\">Kafbat UI 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafbat UI 是一个免费的开源 Web 用户界面，用于监控和管理 Apache Kafka 集群。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafbat UI 是一个简单的工具，使您的数据流变得可观察，帮助更快地发现和排除问题，并提供最佳性能。其轻量级的仪表盘使您能够轻松跟踪 Kafka 集群的关键指标: 包括 Brokers、Topics、Partitions、生产和消费情况。</p>\n</li>\n</ul>\n<h2 id=\"运行-Kafbat-UI\">运行 Kafbat UI</h2>\n<h3 id=\"Docker-运行\">Docker 运行</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -p 8080:8080 \\</span><br><span class=\"line\">    --name kafka-ui \\</span><br><span class=\"line\">    -e KAFKA_CLUSTERS_0_NAME=kafka_c01 \\</span><br><span class=\"line\">    -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092 \\</span><br><span class=\"line\">    -e TZ=Asia/Shanghai \\</span><br><span class=\"line\">    -d ghcr.io/kafbat/kafka-ui:latest</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"Jar-运行\">Jar 运行</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>从<a href=\"https://github.com/kafbat/kafka-ui/releases\">Github</a>上下载最新版jar包，要求 <code>jdk 21+</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /Users/hanqf/myservice_dir/kafka_webui</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置kafka集群，可以同时配置多个，序号从0开始依次递增</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_NAME=kafka_c01</span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网PLAINTEXT访问</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网SASL_PLAINTEXT访问</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9094,68.79.13.235:9094,43.192.84.195:9094</span></span><br><span class=\"line\"><span class=\"comment\"># # SASL_PLAINTEXT认证配置</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># =============================================================================================================</span></span><br><span class=\"line\"><span class=\"comment\"># 外网SASL_SSL访问</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9095,68.79.13.235:9095,43.192.84.195:9095</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_SSL</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=<span class=\"string\">&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># SSL配置</span></span><br><span class=\"line\"><span class=\"comment\"># JKS 格式证书</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=123456</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># PEM 格式证书</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span></span><br><span class=\"line\"><span class=\"comment\"># export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_TYPE=PEM</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=<span class=\"string\">&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># ============================================================================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第二个集群配置示例</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_1_NAME=kafka_c02</span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 时区</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> TZ=Asia/Shanghai</span><br><span class=\"line\"><span class=\"comment\"># 语言</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LANG=zh_CN.UTF-8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># webui访问路径</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SERVER_SERVLET_CONTEXT_PATH=/</span><br><span class=\"line\"><span class=\"comment\"># 认证方式，支持NONE(无认证)，LOGIN_FORM(登录表单认证)</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> AUTH_TYPE=LOGIN_FORM</span><br><span class=\"line\"><span class=\"comment\"># webui认证用户名密码</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPRING_SECURITY_USER_NAME=admin</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPRING_SECURITY_USER_PASSWORD=admin</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=<span class=\"string\">&quot;-Xms512m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 启动</span></span><br><span class=\"line\">/Users/hanqf/develop_soft/jdk21/bin/java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED  <span class=\"variable\">$JAVA_OPTS</span> -jar api-v1.3.0.jar</span><br></pre></td></tr></table></figure>\n<h2 id=\"访问-Kafbat-UI\">访问 Kafbat UI</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>访问 <a href=\"http://localhost:8080\">http://localhost:8080</a><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/ykd6F4.png\" alt=\"\"></p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 Kafka 的 Web UI 之 Kafbat UI Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafbat UI 官网，Kafbat UI Github，Kafbat UI 文档，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。 与 Kafbat UI 类似的 Kafka Web UI 还有一个 kafdrop，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。 Kafbat UI 简介 Kafbat UI 是一个免费的开源 Web 用户界面，用于监控和管理 Apache Kafka 集群。 Kafbat UI 是一个简单的工具，使您的数据流变得可观察，帮助更快地发现和排除问题，并提供最佳性能。其轻量级的仪表盘使您能够轻松跟踪 Kafka 集群的关键指标: 包括 Brokers、Topics、Partitions、生产和消费情况。 运行 Kafbat UI Docker 运行 1234567docker run -it -p 8080:8080 \\ --name kafka-ui \\ -e KAFKA_CLUSTERS_0_NAME=kafka_c01 \\ -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092 \\ -e TZ=Asia/Shanghai \\ -d ghcr.io/kafbat/kafka-ui:latest Jar 运行 从Github上下载最新版jar包，要求 jdk 21+ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859cd /Users/hanqf/myservice_dir/kafka_webui# 配置kafka集群，可以同时配置多个，序号从0开始依次递增export KAFKA_CLUSTERS_0_NAME=kafka_c01# =============================================================================================================# 外网PLAINTEXT访问# export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093# =============================================================================================================# =============================================================================================================# 外网SASL_PLAINTEXT访问# export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9094,68.79.13.235:9094,43.192.84.195:9094# # SASL_PLAINTEXT认证配置# export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_PLAINTEXT# export KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAIN# export KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;# =============================================================================================================# =============================================================================================================# 外网SASL_SSL访问export KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=161.189.227.200:9095,68.79.13.235:9095,43.192.84.195:9095export KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=SASL_SSLexport KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM=PLAINexport KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG=&#x27;org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;alice&quot; password=&quot;alice-secret&quot;;&#x27;# SSL配置# JKS 格式证书export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jksexport KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=123456# PEM 格式证书# export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt# export KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_TYPE=PEM# 禁用主机名验证export KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=&#x27;&#x27;# ============================================================================================================# 第二个集群配置示例export KAFKA_CLUSTERS_1_NAME=kafka_c02export KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS=161.189.227.200:9093,68.79.13.235:9093,43.192.84.195:9093# 时区export TZ=Asia/Shanghai# 语言export LANG=zh_CN.UTF-8# webui访问路径export SERVER_SERVLET_CONTEXT_PATH=/# 认证方式，支持NONE(无认证)，LOGIN_FORM(登录表单认证)export AUTH_TYPE=LOGIN_FORM# webui认证用户名密码export SPRING_SECURITY_USER_NAME=adminexport SPRING_SECURITY_USER_PASSWORD=adminJAVA_OPTS=&quot;-Xms512m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m&quot;# 启动/Users/hanqf/develop_soft/jdk21/bin/java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED $JAVA_OPTS -jar api-v1.3.0.jar 访问 Kafbat UI 访问 http://localhost:8080","summary":"摘要 本文介绍 Kafka 的 Web UI 之 Kafbat UI Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafbat UI 官网，Kafbat UI Github，Kafbat UI 文档，Kafbat UI 支持 Docker 和 Jar 包两种方式运行，支持同时连接多个 Kafka 集群。 与 Kafbat UI 类似的 Kafka Web UI 还有一个 kafdrop，同样支持 Docker 和 Jar 包两种方式运行，只不过其仅支持单个 Kafka 集群，感兴趣的可以自己体验。","date_published":"2025-10-13T15:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-02-protocol/","title":"Kafka 通信协议、SSL加密和身份验证","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Kafka 的 通信协议，以及如何开启外网访问。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-的-通信协议\">Kafka 的 通信协议</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 主要支持四种安全协议</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>协议名称</th>\n<th>加密</th>\n<th>认证</th>\n<th>说明</th>\n<th>推荐场景</th>\n<th>理由</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>PLAINTEXT</strong></td>\n<td>❌ 否</td>\n<td>❌ 否</td>\n<td>无加密、无认证（默认最简单）</td>\n<td>开发 / 测试环境、内网集群通信</td>\n<td>简单、易调试；网络可信，性能优先</td>\n</tr>\n<tr>\n<td><strong>SSL</strong></td>\n<td>✅ 是</td>\n<td>✅ 可选</td>\n<td>使用 TLS/SSL 加密通信，可配置客户端证书认证</td>\n<td>外网客户端访问</td>\n<td>支持数据加密，可选认证，保证安全</td>\n</tr>\n<tr>\n<td><strong>SASL_PLAINTEXT</strong></td>\n<td>❌ 否</td>\n<td>✅ 是</td>\n<td>使用 SASL（用户名密码）认证，但不加密数据</td>\n<td>需要用户认证但局域网环境</td>\n<td>有认证，但不加密，性能开销低</td>\n</tr>\n<tr>\n<td><strong>SASL_SSL</strong></td>\n<td>✅ 是</td>\n<td>✅ 是</td>\n<td>同时支持 SASL 认证和 SSL 加密（最安全）</td>\n<td>外网客户端访问</td>\n<td>既有认证又加密，安全性最高</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 <code>config/server.properties</code> 文件中 可以看到如下配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 套接字服务器监听的地址。</span></span><br><span class=\"line\"><span class=\"comment\"># 如果未配置，则主机名默认等于 `java.net.InetAddress.getCanonicalHostName()` 的返回值，</span></span><br><span class=\"line\"><span class=\"comment\"># 使用监听器名称 `PLAINTEXT`，端口号为 9092。</span></span><br><span class=\"line\"><span class=\"comment\">#   格式：</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = listener_name://host_name:port</span></span><br><span class=\"line\"><span class=\"comment\">#   示例：</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"><span class=\"comment\">#listeners=PLAINTEXT://:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broker 向客户端“通告”的监听器名称、主机名和端口。</span></span><br><span class=\"line\"><span class=\"comment\"># 客户端实际会连接这个地址，而不是直接使用 listeners 的地址。</span></span><br><span class=\"line\"><span class=\"comment\"># 如果未设置，则默认使用 `listeners` 的值。</span></span><br><span class=\"line\"><span class=\"comment\">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将监听器名称映射到安全协议类型。</span></span><br><span class=\"line\"><span class=\"comment\"># 默认情况下，监听器名称与安全协议同名。</span></span><br><span class=\"line\"><span class=\"comment\"># 例如：PLAINTEXT→PLAINTEXT、SSL→SSL、SASL_PLAINTEXT→SASL_PLAINTEXT、SASL_SSL→SASL_SSL。</span></span><br><span class=\"line\"><span class=\"comment\"># 更多细节可参考 Kafka 官方配置文档。</span></span><br><span class=\"line\"><span class=\"comment\">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>作用</th>\n<th>说明值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>listeners</code></td>\n<td>Kafka 实际监听的地址（Broker 对外开放的端口）</td>\n<td><code>PLAINTEXT://:9092</code>这里 PLAINTEXT 是监听器名称，并不是协议名称，实际上可以配置为任何值，具体协议是通过 <code>listener.security.protocol.map</code> 配置的映射关系来确定。</td>\n</tr>\n<tr>\n<td><code>advertised.listeners</code></td>\n<td>Kafka 告诉客户端应该用哪个地址连接（客户端最终连的）</td>\n<td>默认使用 <code>listeners</code> 的值</td>\n</tr>\n<tr>\n<td><code>listener.security.protocol.map</code></td>\n<td>映射监听器名称到通信安全协议（如明文、SSL、SASL 等）</td>\n<td><code>PLAINTEXT:PLAINTEXT</code>，前面是监听器名称，后面是协议名称</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"仅需内网访问\">仅需内网访问</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://worker1:9092 <span class=\"comment\"># 这里是内网ip</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"允许外网访问\">允许外网访问</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listeners=PLAINTEXT://0.0.0.0:9092</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://161.189.227.200:9092 <span class=\"comment\"># 这里是外网ip</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"内外网都要访问（推荐双通道方式）\">内外网都要访问（推荐双通道方式）</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里 INTERNAL 和 EXTERNAL 分别是自定义的监听器名称，此时内网端口为 9092，外网端口为 9093</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093</span><br><span class=\"line\"><span class=\"comment\"># 告诉客户端应该用哪个地址连接</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9093</span><br><span class=\"line\"><span class=\"comment\"># 映射监听器名称到通信安全协议的映射关系</span></span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 集群间通信仍使用内网</span></span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br></pre></td></tr></table></figure>\n<h2 id=\"开启-SASL-PLAINTEXT\">开启 SASL_PLAINTEXT</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里设置外网访问时开启 SASL_PLAINTEXT</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9094</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 集群间通信 still use INTERNAL</span></span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，因为 inter.broker.listener.name=INTERNAL，所以 INTERNAL:SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建 kafka_jaas.conf</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">############################</span></span><br><span class=\"line\"><span class=\"comment\"># Kafka Broker (服务端)</span></span><br><span class=\"line\"><span class=\"comment\">############################</span></span><br><span class=\"line\">KafkaServer &#123;</span><br><span class=\"line\">    <span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">    org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class=\"line\">    <span class=\"comment\"># Broker 自己的身份（用于 broker 之间通信，本示例中没有使用）</span></span><br><span class=\"line\">    username=<span class=\"string\">&quot;admin&quot;</span></span><br><span class=\"line\">    password=<span class=\"string\">&quot;admin-secret&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 客户端可用账号，即 user_xxx，这里 xxx 为用户名，= 右边的为密码</span></span><br><span class=\"line\">    user_admin=<span class=\"string\">&quot;admin-secret&quot;</span></span><br><span class=\"line\">    user_alice=<span class=\"string\">&quot;alice-secret&quot;</span></span><br><span class=\"line\">    user_bob=<span class=\"string\">&quot;bob-secret&quot;</span>;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在启动 Kafka Broker 前，设置环境变量指向 JAAS 文件</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_OPTS=<span class=\"string\">&quot;-Djava.security.auth.login.config=/usr/local/kafka/kafka3/config/kafka_jaas.conf&quot;</span></span><br><span class=\"line\">kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure>\n<h3 id=\"客户端访问\">客户端访问</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建 client.conf</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_PLAINTEXT</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行访问</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建topic</span></span><br><span class=\"line\">kafka-topics.sh --create --topic test-topic --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class=\"line\"><span class=\"comment\"># 查看topic</span></span><br><span class=\"line\">kafka-topics.sh --list --bootstrap-server=161.189.227.200:9094 --command-config=client.conf</span><br><span class=\"line\"><span class=\"comment\"># 创建消费者，--group 指定消费者组名称</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --consumer.config=client.conf --group=test-group</span><br><span class=\"line\"><span class=\"comment\"># 创建生产者</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --producer.config=client.conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"开启-SASL-SSL\">开启 SASL_SSL</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里设置外网访问时开启 SASL_SSL</p>\n</li>\n</ul>\n<h3 id=\"创建证书\">创建证书</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org/39/documentation.html#security_ssl\">官方文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>生成 Broker keystore，用于 存储 broker 的私钥和证书。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -keystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -validity 3650 \\</span><br><span class=\"line\">  -genkey -keyalg RSA \\</span><br><span class=\"line\">  -dname <span class=\"string\">&quot;CN=broker, OU=Kafka, O=YourOrg, L=City, ST=State, C=CN&quot;</span> \\</span><br><span class=\"line\">  -storepass 123456 \\</span><br><span class=\"line\">  -keypass 123456</span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：生成的 keystore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -validity 3650：有效期 3650 天</span></span><br><span class=\"line\"><span class=\"comment\"># -keyalg RSA：密钥算法</span></span><br><span class=\"line\"><span class=\"comment\"># -dname：证书信息</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：keystore 密码</span></span><br><span class=\"line\"><span class=\"comment\"># -keypass：密钥密码</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>导出 Broker 证书（用于客户端 truststore）,生成 kafka.server.crt，客户端会用它来验证 broker。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -keystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -<span class=\"built_in\">export</span> -file kafka.server.crt \\</span><br><span class=\"line\">  -storepass 123456</span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：keystore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -file kafka.server.crt：导出的证书文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：keystore 密码</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>生成 Broker truststore，truststore 用于 存储信任的证书（这里把自己生成的证书导入进去即可）,生成 kafka.truststore.jks</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 注意：这里 server 端 和 client 端 可以共用一个 truststore，也可以分别创建</span></span><br><span class=\"line\">keytool -keystore kafka.truststore.jks \\</span><br><span class=\"line\">  -<span class=\"built_in\">alias</span> broker -import -file kafka.server.crt \\</span><br><span class=\"line\">  -storepass 123456 -noprompt</span><br><span class=\"line\"><span class=\"comment\"># 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -keystore：生成的 truststore 文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -alias broker：证书别名</span></span><br><span class=\"line\"><span class=\"comment\"># -file kafka.server.crt：导入的证书文件路径</span></span><br><span class=\"line\"><span class=\"comment\"># -storepass：truststore 密码</span></span><br><span class=\"line\"><span class=\"comment\"># -noprompt：不提示</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"server-properties-配置-SASL-SSL\">server.properties 配置 SASL_SSL</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SASL</span></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL</span></span><br><span class=\"line\">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/kafka.server.keystore.jks</span><br><span class=\"line\">ssl.keystore.password=123456</span><br><span class=\"line\">ssl.key.password=123456</span><br><span class=\"line\">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\">ssl.truststore.password=123456</span><br><span class=\"line\"><span class=\"comment\"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class=\"line\">ssl.client.auth=none</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka 前同样需要先创建好 kafka_jaas.conf，与 SASL_PLAINTEXT 一样。</p>\n</li>\n</ul>\n<h3 id=\"客户端访问-2\">客户端访问</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>将 <code>kafka.truststore.jks</code> 拷贝到客户端</p>\n</li>\n<li class=\"lvl-2\">\n<p>与 SASL_PLAINTEXT 一样，创建 client.conf，并添加如下信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_SSL</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL 配置</span></span><br><span class=\"line\">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jks</span><br><span class=\"line\">ssl.truststore.password=123456</span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证，否则会校验证书的 SAN，证书域名校验开关，为空则表示关闭，这里需要保持关闭状态，必须设置为空</span></span><br><span class=\"line\">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行访问 与 SASL_PLAINTEXT 一样，这里不再赘述</p>\n</li>\n<li class=\"lvl-2\">\n<p>关于 Kafka JKS格式的SSL证书的创建及配置可以参考<a href=\"https://support.huaweicloud.com/usermanual-kafka/kafka-ug-0008.html\">制作和替换Kafka JKS格式的SSL证书</a></p>\n</li>\n</ul>\n<h4 id=\"PEM-证书\">PEM 证书</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kafka 的 证书 默认使用 JKS 格式，但从 2.7.0 开始支持 PEM 格式</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 监听地址和端口，这里内网和外网分开配置</span></span><br><span class=\"line\">listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095</span><br><span class=\"line\"><span class=\"comment\"># 客户端建立连接后实际返回给客户端的地址</span></span><br><span class=\"line\">advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095</span><br><span class=\"line\">listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL</span><br><span class=\"line\">inter.broker.listener.name=INTERNAL</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SASL</span></span><br><span class=\"line\"><span class=\"comment\"># 认证机制（常见为 PLAIN，也可以是 CRAM-SHA-256、SCRAM-SHA-512）</span></span><br><span class=\"line\"><span class=\"comment\"># client 连接时</span></span><br><span class=\"line\">sasl.enabled.mechanisms=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效</span></span><br><span class=\"line\"><span class=\"comment\">#sasl.mechanism.inter.broker.protocol=PLAIN</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL-PEM</span></span><br><span class=\"line\">ssl.keystore.type=PEM <span class=\"comment\"># 指定证书类型是PEM，支持的类型 PEM、JKS</span></span><br><span class=\"line\">ssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/fullchain.pem <span class=\"comment\"># 包含私钥和公钥</span></span><br><span class=\"line\"><span class=\"comment\"># 指定客户端使用的证书类型是PEM</span></span><br><span class=\"line\">ssl.truststore.type=PEM</span><br><span class=\"line\">ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/server.crt <span class=\"comment\"># 公钥</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如果不要求客户端证书，可以设置 none ，要求则设置为 required</span></span><br><span class=\"line\">ssl.client.auth=none</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>client.conf 配置如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">security.protocol=SASL_SSL</span><br><span class=\"line\"><span class=\"comment\"># 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致</span></span><br><span class=\"line\">sasl.mechanism=PLAIN</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class=\"line\">sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class=\"string\">&quot;admin&quot;</span> password=<span class=\"string\">&quot;admin-secret&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># SSL 配置，将 server 端的 server.crt 拷贝到 client 端</span></span><br><span class=\"line\">ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crt</span><br><span class=\"line\">ssl.truststore.type=PEM</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 禁用主机名验证</span></span><br><span class=\"line\">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>jks 证书转换为 pem 格式</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">从 JKS 导出为 PKCS#12 (.p12)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keytool -importkeystore \\</span><br><span class=\"line\">  -srckeystore kafka.server.keystore.jks \\</span><br><span class=\"line\">  -srcstoretype JKS \\</span><br><span class=\"line\">  -destkeystore kafka.server.p12 \\</span><br><span class=\"line\">  -deststoretype PKCS12 \\</span><br><span class=\"line\">  -srcstorepass 123456 \\</span><br><span class=\"line\">  -deststorepass 123456 \\</span><br><span class=\"line\">  -J<span class=\"string\">&quot;-Djdk.tls.disabledAlgorithms=&quot;</span> \\</span><br><span class=\"line\">  -J<span class=\"string\">&quot;-Dkeystore.pkcs12.legacy=false&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\">  <span class=\"comment\"># -srcstoretype JKS：原始格式；</span></span><br><span class=\"line\">  <span class=\"comment\"># -deststoretype PKCS12：转换为通用格式；</span></span><br><span class=\"line\">  <span class=\"comment\"># .p12 是 PEM 的“中间格式”。</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">导出证书[公钥] (.crt，这里是 PEM 格式)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -clcerts -nokeys -out server.crt -password pass:123456 -provider legacy -provider default</span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -clcerts：只导出证书；</span></span><br><span class=\"line\"><span class=\"comment\"># -nokeys：不导出密钥；</span></span><br><span class=\"line\"><span class=\"comment\"># -out server.crt：导出文件名；</span></span><br><span class=\"line\"><span class=\"comment\"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br><span class=\"line\"><span class=\"comment\"># -provider legacy：启用旧算法支持模块，在 OpenSSL 3.0（及更高版本）中，引入了一个新机制 —— Provider（算法提供者）,默认情况下，OpenSSL 只加载 modern provider（default provider），而许多老旧算法（例如 RC2、MD5、DES、SHA1）被移到了一个单独的 legacy provider 模块中。</span></span><br><span class=\"line\"><span class=\"comment\"># -provider default：同时启用默认 provider，因为有些命令（比如涉及现代加密算法或证书签名）还依赖默认 provider，所以两者一起使用最安全、最兼容</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">导出私钥 (.key，这里是 PEM 格式)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -nocerts -out server.key -nodes -password pass:123456 -provider legacy -provider default</span><br><span class=\"line\"><span class=\"comment\">## 说明：</span></span><br><span class=\"line\"><span class=\"comment\"># -nocerts：只导出密钥；</span></span><br><span class=\"line\"><span class=\"comment\"># -out server.key：导出文件名；</span></span><br><span class=\"line\"><span class=\"comment\"># -nodes：不加密导出的密钥文件</span></span><br><span class=\"line\"><span class=\"comment\"># -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">fullchain.pem</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">openssl pkcs12 -<span class=\"keyword\">in</span> kafka.server.p12 -out fullchain.pem -nodes -password pass:123456 -provider legacy -provider default</span><br></pre></td></tr></table></figure>\n</div>\n","content_text":"摘要 本文介绍 Kafka 的 通信协议，以及如何开启外网访问。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 的 通信协议 Kafka 主要支持四种安全协议 协议名称 加密 认证 说明 推荐场景 理由 PLAINTEXT ❌ 否 ❌ 否 无加密、无认证（默认最简单） 开发 / 测试环境、内网集群通信 简单、易调试；网络可信，性能优先 SSL ✅ 是 ✅ 可选 使用 TLS/SSL 加密通信，可配置客户端证书认证 外网客户端访问 支持数据加密，可选认证，保证安全 SASL_PLAINTEXT ❌ 否 ✅ 是 使用 SASL（用户名密码）认证，但不加密数据 需要用户认证但局域网环境 有认证，但不加密，性能开销低 SASL_SSL ✅ 是 ✅ 是 同时支持 SASL 认证和 SSL 加密（最安全） 外网客户端访问 既有认证又加密，安全性最高 在 config/server.properties 文件中 可以看到如下配置 12345678910111213141516171819# 套接字服务器监听的地址。# 如果未配置，则主机名默认等于 `java.net.InetAddress.getCanonicalHostName()` 的返回值，# 使用监听器名称 `PLAINTEXT`，端口号为 9092。# 格式：# listeners = listener_name://host_name:port# 示例：# listeners = PLAINTEXT://your.host.name:9092#listeners=PLAINTEXT://:9092# Broker 向客户端“通告”的监听器名称、主机名和端口。# 客户端实际会连接这个地址，而不是直接使用 listeners 的地址。# 如果未设置，则默认使用 `listeners` 的值。#advertised.listeners=PLAINTEXT://your.host.name:9092# 将监听器名称映射到安全协议类型。# 默认情况下，监听器名称与安全协议同名。# 例如：PLAINTEXT→PLAINTEXT、SSL→SSL、SASL_PLAINTEXT→SASL_PLAINTEXT、SASL_SSL→SASL_SSL。# 更多细节可参考 Kafka 官方配置文档。#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL 配置项 作用 说明值 listeners Kafka 实际监听的地址（Broker 对外开放的端口） PLAINTEXT://:9092这里 PLAINTEXT 是监听器名称，并不是协议名称，实际上可以配置为任何值，具体协议是通过 listener.security.protocol.map 配置的映射关系来确定。 advertised.listeners Kafka 告诉客户端应该用哪个地址连接（客户端最终连的） 默认使用 listeners 的值 listener.security.protocol.map 映射监听器名称到通信安全协议（如明文、SSL、SASL 等） PLAINTEXT:PLAINTEXT，前面是监听器名称，后面是协议名称 仅需内网访问 12listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://worker1:9092 # 这里是内网ip 允许外网访问 12listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://161.189.227.200:9092 # 这里是外网ip 内外网都要访问（推荐双通道方式） 12345678# 这里 INTERNAL 和 EXTERNAL 分别是自定义的监听器名称，此时内网端口为 9092，外网端口为 9093listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093# 告诉客户端应该用哪个地址连接advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9093# 映射监听器名称到通信安全协议的映射关系listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT# 集群间通信仍使用内网inter.broker.listener.name=INTERNAL 开启 SASL_PLAINTEXT 这里设置外网访问时开启 SASL_PLAINTEXT 12345678910111213# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker1:9092,EXTERNAL://161.189.227.200:9094listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT# 集群间通信 still use INTERNALinter.broker.listener.name=INTERNAL# 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，因为 inter.broker.listener.name=INTERNAL，所以 INTERNAL:SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN 创建 kafka_jaas.conf 123456789101112131415############################# Kafka Broker (服务端)############################KafkaServer &#123; # 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule required org.apache.kafka.common.security.plain.PlainLoginModule required # Broker 自己的身份（用于 broker 之间通信，本示例中没有使用） username=&quot;admin&quot; password=&quot;admin-secret&quot; # 客户端可用账号，即 user_xxx，这里 xxx 为用户名，= 右边的为密码 user_admin=&quot;admin-secret&quot; user_alice=&quot;alice-secret&quot; user_bob=&quot;bob-secret&quot;;&#125;; 启动 kafka 123# 在启动 Kafka Broker 前，设置环境变量指向 JAAS 文件export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/usr/local/kafka/kafka3/config/kafka_jaas.conf&quot;kafka-server-start.sh config/server.properties 客户端访问 创建 client.conf 12345security.protocol=SASL_PLAINTEXT# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;; 命令行访问 12345678# 创建topickafka-topics.sh --create --topic test-topic --bootstrap-server=161.189.227.200:9094 --command-config=client.conf# 查看topickafka-topics.sh --list --bootstrap-server=161.189.227.200:9094 --command-config=client.conf# 创建消费者，--group 指定消费者组名称kafka-console-consumer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --consumer.config=client.conf --group=test-group# 创建生产者kafka-console-producer.sh --bootstrap-server=161.189.227.200:9094 --topic test-topic --producer.config=client.conf 开启 SASL_SSL 这里设置外网访问时开启 SASL_SSL 创建证书 官方文档 生成 Broker keystore，用于 存储 broker 的私钥和证书。 1234567891011121314keytool -keystore kafka.server.keystore.jks \\ -alias broker -validity 3650 \\ -genkey -keyalg RSA \\ -dname &quot;CN=broker, OU=Kafka, O=YourOrg, L=City, ST=State, C=CN&quot; \\ -storepass 123456 \\ -keypass 123456## 参数说明：# -keystore：生成的 keystore 文件路径# -alias broker：证书别名# -validity 3650：有效期 3650 天# -keyalg RSA：密钥算法# -dname：证书信息# -storepass：keystore 密码# -keypass：密钥密码 导出 Broker 证书（用于客户端 truststore）,生成 kafka.server.crt，客户端会用它来验证 broker。 12345678keytool -keystore kafka.server.keystore.jks \\ -alias broker -export -file kafka.server.crt \\ -storepass 123456## 参数说明：# -keystore：keystore 文件路径# -alias broker：证书别名# -file kafka.server.crt：导出的证书文件路径# -storepass：keystore 密码 生成 Broker truststore，truststore 用于 存储信任的证书（这里把自己生成的证书导入进去即可）,生成 kafka.truststore.jks 12345678910# 注意：这里 server 端 和 client 端 可以共用一个 truststore，也可以分别创建keytool -keystore kafka.truststore.jks \\ -alias broker -import -file kafka.server.crt \\ -storepass 123456 -noprompt# 参数说明：# -keystore：生成的 truststore 文件路径# -alias broker：证书别名# -file kafka.server.crt：导入的证书文件路径# -storepass：truststore 密码# -noprompt：不提示 server.properties 配置 SASL_SSL 1234567891011121314151617181920212223# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSLinter.broker.listener.name=INTERNAL# SASL# 认证机制（常见为 PLAIN，也可以是 SCRAM-SHA-256 或者 SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN# SSLssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/kafka.server.keystore.jksssl.keystore.password=123456ssl.key.password=123456ssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/kafka.truststore.jksssl.truststore.password=123456# 如果不要求客户端证书，可以设置 none ，要求则设置为 requiredssl.client.auth=none 启动 kafka 前同样需要先创建好 kafka_jaas.conf，与 SASL_PLAINTEXT 一样。 客户端访问 将 kafka.truststore.jks 拷贝到客户端 与 SASL_PLAINTEXT 一样，创建 client.conf，并添加如下信息 1234567891011security.protocol=SASL_SSL# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;# SSL 配置ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/kafka.truststore.jksssl.truststore.password=123456# 禁用主机名验证，否则会校验证书的 SAN，证书域名校验开关，为空则表示关闭，这里需要保持关闭状态，必须设置为空ssl.endpoint.identification.algorithm= 命令行访问 与 SASL_PLAINTEXT 一样，这里不再赘述 关于 Kafka JKS格式的SSL证书的创建及配置可以参考制作和替换Kafka JKS格式的SSL证书 PEM 证书 Kafka 的 证书 默认使用 JKS 格式，但从 2.7.0 开始支持 PEM 格式 123456789101112131415161718192021222324# 监听地址和端口，这里内网和外网分开配置listeners=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095# 客户端建立连接后实际返回给客户端的地址advertised.listeners=INTERNAL://worker2:9092,EXTERNAL://161.189.227.200:9095listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSLinter.broker.listener.name=INTERNAL# SASL# 认证机制（常见为 PLAIN，也可以是 CRAM-SHA-256、SCRAM-SHA-512）# client 连接时sasl.enabled.mechanisms=PLAIN# broker 之间连接时，需要 inter.broker.listener.name=SASL_PLAINTEXT 才有效#sasl.mechanism.inter.broker.protocol=PLAIN# SSL-PEMssl.keystore.type=PEM # 指定证书类型是PEM，支持的类型 PEM、JKSssl.keystore.location=/usr/local/kafka/kafka3/config/ssl/fullchain.pem # 包含私钥和公钥# 指定客户端使用的证书类型是PEMssl.truststore.type=PEMssl.truststore.location=/usr/local/kafka/kafka3/config/ssl/server.crt # 公钥# 如果不要求客户端证书，可以设置 none ，要求则设置为 requiredssl.client.auth=none client.conf 配置如下： 123456789101112security.protocol=SASL_SSL# 认证机制，支持 PLAIN、SCRAM-SHA-256、SCRAM-SHA-512，要与 服务端一致sasl.mechanism=PLAIN# 如果使用 SCRAM-SHA-256 或者 SCRAM-SHA-512 认证，则需要配置 为 org.apache.kafka.common.security.scram.ScramLoginModule requiredsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;# SSL 配置，将 server 端的 server.crt 拷贝到 client 端ssl.truststore.location=/Users/hanqf/develop_soft/kafka/kafka3/config/ssl/server.crtssl.truststore.type=PEM# 禁用主机名验证ssl.endpoint.identification.algorithm= jks 证书转换为 pem 格式 从 JKS 导出为 PKCS#12 (.p12) 1234567891011121314keytool -importkeystore \\ -srckeystore kafka.server.keystore.jks \\ -srcstoretype JKS \\ -destkeystore kafka.server.p12 \\ -deststoretype PKCS12 \\ -srcstorepass 123456 \\ -deststorepass 123456 \\ -J&quot;-Djdk.tls.disabledAlgorithms=&quot; \\ -J&quot;-Dkeystore.pkcs12.legacy=false&quot;## 说明： # -srcstoretype JKS：原始格式； # -deststoretype PKCS12：转换为通用格式； # .p12 是 PEM 的“中间格式”。 导出证书[公钥] (.crt，这里是 PEM 格式) 12345678openssl pkcs12 -in kafka.server.p12 -clcerts -nokeys -out server.crt -password pass:123456 -provider legacy -provider default## 说明：# -clcerts：只导出证书；# -nokeys：不导出密钥；# -out server.crt：导出文件名；# -password：kafka.server.p12的密钥密码，注意密码前面加上 pass:# -provider legacy：启用旧算法支持模块，在 OpenSSL 3.0（及更高版本）中，引入了一个新机制 —— Provider（算法提供者）,默认情况下，OpenSSL 只加载 modern provider（default provider），而许多老旧算法（例如 RC2、MD5、DES、SHA1）被移到了一个单独的 legacy provider 模块中。# -provider default：同时启用默认 provider，因为有些命令（比如涉及现代加密算法或证书签名）还依赖默认 provider，所以两者一起使用最安全、最兼容 导出私钥 (.key，这里是 PEM 格式) 123456openssl pkcs12 -in kafka.server.p12 -nocerts -out server.key -nodes -password pass:123456 -provider legacy -provider default## 说明：# -nocerts：只导出密钥；# -out server.key：导出文件名；# -nodes：不加密导出的密钥文件# -password：kafka.server.p12的密钥密码，注意密码前面加上 pass: fullchain.pem 1openssl pkcs12 -in kafka.server.p12 -out fullchain.pem -nodes -password pass:123456 -provider legacy -provider default","summary":"摘要 本文介绍 Kafka 的 通信协议，以及如何开启外网访问。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-13T14:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/","url":"https://blog.hanqunfeng.com/2025/10/13/kafka-01-install-zookeeper/","title":"Kafka 的安装：基于 Zookeeper","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kafka.apache.org\">Kafka官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kafka-简介\">Kafka 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Apache Kafka 是一个 <code>分布式的流处理/事件流平台</code>，既可以作为<code>消息系统</code>，也可以作为持久化的 <code>日志/记录存储与流处理平台</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它的设计目标是高吞吐、低延迟、可水平扩展、容错，以及可持久化数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 Kafka 中，消息被归类为 <code>主题（Topic）</code>，每个主题可以根据配置被拆分为多个 <code>分区（Partition）</code>，每个分区内部消息是<code>严格有序</code>的，并以<code>追加</code>方式写入。消费者可以按<code>偏移量（offset）</code>读取消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 提供多个 API：Producer、Consumer、Streams（流处理）、Connect（与外部系统整合）等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 的核心架构要素与工作机制</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>组件 / 概念</th>\n<th>作用 / 描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Broker（节点 / 服务器）</td>\n<td>Kafka 集群中的服务器实例，负责接收、存储、分发消息</td>\n</tr>\n<tr>\n<td>Topic</td>\n<td>消息的“分类”逻辑单元，Producer 写入、Consumer 读取</td>\n</tr>\n<tr>\n<td>Partition</td>\n<td>一个 Topic 被划分的子单元。分区使得主题可以横向扩展，并支持并行读写</td>\n</tr>\n<tr>\n<td>Offset</td>\n<td>每条消息在某个分区中的唯一位置标识，消费者根据 offset 来决定下一条读取</td>\n</tr>\n<tr>\n<td>Replication（副本）</td>\n<td>为了容错性，每个分区可以有多个副本（副本分布在不同 Broker 上）</td>\n</tr>\n<tr>\n<td>Leader / Follower</td>\n<td>在副本中，一个副本为 Leader，接受读写请求；其他为 Follower，从 Leader 同步数据</td>\n</tr>\n<tr>\n<td>Consumer Group</td>\n<td>一组消费者共同消费一个 Topic。每个分区在同一个消费者组中通常只被一个消费者 “拥有”</td>\n</tr>\n<tr>\n<td>ZooKeeper / KRaft</td>\n<td>用于元数据管理、集群协调（在较老版本中是 ZooKeeper；新版本推向 KRaft）</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Xe43JY.png\" alt=\"\" width=\"900\" height=\"600\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>消息写入流程（简化）：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Producer 将消息发送给某个 Topic 的 Leader 分区节点</li>\n<li class=\"lvl-4\">Leader 接收到消息后，将其追加写入本地日志，并返回确认（ACK）</li>\n<li class=\"lvl-4\">Follower 副本从 Leader 拉取数据进行同步</li>\n<li class=\"lvl-4\">消费者根据自己的 offset 从对应 Partition 中读取消息</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>消费控制与容错：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">消费者维护自己的 offset（可以自动提交，也可手动控制），这样即使消费者重启，也可以从上次停止的位置继续。</li>\n<li class=\"lvl-4\">如果某个 Broker 宕机，副本可以切换（Leader 选举），保证服务继续。</li>\n<li class=\"lvl-4\">分区与副本机制使得 Kafka 能够扩展容量 &amp; 提高可靠性。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 的典型使用场景</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景类别</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>实时数据管道 / 数据集成</strong></td>\n<td>用于将各种数据源（如日志、数据库变更、传感器、用户事件等）实时采集、传输、分发到下游系统（如 OLAP、搜索引擎、监控平台等），构建高效的数据通道。</td>\n</tr>\n<tr>\n<td><strong>事件驱动 / 事件溯源</strong></td>\n<td>记录系统内部或跨系统的事件（状态变化），实现事件驱动架构（EDA）或事件溯源（Event Sourcing），可用于审计、回放、状态重建等。</td>\n</tr>\n<tr>\n<td><strong>日志聚合 / 分析</strong></td>\n<td>将分布式系统中的应用日志、监控指标、操作日志等统一收集到 Kafka 中，集中存储与分析，常与 ELK、ClickHouse 等结合。</td>\n</tr>\n<tr>\n<td><strong>流处理</strong></td>\n<td>与 Kafka Streams、Apache Flink、Spark Streaming 等流处理框架配合，对流经 Kafka 的数据进行实时计算、聚合、过滤、窗口统计等操作。</td>\n</tr>\n<tr>\n<td><strong>系统解耦 / 异步通信</strong></td>\n<td>作为系统间的消息中间件，实现发布-订阅模式，减少系统间耦合，支持异步通信、流量削峰、缓冲等，提升系统稳定性与扩展性。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Kafka-安装\">Kafka 安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里先介绍基于 Zookeeper 的安装方式，下文会介绍基于 KRaft 的安装方式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Kafka 3.9.1 的安装与运行需要 JDK 8+，所有我们需要提前安装 JDK 8+。可以选择OpenJDK，<a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">清华大学镜像站</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># root 用户</span></span><br><span class=\"line\"><span class=\"comment\"># 创建安装目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"comment\"># 下载JDK</span></span><br><span class=\"line\">wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class=\"line\">tar -zxvf OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s jdk8u462-b08 jdk8</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export JAVA_HOME=/usr/local/jdk/jdk8&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 注意这里是 单引号，双引号会解析变量，导致配置失败</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export PATH=$JAVA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 检查JDK安装</span></span><br><span class=\"line\">java -version</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>安装过程参考官网文档<a href=\"https://kafka.apache.org/39/documentation.html#quickstart\">Kafka Quick Start</a>。</p>\n</li>\n</ul>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>部署kafka都会使用集群模式，单机模式只作为学习试用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>下载Kafka，<a href=\"https://kafka.apache.org/downloads\">下载页面</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># root 用户</span></span><br><span class=\"line\"><span class=\"comment\"># 创建安装目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> /usr/local/kafka</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/kafka</span><br><span class=\"line\"><span class=\"comment\"># 下载Kafka</span></span><br><span class=\"line\">wget https://dlcdn.apache.org/kafka/3.9.1/kafka_2.13-3.9.1.tgz</span><br><span class=\"line\">tar -zxvf kafka_2.13-3.9.1.tgz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s kafka_2.13-3.9.1 kafka3</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export KAFKA_HOME=/usr/local/kafka/kafka3&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export PATH=$KAFKA_HOME/bin:$PATH&#x27;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看Kafka版本</span></span><br><span class=\"line\">kafka-topics.sh --version</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 Zookeeper，kafka内置了zookeeper，所以不需要单独安装。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 前台运行</span></span><br><span class=\"line\">zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties</span><br><span class=\"line\"><span class=\"comment\"># 后台运行</span></span><br><span class=\"line\"><span class=\"built_in\">nohup</span> zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties &gt; zookeeper.log 2&gt;&amp;1 &amp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 关闭zookeeper，kill进程，过滤 java &amp; QuorumPeerMain</span></span><br><span class=\"line\">zookeeper-server-stop.sh</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -daemon 后台运行</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检查kafka是否启动成功</span></span><br><span class=\"line\">jps -l | grep kafka</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止 kafka，kill进程，过滤 java &amp; &#x27;kafka\\.Kafka&#x27;</span></span><br><span class=\"line\">kafka-server-stop.sh</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">注意：默认情况下 启动 kafka 需要的内存大小为 1G，这一点可以在 <a href=\"http://kafka-server-start.sh\">kafka-server-start.sh</a> 脚本中查看到</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"string\">&quot;x<span class=\"variable\">$KAFKA_HEAP_OPTS</span>&quot;</span> = <span class=\"string\">&quot;x&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">export</span> KAFKA_HEAP_OPTS=<span class=\"string\">&quot;-Xmx1G -Xms1G&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">所以如果内存不够，可以设置环境变量后再启动kafka</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> KAFKA_HEAP_OPTS=<span class=\"string\">&quot;-Xmx512M -Xms512M&quot;</span></span><br><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n</div>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --create --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动消费者</span></span><br><span class=\"line\">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span> --from-beginning</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动生产者</span></span><br><span class=\"line\">kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <span class=\"built_in\">test</span></span><br><span class=\"line\">&gt; hello world <span class=\"comment\"># 输入内容，消费者会收到</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装\">集群安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群安装需要准备多个节点，这里我准备三个节点，分别如下：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.7</span><br><span class=\"line\">10.250.0.174</span><br><span class=\"line\">10.250.0.108</span><br></pre></td></tr></table></figure>\n<h4 id=\"搭建-Zookeeper-集群\">搭建 Zookeeper 集群</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>关于如何搭建 Zookeeper 集群，可以参考我之前的文章 <a href=\"/2025/09/15/zookeeper-study/\" title=\"Zookeeper 的安装及使用\">Zookeeper 的安装及使用</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>如果图省事也可以直接使用 Kafka 自带的 zookeeper，编辑其配置文件 <code>config/zookeeper.properties</code>如下，注意要在 <code>dataDir</code> 目录下创建<code>myid</code>文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataDir=/usr/local/kafka/dataDir/zookeeper</span><br><span class=\"line\"><span class=\"comment\"># the port at which the clients will connect</span></span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\"><span class=\"comment\"># disable the per-ip limit on the number of connections since this is a non-production config</span></span><br><span class=\"line\">maxClientCnxns=0</span><br><span class=\"line\"><span class=\"comment\"># Disable the adminserver by default to avoid port conflicts.</span></span><br><span class=\"line\"><span class=\"comment\"># Set the port to something non-conflicting if choosing to enable this</span></span><br><span class=\"line\">admin.enableServer=<span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># admin.serverPort=8080</span></span><br><span class=\"line\"></span><br><span class=\"line\">initLimit=10</span><br><span class=\"line\">syncLimit=5</span><br><span class=\"line\"></span><br><span class=\"line\">server.1=10.250.0.7:2888:3888</span><br><span class=\"line\">server.2=10.250.0.174:2888:3888</span><br><span class=\"line\">server.3=10.250.0.108:2888:3888</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置-Kafka-集群\">配置 Kafka 集群</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改主机的主机名</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl hostname worker1</span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname worker2</span></span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname worker3</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>为了后续方便维护，将ip地址映射到 hosts 文件中</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.7 worker1</span><br><span class=\"line\">10.250.0.174 worker2</span><br><span class=\"line\">10.250.0.108 worker3</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编辑 <code>config/server.properties</code> 文件，需要修改如下配置项</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#broker 的全局唯⼀编号，不能重复，只能是数字。</span></span><br><span class=\"line\">broker.id=1 <span class=\"comment\"># 这里分别设置为1、2、3</span></span><br><span class=\"line\"><span class=\"comment\">#服务监听地址</span></span><br><span class=\"line\">listeners=PLAINTEXT://worker1:9092</span><br><span class=\"line\"><span class=\"comment\">#数据⽂件地址。同样默认是给的/tmp⽬录。</span></span><br><span class=\"line\">log.dirs=/usr/local/kafka/dataDir/kafka-logs</span><br><span class=\"line\"><span class=\"comment\">#默认的每个Topic的分区数，创建Topic时，如果未指定分区数，则默认为1个分区。</span></span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"><span class=\"comment\"># 每个⽇志⽂件删除之前保存的时间，默认是168小时，即7天。</span></span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"><span class=\"comment\">#zookeeper的服务地址，如果是自建的 Zookeeper 集群，则这里需要填写集群的连接地址</span></span><br><span class=\"line\">zookeeper.connect=worker1:2181,worker2:2181,worker3:2181</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别在三个节点上启动 Kafka</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建 topic</span></span><br><span class=\"line\">kafka-topics.sh --bootstrap-server worker1:9092 --create --replication-factor 3 --partitions 3 --topic disTopic</span><br><span class=\"line\"><span class=\"comment\">## 参数说明</span></span><br><span class=\"line\"><span class=\"comment\"># --replication-factor 3 表示创建的副本数</span></span><br><span class=\"line\"><span class=\"comment\"># --partitions 3 表示创建的分区数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 topic 详情</span></span><br><span class=\"line\">kafka-topics.sh --bootstrap-server worker1:9092 --describe --topic disTopic</span><br><span class=\"line\">Topic: disTopic\tTopicId: VUK7Mc9oQdS1mjGG7OhQzQ\tPartitionCount: 3\tReplicationFactor: Configs:</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 0\tLeader: 2\tReplicas: 2,3,1\tIsr: 2,3,1\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 1\tLeader: 3\tReplicas: 3,1,2\tIsr: 3,1,2\tElr: N/A\tLastKnownElr: N/A</span><br><span class=\"line\">\tTopic: disTopic\tPartition: 2\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: N/A\tLastKnownElr: N/A</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。 Kafka 简介 Apache Kafka 是一个 分布式的流处理/事件流平台，既可以作为消息系统，也可以作为持久化的 日志/记录存储与流处理平台。 它的设计目标是高吞吐、低延迟、可水平扩展、容错，以及可持久化数据。 在 Kafka 中，消息被归类为 主题（Topic），每个主题可以根据配置被拆分为多个 分区（Partition），每个分区内部消息是严格有序的，并以追加方式写入。消费者可以按偏移量（offset）读取消息。 Kafka 提供多个 API：Producer、Consumer、Streams（流处理）、Connect（与外部系统整合）等。 Kafka 的核心架构要素与工作机制 组件 / 概念 作用 / 描述 Broker（节点 / 服务器） Kafka 集群中的服务器实例，负责接收、存储、分发消息 Topic 消息的“分类”逻辑单元，Producer 写入、Consumer 读取 Partition 一个 Topic 被划分的子单元。分区使得主题可以横向扩展，并支持并行读写 Offset 每条消息在某个分区中的唯一位置标识，消费者根据 offset 来决定下一条读取 Replication（副本） 为了容错性，每个分区可以有多个副本（副本分布在不同 Broker 上） Leader / Follower 在副本中，一个副本为 Leader，接受读写请求；其他为 Follower，从 Leader 同步数据 Consumer Group 一组消费者共同消费一个 Topic。每个分区在同一个消费者组中通常只被一个消费者 “拥有” ZooKeeper / KRaft 用于元数据管理、集群协调（在较老版本中是 ZooKeeper；新版本推向 KRaft） 消息写入流程（简化）： Producer 将消息发送给某个 Topic 的 Leader 分区节点 Leader 接收到消息后，将其追加写入本地日志，并返回确认（ACK） Follower 副本从 Leader 拉取数据进行同步 消费者根据自己的 offset 从对应 Partition 中读取消息 消费控制与容错： 消费者维护自己的 offset（可以自动提交，也可手动控制），这样即使消费者重启，也可以从上次停止的位置继续。 如果某个 Broker 宕机，副本可以切换（Leader 选举），保证服务继续。 分区与副本机制使得 Kafka 能够扩展容量 &amp; 提高可靠性。 Kafka 的典型使用场景 场景类别 说明 实时数据管道 / 数据集成 用于将各种数据源（如日志、数据库变更、传感器、用户事件等）实时采集、传输、分发到下游系统（如 OLAP、搜索引擎、监控平台等），构建高效的数据通道。 事件驱动 / 事件溯源 记录系统内部或跨系统的事件（状态变化），实现事件驱动架构（EDA）或事件溯源（Event Sourcing），可用于审计、回放、状态重建等。 日志聚合 / 分析 将分布式系统中的应用日志、监控指标、操作日志等统一收集到 Kafka 中，集中存储与分析，常与 ELK、ClickHouse 等结合。 流处理 与 Kafka Streams、Apache Flink、Spark Streaming 等流处理框架配合，对流经 Kafka 的数据进行实时计算、聚合、过滤、窗口统计等操作。 系统解耦 / 异步通信 作为系统间的消息中间件，实现发布-订阅模式，减少系统间耦合，支持异步通信、流量削峰、缓冲等，提升系统稳定性与扩展性。 Kafka 安装 这里先介绍基于 Zookeeper 的安装方式，下文会介绍基于 KRaft 的安装方式。 Kafka 3.9.1 的安装与运行需要 JDK 8+，所有我们需要提前安装 JDK 8+。可以选择OpenJDK，清华大学镜像站 123456789101112131415# root 用户# 创建安装目录mkdir /usr/local/jdkcd /usr/local/jdk# 下载JDKwget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gztar -zxvf OpenJDK8U-jdk_x64_linux_hotspot_8u462b08.tar.gzln -s jdk8u462-b08 jdk8# 配置环境变量echo &#x27;export JAVA_HOME=/usr/local/jdk/jdk8&#x27; &gt;&gt; /etc/profile# 注意这里是 单引号，双引号会解析变量，导致配置失败echo &#x27;export PATH=$JAVA_HOME/bin:$PATH&#x27; &gt;&gt; /etc/profilesource /etc/profile# 检查JDK安装java -version 安装过程参考官网文档Kafka Quick Start。 单机安装 部署kafka都会使用集群模式，单机模式只作为学习试用。 下载Kafka，下载页面 1234567891011121314# root 用户# 创建安装目录mkdir /usr/local/kafkacd /usr/local/kafka# 下载Kafkawget https://dlcdn.apache.org/kafka/3.9.1/kafka_2.13-3.9.1.tgztar -zxvf kafka_2.13-3.9.1.tgzln -s kafka_2.13-3.9.1 kafka3# 配置环境变量echo &#x27;export KAFKA_HOME=/usr/local/kafka/kafka3&#x27; &gt;&gt; /etc/profileecho &#x27;export PATH=$KAFKA_HOME/bin:$PATH&#x27; &gt;&gt; /etc/profilesource /etc/profile# 查看Kafka版本kafka-topics.sh --version 启动 Zookeeper，kafka内置了zookeeper，所以不需要单独安装。 1234567# 前台运行zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties# 后台运行nohup zookeeper-server-start.sh /usr/local/kafka/kafka3/config/zookeeper.properties &gt; zookeeper.log 2&gt;&amp;1 &amp;# 关闭zookeeper，kill进程，过滤 java &amp; QuorumPeerMainzookeeper-server-stop.sh 启动 kafka 12345678# -daemon 后台运行kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties# 检查kafka是否启动成功jps -l | grep kafka# 停止 kafka，kill进程，过滤 java &amp; &#x27;kafka\\.Kafka&#x27;kafka-server-stop.sh 小贴士 注意：默认情况下 启动 kafka 需要的内存大小为 1G，这一点可以在 kafka-server-start.sh 脚本中查看到 123if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;fi 所以如果内存不够，可以设置环境变量后再启动kafka 12export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Xms512M&quot;kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 测试 123456789# 创建 topickafka-topics.sh --create --bootstrap-server localhost:9092 --topic test# 启动消费者kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning# 启动生产者kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test&gt; hello world # 输入内容，消费者会收到 集群安装 集群安装需要准备多个节点，这里我准备三个节点，分别如下： 12310.250.0.710.250.0.17410.250.0.108 搭建 Zookeeper 集群 关于如何搭建 Zookeeper 集群，可以参考我之前的文章 Zookeeper 的安装及使用 如果图省事也可以直接使用 Kafka 自带的 zookeeper，编辑其配置文件 config/zookeeper.properties如下，注意要在 dataDir 目录下创建myid文件 12345678910111213141516dataDir=/usr/local/kafka/dataDir/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0# Disable the adminserver by default to avoid port conflicts.# Set the port to something non-conflicting if choosing to enable thisadmin.enableServer=false# admin.serverPort=8080initLimit=10syncLimit=5server.1=10.250.0.7:2888:3888server.2=10.250.0.174:2888:3888server.3=10.250.0.108:2888:3888 配置 Kafka 集群 修改主机的主机名 123hostnamectl hostname worker1# hostnamectl hostname worker2# hostnamectl hostname worker3 为了后续方便维护，将ip地址映射到 hosts 文件中 12310.250.0.7 worker110.250.0.174 worker210.250.0.108 worker3 编辑 config/server.properties 文件，需要修改如下配置项 123456789101112#broker 的全局唯⼀编号，不能重复，只能是数字。broker.id=1 # 这里分别设置为1、2、3#服务监听地址listeners=PLAINTEXT://worker1:9092#数据⽂件地址。同样默认是给的/tmp⽬录。log.dirs=/usr/local/kafka/dataDir/kafka-logs#默认的每个Topic的分区数，创建Topic时，如果未指定分区数，则默认为1个分区。num.partitions=1# 每个⽇志⽂件删除之前保存的时间，默认是168小时，即7天。log.retention.hours=168#zookeeper的服务地址，如果是自建的 Zookeeper 集群，则这里需要填写集群的连接地址zookeeper.connect=worker1:2181,worker2:2181,worker3:2181 分别在三个节点上启动 Kafka 1kafka-server-start.sh -daemon /usr/local/kafka/kafka3/config/server.properties 测试 123456789101112# 创建 topickafka-topics.sh --bootstrap-server worker1:9092 --create --replication-factor 3 --partitions 3 --topic disTopic## 参数说明# --replication-factor 3 表示创建的副本数# --partitions 3 表示创建的分区数# 查看 topic 详情kafka-topics.sh --bootstrap-server worker1:9092 --describe --topic disTopicTopic: disTopic TopicId: VUK7Mc9oQdS1mjGG7OhQzQ PartitionCount: 3 ReplicationFactor: Configs: Topic: disTopic Partition: 0 Leader: 2 Replicas: 2,3,1 Isr: 2,3,1 Elr: N/A LastKnownElr: N/A Topic: disTopic Partition: 1 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2 Elr: N/A LastKnownElr: N/A Topic: disTopic Partition: 2 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3 Elr: N/A LastKnownElr: N/A","summary":"摘要 本文介绍 CentOS9 中 Kafka 的安装与使用，基于 Zookeeper。 Kafka官网 本文使用的 Kafka 版本为 3.9.1。Kafka 团队宣布 3.9 会是 最后一个还带有被弃用的 ZooKeeper 模式 的主要版本。以后版本（如 4.0）将完全弃用 ZooKeeper。","date_published":"2025-10-13T13:30:05.000Z","tags":["技术","kafka","分布式","kafka"]},{"id":"https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/","url":"https://blog.hanqunfeng.com/2025/09/25/rabbitmq-cluster/","title":"RabbitMQ 之 Cluster","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RabbitMQ-Cluster-集群-简介\">RabbitMQ Cluster(集群) 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/clustering\">Cluster（集群）</a> 是多个节点组成的集合，用于实现高可用和负载均衡。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 集群是一个或多个（三个、五个、七个或更多）节点的逻辑分组， 每个节点共享 用户、虚拟主机、队列、流、交换、绑定、运行时参数和其他分布式状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，Cluster（集群）的节点分为两种：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">磁盘节点(disk)：会把集群的所有元数据信息（比如交换机、绑定、队列、虚拟主机等信息）持久化到磁盘中。Master 节点必须是磁盘节点。</li>\n<li class=\"lvl-4\">内存节点(ram)：只会将这些信息保存到内存中，如果该节点宕机或重启，内存节点的数据会全部丢失，而磁盘节点的数据不会丢失。Slave 节点可以是内存节点。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 开始， 集群不再区分 <code>普通集群模式（Classic Cluster）</code> 与 <code>镜像集群模式（Mirrored Queue Cluster）</code> ，集群创建好后，会根据队列的<code>初始复制因子参数</code>决定为该队列创建多少个副本，比如 <code>Quroum Queue</code> 的参数是 <code>x-quorum-initial-group-size</code>，默认为3。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 开始，<code>Quroum Queue</code> 和 <code>Stream Queue</code> 默认开启节点间<code>消息复制</code>，但是 <code>Classic Queue</code> 队列不支持节点间的<code>消息复制</code>;</p>\n</li>\n</ul>\n<div class=\"tips\">\n<p><em><strong>RabbitMQ 4.0以前的 集群分为两种模式</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">\n<ol>\n<li class=\"lvl-5\">普通集群模式（Classic Cluster）</li>\n</ol>\n<ul class=\"lvl-3\">\n<li class=\"lvl-4\">在 普通集群模式下，RabbitMQ 节点通过 Erlang 分布式系统实现互联，集群内的各个节点共享 消息队列、交换机、绑定等元素。</li>\n<li class=\"lvl-4\">普通集群的特点：\n<ul class=\"lvl-5\">\n<li class=\"lvl-6\">共享队列：队列数据仅存储在单一节点上，只有该节点可以处理队列中的消息。</li>\n<li class=\"lvl-6\">不自动复制数据：在普通集群中，消息并不会自动复制到其他节点。如果某个节点挂掉，队列上的消息就会丢失，无法恢复。</li>\n<li class=\"lvl-6\">负载均衡：交换机（Exchange）会把消息发送到不同的队列，但队列数据仍然只在一个节点上。因此，普通集群适合不要求极高可用性的场景。</li>\n<li class=\"lvl-6\">不具备高可用性：由于数据不会在集群的其他节点中复制，普通集群在某个节点宕机时，可能会导致消息丢失和系统不可用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<ol start=\"2\">\n<li class=\"lvl-5\">镜像集群模式（Mirrored Queue Cluster）</li>\n</ol>\n<ul class=\"lvl-3\">\n<li class=\"lvl-4\">镜像集群模式 是为了 高可用性 设计的，在该模式下，队列的数据会在集群中的多个节点上进行 复制（镜像），从而保证即使某个节点出现故障，数据也不会丢失。</li>\n<li class=\"lvl-4\">镜像集群的特点：\n<ul class=\"lvl-5\">\n<li class=\"lvl-6\">队列镜像：在镜像集群模式中，队列数据会在集群中的多个节点上复制。每个队列都有一个主节点和多个镜像节点。</li>\n<li class=\"lvl-6\">高可用性：消息会被复制到集群的其他节点上，从而保证如果一个节点宕机，数据不会丢失，系统能迅速恢复。</li>\n<li class=\"lvl-6\">节点故障恢复：当一个节点挂掉时，其他节点会继续处理该队列的消息，保证业务的高可用性。</li>\n<li class=\"lvl-6\">网络负担较重：由于需要在多个节点之间进行数据同步和复制，所以镜像队列模式会增加集群的网络负担和磁盘 I/O。</li>\n<li class=\"lvl-6\">性能影响：镜像队列模式会稍微影响性能，因为每次消息处理后，都需要将数据同步到其他镜像节点，增加了延迟。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</div>\n<h2 id=\"集群搭建\">集群搭建</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>准备三台服务器，分别安装 RabbitMQ ，安装方法参看 <a href=\"/2025/09/18/rabbitmq-install-01/\" title=\"RabbitMQ 的安装及使用\">RabbitMQ 的安装及使用</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>开放端口</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>端口范围</strong></th>\n<th><strong>用途</strong></th>\n<th><strong>备注</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>4369</strong></td>\n<td>epmd（Erlang Port Mapper Daemon）</td>\n<td>RabbitMQ 节点和 CLI 工具使用的帮助程序发现守护进程。</td>\n</tr>\n<tr>\n<td><strong>6000-6500</strong></td>\n<td>RabbitMQ Stream 复制使用</td>\n<td>用于 RabbitMQ Stream 的数据复制。</td>\n</tr>\n<tr>\n<td><strong>25672</strong></td>\n<td>Erlang 分发服务器端口</td>\n<td>用于节点间和 CLI 工具通信，默认情况下仅限于单个端口（AMQP端口 + 20000）。</td>\n</tr>\n<tr>\n<td><strong>35672-35682</strong></td>\n<td>Erlang 分发客户端端口</td>\n<td>用于 CLI 工具与节点通信，计算为服务器分发端口 + 10000 到 服务器分发端口 + 10010。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别修改三台服务器的 <code>hostname</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl hostname rabbitmq01</span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname rabbitmq02</span></span><br><span class=\"line\"><span class=\"comment\"># hostnamectl hostname rabbitmq03</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别修改三台服务器的 <code>/etc/hosts</code> 文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.56  rabbitmq01</span><br><span class=\"line\">10.250.0.232 rabbitmq02</span><br><span class=\"line\">10.250.0.97  rabbitmq03</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>同步集群节点中的cookie</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">默认会在 <code>/var/lib/rabbitmq/</code>目录下生成一个<code>.erlang.cookie</code>，里面有一个字符串。</li>\n<li class=\"lvl-4\">我们使用 <code>rabbitmq01</code> 节点作为集群的主节点，其他节点作为集群的成员节点，我们要做的就是保证集群中三个节点的这个<code>cookie字符串一致</code>。</li>\n<li class=\"lvl-4\">将 <code>rabbitmq01</code> 的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中的<code>cookie字符串</code>复制到其他节点的 <code>/var/lib/rabbitmq/.erlang.cookie</code> 文件中。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>分别启动三台服务器的 RabbitMQ 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start rabbitmq-server</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别登录 <code>rabbitmq02</code> 和 <code>rabbitmq03</code> 节点，执行如下命令，将节点加入集群</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停掉rabbitmq应用</span></span><br><span class=\"line\">rabbitmqctl stop_app</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重置rabbitmq、交换机、队列</span></span><br><span class=\"line\">rabbitmqctl reset</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加入集群，注意此时 rabbitmq01 是主节点，必须处于运行状态，</span></span><br><span class=\"line\"><span class=\"comment\"># --ram 表示以 ram 内存节点 加入集群。如果不带参数默认为 disk 磁盘节点</span></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ的集群节点分为 disk 和 ram，disk节点会将元数据保存到硬盘当中，而ram节点只是在内存中保存元数据。</span></span><br><span class=\"line\">rabbitmqctl join_cluster rabbit@rabbitmq01 --ram</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 启动rabbitmq应用</span></span><br><span class=\"line\">rabbitmqctl start_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录 任意 节点，执行如下命令，查看集群状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl cluster_status</span><br><span class=\"line\"><span class=\"comment\">## 输出类似</span></span><br><span class=\"line\">Cluster status of node rabbit@rabbitmq01 ...</span><br><span class=\"line\">Basics</span><br><span class=\"line\"></span><br><span class=\"line\">Cluster name: rabbit@rabbitmq01</span><br><span class=\"line\">Total CPU cores available cluster-wide: 6</span><br><span class=\"line\"></span><br><span class=\"line\">Cluster Tags</span><br><span class=\"line\"></span><br><span class=\"line\">(none)</span><br><span class=\"line\"></span><br><span class=\"line\">Disk Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq01</span><br><span class=\"line\"></span><br><span class=\"line\">RAM Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq02</span><br><span class=\"line\">rabbit@rabbitmq03</span><br><span class=\"line\"></span><br><span class=\"line\">Running Nodes</span><br><span class=\"line\"></span><br><span class=\"line\">rabbit@rabbitmq01</span><br><span class=\"line\">rabbit@rabbitmq02</span><br><span class=\"line\">rabbit@rabbitmq03</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>PS: 由于ram节点减少了很多与硬盘的交互，所以，ram节点的元数据使用性能会比较高。但是，同时，这也意味着元数据的安全性是不如disk节点的。在我们这个集群中， rabbitmq02 和 rabbitmq03 都以 ram节点 的身份加入到 rabbitmq01 集群里，因此，是存在单点故障的。如果 rabbitmq01 节点服务崩溃，那么元数据就有可能丢失。在企业进行部署时，性能与安全性需要自己进行平衡。</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录任意节点的管理页面，查看集群状态<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/R195gJ.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>此时我们在任意节点中创建虚拟主机、队列、交换机和绑定关系 等元数据，都会自动同步到其他节点中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>我们也可以在 管理控制台 中查看队列时看到，此时多个一列，<code>Node</code>列，显示该队列在哪些节点中存在。只有 <code>Quorum 队列</code> 和 <code>Stream 队列</code> 才会显示多个节点，因为 <code>Classic 队列</code> 不支持多节点复制。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/GjHcLN.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>查看某个具体的 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，可以看到更详细的说明<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/XtIkpp.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>此时新建队列，会要求我们指定主节点(Leader)，即负责存储消息的的节点，而 <code>Quorum 队列</code> 或 <code>Stream 队列</code>，会自动将消息复制到其它节点(Members)。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Leader: 队列的主节点，负责存储消息。</li>\n<li class=\"lvl-4\">Members: 队列的成员节点，负责存储消息的副本。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"演示队列复制\">演示队列复制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>默认情况下，<code>Quorum 队列</code> 和 <code>Stream 队列</code> 的 复制数 都为 3，这里为了演示，我在增加一个节点 <code>rabbitmq04</code>，请自行按上面的方法添加。</p>\n</li>\n</ul>\n<h3 id=\"Quorum-队列\">Quorum 队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在页面上创建一个 <code>Quorum 队列</code>，与单节点上创建队列的区别就是需要我们选择主节点。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/JYfKgg.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 客户端 创建队列时，默认情况下，连接哪个节点，哪个节点就是Leader，但也可以通过参数<code>x-queue-leader-locator</code>指定主节点的选择策略。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqadmin queues <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;/vtest&quot;</span> --name <span class=\"string\">&quot;target.quorum.queue.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;quorum&quot;</span> --durable <span class=\"literal\">true</span> --arguments <span class=\"string\">&#x27;&#123;&quot;x-queue-leader-locator&quot;:&quot;balanced&quot;&#125;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># x-queue-leader-locator 有两种选择策略</span></span><br><span class=\"line\"><span class=\"comment\">## client-local：选择声明队列的客户端所连接的节点。这是默认值。</span></span><br><span class=\"line\"><span class=\"comment\">## balanced：如果队列总数少于 1000 个（经典队列、仲裁队列和流）， 选择托管最小数量的仲裁队列领导者的节点。 如果队列总体超过 1000 个，则随机选择一个节点。</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建成功后，可以看到 <code>Quorum 队列</code> 的主节点和成员节点，可以看到这里成员节点有三个，除了主节点外，其余节点由集群自动选择。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qBfNNh.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>也就是说，默认情况下，<code>Quorum 队列</code> 的复制数是 <code>3</code>，如果我们希望改变复制数，可以在创建队列时指定参数 <code>x-quorum-initial-group-size</code>，其值为 <code>大于 0 的整数</code>，若设置值大于实际成员节点数，则以实际成员节点数为准。<code>x-quorum-initial-group-size</code> 设置为 <code>1</code> 时便不进行复制了。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果集群中增加了新的节点，希望队列也被复制到新的节点中，可以通过如下命令，将新的节点加入成员节点中:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues add_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-queues add_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>如果希望将节点从成员节点中移除，可以通过如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues delete_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-queues delete_member -p /vtest q_4 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>另外，当通过 <code>forget_cluster_node</code> 命令从集群中永久删除节点时，会自动将队列关联的节点从成员节点中移除。</p>\n</li>\n<li class=\"lvl-2\">\n<p>删除节点时，请使用如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 因为要删除 rabbitmq04 节点，所以以下命令不能在 rabbitmq04 节点执行</span></span><br><span class=\"line\"><span class=\"comment\"># 删除前需要先关闭应用</span></span><br><span class=\"line\">rabbitmqctl -n rabbit@rabbitmq04 stop_app</span><br><span class=\"line\"><span class=\"comment\"># 删除节点</span></span><br><span class=\"line\"><span class=\"comment\"># rabbitmqctl forget_cluster_node &lt;node&gt;</span></span><br><span class=\"line\">rabbitmqctl forget_cluster_node rabbit@rabbitmq04</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>新增节点后，一个个的对原有的队列进行复制扩展非常麻烦，可以通过如下命令快速对符合条件的队列进行复制扩展:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-queues grow &lt;node&gt; &lt;all | even&gt; [--vhost-pattern &lt;pattern&gt;] [--queue-pattern &lt;pattern&gt;]</span></span><br><span class=\"line\"><span class=\"comment\">## 参数说明：</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;node&gt;: 这个参数指定了 RabbitMQ 节点的名称，通常是 rabbit@&lt;hostname&gt;。它表示在哪个节点上执行增长操作。</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;all | even&gt;: 这个参数指定了要扩展的队列类型。all 表示扩展所有队列，even 表示扩展偶数编号的队列。</span></span><br><span class=\"line\"><span class=\"comment\"># --vhost-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的虚拟主机名称。</span></span><br><span class=\"line\"><span class=\"comment\"># --queue-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的队列名称。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 示例</span></span><br><span class=\"line\"><span class=\"comment\"># 扩展所有虚拟主机下的所有队列的副本：</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 all</span><br><span class=\"line\"><span class=\"comment\"># 扩展所有虚拟主机下的偶数编号的队列的副本：</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 even</span><br><span class=\"line\"><span class=\"comment\"># 扩展特定虚拟主机和队列名称的队列</span></span><br><span class=\"line\">rabbitmq-queues grow rabbit@rabbitmq04 all --vhost-pattern /vtest --queue-pattern <span class=\"string\">&quot;^q_&quot;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Stream-队列\">Stream 队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Stream 队列 与 Quorum 队列 类似，通过哪个节点创建队列，哪个节点就是 Leader，但也是可以通过参数 <code>x-queue-leader-locator</code> 指定主节点的选择策略。</p>\n</li>\n<li class=\"lvl-2\">\n<p>创建 Stream 队列时，默认复制数就是当前集群的节点数（Quorum 队列 默认是 3），可以通过指定参数 <code>x-initial-cluster-size</code> 进行初始设置。</p>\n</li>\n<li class=\"lvl-2\">\n<p>添加新的节点时，与 Quorum 队列 类似，Stream 队列 也不会自动进行复制，可以通过如下命令手动复制</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-streams add_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除成员节点时，请使用如下命令:</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;</span></span><br><span class=\"line\">rabbitmq-streams delete_replica -p /vtest sq_2 rabbit@rabbitmq02</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看节点复制状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class=\"line\">rabbitmq-streams stream_status -p /vtest sq_2</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当流出现异常状态（如副本分布异常、领导节点挂掉）时，为了恢复可用性，可以重启流</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams restart_stream [-p &lt;vhost&gt;] &lt;stream-name&gt;</span></span><br><span class=\"line\">rabbitmq-streams restart_stream -p /vtest sq_2</span><br><span class=\"line\"><span class=\"comment\">## 重启操作</span></span><br><span class=\"line\"><span class=\"comment\"># 1.停止流的当前副本/分区。</span></span><br><span class=\"line\"><span class=\"comment\"># 2.重新初始化流的存储和元数据。</span></span><br><span class=\"line\"><span class=\"comment\"># 3.让流在集群中恢复为可用状态。</span></span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 RabbitMQ Cluster(集群) 简介 在 RabbitMQ 中，Cluster（集群） 是多个节点组成的集合，用于实现高可用和负载均衡。 RabbitMQ 集群是一个或多个（三个、五个、七个或更多）节点的逻辑分组， 每个节点共享 用户、虚拟主机、队列、流、交换、绑定、运行时参数和其他分布式状态。 在 RabbitMQ 中，Cluster（集群）的节点分为两种： 磁盘节点(disk)：会把集群的所有元数据信息（比如交换机、绑定、队列、虚拟主机等信息）持久化到磁盘中。Master 节点必须是磁盘节点。 内存节点(ram)：只会将这些信息保存到内存中，如果该节点宕机或重启，内存节点的数据会全部丢失，而磁盘节点的数据不会丢失。Slave 节点可以是内存节点。 RabbitMQ 4.0 开始， 集群不再区分 普通集群模式（Classic Cluster） 与 镜像集群模式（Mirrored Queue Cluster） ，集群创建好后，会根据队列的初始复制因子参数决定为该队列创建多少个副本，比如 Quroum Queue 的参数是 x-quorum-initial-group-size，默认为3。 RabbitMQ 4.0 开始，Quroum Queue 和 Stream Queue 默认开启节点间消息复制，但是 Classic Queue 队列不支持节点间的消息复制; RabbitMQ 4.0以前的 集群分为两种模式 普通集群模式（Classic Cluster） 在 普通集群模式下，RabbitMQ 节点通过 Erlang 分布式系统实现互联，集群内的各个节点共享 消息队列、交换机、绑定等元素。 普通集群的特点： 共享队列：队列数据仅存储在单一节点上，只有该节点可以处理队列中的消息。 不自动复制数据：在普通集群中，消息并不会自动复制到其他节点。如果某个节点挂掉，队列上的消息就会丢失，无法恢复。 负载均衡：交换机（Exchange）会把消息发送到不同的队列，但队列数据仍然只在一个节点上。因此，普通集群适合不要求极高可用性的场景。 不具备高可用性：由于数据不会在集群的其他节点中复制，普通集群在某个节点宕机时，可能会导致消息丢失和系统不可用。 镜像集群模式（Mirrored Queue Cluster） 镜像集群模式 是为了 高可用性 设计的，在该模式下，队列的数据会在集群中的多个节点上进行 复制（镜像），从而保证即使某个节点出现故障，数据也不会丢失。 镜像集群的特点： 队列镜像：在镜像集群模式中，队列数据会在集群中的多个节点上复制。每个队列都有一个主节点和多个镜像节点。 高可用性：消息会被复制到集群的其他节点上，从而保证如果一个节点宕机，数据不会丢失，系统能迅速恢复。 节点故障恢复：当一个节点挂掉时，其他节点会继续处理该队列的消息，保证业务的高可用性。 网络负担较重：由于需要在多个节点之间进行数据同步和复制，所以镜像队列模式会增加集群的网络负担和磁盘 I/O。 性能影响：镜像队列模式会稍微影响性能，因为每次消息处理后，都需要将数据同步到其他镜像节点，增加了延迟。 集群搭建 准备三台服务器，分别安装 RabbitMQ ，安装方法参看 RabbitMQ 的安装及使用 开放端口 端口范围 用途 备注 4369 epmd（Erlang Port Mapper Daemon） RabbitMQ 节点和 CLI 工具使用的帮助程序发现守护进程。 6000-6500 RabbitMQ Stream 复制使用 用于 RabbitMQ Stream 的数据复制。 25672 Erlang 分发服务器端口 用于节点间和 CLI 工具通信，默认情况下仅限于单个端口（AMQP端口 + 20000）。 35672-35682 Erlang 分发客户端端口 用于 CLI 工具与节点通信，计算为服务器分发端口 + 10000 到 服务器分发端口 + 10010。 分别修改三台服务器的 hostname 123hostnamectl hostname rabbitmq01# hostnamectl hostname rabbitmq02# hostnamectl hostname rabbitmq03 分别修改三台服务器的 /etc/hosts 文件 12310.250.0.56 rabbitmq0110.250.0.232 rabbitmq0210.250.0.97 rabbitmq03 同步集群节点中的cookie 默认会在 /var/lib/rabbitmq/目录下生成一个.erlang.cookie，里面有一个字符串。 我们使用 rabbitmq01 节点作为集群的主节点，其他节点作为集群的成员节点，我们要做的就是保证集群中三个节点的这个cookie字符串一致。 将 rabbitmq01 的 /var/lib/rabbitmq/.erlang.cookie 文件中的cookie字符串复制到其他节点的 /var/lib/rabbitmq/.erlang.cookie 文件中。 分别启动三台服务器的 RabbitMQ 服务 1systemctl start rabbitmq-server 分别登录 rabbitmq02 和 rabbitmq03 节点，执行如下命令，将节点加入集群 12345678910111213# 停掉rabbitmq应用rabbitmqctl stop_app# 重置rabbitmq、交换机、队列rabbitmqctl reset# 加入集群，注意此时 rabbitmq01 是主节点，必须处于运行状态，# --ram 表示以 ram 内存节点 加入集群。如果不带参数默认为 disk 磁盘节点# RabbitMQ的集群节点分为 disk 和 ram，disk节点会将元数据保存到硬盘当中，而ram节点只是在内存中保存元数据。rabbitmqctl join_cluster rabbit@rabbitmq01 --ram# 启动rabbitmq应用rabbitmqctl start_app 登录 任意 节点，执行如下命令，查看集群状态 1234567891011121314151617181920212223242526rabbitmqctl cluster_status## 输出类似Cluster status of node rabbit@rabbitmq01 ...BasicsCluster name: rabbit@rabbitmq01Total CPU cores available cluster-wide: 6Cluster Tags(none)Disk Nodesrabbit@rabbitmq01RAM Nodesrabbit@rabbitmq02rabbit@rabbitmq03Running Nodesrabbit@rabbitmq01rabbit@rabbitmq02rabbit@rabbitmq03 PS: 由于ram节点减少了很多与硬盘的交互，所以，ram节点的元数据使用性能会比较高。但是，同时，这也意味着元数据的安全性是不如disk节点的。在我们这个集群中， rabbitmq02 和 rabbitmq03 都以 ram节点 的身份加入到 rabbitmq01 集群里，因此，是存在单点故障的。如果 rabbitmq01 节点服务崩溃，那么元数据就有可能丢失。在企业进行部署时，性能与安全性需要自己进行平衡。 登录任意节点的管理页面，查看集群状态 此时我们在任意节点中创建虚拟主机、队列、交换机和绑定关系 等元数据，都会自动同步到其他节点中。 我们也可以在 管理控制台 中查看队列时看到，此时多个一列，Node列，显示该队列在哪些节点中存在。只有 Quorum 队列 和 Stream 队列 才会显示多个节点，因为 Classic 队列 不支持多节点复制。 查看某个具体的 Quorum 队列 或 Stream 队列，可以看到更详细的说明 此时新建队列，会要求我们指定主节点(Leader)，即负责存储消息的的节点，而 Quorum 队列 或 Stream 队列，会自动将消息复制到其它节点(Members)。 Leader: 队列的主节点，负责存储消息。 Members: 队列的成员节点，负责存储消息的副本。 演示队列复制 默认情况下，Quorum 队列 和 Stream 队列 的 复制数 都为 3，这里为了演示，我在增加一个节点 rabbitmq04，请自行按上面的方法添加。 Quorum 队列 在页面上创建一个 Quorum 队列，与单节点上创建队列的区别就是需要我们选择主节点。 通过 客户端 创建队列时，默认情况下，连接哪个节点，哪个节点就是Leader，但也可以通过参数x-queue-leader-locator指定主节点的选择策略。 1234rabbitmqadmin queues declare --vhost &quot;/vtest&quot; --name &quot;target.quorum.queue.name&quot; --type &quot;quorum&quot; --durable true --arguments &#x27;&#123;&quot;x-queue-leader-locator&quot;:&quot;balanced&quot;&#125;&#x27;# x-queue-leader-locator 有两种选择策略## client-local：选择声明队列的客户端所连接的节点。这是默认值。## balanced：如果队列总数少于 1000 个（经典队列、仲裁队列和流）， 选择托管最小数量的仲裁队列领导者的节点。 如果队列总体超过 1000 个，则随机选择一个节点。 创建成功后，可以看到 Quorum 队列 的主节点和成员节点，可以看到这里成员节点有三个，除了主节点外，其余节点由集群自动选择。 也就是说，默认情况下，Quorum 队列 的复制数是 3，如果我们希望改变复制数，可以在创建队列时指定参数 x-quorum-initial-group-size，其值为 大于 0 的整数，若设置值大于实际成员节点数，则以实际成员节点数为准。x-quorum-initial-group-size 设置为 1 时便不进行复制了。 如果集群中增加了新的节点，希望队列也被复制到新的节点中，可以通过如下命令，将新的节点加入成员节点中: 12# rabbitmq-queues add_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;rabbitmq-queues add_member -p /vtest q_4 rabbit@rabbitmq02 如果希望将节点从成员节点中移除，可以通过如下命令: 12# rabbitmq-queues delete_member [-p &lt;vhost&gt;] &lt;queue-name&gt; &lt;node&gt;rabbitmq-queues delete_member -p /vtest q_4 rabbit@rabbitmq02 另外，当通过 forget_cluster_node 命令从集群中永久删除节点时，会自动将队列关联的节点从成员节点中移除。 删除节点时，请使用如下命令: 123456# 因为要删除 rabbitmq04 节点，所以以下命令不能在 rabbitmq04 节点执行# 删除前需要先关闭应用rabbitmqctl -n rabbit@rabbitmq04 stop_app# 删除节点# rabbitmqctl forget_cluster_node &lt;node&gt;rabbitmqctl forget_cluster_node rabbit@rabbitmq04 新增节点后，一个个的对原有的队列进行复制扩展非常麻烦，可以通过如下命令快速对符合条件的队列进行复制扩展: 1234567891011121314# rabbitmq-queues grow &lt;node&gt; &lt;all | even&gt; [--vhost-pattern &lt;pattern&gt;] [--queue-pattern &lt;pattern&gt;]## 参数说明：# &lt;node&gt;: 这个参数指定了 RabbitMQ 节点的名称，通常是 rabbit@&lt;hostname&gt;。它表示在哪个节点上执行增长操作。# &lt;all | even&gt;: 这个参数指定了要扩展的队列类型。all 表示扩展所有队列，even 表示扩展偶数编号的队列。# --vhost-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的虚拟主机名称。# --queue-pattern &lt;pattern&gt; （可选）: 这个参数指定了要匹配的队列名称。## 示例# 扩展所有虚拟主机下的所有队列的副本：rabbitmq-queues grow rabbit@rabbitmq04 all# 扩展所有虚拟主机下的偶数编号的队列的副本：rabbitmq-queues grow rabbit@rabbitmq04 even# 扩展特定虚拟主机和队列名称的队列rabbitmq-queues grow rabbit@rabbitmq04 all --vhost-pattern /vtest --queue-pattern &quot;^q_&quot; Stream 队列 Stream 队列 与 Quorum 队列 类似，通过哪个节点创建队列，哪个节点就是 Leader，但也是可以通过参数 x-queue-leader-locator 指定主节点的选择策略。 创建 Stream 队列时，默认复制数就是当前集群的节点数（Quorum 队列 默认是 3），可以通过指定参数 x-initial-cluster-size 进行初始设置。 添加新的节点时，与 Quorum 队列 类似，Stream 队列 也不会自动进行复制，可以通过如下命令手动复制 12# rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;rabbitmq-streams add_replica -p /vtest sq_2 rabbit@rabbitmq02 删除成员节点时，请使用如下命令: 12# rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;rabbitmq-streams delete_replica -p /vtest sq_2 rabbit@rabbitmq02 查看节点复制状态 12# rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;rabbitmq-streams stream_status -p /vtest sq_2 当流出现异常状态（如副本分布异常、领导节点挂掉）时，为了恢复可用性，可以重启流 123456# rabbitmq-streams restart_stream [-p &lt;vhost&gt;] &lt;stream-name&gt;rabbitmq-streams restart_stream -p /vtest sq_2## 重启操作# 1.停止流的当前副本/分区。# 2.重新初始化流的存储和元数据。# 3.让流在集群中恢复为可用状态。","summary":"摘要 本文介绍 RabbitMQ 的 Cluster 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-25T14:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/","url":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-message/","title":"RabbitMQ 之 Message","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Message 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Message-消息-是什么？\">Message(消息) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，Message（消息）是消息队列中的数据单元。消息包含消息内容、消息属性等信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Message 组成：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">\n<ol>\n<li class=\"lvl-7\">消息内容：消息的内容，可以是任意数据。</li>\n</ol>\n</li>\n<li class=\"lvl-4\">\n<ol start=\"2\">\n<li class=\"lvl-7\">消息属性：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Web-控制台-中-Message-的使用\">Web 控制台 中 Message 的使用</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 Exchange 和 Queue 的管理界面中，都可以在其详情页面测试 Message 的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>关于如何在代码中使用 Message，我会在下一节中详细介绍。</p>\n</li>\n</ul>\n<h3 id=\"Publish-message\">Publish message</h3>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/dHsDyt.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Payload：消息的内容，可以是任意数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Payload encoding：消息内容的编码方式，<code>String</code> 或者 <code>Base64</code>，默认为 <code>String</code>。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Delivery mode：消息的持久化模式，1-Non-persistent 表示非持久化，2-Persistent 表示持久化。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Headers：消息的头信息，用于与 <code>Headers Exchange（头部交换机）</code>中的配置进行匹配。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Properties：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>属性名</th>\n<th>中文含义</th>\n<th>数据类型</th>\n<th>默认值</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>content_type</td>\n<td>内容类型</td>\n<td>String</td>\n<td>null</td>\n<td>指定消息的 MIME 类型，如 <code>&quot;text/plain&quot;</code>、<code>&quot;application/json&quot;</code></td>\n</tr>\n<tr>\n<td>content_encoding</td>\n<td>内容编码</td>\n<td>String</td>\n<td>null</td>\n<td>指定消息内容的编码方式，如 <code>&quot;gzip&quot;</code></td>\n</tr>\n<tr>\n<td>priority</td>\n<td>消息优先级</td>\n<td>Integer (0-255)</td>\n<td>0</td>\n<td>结合 <code>x-max-priority</code> 控制消息处理顺序，数值越大优先级越高</td>\n</tr>\n<tr>\n<td>correlation_id</td>\n<td>关联 ID</td>\n<td>String</td>\n<td>null</td>\n<td>RPC 模式中关联请求与响应</td>\n</tr>\n<tr>\n<td>reply_to</td>\n<td>回复队列名</td>\n<td>String</td>\n<td>null</td>\n<td>RPC 模式中指定响应消息的返回队列</td>\n</tr>\n<tr>\n<td>expiration</td>\n<td>消息过期时间</td>\n<td>String (ms)</td>\n<td>null</td>\n<td>消息的 TTL，毫秒为单位，过期后将被丢弃或进入死信队列</td>\n</tr>\n<tr>\n<td>message_id</td>\n<td>消息 ID</td>\n<td>String</td>\n<td>null</td>\n<td>唯一标识一条消息，通常由生产者指定</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>时间戳</td>\n<td>Date / Long</td>\n<td>null</td>\n<td>消息发送时间，通常是 Unix 时间戳</td>\n</tr>\n<tr>\n<td>type</td>\n<td>消息类型</td>\n<td>String</td>\n<td>null</td>\n<td>描述消息类型，如 <code>&quot;order&quot;</code> 或 <code>&quot;event&quot;</code></td>\n</tr>\n<tr>\n<td>user_id</td>\n<td>用户 ID</td>\n<td>String</td>\n<td>null</td>\n<td>标识发送消息的用户，通常用于安全或审计</td>\n</tr>\n<tr>\n<td>app_id</td>\n<td>应用 ID</td>\n<td>String</td>\n<td>null</td>\n<td>标识发送消息的应用程序</td>\n</tr>\n<tr>\n<td>cluster_id</td>\n<td>集群 ID</td>\n<td>String</td>\n<td>null</td>\n<td>RabbitMQ 集群 ID，实际中很少使用</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>与队列重叠的属性：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>队列参数（Queue Arguments）</th>\n<th>消息属性（Message Properties）</th>\n<th>谁的优先级更高 / 生效方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>priority / x-max-priority</strong></td>\n<td><code>x-max-priority</code>: 定义队列支持的<strong>最大优先级值</strong></td>\n<td><code>priority</code>: 为单个消息设置优先级</td>\n<td>队列先定义范围，消息只能在这个范围内取值 <br> 若 <code>priority &gt; x-max-priority</code>，则以<code>x-max-priority</code>为准</td>\n</tr>\n<tr>\n<td><strong>expiration / x-message-ttl</strong></td>\n<td><code>x-message-ttl</code>: 队列级别的消息<strong>统一 TTL</strong></td>\n<td><code>expiration</code>: 为单个消息设置 TTL（毫秒）</td>\n<td>如果同时设置，<strong>较短的 TTL</strong> 会生效</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"Get-message\">Get message</h3>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/Ar9qob.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Ack Mode：消息确认模式</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Nack message requeue true: 确认失败，消息重新入队，这是默认选择，主要是为了测试后消息依旧存在。</li>\n<li class=\"lvl-4\">Automatic ack: 自动确认</li>\n<li class=\"lvl-4\">Reject requeue true: 拒绝，消息重新入队</li>\n<li class=\"lvl-4\">Reject requeue false: 拒绝，消息不重新入队</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Encoding：消息内容编码方式</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\"><code>Auto String / Base64</code>，默认。如果消息载荷可以解释为UTF-8编码的字符串，就是 <code>String</code>，否则就是 <code>Base64</code>。</li>\n<li class=\"lvl-4\"><code>Base64</code>。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Messages: 一次获取消息数量，默认为 1。</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Message 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Message(消息) 是什么？ 在 RabbitMQ 中，Message（消息）是消息队列中的数据单元。消息包含消息内容、消息属性等信息。 Message 组成： 消息内容：消息的内容，可以是任意数据。 消息属性：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。 Web 控制台 中 Message 的使用 在 Exchange 和 Queue 的管理界面中，都可以在其详情页面测试 Message 的使用。 关于如何在代码中使用 Message，我会在下一节中详细介绍。 Publish message Payload：消息的内容，可以是任意数据。 Payload encoding：消息内容的编码方式，String 或者 Base64，默认为 String。 Delivery mode：消息的持久化模式，1-Non-persistent 表示非持久化，2-Persistent 表示持久化。 Headers：消息的头信息，用于与 Headers Exchange（头部交换机）中的配置进行匹配。 Properties：消息的属性，如消息的过期时间、消息的优先级、消息的标签等。 属性名 中文含义 数据类型 默认值 典型用途 content_type 内容类型 String null 指定消息的 MIME 类型，如 &quot;text/plain&quot;、&quot;application/json&quot; content_encoding 内容编码 String null 指定消息内容的编码方式，如 &quot;gzip&quot; priority 消息优先级 Integer (0-255) 0 结合 x-max-priority 控制消息处理顺序，数值越大优先级越高 correlation_id 关联 ID String null RPC 模式中关联请求与响应 reply_to 回复队列名 String null RPC 模式中指定响应消息的返回队列 expiration 消息过期时间 String (ms) null 消息的 TTL，毫秒为单位，过期后将被丢弃或进入死信队列 message_id 消息 ID String null 唯一标识一条消息，通常由生产者指定 timestamp 时间戳 Date / Long null 消息发送时间，通常是 Unix 时间戳 type 消息类型 String null 描述消息类型，如 &quot;order&quot; 或 &quot;event&quot; user_id 用户 ID String null 标识发送消息的用户，通常用于安全或审计 app_id 应用 ID String null 标识发送消息的应用程序 cluster_id 集群 ID String null RabbitMQ 集群 ID，实际中很少使用 与队列重叠的属性： 参数名称 队列参数（Queue Arguments） 消息属性（Message Properties） 谁的优先级更高 / 生效方式 priority / x-max-priority x-max-priority: 定义队列支持的最大优先级值 priority: 为单个消息设置优先级 队列先定义范围，消息只能在这个范围内取值 若 priority &gt; x-max-priority，则以x-max-priority为准 expiration / x-message-ttl x-message-ttl: 队列级别的消息统一 TTL expiration: 为单个消息设置 TTL（毫秒） 如果同时设置，较短的 TTL 会生效 Get message Ack Mode：消息确认模式 Nack message requeue true: 确认失败，消息重新入队，这是默认选择，主要是为了测试后消息依旧存在。 Automatic ack: 自动确认 Reject requeue true: 拒绝，消息重新入队 Reject requeue false: 拒绝，消息不重新入队 Encoding：消息内容编码方式 Auto String / Base64，默认。如果消息载荷可以解释为UTF-8编码的字符串，就是 String，否则就是 Base64。 Base64。 Messages: 一次获取消息数量，默认为 1。","summary":"摘要 本文介绍 RabbitMQ 的 Message 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-21T14:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/","url":"https://blog.hanqunfeng.com/2025/09/21/rabbitmq-exchange/","title":"RabbitMQ 之 Exchange","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Exchange-交换机-是什么？\">Exchange(交换机) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/exchanges\">Exchange（交换机）</a> 是消息路由的核心组件。它负责接收生产者发送的消息，并根据预定义的路由规则将消息转发到一个或多个队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Exchange 类型决定了消息的路由方式。RabbitMQ 支持的 Exchange 类型</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Exchange 类型</th>\n<th>声明类型</th>\n<th>路由规则描述</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Direct</strong></td>\n<td><code>direct</code></td>\n<td>消息根据 <strong>路由键（routing key）</strong> 精确匹配绑定键（binding key）进行路由。</td>\n<td>精确消息传递，如日志分类、任务分发等。</td>\n</tr>\n<tr>\n<td><strong>Fanout</strong></td>\n<td><code>fanout</code></td>\n<td>消息广播到所有绑定的队列，<strong>忽略路由键</strong>。</td>\n<td>广播消息，如发布/订阅模式、实时通知等。</td>\n</tr>\n<tr>\n<td><strong>Topic</strong></td>\n<td><code>topic</code></td>\n<td>消息根据路由键与绑定键模式的匹配进行路由，支持通配符 <code>*</code>（匹配一个词）和 <code>#</code>（匹配零个或多个词）。</td>\n<td>模块化路由，如日志系统、事件驱动架构等。</td>\n</tr>\n<tr>\n<td><strong>Headers</strong></td>\n<td><code>headers</code></td>\n<td>消息根据 <strong>消息头部（headers）</strong> 与绑定时指定的头部匹配进行路由，支持 <code>x-match</code> 参数（<code>any</code> 或 <code>all</code>）。</td>\n<td>多条件路由，如复杂过滤、动态路由等。</td>\n</tr>\n<tr>\n<td><strong>Local Random Exchange</strong></td>\n<td><code>x-local-random</code></td>\n<td>消息始终被路由到本地队列，如果有多个本地队列绑定，则随机选择一个进行投递。</td>\n<td>请求-响应（RPC）模式，低延迟通信</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 默认为我们提供了如下的交换机<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/SKlqQK.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>每新创建一个 Vhost，RabbitMQ 就会自动创建以下交换机，比如 <code>/vtest</code><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oGJ1oj.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>当然我们也可以根据需要创建新的交换机<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QjnZin.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>配置说明</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">Durability: 指定 Exchange 是否持久化。\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">Durable: 持久化的 Exchange 会被保存在磁盘上，重启 RabbitMQ 时会自动恢复。</li>\n<li class=\"lvl-6\">Transient: 非持久化的 Exchange 会被保存在内存中，重启 RabbitMQ 时会丢失。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Auto-delete: 指定 Exchange 是否自动删除。\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">yes: 如果没有队列或交换机绑定该 Exchange，则该 Exchange 会自动删除。</li>\n<li class=\"lvl-6\">no: 该 Exchange 不会自动删除。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Internal: 用于控制交换机是否可以被生产者直接发布消息\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">yes: 不能被生产者直接发送消息，该交换机只能用于 将消息从其他交换机转发到该交换机。</li>\n<li class=\"lvl-6\">no: 可以被生产者直接发送消息。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">Arguments: 用于设置 Exchange 的其他参数，目前仅支持一个参数\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">Alternate exchange(alternate-exchange): 指定该 Exchange 的备用交换机，如果无法以其他方式将发往此交换机的消息路由出去，则将它们发送至此处指定的备用交换机。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Direct-Exchange（直接交换机）\">Direct Exchange（直接交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的路由键与队列的绑定键完全匹配时，消息被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：需要精确匹配的场景，如日志分类、任务分发等。</p>\n</li>\n</ul>\n<h2 id=\"Fanout-Exchange（扇出交换机）\">Fanout Exchange（扇出交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息广播到所有绑定的队列，忽略路由键。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：无论消息的路由键是什么，都会被路由到所有绑定的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：广播消息，如发布/订阅模式、实时通知等。</p>\n</li>\n</ul>\n<h2 id=\"Topic-Exchange（主题交换机）\">Topic Exchange（主题交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的路由键与队列的绑定键模式匹配时，消息被路由到该队列。支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定键为 <em>.orange.</em>，则路由键为 quick.orange.rabbit 的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：模块化路由，如日志系统、事件驱动架构等。</p>\n</li>\n</ul>\n<h2 id=\"Headers-Exchange（头部交换机）\">Headers Exchange（头部交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>路由规则：消息的头部与队列的绑定头部匹配时，消息被路由到该队列。支持 x-match 参数（any 或 all）。即使配置了路由键也会忽略。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：如果队列绑定头部为 { “x-match”: “all”, “format”: “pdf”, “priority”: “high” }，则只有同时满足这两个条件的消息会被路由到该队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：多条件路由，如复杂过滤、动态路由等。</p>\n</li>\n</ul>\n<h2 id=\"Local-Random-Exchange（本地随机交换机）\">Local Random Exchange（本地随机交换机）</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Local Random Exchange 是 RabbitMQ 4.0 引入的交换机类型，旨在优化<code>请求-响应</code>模式下的消息路由，特别适用于低延迟和高吞吐量的场景。通过结合独占队列使用，可以确保消息快速传递到本地消费者，减少网络延迟，提高系统性能。</p>\n</li>\n<li class=\"lvl-2\">\n<p>路由规则：消息始终被路由到本地队列（位于同一节点上），如果有多个本地队列绑定，则随机选择一个进行投递。</p>\n</li>\n<li class=\"lvl-2\">\n<p>示例：假设节点 A 上有两个绑定了 x-local-random 交换机的队列 Q1 和 Q2，发布的消息会随机路由到 Q1 或 Q2，但不会路由到其他节点的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用场景：请求-响应（RPC）模式下的低延迟通信，适合微服务架构中每个节点上都有消费者的场景。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在使用 Local Random Exchange 时，必须满足以下条件：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">独占队列：消费者应声明独占队列，以确保队列仅绑定到当前节点。</li>\n<li class=\"lvl-4\">每个节点至少一个消费者：每个 RabbitMQ 节点上应至少有一个消费者，否则在该节点上发布的消息将被丢弃。</li>\n<li class=\"lvl-4\">交换机类型声明：使用 <code>x-local-random</code> 类型声明交换机。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Exchange-与-Queue-绑定-Binding\">Exchange 与 Queue 绑定(Binding)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建好 Exchange 之后，需要将 Exchange 与 Queue 绑定，才能将消息发送到指定的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Exchange 与 Queue 的绑定关系，即 Exchange 发送的消息，会根据路由键与队列的绑定键进行匹配，如果匹配成功，则将消息发送到对应的队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在 Exchange 页面点击 Exchange 的名称，进入 Exchange 详情页面，此处可以进行 Exchange 与 Queue 绑定配置<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/taKUjm.png\" alt=\"\"></p>\n<blockquote>\n<p>这里的<code>Arguments</code>用于设置 绑定 的其他参数，比如 <code>Headers Exchange</code> 需要设置 <code>x-match</code> 参数等。</p>\n</blockquote>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Exchange(交换机) 是什么？ 在 RabbitMQ 中，Exchange（交换机） 是消息路由的核心组件。它负责接收生产者发送的消息，并根据预定义的路由规则将消息转发到一个或多个队列。 Exchange 类型决定了消息的路由方式。RabbitMQ 支持的 Exchange 类型 Exchange 类型 声明类型 路由规则描述 典型用途 Direct direct 消息根据 路由键（routing key） 精确匹配绑定键（binding key）进行路由。 精确消息传递，如日志分类、任务分发等。 Fanout fanout 消息广播到所有绑定的队列，忽略路由键。 广播消息，如发布/订阅模式、实时通知等。 Topic topic 消息根据路由键与绑定键模式的匹配进行路由，支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。 模块化路由，如日志系统、事件驱动架构等。 Headers headers 消息根据 消息头部（headers） 与绑定时指定的头部匹配进行路由，支持 x-match 参数（any 或 all）。 多条件路由，如复杂过滤、动态路由等。 Local Random Exchange x-local-random 消息始终被路由到本地队列，如果有多个本地队列绑定，则随机选择一个进行投递。 请求-响应（RPC）模式，低延迟通信 RabbitMQ 默认为我们提供了如下的交换机 每新创建一个 Vhost，RabbitMQ 就会自动创建以下交换机，比如 /vtest 当然我们也可以根据需要创建新的交换机 配置说明 Durability: 指定 Exchange 是否持久化。 Durable: 持久化的 Exchange 会被保存在磁盘上，重启 RabbitMQ 时会自动恢复。 Transient: 非持久化的 Exchange 会被保存在内存中，重启 RabbitMQ 时会丢失。 Auto-delete: 指定 Exchange 是否自动删除。 yes: 如果没有队列或交换机绑定该 Exchange，则该 Exchange 会自动删除。 no: 该 Exchange 不会自动删除。 Internal: 用于控制交换机是否可以被生产者直接发布消息 yes: 不能被生产者直接发送消息，该交换机只能用于 将消息从其他交换机转发到该交换机。 no: 可以被生产者直接发送消息。 Arguments: 用于设置 Exchange 的其他参数，目前仅支持一个参数 Alternate exchange(alternate-exchange): 指定该 Exchange 的备用交换机，如果无法以其他方式将发往此交换机的消息路由出去，则将它们发送至此处指定的备用交换机。 Direct Exchange（直接交换机） 路由规则：消息的路由键与队列的绑定键完全匹配时，消息被路由到该队列。 示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。 适用场景：需要精确匹配的场景，如日志分类、任务分发等。 Fanout Exchange（扇出交换机） 路由规则：消息广播到所有绑定的队列，忽略路由键。 示例：无论消息的路由键是什么，都会被路由到所有绑定的队列。 适用场景：广播消息，如发布/订阅模式、实时通知等。 Topic Exchange（主题交换机） 路由规则：消息的路由键与队列的绑定键模式匹配时，消息被路由到该队列。支持通配符 *（匹配一个词）和 #（匹配零个或多个词）。 示例：如果队列绑定键为 .orange.，则路由键为 quick.orange.rabbit 的消息会被路由到该队列。 适用场景：模块化路由，如日志系统、事件驱动架构等。 Headers Exchange（头部交换机） 路由规则：消息的头部与队列的绑定头部匹配时，消息被路由到该队列。支持 x-match 参数（any 或 all）。即使配置了路由键也会忽略。 示例：如果队列绑定头部为 { “x-match”: “all”, “format”: “pdf”, “priority”: “high” }，则只有同时满足这两个条件的消息会被路由到该队列。 适用场景：多条件路由，如复杂过滤、动态路由等。 Local Random Exchange（本地随机交换机） Local Random Exchange 是 RabbitMQ 4.0 引入的交换机类型，旨在优化请求-响应模式下的消息路由，特别适用于低延迟和高吞吐量的场景。通过结合独占队列使用，可以确保消息快速传递到本地消费者，减少网络延迟，提高系统性能。 路由规则：消息始终被路由到本地队列（位于同一节点上），如果有多个本地队列绑定，则随机选择一个进行投递。 示例：假设节点 A 上有两个绑定了 x-local-random 交换机的队列 Q1 和 Q2，发布的消息会随机路由到 Q1 或 Q2，但不会路由到其他节点的队列。 适用场景：请求-响应（RPC）模式下的低延迟通信，适合微服务架构中每个节点上都有消费者的场景。 在使用 Local Random Exchange 时，必须满足以下条件： 独占队列：消费者应声明独占队列，以确保队列仅绑定到当前节点。 每个节点至少一个消费者：每个 RabbitMQ 节点上应至少有一个消费者，否则在该节点上发布的消息将被丢弃。 交换机类型声明：使用 x-local-random 类型声明交换机。 Exchange 与 Queue 绑定(Binding) 创建好 Exchange 之后，需要将 Exchange 与 Queue 绑定，才能将消息发送到指定的队列。 Exchange 与 Queue 的绑定关系，即 Exchange 发送的消息，会根据路由键与队列的绑定键进行匹配，如果匹配成功，则将消息发送到对应的队列。 在 Exchange 页面点击 Exchange 的名称，进入 Exchange 详情页面，此处可以进行 Exchange 与 Queue 绑定配置 这里的Arguments用于设置 绑定 的其他参数，比如 Headers Exchange 需要设置 x-match 参数等。","summary":"摘要 本文介绍 RabbitMQ 的 Exchange 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-21T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/","url":"https://blog.hanqunfeng.com/2025/09/20/rabbitmq-queue/","title":"RabbitMQ 之 Queue","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 RabbitMQ 的 Queue 的基本概念和用法。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Queue-队列-是什么？\">Queue(队列) 是什么？</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 RabbitMQ 中，<a href=\"https://www.rabbitmq.com/docs/queues\">队列（Queue）</a> 是一种用于存储消息的 数据结构，消息会一直保存在队列中，直到被应用程序或服务消费为止。</p>\n</li>\n<li class=\"lvl-2\">\n<p>生产者（Publisher） 把消息放进队列，消费者（Consumer） 从队列中取出消息。队列中的消息会按照 FIFO（先进先出）的顺序进行消费。</p>\n</li>\n<li class=\"lvl-2\">\n<p>队列在生产者和消费者之间起到缓冲区的作用。生产者不需要知道消费者的存在，它们只需把消息发送到队列。消费者可以根据自身处理速度，按需消费消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 目前 支持三种队列类型：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>队列类型</th>\n<th>描述</th>\n<th>特点</th>\n<th>典型用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Classic Queue（经典队列）</strong></td>\n<td>最常用的队列类型，消息按 FIFO（先进先出）顺序存储和消费</td>\n<td>支持持久化、优先级、TTL、死信等</td>\n<td>大多数常规消息场景</td>\n</tr>\n<tr>\n<td><strong>Quorum Queue（仲裁队列）</strong></td>\n<td>基于 Raft 协议的队列，确保高可用和数据一致性</td>\n<td>内置复制（副本数量可配置）、适合高可靠性场景，但吞吐量略低于经典队列</td>\n<td>关键任务消息、高可靠性场景</td>\n</tr>\n<tr>\n<td><strong>Stream Queue（流式队列）</strong></td>\n<td>面向大量消息的高吞吐队列，支持消息按偏移量读取</td>\n<td>类似 Kafka，可随机访问历史消息、顺序读取、可持久化大量消息</td>\n<td>大数据流、日志处理、事件溯源</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Classic-Queue-经典队列\">Classic Queue(经典队列)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/classic-queues\">RabbitMQ 经典队列（原始队列类型）</a>是一种通用队列类型。实际上它是在 3.8.x 版本之前唯一的队列类型。</p>\n</li>\n<li class=\"lvl-2\">\n<p>经典队列适用于数据安全不是优先事项的用例，因为存储在经典队列中的数据不会被复制。 经典队列使用非复制的 FIFO 队列实现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>经典队列不适合积累太多的消息，如果队列中积累的消息太多了，会严重影响客户端生产消息以及消费消息的性能。因此，经典队列主要用在数据量比较小，并且生产消息和消费消息的速度比较稳定的业务场景。比如内部系统之间的服务调用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 4.0 删除了对经典队列 <code>version1</code> 的支持，同时也不再支持将 经典队列 的消息在节点间复制。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MAdpRV.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Auto expire</strong></td>\n<td><code>x-expires</code></td>\n<td>整数（毫秒）</td>\n<td>队列在 <strong>指定时间内无人使用（无消费者、无发布、无访问）</strong> 时自动删除</td>\n<td>类似“队列空闲过期时间”，节省资源</td>\n</tr>\n<tr>\n<td><strong>Message TTL</strong></td>\n<td><code>x-message-ttl</code></td>\n<td>整数（毫秒）</td>\n<td>消息的 <strong>存活时间</strong>，超过时间后消息会被丢弃或发送到死信队列</td>\n<td>用于限制消息时效性，如延迟消息或短期缓存</td>\n</tr>\n<tr>\n<td><strong>Overflow behaviour</strong></td>\n<td><code>x-overflow</code></td>\n<td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td>\n<td>当队列达到 <strong>最大长度</strong> 或 <strong>最大字节数</strong> 时的行为</td>\n<td>- <code>drop-head</code>：丢弃最早的消息 <br> - <code>reject-publish</code>：拒绝新的消息</td>\n</tr>\n<tr>\n<td><strong>Single active consumer</strong></td>\n<td><code>x-single-active-consumer</code></td>\n<td>布尔值（true/false）</td>\n<td>是否启用 <strong>单活消费者模式</strong>，一次只允许一个消费者消费队列</td>\n<td>用于严格顺序消费，保证某个消息不会被多个消费者同时处理</td>\n</tr>\n<tr>\n<td><strong>Dead letter exchange (DLX)</strong></td>\n<td><code>x-dead-letter-exchange</code></td>\n<td>字符串</td>\n<td>指定队列的 <strong>死信交换机</strong>，用于接收无法消费或过期的消息</td>\n<td>常用于失败重试、消息补偿场景</td>\n</tr>\n<tr>\n<td><strong>Dead letter routing key</strong></td>\n<td><code>x-dead-letter-routing-key</code></td>\n<td>字符串</td>\n<td>消息转发到 DLX 时的 <strong>路由键</strong></td>\n<td>可以灵活转发到不同队列</td>\n</tr>\n<tr>\n<td><strong>Max length</strong></td>\n<td><code>x-max-length</code></td>\n<td>整数</td>\n<td>队列中 <strong>最大消息条数</strong></td>\n<td>超过时按照 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>队列中 <strong>消息总字节数上限</strong></td>\n<td>超过时按照 Overflow behaviour 处理，适合大消息场景</td>\n</tr>\n<tr>\n<td><strong>Maximum priority</strong></td>\n<td><code>x-max-priority</code></td>\n<td>整数</td>\n<td>启用优先级队列时，队列可设置的 <strong>最大优先级值</strong></td>\n<td>消息优先级范围是 0 到这个值，优先级高的消息先被消费</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td>\n<td><code>client-local</code>（默认）：选择客户端所在节点作为Leader <br> <code>balanced</code>：在节点间均衡Leader分布，用于 HA 队列优化</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Quorum-Queue-仲裁队列\">Quorum Queue(仲裁队列)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/quorum-queues\">仲裁队列（Quorum Queue）</a> 是 RabbitMQ 从3.8.0版本之后引入的一种现代队列类型，也是目前官方比较推荐的一种对列类型。未来有可能取代 经典队列 成为默认队列类型。</p>\n</li>\n<li class=\"lvl-2\">\n<p>其基于 Raft 共识算法 实现 持久化、复制和高可用。它保证 数据安全性、可靠的主节点选举，即使在升级或集群波动期间也能保持高可用性。</p>\n</li>\n<li class=\"lvl-2\">\n<p>仲裁队列支持 毒消息处理、至少一次死信投递 以及 AMQP 修改（AMQP.modified）的处理结果。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它适合 以数据安全为首要目标 的场景。与经典队列相比，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/oQ8YiT.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>仲裁队列（Quorum Queue）的 <code>Durability</code> 只能设置为 Durable(true)。<code>Auto delete</code> 只能为 No(false)。</p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Auto expire</strong></td>\n<td><code>x-expires</code></td>\n<td>整数（毫秒）</td>\n<td>队列在指定时间内无人使用（无消费者、无发布、无访问）时自动删除</td>\n<td>节省资源，队列空闲过期时间</td>\n</tr>\n<tr>\n<td><strong>Message TTL</strong></td>\n<td><code>x-message-ttl</code></td>\n<td>整数（毫秒）</td>\n<td>队列中消息的生存时间，超过时间后消息会被丢弃或转入死信队列</td>\n<td>控制消息时效性</td>\n</tr>\n<tr>\n<td><strong>Overflow behaviour</strong></td>\n<td><code>x-overflow</code></td>\n<td>字符串（<code>drop-head</code> 或 <code>reject-publish</code>）</td>\n<td>当队列达到最大长度时的处理方式</td>\n<td><code>drop-head</code>：丢弃最早消息，<code>reject-publish</code>：拒绝新消息</td>\n</tr>\n<tr>\n<td><strong>Single active consumer</strong></td>\n<td><code>x-single-active-consumer</code></td>\n<td>布尔值（true/false）</td>\n<td>是否启用单活消费者模式，一次只允许一个消费者消费队列</td>\n<td>保证严格顺序消费</td>\n</tr>\n<tr>\n<td><strong>Dead letter exchange (DLX)</strong></td>\n<td><code>x-dead-letter-exchange</code></td>\n<td>字符串</td>\n<td>指定队列的死信交换机，用于接收无法消费或过期的消息</td>\n<td>与 DLX 配合使用处理失败消息</td>\n</tr>\n<tr>\n<td><strong>Dead letter routing key</strong></td>\n<td><code>x-dead-letter-routing-key</code></td>\n<td>字符串</td>\n<td>消息转发到 DLX 时的路由键</td>\n<td>灵活路由死信消息</td>\n</tr>\n<tr>\n<td><strong>Max length</strong></td>\n<td><code>x-max-length</code></td>\n<td>整数</td>\n<td>队列中最大消息条数</td>\n<td>超过时按 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>队列消息总字节数上限</td>\n<td>超过时按 Overflow behaviour 处理</td>\n</tr>\n<tr>\n<td><strong>Delivery limit</strong></td>\n<td><code>x-delivery-limit</code></td>\n<td>整数</td>\n<td>消息允许投递的最大次数，超过后变为死信</td>\n<td>控制消息重试次数</td>\n</tr>\n<tr>\n<td><strong>Initial cluster size</strong></td>\n<td><code>x-quorum-initial-group-size</code></td>\n<td>整数</td>\n<td>队列在创建时需要的最小节点数</td>\n<td>用于保证仲裁队列的高可用性</td>\n</tr>\n<tr>\n<td><strong>Target cluster size</strong></td>\n<td><code>x-quorum-target-group-size</code></td>\n<td>整数</td>\n<td>队列运行时的目标节点数</td>\n<td>当集群节点变化时，仲裁队列会尝试调整副本数量</td>\n</tr>\n<tr>\n<td><strong>Dead letter strategy</strong></td>\n<td><code>x-dead-letter-strategy</code></td>\n<td>字符串（<code>at-most-once</code>、<code>at-least-once</code>）</td>\n<td>设置仲裁队列的死信处理策略</td>\n<td>仅适用于 Quorum Queue。<br><code>at-most-once</code>（默认）：消息最多投递一次，可能丢失。<br><code>at-least-once</code>：确保消息至少投递一次，必须将 Overflow behaviour 设置为 <code>reject-publish</code>，否则回退到 <code>at-most-once</code>。</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明队列时，队列主节点（Leader）的选取规则</td>\n<td><code>client-local</code>：选择客户端所在节点作为 Leader <br> <code>balanced</code>：在节点间均衡 Leader 分布</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Quorum Queues 和 Classic Queues 的功能对比如下：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>中文含义</th>\n<th>Classic queues</th>\n<th>Quorum queues</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-durable queues</td>\n<td>非持久化队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 总是持久化，不支持非持久化</td>\n</tr>\n<tr>\n<td>Message replication</td>\n<td>消息复制</td>\n<td>no</td>\n<td>yes</td>\n<td>Quorum queues 内置消息复制，Classic queues 需镜像策略</td>\n</tr>\n<tr>\n<td>Exclusivity</td>\n<td>独占队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Classic queues 支持独占队列，Quorum queues 不支持独占</td>\n</tr>\n<tr>\n<td>Per message persistence</td>\n<td>消息级持久化</td>\n<td>per message</td>\n<td>always</td>\n<td>Quorum queues 消息总是持久化</td>\n</tr>\n<tr>\n<td>Membership changes</td>\n<td>节点成员变更</td>\n<td>no</td>\n<td>semi-automatic</td>\n<td>Quorum queues 节点变化时半自动处理复制</td>\n</tr>\n<tr>\n<td>Message TTL (Time-To-Live)</td>\n<td>消息存活时间</td>\n<td>yes</td>\n<td>yes</td>\n<td>两者都支持消息过期时间</td>\n</tr>\n<tr>\n<td>Queue TTL</td>\n<td>队列存活时间</td>\n<td>yes</td>\n<td>partially</td>\n<td>Quorum queues 的 lease 不会因重新声明而续期</td>\n</tr>\n<tr>\n<td>Queue length limits</td>\n<td>队列长度限制</td>\n<td>yes</td>\n<td>yes</td>\n<td>Quorum queues 支持长度限制，但 <code>x-overflow=reject-publish-dlx</code> 不支持</td>\n</tr>\n<tr>\n<td>Keeps messages in memory</td>\n<td>消息内存保存</td>\n<td>see Classic Queues</td>\n<td>never</td>\n<td>Quorum queues 消息总是写入磁盘，不保留在内存</td>\n</tr>\n<tr>\n<td>Message priority</td>\n<td>消息优先级</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持消息优先级</td>\n</tr>\n<tr>\n<td>Single Active Consumer</td>\n<td>单活消费者</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持单活消费者</td>\n</tr>\n<tr>\n<td>Consumer exclusivity</td>\n<td>独占消费者</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 不支持独占消费者，需使用 Single Active Consumer</td>\n</tr>\n<tr>\n<td>Consumer priority</td>\n<td>消费者优先级</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持消费者优先级</td>\n</tr>\n<tr>\n<td>Dead letter exchanges</td>\n<td>死信交换机</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持死信交换机</td>\n</tr>\n<tr>\n<td>Adheres to policies</td>\n<td>遵循策略</td>\n<td>yes</td>\n<td>yes</td>\n<td>支持策略，但 Quorum queues 的部分策略行为不同</td>\n</tr>\n<tr>\n<td>Poison message handling</td>\n<td>毒消息处理</td>\n<td>no</td>\n<td>yes</td>\n<td>Quorum queues 支持毒消息处理</td>\n</tr>\n<tr>\n<td>Server-named queues</td>\n<td>服务器自动命名队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Quorum queues 不支持服务器自动命名队列</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Stream-流\">Stream(流)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/streams\">Stream</a> 是RabbitMQ自 3.9.0 版本开始引入的一种新的数据队列类型。这种队列类型的消息是持久化到磁盘并且具备分布式备份的，更适合于消费者多，读消息非常频繁的场景。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 的核心是以append-only只添加的日志来记录消息，整体来说，就是消息将以append-only的方式持久化到日志文件中，然后通过调整每个消费者的消费进度offset，来实现消息的多次分发。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 不支持死信交换机，不支持处理毒消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 Stream 不属于队列，流（Streams） 是一种 持久化、可复制的数据结构，功能上类似队列：从生产者缓冲消息供消费者读取。但它与队列有两个重要区别：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">存储模型 – 流是 追加日志（append-only log），消息可以 重复读取直到过期。</li>\n<li class=\"lvl-4\">消费模型 – 流提供 非破坏性消费语义（non-destructive consumer semantics），多个消费者可以多次读取同一条消息而不会删除它。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>Stream 始终是持久化和复制的，保证数据安全。消费者可以通过 RabbitMQ 客户端库 或 专用二进制协议插件 读取流，其中插件方式可以 访问所有流特性 并提供 最佳性能。合理的客户端连接策略有助于提升 吞吐量和效率。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/8KqZY9.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>参数说明(每个版本可能都有变化，具体以页面显示为准)</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>配置参数名</th>\n<th>数据类型</th>\n<th>作用说明</th>\n<th>备注 / 使用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Max length bytes</strong></td>\n<td><code>x-max-length-bytes</code></td>\n<td>整数（字节）</td>\n<td>流中允许存储的 <strong>最大数据总字节数</strong></td>\n<td>超过时流将停止接收新消息，适合控制存储容量</td>\n</tr>\n<tr>\n<td><strong>Max time retention</strong></td>\n<td><code>x-max-age</code></td>\n<td>字符串（时间单位，例如 <code>1h</code>, <code>30m</code>, <code>1d</code>）</td>\n<td>设置流队列中消息的 <strong>最大保留时间</strong>，超过时间的消息会被删除</td>\n<td>支持时间单位：Y=年, M=月, D=天, h=小时, m=分钟, s=秒。例如 <code>&quot;1h&quot;</code> 表示只保留最近 1 小时的消息，用于控制数据量和自动清理过期消息</td>\n</tr>\n<tr>\n<td><strong>Max segment size in bytes</strong></td>\n<td><code>x-stream-max-segment-size</code></td>\n<td>整数（字节）</td>\n<td>流分段存储时的 <strong>每个段的最大字节数</strong></td>\n<td>控制单个文件段大小，有利于 I/O 性能和管理</td>\n</tr>\n<tr>\n<td><strong>Filter size (per chunk) in bytes</strong></td>\n<td><code>x-stream-filter-size-bytes</code></td>\n<td>整数（字节）</td>\n<td>流内部 <strong>过滤索引每块的大小</strong></td>\n<td>用于加速消息定位和读取，影响内存使用和检索效率</td>\n</tr>\n<tr>\n<td><strong>Initial cluster size</strong></td>\n<td><code>x-initial-cluster-size</code></td>\n<td>整数</td>\n<td>流在创建时的 <strong>最小节点数</strong></td>\n<td>保证流的复制和高可用性</td>\n</tr>\n<tr>\n<td><strong>Leader locator</strong></td>\n<td><code>x-queue-leader-locator</code></td>\n<td>字符串（<code>client-local</code>、<code>balanced</code>）</td>\n<td>设置在集群节点上声明流时，主节点（Leader）的选取规则</td>\n<td><code>client-local</code>：客户端所在节点作为 Leader（默认）<br><code>balanced</code>：在节点间均衡 Leader 分布，用于优化 HA</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Classic Queue vs Stream Queue Feature Matrix</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>中文含义</th>\n<th>Classic queues</th>\n<th>Stream queues</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-durable queues</td>\n<td>非持久化队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列总是持久化，不支持非持久化</td>\n</tr>\n<tr>\n<td>Exclusivity</td>\n<td>独占队列</td>\n<td>yes</td>\n<td>no</td>\n<td>Classic 队列支持独占，Stream 队列不支持独占</td>\n</tr>\n<tr>\n<td>Per message persistence</td>\n<td>消息级持久化</td>\n<td>per message</td>\n<td>always</td>\n<td>Stream 队列的消息总是持久化</td>\n</tr>\n<tr>\n<td>Membership changes</td>\n<td>节点成员变更</td>\n<td>no</td>\n<td>manual</td>\n<td>Stream 队列节点变更需要手动管理</td>\n</tr>\n<tr>\n<td>TTL</td>\n<td>消息存活时间</td>\n<td>yes</td>\n<td>no (but see Retention)</td>\n<td>Stream 队列没有消息 TTL，但可通过 Retention 控制过期</td>\n</tr>\n<tr>\n<td>Queue length limits</td>\n<td>队列长度限制</td>\n<td>yes</td>\n<td>no (but see Retention)</td>\n<td>Stream 队列没有固定长度限制，通过 Retention 控制数据量</td>\n</tr>\n<tr>\n<td>Keeps messages in memory</td>\n<td>消息内存保存</td>\n<td>see Classic Queues</td>\n<td>never</td>\n<td>Stream 队列消息不保存在内存中，只写入磁盘</td>\n</tr>\n<tr>\n<td>Message priority</td>\n<td>消息优先级</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持消息优先级</td>\n</tr>\n<tr>\n<td>Consumer priority</td>\n<td>消费者优先级</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持消费者优先级</td>\n</tr>\n<tr>\n<td>Dead letter exchanges</td>\n<td>死信交换机</td>\n<td>yes</td>\n<td>no</td>\n<td>Stream 队列不支持死信交换机</td>\n</tr>\n<tr>\n<td>Adheres to policies</td>\n<td>遵循策略</td>\n<td>yes</td>\n<td>yes (see Retention)</td>\n<td>Stream 队列支持策略，但主要通过 Retention 控制行为</td>\n</tr>\n<tr>\n<td>Reacts to memory alarms</td>\n<td>内存告警响应</td>\n<td>yes</td>\n<td>no (uses minimal RAM)</td>\n<td>Stream 队列使用最小内存，不触发内存告警</td>\n</tr>\n<tr>\n<td>Poison message handling</td>\n<td>毒消息处理</td>\n<td>no</td>\n<td>no</td>\n<td>Stream 队列不支持毒消息处理</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>我们可以激活<code>流插件</code>来使用流的特有功能</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmq-plugins <span class=\"built_in\">enable</span> rabbitmq_stream rabbitmq_stream_management</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>激活<code>流插件</code>后，Stream队列的操作方式可以更高级，具体可以参考<a href=\"https://www.rabbitmq.com/tutorials/tutorial-two-java-stream\">官方文档</a>，作者在<a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo/rabbitmq-stream\">Java Client 示例</a>中也给出了示例代码。</p>\n</li>\n</ul>\n<h3 id=\"超级流-Super-Streams\">超级流(Super Streams)</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>超级流（Super streams） 是一种通过将一个大的流分区成更小的流来实现扩展的方式。它们与 单个消费者（Single Active Consumer） 集成，以在分区内保持消息顺序。超级流从 RabbitMQ 3.11 开始可用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>一个超级流是由多个普通流组成的逻辑流。它是一种通过 RabbitMQ Streams 来扩展发布和消费的方法：一个大型逻辑流被划分成多个分区流，将存储和流量分散到多个集群节点上。</p>\n</li>\n<li class=\"lvl-2\">\n<p>超级流依然是一个逻辑实体：由于客户端库的智能化处理，应用程序会把它视为一个“大型”流。超级流的拓扑结构基于 AMQP 0.9.1 模型，也就是交换机（exchange）、队列（queue）和它们之间的绑定（binding）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>可以使用任何 AMQP 0.9.1 库或管理插件创建超级流的拓扑。它需要创建一个直连交换机（direct exchange）、分区流（partition streams），并将它们绑定在一起。</p>\n</li>\n<li class=\"lvl-2\">\n<p>通过管理控制台创建超级流<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/j2G1HC.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>也可以通过命令创建超级流，以下是如何用命令创建一个包含 3 个分区的超级流：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rabbitmq-streams add_super_stream [-p &lt;vhost&gt;] &lt;stream-name&gt; [--partitions &lt;number&gt;]</span></span><br><span class=\"line\">rabbitmq-streams add_super_stream -p /vtest sq_3 --partitions 3</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>创建的Stream<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4py5OE.png\" alt=\"\"><br>\n创建的 Exchange，名称 sq_3<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/EwfTRM.png\" alt=\"\"><br>\n绑定关系<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/NErhQX.png\" alt=\"\"></p>\n</blockquote>\n<h2 id=\"队列类型扩展\">队列类型扩展</h2>\n<h3 id=\"懒队列\">懒队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>从3.6.x版本到3.12.x版本，RabbitMQ提供了一种针对Classic Queue的优化配置，<code>lazy-mode</code>，<a href=\"https://www.rabbitmq.com/docs/lazy-queues\">懒对列</a>。懒队列会尽可能早的将消息内容保存到硬盘当中，并且只有在用户请求到时，才临时从硬盘加载到RAM内存当中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>默认情况下，RabbitMQ接收到消息时，会保存到内存以便使用，同时把消息写到硬盘。但是，消息写入硬盘的过程中，是会阻塞队列的。RabbitMQ虽然针对写入硬盘速度做了很多算法优化，但是在长队列中，依然表现不是很理想，所以就有了懒队列的出现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>懒队列会尝试尽可能早的把消息写到硬盘中。这意味着在正常操作的大多数情况下，RAM中要保存的消息要少得多。当然，这是以增加磁盘IO为代价的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>懒队列适合消息量大且长期有堆积的队列，可以减少内存使用，加快消费速度。但是这是以大量消耗集群的网络及磁盘IO为代价的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>从3.12往后的版本中，RabbitMQ 不再支持“惰性”模式，因为 经典队列 当前的特性就类似于以前的 懒队列。</p>\n</li>\n</ul>\n<h3 id=\"死信队列\">死信队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/dlx\">死信队列（Dead Letter Queue）</a>，新版中叫做 死信交换机（Dead Letter Exchange, DLX），是RabbitMQ对于未能正常消费的消息进行的一种补救机制，用于保存无法被正常处理的消息。当消息被消费者处理失败时，RabbitMQ会将消息发送到死信队列中，等待消费者处理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>死信队列也是一个普通的队列，同样可以在队列上声明消费者，继续对消息进行消费处理。</p>\n</li>\n<li class=\"lvl-2\">\n<p>有以下几种情况，RabbitMQ会将一个正常消息转成死信</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">消息被拒绝（Message rejection）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">由 AMQP 1.0 接收端使用 rejected 结果拒绝</li>\n<li class=\"lvl-6\">由 AMQP 0.9.1 消费者使用 basic.reject 或 basic.nack，并且参数 requeue=false</li>\n</ul>\n</li>\n<li class=\"lvl-4\">消息过期（Message expiration）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">消息超过其配置的 TTL（生存时间） 后过期。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">队列长度超限（Queue length exceeded）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">队列中的消息数量或总字节数达到配置的最大限制后，被丢弃的消息会死信化。</li>\n</ul>\n</li>\n<li class=\"lvl-4\">投递次数超限（仅适用于仲裁队列 Quorum Queue）\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">消息的投递次数超过了仲裁队列中配置的 delivery-limit。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>使用场景</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">你可以在队列上配置 死信交换机（DLX） 和 死信路由键（Dead Letter Routing Key）。</li>\n<li class=\"lvl-4\">当消息成为死信时，会被 重新发布到 DLX，这样你可以：\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">做错误日志记录</li>\n<li class=\"lvl-6\">进行失败消息重试</li>\n<li class=\"lvl-6\">用于监控和告警</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>死信交换机的配置方法（How Dead Lettering is Configured）</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">在 RabbitMQ 中，任何队列都可以通过 客户端 或者 策略（policies） 来配置 死信交换机（DLX）。</li>\n<li class=\"lvl-4\">配置时主要涉及两个核心参数：</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>配置参数名</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>dead-letter-exchange</strong></td>\n<td>指定用于接收死信消息的 <strong>死信交换机名称</strong></td>\n</tr>\n<tr>\n<td><strong>dead-letter-routing-key</strong></td>\n<td>指定死信消息重新发布时使用的 <strong>路由键（Routing Key）</strong></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>死信在转移到死信队列时，他的 routingkey 也会保存下来。但是如果配置了 <code>x-dead-letter-routing-key</code> 这个参数的话，routingkey 就会被替换为配置的这个值。</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在创建队列时，我们可以通过为队列添加 <code>x-dead-letter-exchange</code> 和 <code>x-dead-letter-routing-key</code> 参数，来指定 死信交换机（DLX）和 死信路由键（Dead Letter Routing Key）。但是这样做很麻烦，每个队列都要单独配置，因此，我们可以使用 策略（policies） 来统一配置。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 仅指定死信交换机，这里交换机的名称是 my-dlx，交换机要提前创建好</span></span><br><span class=\"line\">rabbitmqctl set_policy DLX <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br><span class=\"line\"><span class=\"comment\"># 同时指定 死信交换机 和 路由键</span></span><br><span class=\"line\">rabbitmqctl set_policy DLX <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;&#x27;</span> --apply-to queues --priority 7</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>参数说明：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具</td>\n</tr>\n<tr>\n<td><code>set_policy</code></td>\n<td>设置一个策略（Policy），用于动态配置交换机、队列或绑定的参数</td>\n</tr>\n<tr>\n<td><code>DLX</code></td>\n<td>策略的名称，用户自定义，例如这里叫 <code>DLX</code></td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code></td>\n<td>正则表达式，匹配对象的名称。<code>.*</code> 表示匹配 <strong>所有队列</strong>，也可以指定具体队列名，比如 <code>^my-queue$</code></td>\n</tr>\n<tr>\n<td><code>&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;</code></td>\n<td>策略内容，这里设置了死信交换机名称和路由键：<br> - <code>dead-letter-exchange</code>: 设置死信交换机名称为 <code>my-dlx</code><br> - <code>dead-letter-routing-key</code>: 设置路由键为 <code>my-routing-key</code></td>\n</tr>\n<tr>\n<td><code>--apply-to queues</code></td>\n<td>指定策略作用对象为 <strong>队列（queues）</strong>，而不是交换机（exchanges）或绑定（bindings）</td>\n</tr>\n<tr>\n<td><code>--priority 7</code></td>\n<td>策略的优先级，值越大优先级越高。多个策略作用在同一对象时，优先级高的会覆盖低的</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>执行这条命令后：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">所有队列都会自动带上 <code>x-dead-letter-exchange=my-dlx</code> 和 <code>x-dead-letter-routing-key=my-routing-key</code> 配置。</li>\n<li class=\"lvl-4\">队列中被拒绝、过期、超长或超过投递次数的消息会被重新发布到 <code>my-dlx</code> 交换机，并使用 <code>my-routing-key</code> 作为路由键。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>消息被作为死信转移到死信队列后，会在Header当中增加⼀些消息。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x-first-death-queue：该消息首次成为死信时所在的队列名称</span><br><span class=\"line\">x-first-death-reason：该消息首次被判定为死信的原因</span><br><span class=\"line\">x-first-death-exchange：该消息在首次成为死信前被发布到的交换机名称</span><br><span class=\"line\">x-last-death-queue：该消息最近一次成为死信时所在的队列名称</span><br><span class=\"line\">x-last-death-reason：该消息最近一次被判定为死信的原因</span><br><span class=\"line\">x-last-death-exchange：该消息在最近一次成为死信前被发布到的交换机名称</span><br></pre></td></tr></table></figure>\n<h3 id=\"延迟队列\">延迟队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>延迟队列（Delayed Message Queue）: 延迟队列是一种特殊类型的队列，用于延迟消息的投递。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ中，是不存在延迟队列的功能的，而通常如果要用到延迟队列，就会采用 <code>TTL</code> + <code>死信队列</code> 的方式来实现。</p>\n</li>\n<li class=\"lvl-2\">\n<p>延迟队列的实现原理：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">创建一个普通队列，并设置队列的 TTL（x-message-ttl）参数，以及指定一个死信队列(x-dead-letter-exchange)</li>\n<li class=\"lvl-4\">当消息的 TTL 到期时，消息会被自动从当前队列中删除，并进入死信队列。</li>\n<li class=\"lvl-4\">为死信队列创建一个消费者，并监听死信队列，处理延迟消息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优先级队列\">优先级队列</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>优先级队列（Priority Queue）: RabbitMQ 支持为经典队列（classic queues）添加“优先级”功能。启用“优先级”功能的经典队列通常被称为“优先级队列”（priority queues）。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 支持 1 到 255 之间的优先级值，但强烈建议使用 1 到 5 之间的值。需要注意的是，优先级值越高，会消耗更多的 CPU 和内存资源，因为 RabbitMQ 在内部需要为每个优先级（从 1 到最大配置值）维护一个子队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>只有经典队列支持通过参数<code>x-max-priority</code>指定队列支持的最大优先级，且不支持 通过 策略（policies） 将经典队列声明为优先级队列。</p>\n</li>\n<li class=\"lvl-2\">\n<p>发布消息时，可以通过参数 <code>priority</code> 指定消息的优先级。是的，消息也是可以设置参数的。</p>\n</li>\n<li class=\"lvl-2\">\n<p>优先级队列如何与消费者协同工作</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">若消费者连接到一个 空队列，然后消息陆续被发布，那么这些消息可能 不会 在队列中等待（即刚发布就被消费者接收），此时优先级功能没有机会上场。优先级是在消息排队（ready 消息）状态时才能体现其作用。</li>\n<li class=\"lvl-4\">推荐在消费者端使用 basic.qos(prefetch) 设置（在 manual ack 模式下），以限制消费者同时处理的未确认消息数。这样能让优先级的分级效果更加明显，因为如果 prefetch 数量未满，高优先级消息可以先被取出。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>注意事项</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">未设置 <code>priority</code> 的消息 会被当作优先级 0 处理。若消息指定的优先级大于队列的最大值（x-max-priority），则该消息的优先级就是<code>x-max-priority</code>。</li>\n<li class=\"lvl-4\">TTL / 消息过期 (message expiration)：即使设置了 TTL，过期的消息只会在队列头被检查。这意味着如果一个低优先级的消息在前面但还没过期，而高优先级的消息在后面，低优先级的消息可能会阻塞队列头，导致高优先级的消息被延迟。</li>\n<li class=\"lvl-4\">队列最大长度限制 (max-length)：如果队列设置了最大长度，队列会从头部 (head) 丢弃消息以维持长度限制。这可能导致高优先级消息也被丢弃，从而违背直觉。</li>\n</ul>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 RabbitMQ 的 Queue 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 Queue(队列) 是什么？ 在 RabbitMQ 中，队列（Queue） 是一种用于存储消息的 数据结构，消息会一直保存在队列中，直到被应用程序或服务消费为止。 生产者（Publisher） 把消息放进队列，消费者（Consumer） 从队列中取出消息。队列中的消息会按照 FIFO（先进先出）的顺序进行消费。 队列在生产者和消费者之间起到缓冲区的作用。生产者不需要知道消费者的存在，它们只需把消息发送到队列。消费者可以根据自身处理速度，按需消费消息。 RabbitMQ 目前 支持三种队列类型： 队列类型 描述 特点 典型用途 Classic Queue（经典队列） 最常用的队列类型，消息按 FIFO（先进先出）顺序存储和消费 支持持久化、优先级、TTL、死信等 大多数常规消息场景 Quorum Queue（仲裁队列） 基于 Raft 协议的队列，确保高可用和数据一致性 内置复制（副本数量可配置）、适合高可靠性场景，但吞吐量略低于经典队列 关键任务消息、高可靠性场景 Stream Queue（流式队列） 面向大量消息的高吞吐队列，支持消息按偏移量读取 类似 Kafka，可随机访问历史消息、顺序读取、可持久化大量消息 大数据流、日志处理、事件溯源 Classic Queue(经典队列) RabbitMQ 经典队列（原始队列类型）是一种通用队列类型。实际上它是在 3.8.x 版本之前唯一的队列类型。 经典队列适用于数据安全不是优先事项的用例，因为存储在经典队列中的数据不会被复制。 经典队列使用非复制的 FIFO 队列实现。 经典队列不适合积累太多的消息，如果队列中积累的消息太多了，会严重影响客户端生产消息以及消费消息的性能。因此，经典队列主要用在数据量比较小，并且生产消息和消费消息的速度比较稳定的业务场景。比如内部系统之间的服务调用。 RabbitMQ 4.0 删除了对经典队列 version1 的支持，同时也不再支持将 经典队列 的消息在节点间复制。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Auto expire x-expires 整数（毫秒） 队列在 指定时间内无人使用（无消费者、无发布、无访问） 时自动删除 类似“队列空闲过期时间”，节省资源 Message TTL x-message-ttl 整数（毫秒） 消息的 存活时间，超过时间后消息会被丢弃或发送到死信队列 用于限制消息时效性，如延迟消息或短期缓存 Overflow behaviour x-overflow 字符串（drop-head 或 reject-publish） 当队列达到 最大长度 或 最大字节数 时的行为 - drop-head：丢弃最早的消息 - reject-publish：拒绝新的消息 Single active consumer x-single-active-consumer 布尔值（true/false） 是否启用 单活消费者模式，一次只允许一个消费者消费队列 用于严格顺序消费，保证某个消息不会被多个消费者同时处理 Dead letter exchange (DLX) x-dead-letter-exchange 字符串 指定队列的 死信交换机，用于接收无法消费或过期的消息 常用于失败重试、消息补偿场景 Dead letter routing key x-dead-letter-routing-key 字符串 消息转发到 DLX 时的 路由键 可以灵活转发到不同队列 Max length x-max-length 整数 队列中 最大消息条数 超过时按照 Overflow behaviour 处理 Max length bytes x-max-length-bytes 整数（字节） 队列中 消息总字节数上限 超过时按照 Overflow behaviour 处理，适合大消息场景 Maximum priority x-max-priority 整数 启用优先级队列时，队列可设置的 最大优先级值 消息优先级范围是 0 到这个值，优先级高的消息先被消费 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明队列时，队列主节点（Leader）的选取规则 client-local（默认）：选择客户端所在节点作为Leader balanced：在节点间均衡Leader分布，用于 HA 队列优化 Quorum Queue(仲裁队列) 仲裁队列（Quorum Queue） 是 RabbitMQ 从3.8.0版本之后引入的一种现代队列类型，也是目前官方比较推荐的一种对列类型。未来有可能取代 经典队列 成为默认队列类型。 其基于 Raft 共识算法 实现 持久化、复制和高可用。它保证 数据安全性、可靠的主节点选举，即使在升级或集群波动期间也能保持高可用性。 仲裁队列支持 毒消息处理、至少一次死信投递 以及 AMQP 修改（AMQP.modified）的处理结果。 它适合 以数据安全为首要目标 的场景。与经典队列相比，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。 仲裁队列（Quorum Queue）的 Durability 只能设置为 Durable(true)。Auto delete 只能为 No(false)。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Auto expire x-expires 整数（毫秒） 队列在指定时间内无人使用（无消费者、无发布、无访问）时自动删除 节省资源，队列空闲过期时间 Message TTL x-message-ttl 整数（毫秒） 队列中消息的生存时间，超过时间后消息会被丢弃或转入死信队列 控制消息时效性 Overflow behaviour x-overflow 字符串（drop-head 或 reject-publish） 当队列达到最大长度时的处理方式 drop-head：丢弃最早消息，reject-publish：拒绝新消息 Single active consumer x-single-active-consumer 布尔值（true/false） 是否启用单活消费者模式，一次只允许一个消费者消费队列 保证严格顺序消费 Dead letter exchange (DLX) x-dead-letter-exchange 字符串 指定队列的死信交换机，用于接收无法消费或过期的消息 与 DLX 配合使用处理失败消息 Dead letter routing key x-dead-letter-routing-key 字符串 消息转发到 DLX 时的路由键 灵活路由死信消息 Max length x-max-length 整数 队列中最大消息条数 超过时按 Overflow behaviour 处理 Max length bytes x-max-length-bytes 整数（字节） 队列消息总字节数上限 超过时按 Overflow behaviour 处理 Delivery limit x-delivery-limit 整数 消息允许投递的最大次数，超过后变为死信 控制消息重试次数 Initial cluster size x-quorum-initial-group-size 整数 队列在创建时需要的最小节点数 用于保证仲裁队列的高可用性 Target cluster size x-quorum-target-group-size 整数 队列运行时的目标节点数 当集群节点变化时，仲裁队列会尝试调整副本数量 Dead letter strategy x-dead-letter-strategy 字符串（at-most-once、at-least-once） 设置仲裁队列的死信处理策略 仅适用于 Quorum Queue。at-most-once（默认）：消息最多投递一次，可能丢失。at-least-once：确保消息至少投递一次，必须将 Overflow behaviour 设置为 reject-publish，否则回退到 at-most-once。 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明队列时，队列主节点（Leader）的选取规则 client-local：选择客户端所在节点作为 Leader balanced：在节点间均衡 Leader 分布 Quorum Queues 和 Classic Queues 的功能对比如下： Feature 中文含义 Classic queues Quorum queues 说明 Non-durable queues 非持久化队列 yes no Quorum queues 总是持久化，不支持非持久化 Message replication 消息复制 no yes Quorum queues 内置消息复制，Classic queues 需镜像策略 Exclusivity 独占队列 yes no Classic queues 支持独占队列，Quorum queues 不支持独占 Per message persistence 消息级持久化 per message always Quorum queues 消息总是持久化 Membership changes 节点成员变更 no semi-automatic Quorum queues 节点变化时半自动处理复制 Message TTL (Time-To-Live) 消息存活时间 yes yes 两者都支持消息过期时间 Queue TTL 队列存活时间 yes partially Quorum queues 的 lease 不会因重新声明而续期 Queue length limits 队列长度限制 yes yes Quorum queues 支持长度限制，但 x-overflow=reject-publish-dlx 不支持 Keeps messages in memory 消息内存保存 see Classic Queues never Quorum queues 消息总是写入磁盘，不保留在内存 Message priority 消息优先级 yes yes 支持消息优先级 Single Active Consumer 单活消费者 yes yes 支持单活消费者 Consumer exclusivity 独占消费者 yes no Quorum queues 不支持独占消费者，需使用 Single Active Consumer Consumer priority 消费者优先级 yes yes 支持消费者优先级 Dead letter exchanges 死信交换机 yes yes 支持死信交换机 Adheres to policies 遵循策略 yes yes 支持策略，但 Quorum queues 的部分策略行为不同 Poison message handling 毒消息处理 no yes Quorum queues 支持毒消息处理 Server-named queues 服务器自动命名队列 yes no Quorum queues 不支持服务器自动命名队列 Stream(流) Stream 是RabbitMQ自 3.9.0 版本开始引入的一种新的数据队列类型。这种队列类型的消息是持久化到磁盘并且具备分布式备份的，更适合于消费者多，读消息非常频繁的场景。 Stream 的核心是以append-only只添加的日志来记录消息，整体来说，就是消息将以append-only的方式持久化到日志文件中，然后通过调整每个消费者的消费进度offset，来实现消息的多次分发。 Stream 不支持死信交换机，不支持处理毒消息。 实际上 Stream 不属于队列，流（Streams） 是一种 持久化、可复制的数据结构，功能上类似队列：从生产者缓冲消息供消费者读取。但它与队列有两个重要区别： 存储模型 – 流是 追加日志（append-only log），消息可以 重复读取直到过期。 消费模型 – 流提供 非破坏性消费语义（non-destructive consumer semantics），多个消费者可以多次读取同一条消息而不会删除它。 Stream 始终是持久化和复制的，保证数据安全。消费者可以通过 RabbitMQ 客户端库 或 专用二进制协议插件 读取流，其中插件方式可以 访问所有流特性 并提供 最佳性能。合理的客户端连接策略有助于提升 吞吐量和效率。 参数说明(每个版本可能都有变化，具体以页面显示为准) 参数名称 配置参数名 数据类型 作用说明 备注 / 使用场景 Max length bytes x-max-length-bytes 整数（字节） 流中允许存储的 最大数据总字节数 超过时流将停止接收新消息，适合控制存储容量 Max time retention x-max-age 字符串（时间单位，例如 1h, 30m, 1d） 设置流队列中消息的 最大保留时间，超过时间的消息会被删除 支持时间单位：Y=年, M=月, D=天, h=小时, m=分钟, s=秒。例如 &quot;1h&quot; 表示只保留最近 1 小时的消息，用于控制数据量和自动清理过期消息 Max segment size in bytes x-stream-max-segment-size 整数（字节） 流分段存储时的 每个段的最大字节数 控制单个文件段大小，有利于 I/O 性能和管理 Filter size (per chunk) in bytes x-stream-filter-size-bytes 整数（字节） 流内部 过滤索引每块的大小 用于加速消息定位和读取，影响内存使用和检索效率 Initial cluster size x-initial-cluster-size 整数 流在创建时的 最小节点数 保证流的复制和高可用性 Leader locator x-queue-leader-locator 字符串（client-local、balanced） 设置在集群节点上声明流时，主节点（Leader）的选取规则 client-local：客户端所在节点作为 Leader（默认）balanced：在节点间均衡 Leader 分布，用于优化 HA Classic Queue vs Stream Queue Feature Matrix Feature 中文含义 Classic queues Stream queues 说明 Non-durable queues 非持久化队列 yes no Stream 队列总是持久化，不支持非持久化 Exclusivity 独占队列 yes no Classic 队列支持独占，Stream 队列不支持独占 Per message persistence 消息级持久化 per message always Stream 队列的消息总是持久化 Membership changes 节点成员变更 no manual Stream 队列节点变更需要手动管理 TTL 消息存活时间 yes no (but see Retention) Stream 队列没有消息 TTL，但可通过 Retention 控制过期 Queue length limits 队列长度限制 yes no (but see Retention) Stream 队列没有固定长度限制，通过 Retention 控制数据量 Keeps messages in memory 消息内存保存 see Classic Queues never Stream 队列消息不保存在内存中，只写入磁盘 Message priority 消息优先级 yes no Stream 队列不支持消息优先级 Consumer priority 消费者优先级 yes no Stream 队列不支持消费者优先级 Dead letter exchanges 死信交换机 yes no Stream 队列不支持死信交换机 Adheres to policies 遵循策略 yes yes (see Retention) Stream 队列支持策略，但主要通过 Retention 控制行为 Reacts to memory alarms 内存告警响应 yes no (uses minimal RAM) Stream 队列使用最小内存，不触发内存告警 Poison message handling 毒消息处理 no no Stream 队列不支持毒消息处理 我们可以激活流插件来使用流的特有功能 1rabbitmq-plugins enable rabbitmq_stream rabbitmq_stream_management 激活流插件后，Stream队列的操作方式可以更高级，具体可以参考官方文档，作者在Java Client 示例中也给出了示例代码。 超级流(Super Streams) 超级流（Super streams） 是一种通过将一个大的流分区成更小的流来实现扩展的方式。它们与 单个消费者（Single Active Consumer） 集成，以在分区内保持消息顺序。超级流从 RabbitMQ 3.11 开始可用。 一个超级流是由多个普通流组成的逻辑流。它是一种通过 RabbitMQ Streams 来扩展发布和消费的方法：一个大型逻辑流被划分成多个分区流，将存储和流量分散到多个集群节点上。 超级流依然是一个逻辑实体：由于客户端库的智能化处理，应用程序会把它视为一个“大型”流。超级流的拓扑结构基于 AMQP 0.9.1 模型，也就是交换机（exchange）、队列（queue）和它们之间的绑定（binding）。 可以使用任何 AMQP 0.9.1 库或管理插件创建超级流的拓扑。它需要创建一个直连交换机（direct exchange）、分区流（partition streams），并将它们绑定在一起。 通过管理控制台创建超级流 也可以通过命令创建超级流，以下是如何用命令创建一个包含 3 个分区的超级流： 12# rabbitmq-streams add_super_stream [-p &lt;vhost&gt;] &lt;stream-name&gt; [--partitions &lt;number&gt;]rabbitmq-streams add_super_stream -p /vtest sq_3 --partitions 3 创建的Stream 创建的 Exchange，名称 sq_3 绑定关系 队列类型扩展 懒队列 从3.6.x版本到3.12.x版本，RabbitMQ提供了一种针对Classic Queue的优化配置，lazy-mode，懒对列。懒队列会尽可能早的将消息内容保存到硬盘当中，并且只有在用户请求到时，才临时从硬盘加载到RAM内存当中。 默认情况下，RabbitMQ接收到消息时，会保存到内存以便使用，同时把消息写到硬盘。但是，消息写入硬盘的过程中，是会阻塞队列的。RabbitMQ虽然针对写入硬盘速度做了很多算法优化，但是在长队列中，依然表现不是很理想，所以就有了懒队列的出现。 懒队列会尝试尽可能早的把消息写到硬盘中。这意味着在正常操作的大多数情况下，RAM中要保存的消息要少得多。当然，这是以增加磁盘IO为代价的。 懒队列适合消息量大且长期有堆积的队列，可以减少内存使用，加快消费速度。但是这是以大量消耗集群的网络及磁盘IO为代价的。 从3.12往后的版本中，RabbitMQ 不再支持“惰性”模式，因为 经典队列 当前的特性就类似于以前的 懒队列。 死信队列 死信队列（Dead Letter Queue），新版中叫做 死信交换机（Dead Letter Exchange, DLX），是RabbitMQ对于未能正常消费的消息进行的一种补救机制，用于保存无法被正常处理的消息。当消息被消费者处理失败时，RabbitMQ会将消息发送到死信队列中，等待消费者处理。 死信队列也是一个普通的队列，同样可以在队列上声明消费者，继续对消息进行消费处理。 有以下几种情况，RabbitMQ会将一个正常消息转成死信 消息被拒绝（Message rejection） 由 AMQP 1.0 接收端使用 rejected 结果拒绝 由 AMQP 0.9.1 消费者使用 basic.reject 或 basic.nack，并且参数 requeue=false 消息过期（Message expiration） 消息超过其配置的 TTL（生存时间） 后过期。 队列长度超限（Queue length exceeded） 队列中的消息数量或总字节数达到配置的最大限制后，被丢弃的消息会死信化。 投递次数超限（仅适用于仲裁队列 Quorum Queue） 消息的投递次数超过了仲裁队列中配置的 delivery-limit。 使用场景 你可以在队列上配置 死信交换机（DLX） 和 死信路由键（Dead Letter Routing Key）。 当消息成为死信时，会被 重新发布到 DLX，这样你可以： 做错误日志记录 进行失败消息重试 用于监控和告警 死信交换机的配置方法（How Dead Lettering is Configured） 在 RabbitMQ 中，任何队列都可以通过 客户端 或者 策略（policies） 来配置 死信交换机（DLX）。 配置时主要涉及两个核心参数： 配置参数名 说明 dead-letter-exchange 指定用于接收死信消息的 死信交换机名称 dead-letter-routing-key 指定死信消息重新发布时使用的 路由键（Routing Key） 死信在转移到死信队列时，他的 routingkey 也会保存下来。但是如果配置了 x-dead-letter-routing-key 这个参数的话，routingkey 就会被替换为配置的这个值。 在创建队列时，我们可以通过为队列添加 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数，来指定 死信交换机（DLX）和 死信路由键（Dead Letter Routing Key）。但是这样做很麻烦，每个队列都要单独配置，因此，我们可以使用 策略（policies） 来统一配置。 1234# 仅指定死信交换机，这里交换机的名称是 my-dlx，交换机要提前创建好rabbitmqctl set_policy DLX &quot;.*&quot; &#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;&#125;&#x27; --apply-to queues --priority 7# 同时指定 死信交换机 和 路由键rabbitmqctl set_policy DLX &quot;.*&quot; &#x27;&#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125;&#x27; --apply-to queues --priority 7 参数说明： 部分 含义 rabbitmqctl RabbitMQ 的命令行管理工具 set_policy 设置一个策略（Policy），用于动态配置交换机、队列或绑定的参数 DLX 策略的名称，用户自定义，例如这里叫 DLX &quot;.*&quot; 正则表达式，匹配对象的名称。.* 表示匹配 所有队列，也可以指定具体队列名，比如 ^my-queue$ &#123;&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;, &quot;dead-letter-routing-key&quot;:&quot;my-routing-key&quot;&#125; 策略内容，这里设置了死信交换机名称和路由键： - dead-letter-exchange: 设置死信交换机名称为 my-dlx - dead-letter-routing-key: 设置路由键为 my-routing-key --apply-to queues 指定策略作用对象为 队列（queues），而不是交换机（exchanges）或绑定（bindings） --priority 7 策略的优先级，值越大优先级越高。多个策略作用在同一对象时，优先级高的会覆盖低的 执行这条命令后： 所有队列都会自动带上 x-dead-letter-exchange=my-dlx 和 x-dead-letter-routing-key=my-routing-key 配置。 队列中被拒绝、过期、超长或超过投递次数的消息会被重新发布到 my-dlx 交换机，并使用 my-routing-key 作为路由键。 消息被作为死信转移到死信队列后，会在Header当中增加⼀些消息。 123456x-first-death-queue：该消息首次成为死信时所在的队列名称x-first-death-reason：该消息首次被判定为死信的原因x-first-death-exchange：该消息在首次成为死信前被发布到的交换机名称x-last-death-queue：该消息最近一次成为死信时所在的队列名称x-last-death-reason：该消息最近一次被判定为死信的原因x-last-death-exchange：该消息在最近一次成为死信前被发布到的交换机名称 延迟队列 延迟队列（Delayed Message Queue）: 延迟队列是一种特殊类型的队列，用于延迟消息的投递。 RabbitMQ中，是不存在延迟队列的功能的，而通常如果要用到延迟队列，就会采用 TTL + 死信队列 的方式来实现。 延迟队列的实现原理： 创建一个普通队列，并设置队列的 TTL（x-message-ttl）参数，以及指定一个死信队列(x-dead-letter-exchange) 当消息的 TTL 到期时，消息会被自动从当前队列中删除，并进入死信队列。 为死信队列创建一个消费者，并监听死信队列，处理延迟消息。 优先级队列 优先级队列（Priority Queue）: RabbitMQ 支持为经典队列（classic queues）添加“优先级”功能。启用“优先级”功能的经典队列通常被称为“优先级队列”（priority queues）。 RabbitMQ 支持 1 到 255 之间的优先级值，但强烈建议使用 1 到 5 之间的值。需要注意的是，优先级值越高，会消耗更多的 CPU 和内存资源，因为 RabbitMQ 在内部需要为每个优先级（从 1 到最大配置值）维护一个子队列。 只有经典队列支持通过参数x-max-priority指定队列支持的最大优先级，且不支持 通过 策略（policies） 将经典队列声明为优先级队列。 发布消息时，可以通过参数 priority 指定消息的优先级。是的，消息也是可以设置参数的。 优先级队列如何与消费者协同工作 若消费者连接到一个 空队列，然后消息陆续被发布，那么这些消息可能 不会 在队列中等待（即刚发布就被消费者接收），此时优先级功能没有机会上场。优先级是在消息排队（ready 消息）状态时才能体现其作用。 推荐在消费者端使用 basic.qos(prefetch) 设置（在 manual ack 模式下），以限制消费者同时处理的未确认消息数。这样能让优先级的分级效果更加明显，因为如果 prefetch 数量未满，高优先级消息可以先被取出。 注意事项 未设置 priority 的消息 会被当作优先级 0 处理。若消息指定的优先级大于队列的最大值（x-max-priority），则该消息的优先级就是x-max-priority。 TTL / 消息过期 (message expiration)：即使设置了 TTL，过期的消息只会在队列头被检查。这意味着如果一个低优先级的消息在前面但还没过期，而高优先级的消息在后面，低优先级的消息可能会阻塞队列头，导致高优先级的消息被延迟。 队列最大长度限制 (max-length)：如果队列设置了最大长度，队列会从头部 (head) 丢弃消息以维持长度限制。这可能导致高优先级消息也被丢弃，从而违背直觉。","summary":"摘要 本文介绍 RabbitMQ 的 Queue 的基本概念和用法。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-20T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/","url":"https://blog.hanqunfeng.com/2025/09/18/rabbitmq-install-01/","title":"RabbitMQ 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 RabbitMQ 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 RabbitMQ 版本为 4.1.4。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/rabbitmq-demo\">Java Client 示例</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"RabbitMQ-简介\">RabbitMQ 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 是一个开源的 消息队列中间件，基于 AMQP（Advanced Message Queuing Protocol，高级消息队列协议） 实现，用于在分布式系统中 解耦、缓冲和异步处理消息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它的主要作用是让 <code>不同系统</code> 或 <code>应用</code> 之间可靠地传递消息，即使发送方或接收方暂时不可用，也能保证消息不丢失。</p>\n</li>\n<li class=\"lvl-2\">\n<p>RabbitMQ 的核心特点</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>核心特点</th>\n<th>具体说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>可靠性</strong></td>\n<td>- 支持消息确认（ACK）机制<br>- 消息持久化到磁盘<br>- 支持事务或确认模式，保证消息不会丢失</td>\n</tr>\n<tr>\n<td><strong>灵活的路由</strong></td>\n<td>- 通过 <strong>交换机（Exchange）</strong> 将消息路由到不同的 <strong>队列（Queue）</strong><br>- 支持多种路由策略：<br>  • direct：直连，按队列名路由<br>  • fanout：广播，所有队列都收到<br>  • topic：主题匹配，类似订阅模式<br>  • headers：按消息头匹配</td>\n</tr>\n<tr>\n<td><strong>高性能</strong></td>\n<td>- 内存队列快速处理消息<br>- 支持异步 IO 和 Erlang 的并发模型</td>\n</tr>\n<tr>\n<td><strong>多语言支持</strong></td>\n<td>- 客户端库丰富：Java、Python、Go、C#、Node.js 等<br>- 可在多种平台和框架中使用</td>\n</tr>\n<tr>\n<td><strong>集群与高可用</strong></td>\n<td>- 支持集群模式<br>- 队列可以镜像到多个节点，保证高可用</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的核心概念</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>含义</th>\n<th>作用范围</th>\n<th>类比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Broker</strong></td>\n<td>一个 <strong>RabbitMQ 服务实例</strong>，包含整个 AMQP 服务、管理插件、队列、交换机等资源</td>\n<td>运行在一台服务器上，或集群中的一个节点</td>\n<td>类似于数据库的 <strong>实例</strong></td>\n</tr>\n<tr>\n<td><strong>Vhost</strong></td>\n<td>Broker 内部的 <strong>逻辑分区</strong>，用于隔离不同的队列、交换机、绑定等资源</td>\n<td>一个 Broker 可以有多个 vhost，每个 vhost 彼此隔离</td>\n<td>类似于数据库实例里的 <strong>schema</strong>，实际使用中建议为每个业务配置一个独立的 vhost，并为每个vhost单独配置一个管理用户</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Producer</strong></td>\n<td>消息生产者，发送消息到 RabbitMQ</td>\n</tr>\n<tr>\n<td><strong>Queue</strong></td>\n<td>队列，存储消息的地方</td>\n</tr>\n<tr>\n<td><strong>Consumer</strong></td>\n<td>消息消费者，从队列获取消息</td>\n</tr>\n<tr>\n<td><strong>Exchange</strong></td>\n<td>交换机，接收 Producer 的消息并根据规则路由到队列</td>\n</tr>\n<tr>\n<td><strong>Binding</strong></td>\n<td>绑定，定义 Exchange 与 Queue 的路由规则</td>\n</tr>\n<tr>\n<td><strong>Message</strong></td>\n<td>消息，RabbitMQ 传递的数据单元</td>\n</tr>\n<tr>\n<td><strong>Connection</strong></td>\n<td>连接，客户端与 RabbitMQ Broker 之间的 <strong>TCP 连接</strong>，是通信的物理通道</td>\n</tr>\n<tr>\n<td><strong>Channel</strong></td>\n<td>通道，Connection 内部的 <strong>逻辑连接</strong>，轻量级且多路复用，一个连接可开多个通道</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                        ┌─ Broker (RabbitMQ 实例)──────────┐</span><br><span class=\"line\">                        │                                 │</span><br><span class=\"line\">                        │    ┌───── Virtual Host ─────┐   │</span><br><span class=\"line\">        Producer ─── TCP ──────&gt; Exchange ──&gt; Queue ────────&gt; TCP ── Consumer</span><br><span class=\"line\">(Connection ──&gt; Channel)│    └────────────────────────┘   │</span><br><span class=\"line\">                        │                                 │</span><br><span class=\"line\">                        └─────────────────────────────────┘</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/qgdFHL.png\" alt=\"\"></p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的典型应用场景</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>应用场景</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>异步处理</strong></td>\n<td>用户请求不直接处理，消息入队后由后台异步消费，例如邮件发送、图片处理</td>\n</tr>\n<tr>\n<td><strong>削峰填谷</strong></td>\n<td>缓冲高峰流量，平滑系统压力</td>\n</tr>\n<tr>\n<td><strong>系统解耦</strong></td>\n<td>不同服务之间不直接调用，降低耦合</td>\n</tr>\n<tr>\n<td><strong>广播/通知</strong></td>\n<td>发布/订阅模式，实现多服务同时收到消息</td>\n</tr>\n<tr>\n<td><strong>日志收集</strong></td>\n<td>统一接收、分发日志到不同处理系统</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-4-0-有哪些升级\">RabbitMQ 4.0+ 有哪些升级</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>特性标志（Feature Flags）的优化与强制性要求</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>在升级到 4.0 之前，用户必须先升级到 3.13.x 版本并手动启用所有稳定的特性标志。</p>\n</li>\n<li class=\"lvl-3\">\n<p>从 4.0+ 开始，如果集群中的所有节点都支持某个必需的特性标志，系统会在节点启动时自动启用该标志，无需人工干预。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>AMQP 协议的增强</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>新增了对 AMQP 过滤表达式（AMQP Filter Expressions）Version 1.0 Working Draft 09 的支持。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>MQTT 协议的改进</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>默认的 MQTT 最大包大小从之前的 256 MiB 降低到 16 MiB，同时仍允许用户通过配置项 mqtt.max_packet_size_authenticated 自定义该值</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Classic队列的变化</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>删除了对 Classic队列 <code>version1</code> 的支持，默认就是 <code>version2</code></p>\n</li>\n<li class=\"lvl-3\">\n<p>不再支持 Classic队列 的镜像功能，官方推荐使用 Quorum 队列 ，未来会将 Quorum 队列 作为默认队列。</p>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群状态下创建 Quorum 队列 和 Stream 队列 会自动升级为 复制队列（镜像）</p>\n</li>\n</ul>\n<h2 id=\"RabbitMQ-单机安装\">RabbitMQ 单机安装</h2>\n<h3 id=\"安装Erlang\">安装Erlang</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ是基于Erlang语言开发的，所以安装RabbitMQ之前需要安装Erlang语言环境。需要注意的是RabbitMQ与Erlang语言之间是有版本对应关系的。参考官方文档<a href=\"https://www.rabbitmq.com/docs/which-erlang\">Erlang Version Requirements</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>目前RabbitMQ最新版本是<code>4.1.4</code>，Erlang版本可以选择 <code>27.x</code>，<a href=\"https://github.com/rabbitmq/erlang-rpm/releases\">GitHub下载地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载 el9 的版本，对应 CentOS 9</span></span><br><span class=\"line\">wget https://github.com/rabbitmq/erlang-rpm/releases/download/v27.3.4.3/erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rpm -ivh erlang-27.3.4.3-1.el9.x86_64.rpm</span><br><span class=\"line\"><span class=\"comment\"># 查看安装的版本</span></span><br><span class=\"line\">erl</span><br><span class=\"line\"><span class=\"comment\"># 输出类似于，这里 Erlang/OTP 27 就表示安装的是 27.x 版本</span></span><br><span class=\"line\">Erlang/OTP 27 [erts-15.2.7.2] [<span class=\"built_in\">source</span>] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:1] [jit:ns]</span><br><span class=\"line\"></span><br><span class=\"line\">Eshell V15.2.7.2 (press Ctrl+G to abort, <span class=\"built_in\">type</span> <span class=\"built_in\">help</span>(). <span class=\"keyword\">for</span> <span class=\"built_in\">help</span>)</span><br><span class=\"line\">1&gt; q().  <span class=\"comment\"># 退出命令，注意是括号后面还有一个点。输入 help(). 显示帮助信息</span></span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装-RabbitMQ\">安装 RabbitMQ</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>目前RabbitMQ最新版本是<code>4.1.4</code>，<a href=\"https://github.com/rabbitmq/rabbitmq-server/releases\">GitHub下载地址</a>]</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载，noarch 表示架构无关，即 X86_64 和 ARM64 都可以</span></span><br><span class=\"line\"><span class=\"comment\"># 因为没有对应的 el9 的包，所以只能用 el8 的包了，实际使用中没有问题。</span></span><br><span class=\"line\">wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v4.1.4/rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rpm -ivh rabbitmq-server-4.1.4-1.el8.noarch.rpm</span><br><span class=\"line\"><span class=\"comment\"># 查看版本信息</span></span><br><span class=\"line\">rabbitmq-diagnostics version <span class=\"comment\"># 无需启动服务</span></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ 服务启动后方可正确输出</span></span><br><span class=\"line\">rabbitmqctl version</span><br></pre></td></tr></table></figure>\n<h3 id=\"RabbitMQ-启动与停止命令\">RabbitMQ 启动与停止命令</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Erlang VM 是 Erlang 语言运行环境，RabbitMQ 应用运行在 Erlang VM 下。</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动 RabbitMQ 服务(Erlang VM) + 应用</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者，--detached 后台运行，不加就是前台运行</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmq-server -detached</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 单独启动 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl start_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>停止 RabbitMQ 服务(Erlang VM) + 应用</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停止 RabbitMQ 服务(Erlang VM) + 应用</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者，单机模式 stop，集群模式 shutdown</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl stop / shutdown</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 单独停止 RabbitMQ 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl stop_app</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看RabbitMQ 服务状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl status rabbitmq-server</span><br><span class=\"line\"><span class=\"comment\"># 或者</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl status</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 在 CentOS 9 (RPM 安装) 的目录结构</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>目录路径</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>配置文件</td>\n<td><code>/etc/rabbitmq</code></td>\n<td><code>rabbitmq.conf</code>、<code>advanced.config</code> 等配置</td>\n</tr>\n<tr>\n<td>日志文件</td>\n<td><code>/var/log/rabbitmq</code></td>\n<td>RabbitMQ 运行日志，默认存放在这里</td>\n</tr>\n<tr>\n<td>数据目录</td>\n<td><code>/var/lib/rabbitmq/mnesia</code></td>\n<td>消息队列、元数据存储目录</td>\n</tr>\n<tr>\n<td>Erlang Cookie</td>\n<td><code>/var/lib/rabbitmq/.erlang.cookie</code></td>\n<td>Erlang 节点间通信的 cookie 文件</td>\n</tr>\n<tr>\n<td>可执行文件</td>\n<td><code>/usr/lib/rabbitmq/bin</code></td>\n<td><code>rabbitmq-server</code>、<code>rabbitmqctl</code> 等命令</td>\n</tr>\n<tr>\n<td>启动脚本</td>\n<td><code>/usr/lib/systemd/system/rabbitmq-server.service</code></td>\n<td>systemd 管理 RabbitMQ 的启动脚本</td>\n</tr>\n<tr>\n<td>插件目录</td>\n<td><code>/usr/lib/rabbitmq/lib/rabbitmq_server-&lt;version&gt;/plugins</code></td>\n<td>所有插件文件存放路径</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"激活Web管理控制台插件\">激活Web管理控制台插件</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>对于 RabbitMQ 所有的操作基本都可以通过命令行完成，但是使用起来并不方便，这时我们可以激活 <code>rabbitmq_management</code> 插件，该插件提供了 Web 管理控制台，我们可以通过 Web 管理控制台来管理 RabbitMQ</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://www.rabbitmq.com/docs/management\">rabbitmq_management</a> 插件为 官方插件，默认已经安装，不需要下载，直接激活即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 激活插件</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmq-plugins <span class=\"built_in\">enable</span> rabbitmq_management</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>该插件除了提供了 <code>Web 管理控制台</code> ，还提供 <code>基于 HTTP 的 API</code> 用于管理和监控 RabbitMQ 节点和集群，以及 <code>命令行工具 rabbitmqadmin</code>，这个后面会介绍。</p>\n</li>\n</ul>\n<h4 id=\"设置远程访问帐号\">设置远程访问帐号</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>插件激活后可以通过浏览器访问 <code>http://&lt;ip&gt;:15672</code>，rabbitmq_management 插件默认用户名和密码都是 <code>guest</code>，但是默认情况下其只能通过 <code>127.0.0.1</code> 访问，此时我们有两种方法可以解决</p>\n</li>\n</ul>\n<h5 id=\"1-允许-guest-账号远程访问\">1. 允许 <code>guest</code> 账号远程访问</h5>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 修改 /etc/rabbitmq/rabbitmq.conf 文件</span></span><br><span class=\"line\"><span class=\"comment\"># 允许guest用户远程访问，`官方不推荐` 一直开启，建议开启后在 web 控制台中创建一个管理员账号，然后立刻关闭该配置</span></span><br><span class=\"line\">loopback_users.guest = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 默认的用户名和密码，注意这里 user 如果改成 admin，则上面的开启远程访问中的 guest 也要改成 admin</span></span><br><span class=\"line\">default_user = guest</span><br><span class=\"line\">default_pass = guest</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改完成后，重启 RabbitMQ 服务</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl restart rabbitmq-server</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-新创建一个可以远程访问的管理员账号\">2. 新创建一个可以远程访问的管理员账号</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建管理员账号，比如这里 用户名为 <code>admin</code>，密码为 <code>rabbitmq</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl add_user admin rabbitmq</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>给管理员账号添加资源管理权限</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl set_permissions -p / admin <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&quot;.*&quot;</span> <span class=\"string\">&quot;.*&quot;</span></span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具，用于管理用户、权限、队列、交换机等。</td>\n</tr>\n<tr>\n<td><code>set_permissions</code></td>\n<td>设置指定用户在某个虚拟主机（vhost）下的权限。</td>\n</tr>\n<tr>\n<td><code>-p /</code></td>\n<td>指定虚拟主机（vhost）。这里的 <code>/</code> 是默认虚拟主机。</td>\n</tr>\n<tr>\n<td><code>admin</code></td>\n<td>用户名，这里是为 <code>admin</code> 用户设置权限。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（配置权限）</td>\n<td>第一个正则表达式，控制用户对资源配置的权限，比如创建交换机、队列、绑定等。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（写权限）</td>\n<td>第二个正则表达式，控制用户向哪些资源发送消息。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n<tr>\n<td><code>&quot;.*&quot;</code>（读权限）</td>\n<td>第三个正则表达式，控制用户从哪些资源消费消息。<code>&quot;.*&quot;</code> 表示全部允许。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>设置admin账号为控制台管理员</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> rabbitmqctl set_user_tags admin administrator</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>部分</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>RabbitMQ 的命令行管理工具。</td>\n</tr>\n<tr>\n<td><code>set_user_tags</code></td>\n<td>用来为用户设置标签（tag），标签决定了用户在管理界面或 API 中的权限级别。</td>\n</tr>\n<tr>\n<td><code>admin</code></td>\n<td>用户名，这里是为 <code>admin</code> 用户设置标签。</td>\n</tr>\n<tr>\n<td><code>administrator</code></td>\n<td>标签名，表示给该用户赋予管理员权限。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>常见的用户标签</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>标签</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>administrator</code></td>\n<td>管理员，拥有最高权限，可通过 Web 管理界面、CLI、API 管理 RabbitMQ 所有内容</td>\n</tr>\n<tr>\n<td><code>monitoring</code></td>\n<td>监控用户，可查看所有监控信息，但不能修改配置</td>\n</tr>\n<tr>\n<td><code>management</code></td>\n<td>普通管理用户，可以登录管理界面，但权限受限</td>\n</tr>\n<tr>\n<td><code>policymaker</code></td>\n<td>策略管理用户，可以管理策略和参数，但不能管理其他用户</td>\n</tr>\n<tr>\n<td>无标签</td>\n<td>普通用户，只能收发消息，不能登录管理界面</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>set_permissions</code> 与 <code>set_user_tags</code> 总结对比</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>控制范围</th>\n<th>主要作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>set_permissions</code></td>\n<td>vhost 内的资源</td>\n<td>发消息、收消息、创建队列、交换机</td>\n</tr>\n<tr>\n<td><code>set_user_tags</code></td>\n<td>管理界面、管理 API</td>\n<td>用户管理、策略管理、集群管理</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/4lP2cD.png\" alt=\"\"></p>\n<h3 id=\"启用所有稳定的-Feature-Flags\">启用所有稳定的 Feature Flags</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录控制台后我们会看到一条告警信息，参考：<a href=\"https://www.rabbitmq.com/docs/feature-flags\">Feature Flags</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">⚠ All stable feature flags must be enabled after completing an upgrade.</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>它的意思是：RabbitMQ 在新版本中引入了一些 Feature Flags（特性标志），这些特性标志用于控制一些新的功能或行为是否启用。升级 RabbitMQ 后，有些功能会处于 <code>未启用状态</code>，需要你手动开启，确保集群完全运行在最新的功能模式下。</p>\n</li>\n<li class=\"lvl-2\">\n<p>背景：为什么有 Feature Flags？</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">向后兼容：RabbitMQ 升级时，可能引入了新的数据格式或内部机制，如果立即启用，旧版本节点可能无法理解。</li>\n<li class=\"lvl-4\">滚动升级支持：升级集群时，可以先升级节点，再统一启用功能，避免中途出问题。</li>\n<li class=\"lvl-4\">可控性：你可以选择在确认集群稳定后再启用新功能。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>查看当前 Feature Flags 状态</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl -q --formatter pretty_table list_feature_flags</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出会类似这样：</span></span><br><span class=\"line\">┌──────────────────────────────────────┬──────────┐</span><br><span class=\"line\">│ name                                 │ state    │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ classic_mirrored_queue_version       │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ classic_queue_type_delivery_support  │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ detailed_queues_endpoint             │ disabled │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\">│ direct_exchange_routing_v2           │ enabled  │</span><br><span class=\"line\">├──────────────────────────────────────┼──────────┤</span><br><span class=\"line\"></span><br><span class=\"line\">&gt; enabled：特性已启用</span><br><span class=\"line\">&gt; disabled：特性未启用</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>可以输出 其它 格式，显示更详细的信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># json</span></span><br><span class=\"line\">rabbitmqctl -q --formatter json list_feature_flags name state provided_by desc doc_url | jq</span><br><span class=\"line\"><span class=\"comment\"># table</span></span><br><span class=\"line\">rabbitmqctl -q --formatter pretty_table list_feature_flags name state provided_by desc doc_url</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启用所有已标记为 stable 的特性，建议升级下一个 RabbitMQ 版本 前一定要确保当前版本的 Feature Flags 都是启用的，避免升级后无法顺利启动服务。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rabbitmqctl enable_feature_flag all</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在控制台中也可以查看和开启这些 Feature Flags 的状态<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/VqNm1y.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里要注意，<strong>Feature Flags 一旦开启就无法关闭。</strong></p>\n</li>\n</ul>\n<h2 id=\"RabbitMQ-配置文件\">RabbitMQ 配置文件</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>对于 RPM/YUM/DNF 安装的 RabbitMQ，配置文件默认路径是</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>文件类型</th>\n<th>默认位置</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>主配置文件（推荐）</td>\n<td><code>/etc/rabbitmq/rabbitmq.conf</code></td>\n<td>使用 <strong>INI 格式</strong>，主要配置都在这里</td>\n</tr>\n<tr>\n<td>环境变量配置</td>\n<td><code>/etc/rabbitmq/rabbitmq-env.conf</code></td>\n<td>定义节点名、Cookie 位置、数据/日志目录等</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>安装后 <code>/etc/rabbitmq/</code> 目录可能是空的，你需要手动创建 <code>rabbitmq.conf</code>，详细的参数说明可以参看<a href=\"https://rabbitmq.com/configure.html\">官网指南</a>，<a href=\"https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbit/docs/rabbitmq.conf.example\">rabbitmq.conf 示例</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/rabbitmq/rabbitmq.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 监听端口</span></span><br><span class=\"line\">listeners.tcp.default = 5672</span><br><span class=\"line\"><span class=\"comment\"># 管理界面端口</span></span><br><span class=\"line\">management.tcp.port = 15672</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmq-env.conf</code> 用来 定义节点名、Cookie 、数据/日志目录等的环境变量，RabbitMQ 启动时会自动读取该文件，以下是通过 RPM 安装的 RabbitMQ 的默认值</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># /etc/rabbitmq/rabbitmq-env.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 节点名称，默认使用主机短名(hostname -s)，例如 rabbit@myhost</span></span><br><span class=\"line\">NODENAME=rabbit@&lt;hostname&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绑定的 IP 地址，留空表示监听所有地址，等价于 0.0.0.0</span></span><br><span class=\"line\">NODE_IP_ADDRESS=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># AMQP 协议端口，默认 5672</span></span><br><span class=\"line\">NODE_PORT=5672</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># RabbitMQ 数据库存储目录</span></span><br><span class=\"line\">MNESIA_BASE=/var/lib/rabbitmq/mnesia</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 日志存放目录</span></span><br><span class=\"line\">LOG_BASE=/var/log/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置文件路径，不带 .conf 后缀</span></span><br><span class=\"line\">CONFIG_FILE=/etc/rabbitmq/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 是否使用长主机名，true/false (长主机名 hostname -f)</span></span><br><span class=\"line\">USE_LONGNAME=<span class=\"literal\">false</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>两个文件的作用</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>文件</th>\n<th>作用范围</th>\n<th>典型参数</th>\n<th>何时加载</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>rabbitmq-env.conf</strong></td>\n<td>设置 RabbitMQ 启动时的 <strong>环境变量</strong></td>\n<td>NODENAME, NODE_IP_ADDRESS, NODE_PORT, LOG_BASE, MNESIA_BASE</td>\n<td>在启动 RabbitMQ 服务前由 <code>rabbitmq-env</code> 脚本读取</td>\n</tr>\n<tr>\n<td><strong>rabbitmq.conf</strong></td>\n<td>RabbitMQ <strong>运行时配置</strong>（内部参数、插件配置等）</td>\n<td>listeners.tcp.default, log, cluster_formation 等</td>\n<td>RabbitMQ 启动后由 Erlang VM 内部读取</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p><code>rabbitmq-env.conf</code> 决定 RabbitMQ 启动时的基本环境，比如节点名、数据目录、监听 IP 等，必须在启动前就确定。</p>\n</li>\n<li class=\"lvl-4\">\n<p><code>rabbitmq.conf</code> 决定运行时的功能，比如端口监听、日志等级、集群配置等，可以动态修改，重启应用后生效。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><code>rabbitmq-env.conf</code> 变量</th>\n<th><code>rabbitmq.conf</code> 对应配置</th>\n<th>优先级</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NODE_IP_ADDRESS</td>\n<td><code>listeners.tcp.default = &lt;IP&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>只要在 <code>rabbitmq.conf</code> 里配置，就覆盖环境变量</td>\n</tr>\n<tr>\n<td>NODE_PORT</td>\n<td><code>listeners.tcp.default = &lt;Port&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>同上，IP 和端口可以一起配置</td>\n</tr>\n<tr>\n<td>NODENAME</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>节点名只能通过 <code>rabbitmq-env.conf</code> 或环境变量设定</td>\n</tr>\n<tr>\n<td>MNESIA_BASE</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>数据目录只能在启动前设定</td>\n</tr>\n<tr>\n<td>LOG_BASE</td>\n<td><code>log.dir = &lt;path&gt;</code></td>\n<td><code>rabbitmq.conf</code></td>\n<td>运行时配置覆盖环境变量</td>\n</tr>\n<tr>\n<td>CONFIG_FILE</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>这个只决定加载哪个 <code>rabbitmq.conf</code> 文件</td>\n</tr>\n<tr>\n<td>USE_LONGNAME</td>\n<td><strong>无直接对应</strong></td>\n<td><code>rabbitmq-env.conf</code></td>\n<td>节点名是否使用长主机名只能启动前决定</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-环境变量\">RabbitMQ 环境变量</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmq-env.conf</code> 文件就是用来定义环境变量的，但要注意，<code>rabbitmq-env.conf</code> 文件中定义的变量 去掉了 <code>RABBITMQ_</code> 前缀，例如在环境中设置的变量名通常是 <code>RABBITMQ_NODENAME</code>，但在 <code>rabbitmq-env.conf</code> 中，设置变量时会去掉 <code>RABBITMQ_</code> 前缀，直接使用 <code>NODENAME</code>。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在 rabbitmq-env.conf 中配置</span></span><br><span class=\"line\">NODENAME=rabbit@localhost</span><br><span class=\"line\">NODE_PORT=5672</span><br><span class=\"line\">LOG_BASE=/var/log/rabbitmq</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 而在环境中，你实际设置的变量是</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_NODENAME=rabbit@localhost</span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_NODE_PORT=5672</span><br><span class=\"line\"><span class=\"built_in\">export</span> RABBITMQ_LOG_BASE=/var/log/rabbitmq</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th>环境变量名称</th>\n<th>描述</th>\n<th>Linux RPM 安装的默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>RABBITMQ_BASE</strong></td>\n<td>只针对 Windows 系统。该基目录包含 RabbitMQ 服务器的数据库和日志文件的子目录。</td>\n<td>无（仅适用于 Windows）</td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_CONFIG_FILE</strong></td>\n<td>配置文件的路径，没有 <code>.config</code> 扩展名。RabbitMQ 服务器使用该配置文件来配置组件。</td>\n<td>默认配置文件路径：<code>/etc/rabbitmq/rabbitmq.conf</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_GENERATED_CONFIG_DIR</strong></td>\n<td>RabbitMQ 写入其生成的配置文件的目录。</td>\n<td>默认生成路径：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_MNESIA_BASE</strong></td>\n<td>RabbitMQ 服务器节点数据库、消息存储和集群状态文件的基目录，每个节点一个。通常会覆盖 <code>RABBITMQ_MNESIA_DIR</code>。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_MNESIA_DIR</strong></td>\n<td>存储 RabbitMQ 节点数据的目录，包含模式数据库、消息存储、集群成员信息和其他持久节点状态。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_SCHEMA_DIR</strong></td>\n<td>RabbitMQ 保存新格式配置文件使用的配置模式的目录。</td>\n<td>默认值：<code>/etc/rabbitmq</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_LOG_BASE</strong></td>\n<td>该基目录包含 RabbitMQ 服务器的日志文件。</td>\n<td>默认值：<code>/var/log/rabbitmq</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_LOGS</strong></td>\n<td>RabbitMQ 服务器的 Erlang 日志文件的路径。</td>\n<td>默认值：<code>/var/log/rabbitmq/rabbitmq.log</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PLUGINS_DIR</strong></td>\n<td>RabbitMQ 的插件目录。路径由特定操作系统的分隔符定义（Unix 使用 <code>:</code>，Windows 使用 <code>;</code>）。</td>\n<td>默认值：<code>/usr/lib/rabbitmq/plugins</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PLUGINS_EXPAND_DIR</strong></td>\n<td>用于展开启用的插件的工作目录。确保有效的 RabbitMQ 用户有足够权限读取和创建该目录中的文件。</td>\n<td>默认值：<code>/var/lib/rabbitmq/mnesia</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_ENABLED_PLUGINS_FILE</strong></td>\n<td>显式记录启用的插件的文件，启用或禁用插件时会重新创建该文件。确保有效的 RabbitMQ 用户有足够权限随时读取、写入和创建该文件。</td>\n<td>默认值：<code>/var/lib/rabbitmq/.enabled_plugins</code></td>\n</tr>\n<tr>\n<td><strong>RABBITMQ_PID_FILE</strong></td>\n<td>用于 <code>rabbitmqctl</code> 的进程 ID 文件。</td>\n<td>默认值：<code>/var/run/rabbitmq/rabbitmq.pid</code></td>\n</tr>\n</tbody>\n</table>\n<div class=\"warning\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">安装好 RabbitMQ 后，不要随便修改 <code>hostname</code>，因为默认情况下，RabbitMQ 的数据目录是基于 <code>hostname</code> 创建的，如果修改了 <code>hostname</code>，RabbitMQ 就会指向新的数据目录</li>\n<li class=\"lvl-2\">数据目录默认是 <code>/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt;</code></li>\n<li class=\"lvl-2\">如果修改了 <code>hostname</code>，但仍要使用原来的数据目录，可以设置 <code>RABBITMQ_MNESIA_DIR</code> 环境变量，指向原来的数据目录</li>\n</ul>\n</div>\n<h2 id=\"RabbitMQ-相关命令\">RabbitMQ 相关命令</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>日常使用中，基本都是通过 Web 管理界面操作，这里仅对命令进行简要介绍。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（简要）</th>\n<th>常用示例（典型用法 + 中文说明）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>rabbitmq-defaults</code></td>\n<td>定义/显示 RabbitMQ 安装默认目录和运行时前缀</td>\n<td><code>编辑 sbin/rabbitmq-defaults 中 PREFIX/SYS_PREFIX</code>（修改默认目录到系统目录）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-diagnostics</code></td>\n<td>健康检查 / 诊断工具，可用于监控</td>\n<td><code>rabbitmq-diagnostics -q ping</code>（检查节点是否可达）<br><code>rabbitmq-diagnostics -q status</code>（查看节点状态）<br><code>rabbitmq-diagnostics -q check_running</code>（确认节点运行中）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-env</code></td>\n<td><code>rabbitmq-env</code> 其实不是一个直接在命令行里单独使用的工具，而是 RabbitMQ 服务启动脚本 中用来加载 RabbitMQ 环境变量的脚本。</td>\n<td>在 <code>/etc/rabbitmq/rabbitmq-env.conf</code> 中设置：<br><code>RABBITMQ_NODENAME=myrabbit</code>（设置节点名）<br>或用 <code>rabbitmq-env</code> 输出查看实际环境</td>\n</tr>\n<tr>\n<td><code>rabbitmq-plugins</code></td>\n<td>插件管理：列出/启用/禁用插件</td>\n<td><code>rabbitmq-plugins list</code>（列出所有插件）<br><code>rabbitmq-plugins enable rabbitmq_management</code>（启用 Web 管理插件）<br><code>rabbitmq-plugins disable --offline plugin</code>（离线禁用插件）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-queues</code></td>\n<td>队列副本管理：rebalance/grow/shrink</td>\n<td><code>rabbitmq-queues rebalance all --vhost-pattern &quot;.*&quot; --queue-pattern &quot;.*&quot;</code>（重平衡所有队列副本）<br><code>rabbitmq-queues add_member --vhost / qname rabbit@node</code>（为队列增加节点副本）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-server</code></td>\n<td>启动 RabbitMQ 节点（前台/后台）</td>\n<td><code>rabbitmq-server</code>（前台启动）<br><code>rabbitmq-server -detached</code>（后台启动）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-upgrade</code></td>\n<td>升级相关操作：drain/恢复等</td>\n<td><code>rabbitmq-upgrade drain</code>（让节点进入维护模式，停止接收新连接）<br><code>rabbitmq-upgrade post_upgrade</code>（执行升级后收尾操作）<br><code>rabbitmq-upgrade revive</code>（恢复维护模式中的节点）</td>\n</tr>\n<tr>\n<td><code>rabbitmqctl</code></td>\n<td>最常用管理命令：用户、队列、集群管理</td>\n<td><code>rabbitmqctl status</code>（查看节点状态）<br><code>rabbitmqctl list_queues</code>（列出所有队列）<br><code>rabbitmqctl add_user bob s3cr3t</code>（添加用户 bob，密码 s3cr3t）</td>\n</tr>\n<tr>\n<td><code>rabbitmq-streams</code></td>\n<td>管理 Streams（流式队列）</td>\n<td><code>rabbitmq-streams stream_status --vhost / my-stream</code>（查看 my-stream 状态）<br><code>rabbitmq-streams add_replica --vhost / my-stream rabbit@node</code>（为 my-stream 增加副本节点）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"最常用的命令-rabbitmqctl\">最常用的命令 <code>rabbitmqctl</code></h3>\n<h4 id=\"命令自动补全\">命令自动补全</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl</code> 有一个 <code>autocomplete</code> 参数，可以自动完成命令参数，我们可以利用这个命令来实现命令自动补全</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>vim ~/.bashrc</code> 添加如下内容：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"title\">_rabbitmqctl_completion</span></span>() &#123;</span><br><span class=\"line\">    <span class=\"built_in\">local</span> cur opts</span><br><span class=\"line\">    cur=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span>           <span class=\"comment\"># 当前光标所在单词</span></span><br><span class=\"line\">    opts=$(rabbitmqctl autocomplete <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>)   <span class=\"comment\"># 只传当前单词作为前缀</span></span><br><span class=\"line\">    COMPREPLY=( $(compgen -W <span class=\"string\">&quot;<span class=\"variable\">$&#123;opts&#125;</span>&quot;</span> -- <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>) )</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">complete -F _rabbitmqctl_completion rabbitmqctl</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>实际上 RabbitMQ 的大部分命令都有 <code>autocomplete</code> 参数，都可以自动完成命令参数</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义通用补全函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">_rabbitmq_completion</span></span>() &#123;</span><br><span class=\"line\">    <span class=\"built_in\">local</span> cur opts</span><br><span class=\"line\">    cur=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[COMP_CWORD]&#125;</span>&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 当前命令名，自动判断</span></span><br><span class=\"line\">    <span class=\"built_in\">local</span> cmd=<span class=\"string\">&quot;<span class=\"variable\">$&#123;COMP_WORDS[0]&#125;</span>&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 给对应命令传当前前缀</span></span><br><span class=\"line\">    opts=$(<span class=\"variable\">$cmd</span> autocomplete <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span> 2&gt;/dev/null)</span><br><span class=\"line\">    COMPREPLY=( $(compgen -W <span class=\"string\">&quot;<span class=\"variable\">$&#123;opts&#125;</span>&quot;</span> -- <span class=\"string\">&quot;<span class=\"variable\">$cur</span>&quot;</span>) )</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 一次性绑定多个命令</span></span><br><span class=\"line\">complete -F _rabbitmq_completion rabbitmqctl rabbitmq-plugins rabbitmq-diagnostics rabbitmq-queues rabbitmq-upgrade</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使补全生效</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br><span class=\"line\"><span class=\"comment\"># tab 补全</span></span><br><span class=\"line\">rabbitmqctl st&lt;TAB&gt;</span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">start_app  status     stop       stop_app</span><br></pre></td></tr></table></figure>\n<h4 id=\"常用命令参数\">常用命令参数</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl help</code> 获取所有命令参数的简介</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>rabbitmqctl help &lt;command&gt;</code> 获取指定命令的帮助</p>\n</li>\n<li class=\"lvl-2\">\n<p>日常使用中基本都是通过 <code>web 控制台</code> 完成，这里只做了解。</p>\n</li>\n</ul>\n<h5 id=\"1-节点管理\">1.节点管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>status</code></td>\n<td>查看节点状态，包括运行状态、版本、内存、队列数量等</td>\n<td><code>rabbitmqctl status</code></td>\n</tr>\n<tr>\n<td><code>stop</code></td>\n<td>停止 RabbitMQ 节点</td>\n<td><code>rabbitmqctl stop</code></td>\n</tr>\n<tr>\n<td><code>stop_app</code></td>\n<td>停止 RabbitMQ 应用（保留节点运行）</td>\n<td><code>rabbitmqctl stop_app</code></td>\n</tr>\n<tr>\n<td><code>start_app</code></td>\n<td>启动 RabbitMQ 应用</td>\n<td><code>rabbitmqctl start_app</code></td>\n</tr>\n<tr>\n<td><code>reset</code></td>\n<td>重置 RabbitMQ 节点，删除所有队列和数据（慎用）</td>\n<td><code>rabbitmqctl reset</code></td>\n</tr>\n<tr>\n<td><code>force_reset</code></td>\n<td>强制重置节点（即使在集群中也会重置）</td>\n<td><code>rabbitmqctl force_reset</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"2-用户和权限管理\">2. 用户和权限管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_users</code></td>\n<td>列出所有用户</td>\n<td><code>rabbitmqctl list_users</code></td>\n</tr>\n<tr>\n<td><code>add_user &lt;user&gt; &lt;password&gt;</code></td>\n<td>添加新用户</td>\n<td><code>rabbitmqctl add_user alice mypassword</code></td>\n</tr>\n<tr>\n<td><code>delete_user &lt;user&gt;</code></td>\n<td>删除用户</td>\n<td><code>rabbitmqctl delete_user alice</code></td>\n</tr>\n<tr>\n<td><code>change_password &lt;user&gt; &lt;password&gt;</code></td>\n<td>修改用户密码</td>\n<td><code>rabbitmqctl change_password alice newpass</code></td>\n</tr>\n<tr>\n<td><code>list_permissions &lt;user&gt;</code></td>\n<td>查看某用户的权限</td>\n<td><code>rabbitmqctl list_permissions alice</code></td>\n</tr>\n<tr>\n<td><code>set_permissions -p &lt;vhost&gt; &lt;user&gt; &quot;&lt;conf&gt;&quot; &quot;&lt;write&gt;&quot; &quot;&lt;read&gt;&quot;</code></td>\n<td>设置用户在虚拟主机的权限</td>\n<td><code>rabbitmqctl set_permissions -p / alice &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"3-虚拟主机（vhost）管理\">3. 虚拟主机（vhost）管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_vhosts</code></td>\n<td>列出所有虚拟主机</td>\n<td><code>rabbitmqctl list_vhosts</code></td>\n</tr>\n<tr>\n<td><code>add_vhost &lt;vhost&gt;</code></td>\n<td>添加虚拟主机</td>\n<td><code>rabbitmqctl add_vhost my_vhost</code></td>\n</tr>\n<tr>\n<td><code>delete_vhost &lt;vhost&gt;</code></td>\n<td>删除虚拟主机</td>\n<td><code>rabbitmqctl delete_vhost my_vhost</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"4-队列管理\">4. 队列管理</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>队列可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看和删除队列</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_queues</code></td>\n<td>列出队列</td>\n<td><code>rabbitmqctl list_queues</code></td>\n</tr>\n<tr>\n<td><code>list_queues name messages consumers</code></td>\n<td>列出队列及消息数、消费者数</td>\n<td><code>rabbitmqctl list_queues name messages consumers</code></td>\n</tr>\n<tr>\n<td><code>purge_queue &lt;queue&gt;</code></td>\n<td>清空队列消息</td>\n<td><code>rabbitmqctl purge_queue my_queue</code></td>\n</tr>\n<tr>\n<td><code>delete_queue &lt;queue&gt;</code></td>\n<td>删除队列</td>\n<td><code>rabbitmqctl delete_queue my_queue</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"5-交换机和绑定\">5. 交换机和绑定</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>交换机可以通过 <code>web 控制台</code> 创建， 也可以通过 <code>客户端(比如Java)</code> 创建，<code>rabbitmqctl</code> 只能查看</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_exchanges</code></td>\n<td>列出交换机</td>\n<td><code>rabbitmqctl list_exchanges</code></td>\n</tr>\n<tr>\n<td><code>list_bindings</code></td>\n<td>列出绑定关系</td>\n<td><code>rabbitmqctl list_bindings</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"6-集群管理\">6. 集群管理</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>cluster_status</code></td>\n<td>查看集群状态</td>\n<td><code>rabbitmqctl cluster_status</code></td>\n</tr>\n<tr>\n<td><code>join_cluster &lt;node&gt;</code></td>\n<td>节点加入集群</td>\n<td><code>rabbitmqctl join_cluster rabbit@node1</code></td>\n</tr>\n<tr>\n<td><code>forget_cluster_node &lt;node&gt;</code></td>\n<td>将节点从集群中移除</td>\n<td><code>rabbitmqctl forget_cluster_node rabbit@node2</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"7-日志和调试\">7. 日志和调试</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>report</code></td>\n<td>输出节点诊断报告</td>\n<td><code>rabbitmqctl report</code></td>\n</tr>\n<tr>\n<td><code>eval &lt;expression&gt;</code></td>\n<td>执行 Erlang 表达式</td>\n<td><code>rabbitmqctl eval 'rabbit_mnesia:info().'</code></td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"8-其他命令\">8. 其他命令</h5>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>help</code></td>\n<td>查看帮助命令</td>\n<td><code>rabbitmqctl help</code></td>\n</tr>\n<tr>\n<td><code>version</code></td>\n<td>查看 RabbitMQ 版本</td>\n<td><code>rabbitmqctl version</code></td>\n</tr>\n<tr>\n<td><code>authenticate_user &lt;user&gt; &lt;password&gt;</code></td>\n<td>验证用户密码</td>\n<td><code>rabbitmqctl authenticate_user alice mypassword</code></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"RabbitMQ-HTTP-API\">RabbitMQ HTTP API</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>RabbitMQ 的 HTTP API 是一个 基于 REST 的管理接口，主要用于对 RabbitMQ 的 资源管理和监控，它是 管理插件 <code>rabbitmq_management</code> 提供的功能。通过 HTTP API，你可以不用 <code>rabbitmqctl</code> 就能操作 RabbitMQ。</p>\n</li>\n<li class=\"lvl-2\">\n<p>要使用 HTTP API，你需要在 RabbitMQ 节点上确保 <code>rabbitmq_management</code> 插件已经启动。前面我们介绍<code>web 管理控制台</code>时已经启动了该插件，所以你可以直接使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 <code>Web管理控制台</code> 就是通过发送 AJAX 请求到 <code>/api/…</code> 接口来获取数据和执行操作。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/980Wwu.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>这里有 HTTP API 的详细说明，本文不再赘述。</p>\n</li>\n</ul>\n<h2 id=\"rabbitmqadmin\">rabbitmqadmin</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 是 管理插件 <code>rabbitmq_management</code> 提供的命令行工具，用于管理 RabbitMQ 的资源，如创建队列、交换机、绑定关系、查看队列、交换机、绑定关系等。</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 是一个使用 <code>HTTP API</code> 的命令行工具，所以底层实际上是调用了 <code>HTTP API</code> 。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/rabbitmq/rabbitmqadmin-ng/releases\">下载地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget -O /usr/local/bin/rabbitmqadmin https://github.com/rabbitmq/rabbitmqadmin-ng/releases/download/v2.10.0/rabbitmqadmin-2.10.0-x86_64-unknown-linux-gnu</span><br><span class=\"line\"><span class=\"comment\"># 设置权限</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">chmod</span> +x /usr/local/bin/rabbitmqadmin</span><br><span class=\"line\"><span class=\"comment\"># 查看帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看子命令帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> &lt;<span class=\"built_in\">command</span>&gt;</span><br><span class=\"line\"><span class=\"comment\">## 示例</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 队列 帮助</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> queues</span><br><span class=\"line\"><span class=\"comment\"># 查看 队列声明 帮助，子子命令</span></span><br><span class=\"line\">rabbitmqadmin <span class=\"built_in\">help</span> queues <span class=\"built_in\">declare</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>rabbitmqadmin</code> 的功能非常强大，但是因为<code>HTTP API</code>故意没有公开某些操作，所以其不能替代 <code>rabbitmqctl</code> 或 <code>rabbitmq-plugins</code>等命令。</p>\n</li>\n<li class=\"lvl-2\">\n<p>因为实际使用中很少直接通过命令行，所以这里只做简单介绍。上文提到了 <code>rabbitmqctl</code> 不支持声明(创建) 交换机和队列，这个通过 <code>rabbitmqadmin</code> 实现</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建虚拟主机</span></span><br><span class=\"line\">rabbitmqadmin vhosts <span class=\"built_in\">declare</span> --name <span class=\"string\">&quot;my-vhost&quot;</span> --default-queue-type <span class=\"string\">&quot;quorum&quot;</span> --description <span class=\"string\">&quot;Used to test&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 声明队列</span></span><br><span class=\"line\">rabbitmqadmin queues <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --name <span class=\"string\">&quot;target.classic.queue.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;classic&quot;</span> --durable <span class=\"literal\">true</span> --auto-delete <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 声明交换机</span></span><br><span class=\"line\">rabbitmqadmin exchanges <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --name <span class=\"string\">&quot;target.direct.exchange.name&quot;</span> --<span class=\"built_in\">type</span> <span class=\"string\">&quot;direct&quot;</span> --durable <span class=\"literal\">true</span> --auto-delete <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 绑定队列和交换机</span></span><br><span class=\"line\">rabbitmqadmin bindings <span class=\"built_in\">declare</span> --vhost <span class=\"string\">&quot;my-vhost&quot;</span> --<span class=\"built_in\">source</span> <span class=\"string\">&quot;target.direct.exchange.name&quot;</span> --destination <span class=\"string\">&quot;target.classic.queue.name&quot;</span> --destination-type <span class=\"string\">&quot;queue&quot;</span> --routing-key <span class=\"string\">&quot;target.routing.key&quot;</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>还有就是定期备份 RabbitMQ 的结构数据(不包括消息)</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导出</span></span><br><span class=\"line\">abbitmqadmin definitions <span class=\"built_in\">export</span> --file backup.json</span><br><span class=\"line\"><span class=\"comment\"># 导入</span></span><br><span class=\"line\">rabbitmqadmin definitions import --file backup.json</span><br></pre></td></tr></table></figure>\n<h2 id=\"RabbitMQ-需要开放哪些端口\">RabbitMQ 需要开放哪些端口</h2>\n<table>\n<thead>\n<tr>\n<th>端口号</th>\n<th>协议</th>\n<th>用途说明</th>\n<th>默认状态</th>\n<th>安全建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5672</td>\n<td>AMQP</td>\n<td>主客户端连接端口</td>\n<td>开放</td>\n<td>必须开放，限制IP</td>\n</tr>\n<tr>\n<td>5671</td>\n<td>AMQP/SSL</td>\n<td>TLS加密连接端口</td>\n<td>关闭</td>\n<td>如使用TLS则开放</td>\n</tr>\n<tr>\n<td>15672</td>\n<td>HTTP</td>\n<td>管理界面端口</td>\n<td>关闭</td>\n<td>建议内网访问</td>\n</tr>\n<tr>\n<td>15671</td>\n<td>HTTPS</td>\n<td>TLS管理界面端口</td>\n<td>关闭</td>\n<td>如使用HTTPS则开放</td>\n</tr>\n<tr>\n<td>25672</td>\n<td>Erlang Distribution</td>\n<td>集群节点通信</td>\n<td>开放</td>\n<td>集群内部使用</td>\n</tr>\n<tr>\n<td>35672-35682</td>\n<td>Erlang Distribution</td>\n<td>集群节点发现</td>\n<td>开放</td>\n<td>集群内部使用</td>\n</tr>\n<tr>\n<td>5552</td>\n<td>Stream Protocol</td>\n<td>流协议端口,RabbitMQ 3.9+</td>\n<td>关闭</td>\n<td>使用流功能时开放</td>\n</tr>\n<tr>\n<td>5551</td>\n<td>Stream Protocol/SSL</td>\n<td>流协议TLS端口,RabbitMQ 3.9+</td>\n<td>关闭</td>\n<td>如使用TLS则开放</td>\n</tr>\n<tr>\n<td>61613</td>\n<td>STOMP</td>\n<td>STOMP协议支持端口</td>\n<td>关闭</td>\n<td>如使用STOMP协议则开放</td>\n</tr>\n<tr>\n<td>61614</td>\n<td>STOMP/SSL</td>\n<td>STOMP TLS加密端口</td>\n<td>关闭</td>\n<td>如使用STOMP over TLS则开放</td>\n</tr>\n<tr>\n<td>1883</td>\n<td>MQTT</td>\n<td>MQTT协议支持端口</td>\n<td>关闭</td>\n<td>如使用MQTT协议则开放</td>\n</tr>\n<tr>\n<td>8883</td>\n<td>MQTT/SSL</td>\n<td>MQTT TLS加密端口</td>\n<td>关闭</td>\n<td>如使用MQTT over TLS则开放</td>\n</tr>\n<tr>\n<td>15674</td>\n<td>Web STOMP</td>\n<td>WebSocket STOMP支持端口</td>\n<td>关闭</td>\n<td>如使用Web STOMP则开放</td>\n</tr>\n<tr>\n<td>15675</td>\n<td>Web MQTT</td>\n<td>WebSocket MQTT支持端口</td>\n<td>关闭</td>\n<td>如使用Web MQTT则开放</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 CentOS9 中 RabbitMQ 的安装与使用。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例 RabbitMQ 简介 RabbitMQ 是一个开源的 消息队列中间件，基于 AMQP（Advanced Message Queuing Protocol，高级消息队列协议） 实现，用于在分布式系统中 解耦、缓冲和异步处理消息。 它的主要作用是让 不同系统 或 应用 之间可靠地传递消息，即使发送方或接收方暂时不可用，也能保证消息不丢失。 RabbitMQ 的核心特点 核心特点 具体说明 可靠性 - 支持消息确认（ACK）机制- 消息持久化到磁盘- 支持事务或确认模式，保证消息不会丢失 灵活的路由 - 通过 交换机（Exchange） 将消息路由到不同的 队列（Queue）- 支持多种路由策略： • direct：直连，按队列名路由 • fanout：广播，所有队列都收到 • topic：主题匹配，类似订阅模式 • headers：按消息头匹配 高性能 - 内存队列快速处理消息- 支持异步 IO 和 Erlang 的并发模型 多语言支持 - 客户端库丰富：Java、Python、Go、C#、Node.js 等- 可在多种平台和框架中使用 集群与高可用 - 支持集群模式- 队列可以镜像到多个节点，保证高可用 RabbitMQ 的核心概念 概念 含义 作用范围 类比 Broker 一个 RabbitMQ 服务实例，包含整个 AMQP 服务、管理插件、队列、交换机等资源 运行在一台服务器上，或集群中的一个节点 类似于数据库的 实例 Vhost Broker 内部的 逻辑分区，用于隔离不同的队列、交换机、绑定等资源 一个 Broker 可以有多个 vhost，每个 vhost 彼此隔离 类似于数据库实例里的 schema，实际使用中建议为每个业务配置一个独立的 vhost，并为每个vhost单独配置一个管理用户 名称 说明 Producer 消息生产者，发送消息到 RabbitMQ Queue 队列，存储消息的地方 Consumer 消息消费者，从队列获取消息 Exchange 交换机，接收 Producer 的消息并根据规则路由到队列 Binding 绑定，定义 Exchange 与 Queue 的路由规则 Message 消息，RabbitMQ 传递的数据单元 Connection 连接，客户端与 RabbitMQ Broker 之间的 TCP 连接，是通信的物理通道 Channel 通道，Connection 内部的 逻辑连接，轻量级且多路复用，一个连接可开多个通道 1234567 ┌─ Broker (RabbitMQ 实例)──────────┐ │ │ │ ┌───── Virtual Host ─────┐ │ Producer ─── TCP ──────&gt; Exchange ──&gt; Queue ────────&gt; TCP ── Consumer(Connection ──&gt; Channel)│ └────────────────────────┘ │ │ │ └─────────────────────────────────┘ RabbitMQ 的典型应用场景 应用场景 说明 异步处理 用户请求不直接处理，消息入队后由后台异步消费，例如邮件发送、图片处理 削峰填谷 缓冲高峰流量，平滑系统压力 系统解耦 不同服务之间不直接调用，降低耦合 广播/通知 发布/订阅模式，实现多服务同时收到消息 日志收集 统一接收、分发日志到不同处理系统 RabbitMQ 4.0+ 有哪些升级 特性标志（Feature Flags）的优化与强制性要求 在升级到 4.0 之前，用户必须先升级到 3.13.x 版本并手动启用所有稳定的特性标志。 从 4.0+ 开始，如果集群中的所有节点都支持某个必需的特性标志，系统会在节点启动时自动启用该标志，无需人工干预。 AMQP 协议的增强 新增了对 AMQP 过滤表达式（AMQP Filter Expressions）Version 1.0 Working Draft 09 的支持。 MQTT 协议的改进 默认的 MQTT 最大包大小从之前的 256 MiB 降低到 16 MiB，同时仍允许用户通过配置项 mqtt.max_packet_size_authenticated 自定义该值 Classic队列的变化 删除了对 Classic队列 version1 的支持，默认就是 version2 不再支持 Classic队列 的镜像功能，官方推荐使用 Quorum 队列 ，未来会将 Quorum 队列 作为默认队列。 集群状态下创建 Quorum 队列 和 Stream 队列 会自动升级为 复制队列（镜像） RabbitMQ 单机安装 安装Erlang RabbitMQ是基于Erlang语言开发的，所以安装RabbitMQ之前需要安装Erlang语言环境。需要注意的是RabbitMQ与Erlang语言之间是有版本对应关系的。参考官方文档Erlang Version Requirements 目前RabbitMQ最新版本是4.1.4，Erlang版本可以选择 27.x，GitHub下载地址 123456789101112# 下载 el9 的版本，对应 CentOS 9wget https://github.com/rabbitmq/erlang-rpm/releases/download/v27.3.4.3/erlang-27.3.4.3-1.el9.x86_64.rpm# 安装sudo rpm -ivh erlang-27.3.4.3-1.el9.x86_64.rpm# 查看安装的版本erl# 输出类似于，这里 Erlang/OTP 27 就表示安装的是 27.x 版本Erlang/OTP 27 [erts-15.2.7.2] [source] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:1] [jit:ns]Eshell V15.2.7.2 (press Ctrl+G to abort, type help(). for help)1&gt; q(). # 退出命令，注意是括号后面还有一个点。输入 help(). 显示帮助信息ok 安装 RabbitMQ 目前RabbitMQ最新版本是4.1.4，GitHub下载地址] 123456789# 下载，noarch 表示架构无关，即 X86_64 和 ARM64 都可以# 因为没有对应的 el9 的包，所以只能用 el8 的包了，实际使用中没有问题。wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v4.1.4/rabbitmq-server-4.1.4-1.el8.noarch.rpm# 安装sudo rpm -ivh rabbitmq-server-4.1.4-1.el8.noarch.rpm# 查看版本信息rabbitmq-diagnostics version # 无需启动服务# RabbitMQ 服务启动后方可正确输出rabbitmqctl version RabbitMQ 启动与停止命令 Erlang VM 是 Erlang 语言运行环境，RabbitMQ 应用运行在 Erlang VM 下。 启动 RabbitMQ 服务(Erlang VM) + 应用 1234567# 启动 RabbitMQ 服务(Erlang VM) + 应用sudo systemctl start rabbitmq-server# 或者，--detached 后台运行，不加就是前台运行sudo rabbitmq-server -detached# 单独启动 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令sudo rabbitmqctl start_app 停止 RabbitMQ 服务(Erlang VM) + 应用 1234567# 停止 RabbitMQ 服务(Erlang VM) + 应用sudo systemctl stop rabbitmq-server# 或者，单机模式 stop，集群模式 shutdownsudo rabbitmqctl stop / shutdown# 单独停止 RabbitMQ 应用，此时需要保证 RabbitMQ 服务(Erlang VM) 正在运行，一般重启 应用 时使用该命令sudo rabbitmqctl stop_app 查看RabbitMQ 服务状态 123sudo systemctl status rabbitmq-server# 或者sudo rabbitmqctl status RabbitMQ 在 CentOS 9 (RPM 安装) 的目录结构 类型 目录路径 说明 配置文件 /etc/rabbitmq rabbitmq.conf、advanced.config 等配置 日志文件 /var/log/rabbitmq RabbitMQ 运行日志，默认存放在这里 数据目录 /var/lib/rabbitmq/mnesia 消息队列、元数据存储目录 Erlang Cookie /var/lib/rabbitmq/.erlang.cookie Erlang 节点间通信的 cookie 文件 可执行文件 /usr/lib/rabbitmq/bin rabbitmq-server、rabbitmqctl 等命令 启动脚本 /usr/lib/systemd/system/rabbitmq-server.service systemd 管理 RabbitMQ 的启动脚本 插件目录 /usr/lib/rabbitmq/lib/rabbitmq_server-&lt;version&gt;/plugins 所有插件文件存放路径 激活Web管理控制台插件 对于 RabbitMQ 所有的操作基本都可以通过命令行完成，但是使用起来并不方便，这时我们可以激活 rabbitmq_management 插件，该插件提供了 Web 管理控制台，我们可以通过 Web 管理控制台来管理 RabbitMQ rabbitmq_management 插件为 官方插件，默认已经安装，不需要下载，直接激活即可 12# 激活插件sudo rabbitmq-plugins enable rabbitmq_management 该插件除了提供了 Web 管理控制台 ，还提供 基于 HTTP 的 API 用于管理和监控 RabbitMQ 节点和集群，以及 命令行工具 rabbitmqadmin，这个后面会介绍。 设置远程访问帐号 插件激活后可以通过浏览器访问 http://&lt;ip&gt;:15672，rabbitmq_management 插件默认用户名和密码都是 guest，但是默认情况下其只能通过 127.0.0.1 访问，此时我们有两种方法可以解决 1. 允许 guest 账号远程访问 123456# 修改 /etc/rabbitmq/rabbitmq.conf 文件# 允许guest用户远程访问，`官方不推荐` 一直开启，建议开启后在 web 控制台中创建一个管理员账号，然后立刻关闭该配置loopback_users.guest = false# 默认的用户名和密码，注意这里 user 如果改成 admin，则上面的开启远程访问中的 guest 也要改成 admindefault_user = guestdefault_pass = guest 修改完成后，重启 RabbitMQ 服务 1sudo systemctl restart rabbitmq-server 2. 新创建一个可以远程访问的管理员账号 创建管理员账号，比如这里 用户名为 admin，密码为 rabbitmq 1sudo rabbitmqctl add_user admin rabbitmq 给管理员账号添加资源管理权限 1sudo rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 部分 解释 rabbitmqctl RabbitMQ 的命令行管理工具，用于管理用户、权限、队列、交换机等。 set_permissions 设置指定用户在某个虚拟主机（vhost）下的权限。 -p / 指定虚拟主机（vhost）。这里的 / 是默认虚拟主机。 admin 用户名，这里是为 admin 用户设置权限。 &quot;.*&quot;（配置权限） 第一个正则表达式，控制用户对资源配置的权限，比如创建交换机、队列、绑定等。&quot;.*&quot; 表示全部允许。 &quot;.*&quot;（写权限） 第二个正则表达式，控制用户向哪些资源发送消息。&quot;.*&quot; 表示全部允许。 &quot;.*&quot;（读权限） 第三个正则表达式，控制用户从哪些资源消费消息。&quot;.*&quot; 表示全部允许。 设置admin账号为控制台管理员 1sudo rabbitmqctl set_user_tags admin administrator 部分 解释 rabbitmqctl RabbitMQ 的命令行管理工具。 set_user_tags 用来为用户设置标签（tag），标签决定了用户在管理界面或 API 中的权限级别。 admin 用户名，这里是为 admin 用户设置标签。 administrator 标签名，表示给该用户赋予管理员权限。 常见的用户标签 标签 说明 administrator 管理员，拥有最高权限，可通过 Web 管理界面、CLI、API 管理 RabbitMQ 所有内容 monitoring 监控用户，可查看所有监控信息，但不能修改配置 management 普通管理用户，可以登录管理界面，但权限受限 policymaker 策略管理用户，可以管理策略和参数，但不能管理其他用户 无标签 普通用户，只能收发消息，不能登录管理界面 set_permissions 与 set_user_tags 总结对比 命令 控制范围 主要作用 set_permissions vhost 内的资源 发消息、收消息、创建队列、交换机 set_user_tags 管理界面、管理 API 用户管理、策略管理、集群管理 启用所有稳定的 Feature Flags 登录控制台后我们会看到一条告警信息，参考：Feature Flags 1⚠ All stable feature flags must be enabled after completing an upgrade. 它的意思是：RabbitMQ 在新版本中引入了一些 Feature Flags（特性标志），这些特性标志用于控制一些新的功能或行为是否启用。升级 RabbitMQ 后，有些功能会处于 未启用状态，需要你手动开启，确保集群完全运行在最新的功能模式下。 背景：为什么有 Feature Flags？ 向后兼容：RabbitMQ 升级时，可能引入了新的数据格式或内部机制，如果立即启用，旧版本节点可能无法理解。 滚动升级支持：升级集群时，可以先升级节点，再统一启用功能，避免中途出问题。 可控性：你可以选择在确认集群稳定后再启用新功能。 查看当前 Feature Flags 状态 1234567891011121314151617rabbitmqctl -q --formatter pretty_table list_feature_flags# 输出会类似这样：┌──────────────────────────────────────┬──────────┐│ name │ state │├──────────────────────────────────────┼──────────┤│ classic_mirrored_queue_version │ enabled │├──────────────────────────────────────┼──────────┤│ classic_queue_type_delivery_support │ enabled │├──────────────────────────────────────┼──────────┤│ detailed_queues_endpoint │ disabled │├──────────────────────────────────────┼──────────┤│ direct_exchange_routing_v2 │ enabled │├──────────────────────────────────────┼──────────┤&gt; enabled：特性已启用&gt; disabled：特性未启用 可以输出 其它 格式，显示更详细的信息 1234# jsonrabbitmqctl -q --formatter json list_feature_flags name state provided_by desc doc_url | jq# tablerabbitmqctl -q --formatter pretty_table list_feature_flags name state provided_by desc doc_url 启用所有已标记为 stable 的特性，建议升级下一个 RabbitMQ 版本 前一定要确保当前版本的 Feature Flags 都是启用的，避免升级后无法顺利启动服务。 1rabbitmqctl enable_feature_flag all 在控制台中也可以查看和开启这些 Feature Flags 的状态 这里要注意，Feature Flags 一旦开启就无法关闭。 RabbitMQ 配置文件 对于 RPM/YUM/DNF 安装的 RabbitMQ，配置文件默认路径是 文件类型 默认位置 作用 主配置文件（推荐） /etc/rabbitmq/rabbitmq.conf 使用 INI 格式，主要配置都在这里 环境变量配置 /etc/rabbitmq/rabbitmq-env.conf 定义节点名、Cookie 位置、数据/日志目录等 安装后 /etc/rabbitmq/ 目录可能是空的，你需要手动创建 rabbitmq.conf，详细的参数说明可以参看官网指南，rabbitmq.conf 示例 123456# /etc/rabbitmq/rabbitmq.conf# 监听端口listeners.tcp.default = 5672# 管理界面端口management.tcp.port = 15672 rabbitmq-env.conf 用来 定义节点名、Cookie 、数据/日志目录等的环境变量，RabbitMQ 启动时会自动读取该文件，以下是通过 RPM 安装的 RabbitMQ 的默认值 12345678910111213141516171819202122# /etc/rabbitmq/rabbitmq-env.conf# 节点名称，默认使用主机短名(hostname -s)，例如 rabbit@myhostNODENAME=rabbit@&lt;hostname&gt;# 绑定的 IP 地址，留空表示监听所有地址，等价于 0.0.0.0NODE_IP_ADDRESS=# AMQP 协议端口，默认 5672NODE_PORT=5672# RabbitMQ 数据库存储目录MNESIA_BASE=/var/lib/rabbitmq/mnesia# 日志存放目录LOG_BASE=/var/log/rabbitmq# 配置文件路径，不带 .conf 后缀CONFIG_FILE=/etc/rabbitmq/rabbitmq# 是否使用长主机名，true/false (长主机名 hostname -f)USE_LONGNAME=false 两个文件的作用 文件 作用范围 典型参数 何时加载 rabbitmq-env.conf 设置 RabbitMQ 启动时的 环境变量 NODENAME, NODE_IP_ADDRESS, NODE_PORT, LOG_BASE, MNESIA_BASE 在启动 RabbitMQ 服务前由 rabbitmq-env 脚本读取 rabbitmq.conf RabbitMQ 运行时配置（内部参数、插件配置等） listeners.tcp.default, log, cluster_formation 等 RabbitMQ 启动后由 Erlang VM 内部读取 rabbitmq-env.conf 决定 RabbitMQ 启动时的基本环境，比如节点名、数据目录、监听 IP 等，必须在启动前就确定。 rabbitmq.conf 决定运行时的功能，比如端口监听、日志等级、集群配置等，可以动态修改，重启应用后生效。 rabbitmq-env.conf 变量 rabbitmq.conf 对应配置 优先级 说明 NODE_IP_ADDRESS listeners.tcp.default = &lt;IP&gt; rabbitmq.conf 只要在 rabbitmq.conf 里配置，就覆盖环境变量 NODE_PORT listeners.tcp.default = &lt;Port&gt; rabbitmq.conf 同上，IP 和端口可以一起配置 NODENAME 无直接对应 rabbitmq-env.conf 节点名只能通过 rabbitmq-env.conf 或环境变量设定 MNESIA_BASE 无直接对应 rabbitmq-env.conf 数据目录只能在启动前设定 LOG_BASE log.dir = &lt;path&gt; rabbitmq.conf 运行时配置覆盖环境变量 CONFIG_FILE 无直接对应 rabbitmq-env.conf 这个只决定加载哪个 rabbitmq.conf 文件 USE_LONGNAME 无直接对应 rabbitmq-env.conf 节点名是否使用长主机名只能启动前决定 RabbitMQ 环境变量 rabbitmq-env.conf 文件就是用来定义环境变量的，但要注意，rabbitmq-env.conf 文件中定义的变量 去掉了 RABBITMQ_ 前缀，例如在环境中设置的变量名通常是 RABBITMQ_NODENAME，但在 rabbitmq-env.conf 中，设置变量时会去掉 RABBITMQ_ 前缀，直接使用 NODENAME。 123456789# 在 rabbitmq-env.conf 中配置NODENAME=rabbit@localhostNODE_PORT=5672LOG_BASE=/var/log/rabbitmq# 而在环境中，你实际设置的变量是export RABBITMQ_NODENAME=rabbit@localhostexport RABBITMQ_NODE_PORT=5672export RABBITMQ_LOG_BASE=/var/log/rabbitmq 环境变量名称 描述 Linux RPM 安装的默认值 RABBITMQ_BASE 只针对 Windows 系统。该基目录包含 RabbitMQ 服务器的数据库和日志文件的子目录。 无（仅适用于 Windows） RABBITMQ_CONFIG_FILE 配置文件的路径，没有 .config 扩展名。RabbitMQ 服务器使用该配置文件来配置组件。 默认配置文件路径：/etc/rabbitmq/rabbitmq.conf RABBITMQ_GENERATED_CONFIG_DIR RabbitMQ 写入其生成的配置文件的目录。 默认生成路径：/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_BASE RabbitMQ 服务器节点数据库、消息存储和集群状态文件的基目录，每个节点一个。通常会覆盖 RABBITMQ_MNESIA_DIR。 默认值：/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR 存储 RabbitMQ 节点数据的目录，包含模式数据库、消息存储、集群成员信息和其他持久节点状态。 默认值：/var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt; RABBITMQ_SCHEMA_DIR RabbitMQ 保存新格式配置文件使用的配置模式的目录。 默认值：/etc/rabbitmq RABBITMQ_LOG_BASE 该基目录包含 RabbitMQ 服务器的日志文件。 默认值：/var/log/rabbitmq RABBITMQ_LOGS RabbitMQ 服务器的 Erlang 日志文件的路径。 默认值：/var/log/rabbitmq/rabbitmq.log RABBITMQ_PLUGINS_DIR RabbitMQ 的插件目录。路径由特定操作系统的分隔符定义（Unix 使用 :，Windows 使用 ;）。 默认值：/usr/lib/rabbitmq/plugins RABBITMQ_PLUGINS_EXPAND_DIR 用于展开启用的插件的工作目录。确保有效的 RabbitMQ 用户有足够权限读取和创建该目录中的文件。 默认值：/var/lib/rabbitmq/mnesia RABBITMQ_ENABLED_PLUGINS_FILE 显式记录启用的插件的文件，启用或禁用插件时会重新创建该文件。确保有效的 RabbitMQ 用户有足够权限随时读取、写入和创建该文件。 默认值：/var/lib/rabbitmq/.enabled_plugins RABBITMQ_PID_FILE 用于 rabbitmqctl 的进程 ID 文件。 默认值：/var/run/rabbitmq/rabbitmq.pid 小贴士 安装好 RabbitMQ 后，不要随便修改 hostname，因为默认情况下，RabbitMQ 的数据目录是基于 hostname 创建的，如果修改了 hostname，RabbitMQ 就会指向新的数据目录 数据目录默认是 /var/lib/rabbitmq/mnesia/rabbit@&lt;hostname&gt; 如果修改了 hostname，但仍要使用原来的数据目录，可以设置 RABBITMQ_MNESIA_DIR 环境变量，指向原来的数据目录 RabbitMQ 相关命令 日常使用中，基本都是通过 Web 管理界面操作，这里仅对命令进行简要介绍。 命令 作用（简要） 常用示例（典型用法 + 中文说明） rabbitmq-defaults 定义/显示 RabbitMQ 安装默认目录和运行时前缀 编辑 sbin/rabbitmq-defaults 中 PREFIX/SYS_PREFIX（修改默认目录到系统目录） rabbitmq-diagnostics 健康检查 / 诊断工具，可用于监控 rabbitmq-diagnostics -q ping（检查节点是否可达）rabbitmq-diagnostics -q status（查看节点状态）rabbitmq-diagnostics -q check_running（确认节点运行中） rabbitmq-env rabbitmq-env 其实不是一个直接在命令行里单独使用的工具，而是 RabbitMQ 服务启动脚本 中用来加载 RabbitMQ 环境变量的脚本。 在 /etc/rabbitmq/rabbitmq-env.conf 中设置：RABBITMQ_NODENAME=myrabbit（设置节点名）或用 rabbitmq-env 输出查看实际环境 rabbitmq-plugins 插件管理：列出/启用/禁用插件 rabbitmq-plugins list（列出所有插件）rabbitmq-plugins enable rabbitmq_management（启用 Web 管理插件）rabbitmq-plugins disable --offline plugin（离线禁用插件） rabbitmq-queues 队列副本管理：rebalance/grow/shrink rabbitmq-queues rebalance all --vhost-pattern &quot;.*&quot; --queue-pattern &quot;.*&quot;（重平衡所有队列副本）rabbitmq-queues add_member --vhost / qname rabbit@node（为队列增加节点副本） rabbitmq-server 启动 RabbitMQ 节点（前台/后台） rabbitmq-server（前台启动）rabbitmq-server -detached（后台启动） rabbitmq-upgrade 升级相关操作：drain/恢复等 rabbitmq-upgrade drain（让节点进入维护模式，停止接收新连接）rabbitmq-upgrade post_upgrade（执行升级后收尾操作）rabbitmq-upgrade revive（恢复维护模式中的节点） rabbitmqctl 最常用管理命令：用户、队列、集群管理 rabbitmqctl status（查看节点状态）rabbitmqctl list_queues（列出所有队列）rabbitmqctl add_user bob s3cr3t（添加用户 bob，密码 s3cr3t） rabbitmq-streams 管理 Streams（流式队列） rabbitmq-streams stream_status --vhost / my-stream（查看 my-stream 状态）rabbitmq-streams add_replica --vhost / my-stream rabbit@node（为 my-stream 增加副本节点） 最常用的命令 rabbitmqctl 命令自动补全 rabbitmqctl 有一个 autocomplete 参数，可以自动完成命令参数，我们可以利用这个命令来实现命令自动补全 vim ~/.bashrc 添加如下内容： 12345678_rabbitmqctl_completion() &#123; local cur opts cur=&quot;$&#123;COMP_WORDS[COMP_CWORD]&#125;&quot; # 当前光标所在单词 opts=$(rabbitmqctl autocomplete &quot;$cur&quot;) # 只传当前单词作为前缀 COMPREPLY=( $(compgen -W &quot;$&#123;opts&#125;&quot; -- &quot;$cur&quot;) )&#125;complete -F _rabbitmqctl_completion rabbitmqctl 实际上 RabbitMQ 的大部分命令都有 autocomplete 参数，都可以自动完成命令参数 12345678910111213# 定义通用补全函数_rabbitmq_completion() &#123; local cur opts cur=&quot;$&#123;COMP_WORDS[COMP_CWORD]&#125;&quot; # 当前命令名，自动判断 local cmd=&quot;$&#123;COMP_WORDS[0]&#125;&quot; # 给对应命令传当前前缀 opts=$($cmd autocomplete &quot;$cur&quot; 2&gt;/dev/null) COMPREPLY=( $(compgen -W &quot;$&#123;opts&#125;&quot; -- &quot;$cur&quot;) )&#125;# 一次性绑定多个命令complete -F _rabbitmq_completion rabbitmqctl rabbitmq-plugins rabbitmq-diagnostics rabbitmq-queues rabbitmq-upgrade 测试 123456# 使补全生效source ~/.bashrc# tab 补全rabbitmqctl st&lt;TAB&gt;# 输出start_app status stop stop_app 常用命令参数 rabbitmqctl help 获取所有命令参数的简介 rabbitmqctl help &lt;command&gt; 获取指定命令的帮助 日常使用中基本都是通过 web 控制台 完成，这里只做了解。 1.节点管理 命令 功能 示例 status 查看节点状态，包括运行状态、版本、内存、队列数量等 rabbitmqctl status stop 停止 RabbitMQ 节点 rabbitmqctl stop stop_app 停止 RabbitMQ 应用（保留节点运行） rabbitmqctl stop_app start_app 启动 RabbitMQ 应用 rabbitmqctl start_app reset 重置 RabbitMQ 节点，删除所有队列和数据（慎用） rabbitmqctl reset force_reset 强制重置节点（即使在集群中也会重置） rabbitmqctl force_reset 2. 用户和权限管理 命令 功能 示例 list_users 列出所有用户 rabbitmqctl list_users add_user &lt;user&gt; &lt;password&gt; 添加新用户 rabbitmqctl add_user alice mypassword delete_user &lt;user&gt; 删除用户 rabbitmqctl delete_user alice change_password &lt;user&gt; &lt;password&gt; 修改用户密码 rabbitmqctl change_password alice newpass list_permissions &lt;user&gt; 查看某用户的权限 rabbitmqctl list_permissions alice set_permissions -p &lt;vhost&gt; &lt;user&gt; &quot;&lt;conf&gt;&quot; &quot;&lt;write&gt;&quot; &quot;&lt;read&gt;&quot; 设置用户在虚拟主机的权限 rabbitmqctl set_permissions -p / alice &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 3. 虚拟主机（vhost）管理 命令 功能 示例 list_vhosts 列出所有虚拟主机 rabbitmqctl list_vhosts add_vhost &lt;vhost&gt; 添加虚拟主机 rabbitmqctl add_vhost my_vhost delete_vhost &lt;vhost&gt; 删除虚拟主机 rabbitmqctl delete_vhost my_vhost 4. 队列管理 队列可以通过 web 控制台 创建， 也可以通过 客户端(比如Java) 创建，rabbitmqctl 只能查看和删除队列 命令 功能 示例 list_queues 列出队列 rabbitmqctl list_queues list_queues name messages consumers 列出队列及消息数、消费者数 rabbitmqctl list_queues name messages consumers purge_queue &lt;queue&gt; 清空队列消息 rabbitmqctl purge_queue my_queue delete_queue &lt;queue&gt; 删除队列 rabbitmqctl delete_queue my_queue 5. 交换机和绑定 交换机可以通过 web 控制台 创建， 也可以通过 客户端(比如Java) 创建，rabbitmqctl 只能查看 命令 功能 示例 list_exchanges 列出交换机 rabbitmqctl list_exchanges list_bindings 列出绑定关系 rabbitmqctl list_bindings 6. 集群管理 命令 功能 示例 cluster_status 查看集群状态 rabbitmqctl cluster_status join_cluster &lt;node&gt; 节点加入集群 rabbitmqctl join_cluster rabbit@node1 forget_cluster_node &lt;node&gt; 将节点从集群中移除 rabbitmqctl forget_cluster_node rabbit@node2 7. 日志和调试 命令 功能 示例 report 输出节点诊断报告 rabbitmqctl report eval &lt;expression&gt; 执行 Erlang 表达式 rabbitmqctl eval 'rabbit_mnesia:info().' 8. 其他命令 命令 功能 示例 help 查看帮助命令 rabbitmqctl help version 查看 RabbitMQ 版本 rabbitmqctl version authenticate_user &lt;user&gt; &lt;password&gt; 验证用户密码 rabbitmqctl authenticate_user alice mypassword RabbitMQ HTTP API RabbitMQ 的 HTTP API 是一个 基于 REST 的管理接口，主要用于对 RabbitMQ 的 资源管理和监控，它是 管理插件 rabbitmq_management 提供的功能。通过 HTTP API，你可以不用 rabbitmqctl 就能操作 RabbitMQ。 要使用 HTTP API，你需要在 RabbitMQ 节点上确保 rabbitmq_management 插件已经启动。前面我们介绍web 管理控制台时已经启动了该插件，所以你可以直接使用。 实际上 Web管理控制台 就是通过发送 AJAX 请求到 /api/… 接口来获取数据和执行操作。 这里有 HTTP API 的详细说明，本文不再赘述。 rabbitmqadmin rabbitmqadmin 是 管理插件 rabbitmq_management 提供的命令行工具，用于管理 RabbitMQ 的资源，如创建队列、交换机、绑定关系、查看队列、交换机、绑定关系等。 rabbitmqadmin 是一个使用 HTTP API 的命令行工具，所以底层实际上是调用了 HTTP API 。 下载地址 12345678910111213# 下载sudo wget -O /usr/local/bin/rabbitmqadmin https://github.com/rabbitmq/rabbitmqadmin-ng/releases/download/v2.10.0/rabbitmqadmin-2.10.0-x86_64-unknown-linux-gnu# 设置权限sudo chmod +x /usr/local/bin/rabbitmqadmin# 查看帮助rabbitmqadmin help# 查看子命令帮助rabbitmqadmin help &lt;command&gt;## 示例# 查看 队列 帮助rabbitmqadmin help queues# 查看 队列声明 帮助，子子命令rabbitmqadmin help queues declare rabbitmqadmin 的功能非常强大，但是因为HTTP API故意没有公开某些操作，所以其不能替代 rabbitmqctl 或 rabbitmq-plugins等命令。 因为实际使用中很少直接通过命令行，所以这里只做简单介绍。上文提到了 rabbitmqctl 不支持声明(创建) 交换机和队列，这个通过 rabbitmqadmin 实现 12345678# 创建虚拟主机rabbitmqadmin vhosts declare --name &quot;my-vhost&quot; --default-queue-type &quot;quorum&quot; --description &quot;Used to test&quot;# 声明队列rabbitmqadmin queues declare --vhost &quot;my-vhost&quot; --name &quot;target.classic.queue.name&quot; --type &quot;classic&quot; --durable true --auto-delete false# 声明交换机rabbitmqadmin exchanges declare --vhost &quot;my-vhost&quot; --name &quot;target.direct.exchange.name&quot; --type &quot;direct&quot; --durable true --auto-delete false# 绑定队列和交换机rabbitmqadmin bindings declare --vhost &quot;my-vhost&quot; --source &quot;target.direct.exchange.name&quot; --destination &quot;target.classic.queue.name&quot; --destination-type &quot;queue&quot; --routing-key &quot;target.routing.key&quot; 还有就是定期备份 RabbitMQ 的结构数据(不包括消息) 1234# 导出abbitmqadmin definitions export --file backup.json# 导入rabbitmqadmin definitions import --file backup.json RabbitMQ 需要开放哪些端口 端口号 协议 用途说明 默认状态 安全建议 5672 AMQP 主客户端连接端口 开放 必须开放，限制IP 5671 AMQP/SSL TLS加密连接端口 关闭 如使用TLS则开放 15672 HTTP 管理界面端口 关闭 建议内网访问 15671 HTTPS TLS管理界面端口 关闭 如使用HTTPS则开放 25672 Erlang Distribution 集群节点通信 开放 集群内部使用 35672-35682 Erlang Distribution 集群节点发现 开放 集群内部使用 5552 Stream Protocol 流协议端口,RabbitMQ 3.9+ 关闭 使用流功能时开放 5551 Stream Protocol/SSL 流协议TLS端口,RabbitMQ 3.9+ 关闭 如使用TLS则开放 61613 STOMP STOMP协议支持端口 关闭 如使用STOMP协议则开放 61614 STOMP/SSL STOMP TLS加密端口 关闭 如使用STOMP over TLS则开放 1883 MQTT MQTT协议支持端口 关闭 如使用MQTT协议则开放 8883 MQTT/SSL MQTT TLS加密端口 关闭 如使用MQTT over TLS则开放 15674 Web STOMP WebSocket STOMP支持端口 关闭 如使用Web STOMP则开放 15675 Web MQTT WebSocket MQTT支持端口 关闭 如使用Web MQTT则开放","summary":"摘要 本文介绍 CentOS9 中 RabbitMQ 的安装与使用。 Zookeeper官网 本文使用的 RabbitMQ 版本为 4.1.4。 Java Client 示例","date_published":"2025-09-18T13:30:05.000Z","tags":["技术","rabbitmq","分布式","rabbitmq"]},{"id":"https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/","url":"https://blog.hanqunfeng.com/2025/09/15/zookeeper-study/","title":"Zookeeper 的安装及使用","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 CentOS9 中 Zookeeper 的安装与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://zookeeper.apache.org\">Zookeeper官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文使用的 Zookeeper 版本为 3.8.4。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Zookeeper-简介\">Zookeeper 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 是一个集中式服务，用于：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>ZooKeeper 官方功能</th>\n<th>主要节点类型</th>\n<th>具体场景示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>配置中心 (Config Center)</td>\n<td>维护配置信息 (Configuration Management)</td>\n<td>持久节点（Persistent）</td>\n<td>把数据库连接信息、系统参数等放在 ZooKeeper 里，动态更新，像 Apollo、Spring Cloud Config 一样。</td>\n</tr>\n<tr>\n<td>注册中心 (Service Registry)</td>\n<td>提供命名服务 (Naming Service)</td>\n<td>临时节点（Ephemeral）</td>\n<td>服务实例启动时在 ZooKeeper 里注册自己的地址，客户端从 ZooKeeper 获取服务列表，类似于 Nacos、Eureka。</td>\n</tr>\n<tr>\n<td>分布式锁 (Distributed Lock)</td>\n<td>分布式同步 (Distributed Synchronization)</td>\n<td>临时顺序节点（Ephemeral Sequential）</td>\n<td>用临时顺序节点实现分布式锁，保证只有一个实例在执行关键任务，典型应用是分布式定时任务调度。</td>\n</tr>\n<tr>\n<td>消息队列 (Message Queue)</td>\n<td>集群管理服务 (Cluster Management)</td>\n<td>持久/临时节点 + Watch 机制</td>\n<td>通过 Watch 机制监听 ZNode 变化，节点间用数据变更当“信号”传递消息，早期 Kafka 用过这种方式。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。</p>\n</li>\n<li class=\"lvl-2\">\n<p>不同于文件系统，每个节点都可以保存数据，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识，每个节点都有一个版本(version)，版本从0开始计数。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/QgdBSR.png\" alt=\"\"></p>\n</li>\n</ul>\n<h2 id=\"Zookeeper-安装\">Zookeeper 安装</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>运行 Zookeeper 需要安装 JDK1.8+。我这里使用 <a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">OpenJDK11</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mkdir</span> -p /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local/jdk</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">ln</span> -s jdk-11.0.28+6 jdk11</span><br><span class=\"line\"><span class=\"comment\"># 配置环境变量</span></span><br><span class=\"line\">vim /etc/profile <span class=\"comment\"># 添加如下内容</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> JAVA_HOME=/usr/local/jdk/jdk11</span><br><span class=\"line\">  <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 立即生效</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 查看java版本</span></span><br><span class=\"line\">java -version</span><br><span class=\"line\">openjdk version <span class=\"string\">&quot;11.0.28&quot;</span> 2025-07-15</span><br><span class=\"line\">OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)</span><br><span class=\"line\">OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode)</span><br></pre></td></tr></table></figure>\n<h3 id=\"单机安装\">单机安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://zookeeper.apache.org/releases.html\">下载 Zookeeper</a>，目前最新的稳定版本为 <code>3.8.4</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载</span></span><br><span class=\"line\">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class=\"line\"><span class=\"comment\"># 解压</span></span><br><span class=\"line\">tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz</span><br><span class=\"line\"><span class=\"comment\"># 配置个软连接，方便以后升级</span></span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s apache-zookeeper-3.8.4-bin zookeeper</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改配置文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> zookeeper/conf</span><br><span class=\"line\"><span class=\"built_in\">cp</span> zoo_sample.cfg zoo.cfg</span><br><span class=\"line\"><span class=\"comment\"># 建议修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改为指定的data目录</span></span><br><span class=\"line\">vim zoo.cfg</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>zoo.cfg 参数说明</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>说明</th>\n<th>默认值</th>\n<th>单位 / 备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>tickTime</strong></td>\n<td>ZooKeeper 时间配置中的基本单位</td>\n<td>2000</td>\n<td>毫秒</td>\n</tr>\n<tr>\n<td><strong>initLimit</strong></td>\n<td>follower 初始化连接到 leader 的最大时长，单位为 tickTime 倍数</td>\n<td>10</td>\n<td>10 × tickTime = 20000 ms</td>\n</tr>\n<tr>\n<td><strong>syncLimit</strong></td>\n<td>follower 与 leader 数据同步的最大时长，单位为 tickTime 倍数</td>\n<td>5</td>\n<td>5 × tickTime = 10000 ms</td>\n</tr>\n<tr>\n<td><strong>dataDir</strong></td>\n<td>数据和日志存储目录（未指定 dataLogDir 时，日志也会保存在此目录）</td>\n<td>/tmp/zookeeper</td>\n<td>目录路径</td>\n</tr>\n<tr>\n<td><strong>clientPort</strong></td>\n<td>客户端连接 ZooKeeper 的端口号</td>\n<td>2181</td>\n<td>默认 2181</td>\n</tr>\n<tr>\n<td><strong>maxClientCnxns</strong></td>\n<td>单个客户端最大并发连接数</td>\n<td>60</td>\n<td>超过限制后新连接会被拒绝</td>\n</tr>\n<tr>\n<td><strong>autopurge.snapRetainCount</strong></td>\n<td>快照文件保留个数，超过数量的将会被清理</td>\n<td>3</td>\n<td>默认 3</td>\n</tr>\n<tr>\n<td><strong>autopurge.purgeInterval</strong></td>\n<td>清理任务执行间隔时间，单位小时，0 表示不自动清理</td>\n<td>1</td>\n<td>1 小时</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 zookeeper</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> zookeeper</span><br><span class=\"line\"><span class=\"comment\"># 启动</span></span><br><span class=\"line\">bin/zkServer.sh start</span><br><span class=\"line\"><span class=\"comment\"># 指定配置文件</span></span><br><span class=\"line\">bin/zkServer.sh start conf/zoo.cfg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止</span></span><br><span class=\"line\">bin/zkServer.sh stop</span><br><span class=\"line\"><span class=\"comment\"># 查看状态</span></span><br><span class=\"line\">bin/zkServer.sh status</span><br><span class=\"line\"><span class=\"comment\"># 查看版本</span></span><br><span class=\"line\">./bin/zkServer.sh version</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群安装\">集群安装</h3>\n<h4 id=\"ZooKeeper-集群角色\">ZooKeeper 集群角色</h4>\n<h5 id=\"1-Leader（领导者）\">1. Leader（领导者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性；</li>\n<li class=\"lvl-4\">集群内部各个服务器的调度者；</li>\n<li class=\"lvl-4\">对于 <code>create</code>、<code>setData</code>、<code>delete</code> 等写操作请求，统一转发给 Leader 处理；</li>\n<li class=\"lvl-4\">Leader 负责决定编号、执行操作，这个过程称为 <strong>事务</strong>。</li>\n</ul>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>三台虚拟机 zoo.cfg 文件末尾添加配置，启动时会自动选举出 Leader 角色，则其余就是 Follower 角色。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.1=10.250.0.229:2888:3888</span><br><span class=\"line\">server.2=10.250.0.152:2888:3888</span><br><span class=\"line\">server.3=10.250.0.36:2888:3888</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-Follower（跟随者）\">2. Follower（跟随者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">处理客户端非事务（读操作）请求（可以直接响应）；</li>\n<li class=\"lvl-4\">转发事务请求给 Leader；</li>\n<li class=\"lvl-4\">参与集群 Leader 选举投票。</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>leader节点可以处理读写请求，follower只可以处理读请求。follower在接到写请求时会把写请求转发给leader来处理。</p>\n</blockquote>\n<h5 id=\"3-Observer（观察者）\">3. Observer（观察者）</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>职责：</strong></p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">对于非事务请求（读操作）可以独立处理；</li>\n<li class=\"lvl-4\">对于事务请求会转发给 Leader 处理；</li>\n<li class=\"lvl-4\">接收来自 Leader 的 <code>inform</code> 信息，更新本地存储；</li>\n<li class=\"lvl-4\">不参与提交和选举投票；</li>\n<li class=\"lvl-4\">通常用于 <strong>提升集群非事务处理能力</strong>，不影响集群事务处理性能。</li>\n</ul>\n</li>\n</ul>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置一个 ID 为 4 的观察者节点：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群搭建\">集群搭建</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>环境准备：4台服务器，按照 <code>单机安装</code> 的方式准备好 Zookeeper 环境</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10.250.0.229</span><br><span class=\"line\">10.250.0.152</span><br><span class=\"line\">10.250.0.36</span><br><span class=\"line\">10.250.0.56</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>zoo.cfg</code> 文件末尾添加配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server.1=10.250.0.229:2888:3888</span><br><span class=\"line\">server.2=10.250.0.152:2888:3888</span><br><span class=\"line\">server.3=10.250.0.36:2888:3888</span><br><span class=\"line\">server.4=10.250.0.56:2888:3888:observer</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别在 <code>dataDir</code> 目录下创建 <code>myid</code> 文件，在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格）</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 注意 节点编号不能重复，而且要与 zoo.cfg 文件中的 server.id 一致</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; myid</span><br><span class=\"line\"><span class=\"comment\"># echo 2 &gt; myid</span></span><br><span class=\"line\"><span class=\"comment\"># echo 3 &gt; myid</span></span><br><span class=\"line\"><span class=\"comment\"># echo 4 &gt; myid</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分别启动 Zookeeper 服务器</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别启动4个节点的zookeeper server</span></span><br><span class=\"line\">bin/zkServer.sh start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看状态，可以看到节点角色类型</span></span><br><span class=\"line\">bin/zkServer.sh status</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群最少节点要求和扩容规则\">集群最少节点要求和扩容规则</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 使用 多数派（quorum）机制 来保证数据一致性</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1.集群总节点数 N</span><br><span class=\"line\">2.容忍的宕机节点数 F = (N-1)/2（向下取整）</span><br><span class=\"line\">3.要保证集群可用，需要 大于 N/2 的节点存活</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群扩容规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1.节点总数必须是奇数</span><br><span class=\"line\">  奇数节点可以保证多数派投票机制正常</span><br><span class=\"line\">  偶数节点不推荐，容错能力不增加（比如 4 台，仍然只容忍 1 台宕机）</span><br><span class=\"line\"></span><br><span class=\"line\">2.每次扩容建议 +2 节点</span><br><span class=\"line\">  这样既保持奇数，又增加 quorum 容错能力</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>最少节点与容错能力表格</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>集群总节点数 N</th>\n<th>容忍宕机数 F</th>\n<th>可用 quorum 节点数</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>不推荐，无法容忍故障</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0</td>\n<td>2</td>\n<td>不推荐，1 台宕机就不可用</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n<td>最小可用生产集群</td>\n</tr>\n<tr>\n<td>5</td>\n<td>2</td>\n<td>3</td>\n<td>推荐生产集群规模</td>\n</tr>\n<tr>\n<td>7</td>\n<td>3</td>\n<td>4</td>\n<td>高可用大集群</td>\n</tr>\n<tr>\n<td>9</td>\n<td>4</td>\n<td>5</td>\n<td>更大集群，高容错</td>\n</tr>\n<tr>\n<td>11</td>\n<td>5</td>\n<td>6</td>\n<td>极高可用场景</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"ZooKeeper-默认端口说明\">ZooKeeper 默认端口说明</h2>\n<table>\n<thead>\n<tr>\n<th>端口</th>\n<th>用途</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2181</td>\n<td>客户端连接端口</td>\n<td>客户端通过这个端口访问 ZooKeeper</td>\n</tr>\n<tr>\n<td>2888</td>\n<td>集群内部通信</td>\n<td>follower 与 leader 之间同步数据</td>\n</tr>\n<tr>\n<td>3888</td>\n<td>leader 选举端口</td>\n<td>集群选举 leader 使用</td>\n</tr>\n<tr>\n<td>8080 (可选)</td>\n<td>admin/metrics web端口</td>\n<td>如果开启了 adminServer</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 永久开启端口</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=2181/tcp</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=2888/tcp</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=3888/tcp</span><br><span class=\"line\"><span class=\"comment\"># 如果使用 adminServer</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --permanent --add-port=8080/tcp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新加载防火墙配置</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --reload</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看是否开放成功</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> firewall-cmd --list-all</span><br></pre></td></tr></table></figure>\n<h2 id=\"客户端连接\">客户端连接</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>命令行</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认连接 127.0.0.1:2181</span></span><br><span class=\"line\">bin/zkCli.sh</span><br><span class=\"line\"><span class=\"comment\"># 指定 -server ip:port，如果是集群，则连接任意一个节点，ZooKeeper 会自动处理与 Leader/Follower 的交互</span></span><br><span class=\"line\">bin/zkCli.sh -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>客户端命令简介：<a href=\"https://zookeeper.apache.org/doc/r3.8.4/zookeeperCLI.html\">参考官网</a></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>语法示例</th>\n<th>功能描述</th>\n<th>常用参数及说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>help</strong></td>\n<td><code>help</code></td>\n<td>显示所有操作命令</td>\n<td>无</td>\n<td><code>help</code></td>\n</tr>\n<tr>\n<td><strong>version</strong></td>\n<td><code>version</code></td>\n<td>查看客户端和服务器版本信息</td>\n<td>无</td>\n<td><code>version</code></td>\n</tr>\n<tr>\n<td><strong>connect</strong></td>\n<td><code>connect host:port</code></td>\n<td>连接到指定 ZooKeeper 服务器</td>\n<td><code>host:port</code>: 服务器地址</td>\n<td><code>connect 127.0.0.1:2181</code></td>\n</tr>\n<tr>\n<td><strong>close</strong></td>\n<td><code>close</code></td>\n<td>关闭当前会话 ,通过 <code>connect</code> 可重连</td>\n<td>无</td>\n<td><code>close</code></td>\n</tr>\n<tr>\n<td><strong>quit</strong></td>\n<td><code>quit</code></td>\n<td>退出客户端</td>\n<td>无</td>\n<td><code>quit</code></td>\n</tr>\n<tr>\n<td><strong>ls</strong></td>\n<td><code>ls [-s] [-w] [-R] path</code></td>\n<td>查看节点的子节点</td>\n<td>- <code>-w</code>: 监听子节点变化<br>- <code>-s</code>: 显示节点状态信息<br>- <code>-R</code>: 递归查看</td>\n<td><code>ls -s -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getAllChildrenNumber</strong></td>\n<td><code>getAllChildrenNumber path</code></td>\n<td>获取某节点所有子节点的总数</td>\n<td>无</td>\n<td><code>getAllChildrenNumber /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getEphemerals</strong></td>\n<td><code>getEphemerals path</code></td>\n<td>获取某路径下所有临时节点</td>\n<td>无</td>\n<td><code>getEphemerals /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>create</strong></td>\n<td><code>create [-s] [-e] [-c] [-t ttl] path [data] [acl]</code></td>\n<td>创建节点</td>\n<td>- <code>-s</code>: 顺序节点<br>- <code>-e</code>: 临时节点<br>- <code>-c</code>: 容器节点<br>- <code>-t ttl</code>: TTL节点，单位毫秒</td>\n<td><code>create -e /zk_test_ephemeral &quot;temp_data&quot;</code></td>\n</tr>\n<tr>\n<td><strong>get</strong></td>\n<td><code>get [-s] [-w] path</code></td>\n<td>获取节点数据信息</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-w</code>: 监听节点变化</td>\n<td><code>get -s -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>set</strong></td>\n<td><code>set [-s] [-v version] path data</code></td>\n<td>设置节点数据</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号</td>\n<td><code>set /zk_test &quot;new_data&quot;</code></td>\n</tr>\n<tr>\n<td><strong>stat</strong></td>\n<td><code>stat [-w] path</code></td>\n<td>查看节点状态信息</td>\n<td>- <code>-w</code>: 监听节点变化</td>\n<td><code>stat -w /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>sync</strong></td>\n<td><code>sync path</code></td>\n<td>同步指定节点数据</td>\n<td>无</td>\n<td><code>sync /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>delete</strong></td>\n<td><code>delete [-v version] path</code></td>\n<td>删除某一节点（无子节点）</td>\n<td>- <code>-v</code>: 节点版本号</td>\n<td><code>delete /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>deleteall</strong></td>\n<td><code>deleteall path</code></td>\n<td>递归删除某一节点及其子节点</td>\n<td>无</td>\n<td><code>deleteall /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>getAcl</strong></td>\n<td><code>getAcl [-s] path</code></td>\n<td>获取节点访问控制信息</td>\n<td>- <code>-s</code>: 显示节点状态信息</td>\n<td><code>getAcl /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>setAcl</strong></td>\n<td><code>setAcl [-s] [-v version] [-R] path acl</code></td>\n<td>设置节点访问控制列表</td>\n<td>- <code>-s</code>: 显示节点状态信息<br>- <code>-v</code>: 指定版本号<br>- <code>-R</code>: 递归设置</td>\n<td><code>setAcl /zk_test world:anyone:r</code></td>\n</tr>\n<tr>\n<td><strong>listquota</strong></td>\n<td><code>listquota path</code></td>\n<td>查看节点配额信息</td>\n<td>无</td>\n<td><code>listquota /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>setquota</strong></td>\n<td><code>setquota [-n] [-b] val path</code></td>\n<td>对节点增加限制</td>\n<td>- <code>-n</code>: 子节点最大个数<br>- <code>-b</code>: 数据值最大长度，-1 表示无限制</td>\n<td><code>setquota -n 5 /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>delquota</strong></td>\n<td><code>delquota [-n                                    | -b] path</code></td>\n<td>删除节点配额限制</td>\n<td>- <code>-n</code>: 删除子节点数限制<br>- <code>-b</code>: 删除数据值大小限制</td>\n<td><code>delquota -n /zk_test</code></td>\n</tr>\n<tr>\n<td><strong>config</strong></td>\n<td><code>config</code></td>\n<td>查看服务器配置</td>\n<td>无</td>\n<td><code>config</code></td>\n</tr>\n<tr>\n<td><strong>whoami</strong></td>\n<td><code>whoami</code></td>\n<td>查看当前会话身份</td>\n<td>无</td>\n<td><code>whoami</code></td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>GUI 工具</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>类型 / 运行方式</th>\n<th>优点</th>\n<th>注意事项</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>PrettyZoo</strong></td>\n<td>桌面应用（JavaFX）(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n<td>支持 Mac/Windows/Linux，界面友好；支持节点创建/删除/更新/查询，ACL 管理，多 ZK 实例管理，SSH 隧道等功能。(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n<td>项目已经 archived，维护可能不活跃。最新版可能在兼容性或 Bug 修复方面不如活跃项目。也可能需要自己构建或调试。(<a href=\"https://github.com/vran-dev/PrettyZoo\" title=\"vran-dev/PrettyZoo: 😉 Pretty nice Zookeeper GUI, Support ...\">GitHub</a>)</td>\n</tr>\n<tr>\n<td><strong>ZooNavigator</strong></td>\n<td>Web 界面 + 可 Docker 部署或本地启动(<a href=\"https://github.com/elkozmon/zoonavigator\" title=\"elkozmon/zoonavigator: Web-based ZooKeeper UI\">GitHub</a>)</td>\n<td>功能丰富；支持多个 Zookeeper 版本（如 3.5.x ～ 3.9.x）；浏览 / 编辑 /搜索节点；导入导出配置；支持浏览器访问，无需本地 heavy GUI。(<a href=\"https://github.com/elkozmon/zoonavigator\" title=\"elkozmon/zoonavigator: Web-based ZooKeeper UI\">GitHub</a>)</td>\n<td>因为 Web 应用，可能对浏览器安全策略与网络延迟敏感；需要部署自己版本或 Docker；如果要求本地脱机操作时，有些功能可能稍不如桌面应用。</td>\n</tr>\n<tr>\n<td><strong>ZooKeeper Assistant</strong></td>\n<td>桌面／管理员面板类型（支持监控界面等）(<a href=\"https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo\" title=\"An exciting Apache ZooKeeper Desktop GUI\">DEV Community</a>)</td>\n<td>除了浏览节点树以外，还提供健康状态监控（延迟、请求数等）、不同数据格式支持（JSON/XML 等）、导入/导出节点数据、命令行操作集成。(<a href=\"https://dev.to/redisant/an-exciting-apache-zookeeper-desktop-gui-1fdo\" title=\"An exciting Apache ZooKeeper Desktop GUI\">DEV Community</a>)</td>\n<td>有些功能可能在 Mac 上兼容性或视觉体验需要调试；具体版本支持情况要看最近更新。某些监控界面可能依赖于 ZK 的指标或插件。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Zookeeper-节点类型\">Zookeeper 节点类型</h2>\n<table>\n<thead>\n<tr>\n<th>节点类型</th>\n<th>生命周期说明</th>\n<th>创建命令示例</th>\n<th>特点说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>持久节点</strong> (Persistent)</td>\n<td>节点一直存在，除非手动删除，即使客户端会话关闭，节点也不会消失</td>\n<td><code>create /locks</code></td>\n<td>适合存储配置信息、元数据等持久数据</td>\n</tr>\n<tr>\n<td><strong>临时节点</strong> (Ephemeral)</td>\n<td>客户端会话关闭（异常或超时）时，节点自动被删除</td>\n<td><code>create -e /locks/DBLock</code></td>\n<td>常用于分布式锁、临时会话数据</td>\n</tr>\n<tr>\n<td><strong>有序节点</strong> (Sequential)</td>\n<td>在持久或临时节点基础上，增加有序编号，ZooKeeper 自动在节点名后加递增序号</td>\n<td><code>create -e -s /jobs/job</code></td>\n<td>常用于分布式锁、队列等需要顺序的场景</td>\n</tr>\n<tr>\n<td><strong>容器节点</strong> (Container)</td>\n<td>V3.5.3+，当容器节点下的最后一个子节点被删除后，容器节点也会自动删除</td>\n<td><code>create -c /work</code></td>\n<td>适合分布式任务临时目录、动态数据目录</td>\n</tr>\n<tr>\n<td><strong>TTL 节点</strong> (TTL)</td>\n<td>在指定 TTL 时间内未修改且无子节点，节点会被自动删除（需开启 <code>extendedTypesEnabled=true</code> 配置）</td>\n<td><code>create -t 3000 /ttl_node</code></td>\n<td>适合临时缓存、临时状态数据，过期自动清理</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注意</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">同一级节点 key 名称是唯一的</li>\n<li class=\"lvl-4\">创建节点时，必须要带上全路径</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>节点状态信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 16] <span class=\"built_in\">stat</span> /test</span><br><span class=\"line\">cZxid = 0x100000002                   <span class=\"comment\"># Znode创建的事务id</span></span><br><span class=\"line\">ctime = Mon Sep 15 09:44:51 UTC 2025  <span class=\"comment\"># 创建时间</span></span><br><span class=\"line\">mZxid = 0x100000004                   <span class=\"comment\"># 最后一次修改事务id</span></span><br><span class=\"line\">mtime = Mon Sep 15 09:47:12 UTC 2025  <span class=\"comment\"># 最后一次修改时间</span></span><br><span class=\"line\">pZxid = 0x400000004                   <span class=\"comment\"># 表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID（注意: 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）</span></span><br><span class=\"line\">cversion = 1                          <span class=\"comment\"># 子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。</span></span><br><span class=\"line\">dataVersion = 1                       <span class=\"comment\"># znode的数据版本号。每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据），可有效避免了数据更新时出现的先后顺序问题</span></span><br><span class=\"line\">aclVersion = 0                        <span class=\"comment\"># znode的ACL版本号。每次对节点进行ACL设置，aclVersion的值都会增加1</span></span><br><span class=\"line\">ephemeralOwner = 0x0                  <span class=\"comment\"># 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id。如果不是, ephemeralOwner值为0(持久节点)。</span></span><br><span class=\"line\">dataLength = 3                        <span class=\"comment\"># znode的数据长度</span></span><br><span class=\"line\">numChildren = 1                       <span class=\"comment\"># znode的子节点数量（只统计直接子节点的数量）</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Zookeeper-监听机制\">Zookeeper 监听机制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>watch机制，顾名思义是一个监听机制。Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发生时才会触发监听，通知给客户端。</p>\n</li>\n<li class=\"lvl-2\">\n<p>监听的对象是事件，支持的事件类型如下：</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- None: 连接建立事件</span><br><span class=\"line\">- NodeCreated： 节点创建</span><br><span class=\"line\">- NodeDeleted： 节点删除</span><br><span class=\"line\">- NodeDataChanged：节点数据变化</span><br><span class=\"line\">- NodeChildrenChanged：子节点列表变化</span><br><span class=\"line\">- DataWatchRemoved：节点监听被移除</span><br><span class=\"line\">- ChildWatchRemoved：子节点监听被移除</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>监听特性</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>一次性触发</strong></td>\n<td>Watch 是一次性的，一旦被触发就会被移除。再次使用时需要重新注册。</td>\n</tr>\n<tr>\n<td><strong>客户端顺序回调</strong></td>\n<td>Watch 回调是顺序串行执行的，客户端只有在回调完成后才能看到最新的数据状态。</td>\n</tr>\n<tr>\n<td><strong>轻量级</strong></td>\n<td>Watcher 回调逻辑不应过多，以免阻塞或影响其他 Watch 的执行。</td>\n</tr>\n<tr>\n<td><strong>最小通信单位</strong></td>\n<td><code>WatchEvent</code> 是最小的通信单位，只包含通知状态、事件类型和节点路径，不包含节点数据变化前后的具体内容。</td>\n</tr>\n<tr>\n<td><strong>时效性</strong></td>\n<td>Watcher 仅在当前 Session 完全失效时才无效。如果 Session 快速重连成功，Watcher 依然有效，可继续接收通知。</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>可以开启监听的命令</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#监听节点数据的变化</span></span><br><span class=\"line\">get -w path</span><br><span class=\"line\"><span class=\"built_in\">stat</span> -w path</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#监听子节点增减的变化</span></span><br><span class=\"line\"><span class=\"built_in\">ls</span> -w path</span><br></pre></td></tr></table></figure>\n<h3 id=\"永久性-Watch\">永久性 Watch</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在被触发之后，仍然保留，可以继续监听ZNode上的变更，是Zookeeper 3.6.0版本新增的功能</p>\n</li>\n<li class=\"lvl-2\">\n<p>创建监听</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addWatch [-m mode] path</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mode:</span></span><br><span class=\"line\"><span class=\"comment\"># - PERSISTENT: 持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。</span></span><br><span class=\"line\"><span class=\"comment\"># - PERSISTENT_RECURSIVE: 持久化递归订阅(这个是默认值)，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性）</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除监听</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 普通一次性 Watch 不需要手动删除，触发后会自动移除；removewatches 主要用于持久 Watch（persistent watch）。</span></span><br><span class=\"line\">removewatches path [-c|-d|-a] [-l]</span><br><span class=\"line\"><span class=\"comment\"># -c: 仅删除当前客户端的 Watch</span></span><br><span class=\"line\"><span class=\"comment\"># -d: 删除指定节点的所有 Watch(包括其他客户端注册的)</span></span><br><span class=\"line\"><span class=\"comment\"># -a: 删除所有节点的所有 Watch（包括其他客户端的 Watch），慎用！！！</span></span><br><span class=\"line\"><span class=\"comment\"># -l: 显示被删除的 Watch 列表</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"监听器应用场景\">监听器应用场景</h3>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>特点</th>\n<th>应用场景举例</th>\n<th>适合的节点类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>临时监听</strong>（一次性 Watch）</td>\n<td>- 触发一次后自动移除<br>- 客户端需手动重新注册<br>- 轻量级，适合单次通知</td>\n<td>1. <strong>配置中心</strong>：配置变化时通知客户端，客户端收到通知后重新拉取最新配置 <br> 2. <strong>分布式锁</strong>：节点删除（锁释放）后通知等待的客户端重新竞争锁 <br> 3. <strong>主从选举</strong>：主节点宕机后，其他节点收到通知重新选主</td>\n<td><strong>持久节点</strong>（Persistent） <br><strong>临时节点</strong>（Ephemeral，用于锁和选主）</td>\n</tr>\n<tr>\n<td><strong>永久监听</strong>（Persistent Watch）</td>\n<td>- 注册后持续有效，直到客户端主动移除<br>- 支持子节点变化、数据变化的长期监听</td>\n<td>1. <strong>服务发现</strong>：客户端长期监听服务节点变化，节点上线/下线时自动更新本地服务列表 <br> 2. <strong>监控告警</strong>：监控重要节点状态，节点数据变化或被删除时自动触发告警 <br> 3. <strong>分布式缓存</strong>：缓存节点变化时，通知客户端刷新缓存</td>\n<td><strong>持久节点</strong>（Persistent）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"ACL权限控制\">ACL权限控制</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 默认情况下，所有节点的权限都是 <code>OPEN_ACL_UNSAFE</code> ，任何客户端都可以读写任意节点数据。</p>\n</li>\n<li class=\"lvl-2\">\n<p>生产环境中，通常需要限制对节点的访问权限，即 <code>ACL</code> 权限控制。</p>\n</li>\n<li class=\"lvl-2\">\n<p>ZooKeeper 里的 ACL（Access Control List，访问控制列表） 主要用于控制 谁可以对某个节点做什么操作，它是 ZooKeeper 提供的安全机制之一。</p>\n</li>\n</ul>\n<h3 id=\"ACL-的作用\">ACL 的作用</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>限制访问：只允许授权用户或客户端对指定节点进行读、写、删除等操作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>防止误操作：保护重要节点不被未授权的客户端修改或删除。</p>\n</li>\n<li class=\"lvl-2\">\n<p>安全隔离：不同的应用或团队可以在同一 ZooKeeper 集群里安全共存。</p>\n</li>\n</ul>\n<h3 id=\"ACL-的组成\">ACL 的组成</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>zookeeper 的 acl 通过 <code>scheme:id:permissions</code> 来构成权限列表。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">scheme：授权的模式，代表采用的某种权限机制，包括 world、auth、digest、ip、super 几种。</li>\n<li class=\"lvl-4\">id：授权对象，代表允许访问的用户。如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。</li>\n<li class=\"lvl-4\">permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限， 创建权限 create©、删除权限 delete(d)、读权限 read®、写权限 write(w)、管理权限admin(a)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见的-scheme-类型\">常见的 scheme 类型</h3>\n<table>\n<thead>\n<tr>\n<th>Scheme</th>\n<th>说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>world</code></td>\n<td>开放给所有用户，仅可设置为 <code>anyone</code> 代表所有客户端</td>\n<td><code>world:anyone:r</code></td>\n</tr>\n<tr>\n<td><code>auth</code></td>\n<td>已通过 <code>addauth</code> 添加认证的客户端</td>\n<td><code>auth:user1:rw</code></td>\n</tr>\n<tr>\n<td><code>digest</code></td>\n<td>用户名+密码认证（常用），<code>user:pwd</code> 需要加密存储</td>\n<td><code>digest:user1:password:rw</code></td>\n</tr>\n<tr>\n<td><code>ip</code></td>\n<td>基于 IP 地址控制访问</td>\n<td><code>ip:192.168.1.10:r</code></td>\n</tr>\n<tr>\n<td><code>super</code></td>\n<td>超级用户，拥有所有权限</td>\n<td><code>super:admin:secret</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"权限类型\">权限类型</h3>\n<table>\n<thead>\n<tr>\n<th>权限字符</th>\n<th>权限名称</th>\n<th>允许的操作/命令示例</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>r</code></strong></td>\n<td>读取(Read)</td>\n<td><code>get /node</code> <br> <code>ls /node</code> <br> <code>getAcl /node</code></td>\n<td>允许读取节点数据和子节点列表</td>\n</tr>\n<tr>\n<td><strong><code>w</code></strong></td>\n<td>写入(Write)</td>\n<td><code>set /node data</code></td>\n<td>允许修改节点数据</td>\n</tr>\n<tr>\n<td><strong><code>c</code></strong></td>\n<td>创建(Create)</td>\n<td><code>create /node/sub &quot;data&quot;</code></td>\n<td>允许在当前节点下创建子节点</td>\n</tr>\n<tr>\n<td><strong><code>d</code></strong></td>\n<td>删除(Delete)</td>\n<td><code>delete /node/sub</code></td>\n<td>允许删除当前节点的子节点</td>\n</tr>\n<tr>\n<td><strong><code>a</code></strong></td>\n<td>管理(Admin)</td>\n<td><code>setAcl /node acl</code></td>\n<td>允许修改 ACL 权限</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"典型应用场景\">典型应用场景</h3>\n<table>\n<thead>\n<tr>\n<th>认证方式（scheme）</th>\n<th>权限类型（permissions）</th>\n<th>典型 ACL 配置示例</th>\n<th>应用场景</th>\n<th>特点说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>world</strong></td>\n<td><code>r</code>（只读）</td>\n<td><code>world:anyone:r</code></td>\n<td>公共配置节点，所有客户端都可读取</td>\n<td>简单、无认证，适合对安全性要求不高的只读场景</td>\n</tr>\n<tr>\n<td><strong>auth</strong></td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>auth:user:rwcd</code></td>\n<td>内部应用共享节点，需客户端认证</td>\n<td>需先 <code>addauth digest user1:password</code> 添加认证，适合多客户端共享</td>\n</tr>\n<tr>\n<td><strong>digest</strong>（常用）</td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>digest:user:secret:crwda</code></td>\n<td>高安全节点，配置中心，分布式锁</td>\n<td>用户名+密码认证，需加密存储密码，灵活安全</td>\n</tr>\n<tr>\n<td><strong>ip</strong></td>\n<td><code>r,w,c,d,a</code>（可组合）</td>\n<td><code>ip:192.168.1.100:r</code></td>\n<td>基于 IP 限制访问的场景</td>\n<td>快速控制某些固定 IP 可访问，适合内部网络应用</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"ACL-相关命令\">ACL 相关命令</h3>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>语法</th>\n<th>功能说明</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>getAcl</strong></td>\n<td><code>getAcl path</code></td>\n<td>读取指定节点的 ACL</td>\n<td><code>getAcl /my_node</code></td>\n</tr>\n<tr>\n<td><strong>setAcl</strong></td>\n<td><code>setAcl path acl</code></td>\n<td>设置指定节点的 ACL</td>\n<td><code>setAcl /my_node world:anyone:crdwa</code></td>\n</tr>\n<tr>\n<td><strong>create</strong></td>\n<td><code>create path data [acl]</code></td>\n<td>创建节点时指定 ACL</td>\n<td><code>create /secure_node &quot;secret_data&quot; digest:user1:pwd:crwa</code></td>\n</tr>\n<tr>\n<td><strong>addAuth</strong></td>\n<td><code>addauth scheme auth</code></td>\n<td>添加认证用户（类似登录）</td>\n<td><code>addauth digest user1:password</code></td>\n</tr>\n<tr>\n<td><strong>deleteAcl(不存在)</strong></td>\n<td><code>setAcl path world:anyone:</code></td>\n<td>删除节点 ACL（设为空或全开放）</td>\n<td><code>setAcl /my_node world:anyone:</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"auth-与-digest-的区别\"><code>auth</code> 与 <code>digest</code> 的区别</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用 <code>auth</code> 时，需先 <code>addauth digest user1:password</code> 添加认证，<code>setAcl</code> 时，使用 <code>auth:user1:rw</code>，这里是为已经登录的用户设置节点权限，所以不需要设置密码</p>\n</li>\n<li class=\"lvl-2\">\n<p>使用 <code>digest</code> 时，无需进行登录认证，所以需要指定密码，即<code>setAcl</code> 时，使用 <code>digest:user1:password:rw</code></p>\n</li>\n<li class=\"lvl-2\">\n<p><code>digest</code> 的密码是经过加密的，所以不能直接使用明文密码</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 加密密码</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -n user:123456 | openssl dgst -binary -sha1 | openssl <span class=\"built_in\">base64</span></span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">6DY5WhzOfGsWQ1XFuIyzxkpwdPo=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># zookeeper客户端中设置权限</span></span><br><span class=\"line\">setAcl /name digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:cdrwa</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 登录时密码是明文</span></span><br><span class=\"line\">addauth digest user:123456</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论使用 <code>digest</code> 还是 <code>auth</code>，在需要访问节点前，都需要先登录。</p>\n</li>\n</ul>\n<h3 id=\"super-超级管理员\"><code>super</code> 超级管理员</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>拥有全部节点的所有权限: <code>crwda</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>设置超级管理员</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 加密密码，用户和密码可以随意设置</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -n admin:123456 | openssl dgst -binary -sha1 | openssl <span class=\"built_in\">base64</span></span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打开 conf/zoo.cfg 文件并编辑，在文件中添加下面内容</span></span><br><span class=\"line\">DigestAuthenticationProvider.superDigest=admin:0uek/hZ/V9fgiM35b0Z2226acMQ=</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>重新启动服务后登录客户端进行测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建节点并设置权限，这里将节点授权给用户user</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 10] create /testNode 666 digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:rw</span><br><span class=\"line\">Created /testNode</span><br><span class=\"line\"><span class=\"comment\"># 查看节点内容被拒绝</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 11] get /testNode</span><br><span class=\"line\">Insufficient permission : /testNode</span><br><span class=\"line\"><span class=\"comment\"># 登录super用户，验证超级用户是否有权限访问节点</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 12] addauth digest admin:123456</span><br><span class=\"line\"><span class=\"comment\"># 此时查看节点内容就可以了</span></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 13] get /testNode</span><br><span class=\"line\">666</span><br></pre></td></tr></table></figure>\n<h2 id=\"4字母命令\">4字母命令</h2>\n<h3 id=\"什么是-4-字母命令\">什么是 <code>4 字母命令</code>?</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper 提供了一组简短的 <code>4个字母的管理命令</code>(Four Letter Words Commands, 4lw)，可以通过 TCP 连接 ZooKeeper 端口（默认 2181）发送这些命令，快速查看或管理 ZooKeeper 状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>常用的 <code>4字母命令</code></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>引入版本</th>\n<th>功能描述</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>conf</code></td>\n<td>3.3.0</td>\n<td>打印服务相关配置的详细信息</td>\n<td><code>echo conf | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>cons</code></td>\n<td>3.3.0</td>\n<td>列出所有连接到该服务器的客户端连接/会话详细信息，包括接收/发送的包数量、会话ID、操作延迟、最后操作执行时间等</td>\n<td><code>echo cons | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>crst</code></td>\n<td>3.3.0</td>\n<td>重置所有连接的连接和会话统计信息</td>\n<td><code>echo crst | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>dump</code></td>\n<td>-</td>\n<td>列出重要的会话和临时节点信息，仅在 Leader 节点上有效</td>\n<td><code>echo dump | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>envi</code></td>\n<td>-</td>\n<td>打印服务环境的详细信息</td>\n<td><code>echo envi | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>reqs</code></td>\n<td>-</td>\n<td>列出未经处理的请求</td>\n<td><code>echo reqs | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>ruok</code></td>\n<td>-</td>\n<td>测试服务是否处于正常状态；正常返回 <code>imok</code></td>\n<td><code>echo ruok | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>stat</code></td>\n<td>-</td>\n<td>输出关于性能和客户端连接的列表信息</td>\n<td><code>echo stat | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>srst</code></td>\n<td>-</td>\n<td>重置服务器统计信息</td>\n<td><code>echo srst | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>srvr</code></td>\n<td>3.3.0</td>\n<td>列出连接服务器的详细信息</td>\n<td><code>echo srvr | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchs</code></td>\n<td>3.3.0</td>\n<td>列出服务器 Watch 的详细信息</td>\n<td><code>echo wchs | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchc</code></td>\n<td>3.3.0</td>\n<td>通过会话列出服务器 Watch 的详细信息，输出与 Watch 相关的会话列表</td>\n<td><code>echo wchc | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>wchp</code></td>\n<td>3.3.0</td>\n<td>通过路径列出服务器 Watch 的详细信息，输出与会话相关的路径</td>\n<td><code>echo wchp | nc 127.0.0.1 2181</code></td>\n</tr>\n<tr>\n<td><code>mntr</code></td>\n<td>3.4.0</td>\n<td>输出可用于检测集群健康状态的关键指标变量列表</td>\n<td><code>echo mntr | nc 127.0.0.1 2181</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"开启-4字母命令\">开启 <code>4字母命令</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 ZooKeeper 3.5.0 及之后的版本，4lw 命令默认是禁用的，必须在配置文件(zoo.cfg)中显式开启。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 表示允许所有 4lw 命令都能用（风险最大）</span></span><br><span class=\"line\">4lw.commands.whitelist=*</span><br><span class=\"line\"><span class=\"comment\"># 这样只允许执行 stat、conf、ruok 这几个命令。</span></span><br><span class=\"line\">4lw.commands.whitelist=<span class=\"built_in\">stat</span>,conf,ruok</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用方法</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 如果没有安装 nc，可以使用 yum 安装</span></span><br><span class=\"line\">yum install nc -y</span><br><span class=\"line\"><span class=\"comment\"># 查看节点状态</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"built_in\">stat</span> | nc 127.0.0.1 2181</span><br></pre></td></tr></table></figure>\n<h2 id=\"Zookeeper-Java-Client\">Zookeeper Java Client</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>项目示例：<a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/zookeeper-demo/\">Github地址</a>，单元测试。</p>\n</li>\n</ul>\n<h3 id=\"Zookeeper-官方Java客户端\">Zookeeper 官方Java客户端</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ZooKeeper官方的客户端API提供了基本的操作。例如，创建会话、创建节点、读取节点、更新数据、删除节点和检查节点是否存在等。不过，对于实际开发来说，ZooKeeper官方API有一些不足之处，具体如下：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">ZooKeeper的Watcher监测是一次性的，每次触发之后都需要重新进行注册。</li>\n<li class=\"lvl-4\">会话超时之后没有实现重连机制。</li>\n<li class=\"lvl-4\">异常处理烦琐，ZooKeeper提供了很多异常，对于开发人员来说可能根本不知道应该如何处理这些抛出的异常。</li>\n<li class=\"lvl-4\">仅提供了简单的byte[]数组类型的接口，没有提供Java POJO级别的序列化数据处理接口。</li>\n<li class=\"lvl-4\">创建节点时如果抛出异常，需要自行检查节点是否存在。</li>\n<li class=\"lvl-4\">无法实现级联删除。</li>\n<li class=\"lvl-4\">总之，ZooKeeper官方API功能比较简单，在实际开发过程中比较笨重，一般不推荐使用。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>项目引入依赖时，最好保持与服务端版本一致，否则可能会有一些兼容性的问题</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- zookeeper client --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.4<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Zookeeper-第三方Java客户端-Curator\">Zookeeper 第三方Java客户端 Curator</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://curator.apache.org/docs/about\">Curator</a>是Netflix公司开源的一套ZooKeeper客户端框架，和ZkClient一样它解决了非常底层的细节开发工作，包括连接、重连、反复注册Watcher的问题以及NodeExistsException异常等。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Curator是Apache基金会的顶级项目之一，Curator具有更加完善的文档，另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Curator还为ZooKeeper客户端框架提供了一些比较普遍的、开箱即用的、分布式开发用的解决方案，例如Recipe、共享锁服务、Master选举机制和分布式计算器等，帮助开发者避免了“重复造轮子”的无效开发工作。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在实际的开发场景中，使用Curator客户端就足以应付日常的ZooKeeper集群操作的需求。</p>\n</li>\n<li class=\"lvl-2\">\n<p>引入依赖说明：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>模块</th>\n<th>依赖关系</th>\n<th>功能定位</th>\n<th>典型功能举例</th>\n<th>常用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>curator-client</strong></td>\n<td>依赖 zookeeper</td>\n<td>连接管理、重试策略、底层 API</td>\n<td>连接会话管理、RetryPolicy</td>\n<td>需要最轻量的 ZooKeeper 客户端</td>\n</tr>\n<tr>\n<td><strong>curator-framework</strong></td>\n<td>依赖 curator-client</td>\n<td>高层 API 封装，简化 ZK 操作</td>\n<td>创建节点、Watcher 管理、自动重连</td>\n<td>通用 ZooKeeper 客户端开发</td>\n</tr>\n<tr>\n<td><strong>curator-recipes</strong></td>\n<td>依赖 curator-framework → curator-client</td>\n<td>分布式模式现成实现</td>\n<td>分布式锁、Leader 选举、队列、Barrier</td>\n<td>直接用分布式工具，无需自己实现</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>使用建议</p>\n</blockquote>\n<ul class=\"lvl-0\">\n<li class=\"lvl-4\">\n<p>如果你只想轻量访问 ZooKeeper → <code>curator-client</code> 就够了，但几乎没人单独用。</p>\n</li>\n<li class=\"lvl-4\">\n<p>如果你想方便操作 ZooKeeper API → <code>curator-framework</code>，大部分情况都适用。</p>\n</li>\n<li class=\"lvl-4\">\n<p>如果你想用分布式锁、选举、Barrier → <code>curator-recipes</code>（它会自动引入前两个）。</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- zookeeper client --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.8.4<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!--curator--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.curator<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>curator-recipes<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.9.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">exclusions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">exclusion</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.zookeeper<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">exclusion</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">exclusions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 CentOS9 中 Zookeeper 的安装与使用。 Zookeeper官网 本文使用的 Zookeeper 版本为 3.8.4。 Zookeeper 简介 ZooKeeper 是一个集中式服务，用于： 场景 ZooKeeper 官方功能 主要节点类型 具体场景示例 配置中心 (Config Center) 维护配置信息 (Configuration Management) 持久节点（Persistent） 把数据库连接信息、系统参数等放在 ZooKeeper 里，动态更新，像 Apollo、Spring Cloud Config 一样。 注册中心 (Service Registry) 提供命名服务 (Naming Service) 临时节点（Ephemeral） 服务实例启动时在 ZooKeeper 里注册自己的地址，客户端从 ZooKeeper 获取服务列表，类似于 Nacos、Eureka。 分布式锁 (Distributed Lock) 分布式同步 (Distributed Synchronization) 临时顺序节点（Ephemeral Sequential） 用临时顺序节点实现分布式锁，保证只有一个实例在执行关键任务，典型应用是分布式定时任务调度。 消息队列 (Message Queue) 集群管理服务 (Cluster Management) 持久/临时节点 + Watch 机制 通过 Watch 机制监听 ZNode 变化，节点间用数据变更当“信号”传递消息，早期 Kafka 用过这种方式。 ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。 不同于文件系统，每个节点都可以保存数据，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识，每个节点都有一个版本(version)，版本从0开始计数。 Zookeeper 安装 运行 Zookeeper 需要安装 JDK1.8+。我这里使用 OpenJDK11 12345678910111213141516sudo mkdir -p /usr/local/jdkcd /usr/local/jdksudo wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzsudo tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzsudo ln -s jdk-11.0.28+6 jdk11# 配置环境变量vim /etc/profile # 添加如下内容 export JAVA_HOME=/usr/local/jdk/jdk11 export PATH=$JAVA_HOME/bin:$PATH# 立即生效source /etc/profile# 查看java版本java -versionopenjdk version &quot;11.0.28&quot; 2025-07-15OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode) 单机安装 下载 Zookeeper，目前最新的稳定版本为 3.8.4 123456# 下载wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz# 解压tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz# 配置个软连接，方便以后升级ln -s apache-zookeeper-3.8.4-bin zookeeper 修改配置文件 1234cd zookeeper/confcp zoo_sample.cfg zoo.cfg# 建议修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改为指定的data目录vim zoo.cfg zoo.cfg 参数说明 配置项 说明 默认值 单位 / 备注 tickTime ZooKeeper 时间配置中的基本单位 2000 毫秒 initLimit follower 初始化连接到 leader 的最大时长，单位为 tickTime 倍数 10 10 × tickTime = 20000 ms syncLimit follower 与 leader 数据同步的最大时长，单位为 tickTime 倍数 5 5 × tickTime = 10000 ms dataDir 数据和日志存储目录（未指定 dataLogDir 时，日志也会保存在此目录） /tmp/zookeeper 目录路径 clientPort 客户端连接 ZooKeeper 的端口号 2181 默认 2181 maxClientCnxns 单个客户端最大并发连接数 60 超过限制后新连接会被拒绝 autopurge.snapRetainCount 快照文件保留个数，超过数量的将会被清理 3 默认 3 autopurge.purgeInterval 清理任务执行间隔时间，单位小时，0 表示不自动清理 1 1 小时 启动 zookeeper 123456789101112cd zookeeper# 启动bin/zkServer.sh start# 指定配置文件bin/zkServer.sh start conf/zoo.cfg# 停止bin/zkServer.sh stop# 查看状态bin/zkServer.sh status# 查看版本./bin/zkServer.sh version 集群安装 ZooKeeper 集群角色 1. Leader（领导者） 职责： 事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性； 集群内部各个服务器的调度者； 对于 create、setData、delete 等写操作请求，统一转发给 Leader 处理； Leader 负责决定编号、执行操作，这个过程称为 事务。 三台虚拟机 zoo.cfg 文件末尾添加配置，启动时会自动选举出 Leader 角色，则其余就是 Follower 角色。 123server.1=10.250.0.229:2888:3888server.2=10.250.0.152:2888:3888server.3=10.250.0.36:2888:3888 2. Follower（跟随者） 职责： 处理客户端非事务（读操作）请求（可以直接响应）； 转发事务请求给 Leader； 参与集群 Leader 选举投票。 leader节点可以处理读写请求，follower只可以处理读请求。follower在接到写请求时会把写请求转发给leader来处理。 3. Observer（观察者） 职责： 对于非事务请求（读操作）可以独立处理； 对于事务请求会转发给 Leader 处理； 接收来自 Leader 的 inform 信息，更新本地存储； 不参与提交和选举投票； 通常用于 提升集群非事务处理能力，不影响集群事务处理性能。 配置一个 ID 为 4 的观察者节点： 1server.4=10.250.0.56:2888:3888:observer 集群搭建 环境准备：4台服务器，按照 单机安装 的方式准备好 Zookeeper 环境 123410.250.0.22910.250.0.15210.250.0.3610.250.0.56 zoo.cfg 文件末尾添加配置 1234server.1=10.250.0.229:2888:3888server.2=10.250.0.152:2888:3888server.3=10.250.0.36:2888:3888server.4=10.250.0.56:2888:3888:observer 分别在 dataDir 目录下创建 myid 文件，在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格） 12345# 注意 节点编号不能重复，而且要与 zoo.cfg 文件中的 server.id 一致echo 1 &gt; myid# echo 2 &gt; myid# echo 3 &gt; myid# echo 4 &gt; myid 分别启动 Zookeeper 服务器 12345# 分别启动4个节点的zookeeper serverbin/zkServer.sh start# 查看状态，可以看到节点角色类型bin/zkServer.sh status 集群最少节点要求和扩容规则 ZooKeeper 使用 多数派（quorum）机制 来保证数据一致性 1231.集群总节点数 N2.容忍的宕机节点数 F = (N-1)/2（向下取整）3.要保证集群可用，需要 大于 N/2 的节点存活 集群扩容规则 1234561.节点总数必须是奇数 奇数节点可以保证多数派投票机制正常 偶数节点不推荐，容错能力不增加（比如 4 台，仍然只容忍 1 台宕机）2.每次扩容建议 +2 节点 这样既保持奇数，又增加 quorum 容错能力 最少节点与容错能力表格 集群总节点数 N 容忍宕机数 F 可用 quorum 节点数 备注 1 0 1 不推荐，无法容忍故障 2 0 2 不推荐，1 台宕机就不可用 3 1 2 最小可用生产集群 5 2 3 推荐生产集群规模 7 3 4 高可用大集群 9 4 5 更大集群，高容错 11 5 6 极高可用场景 ZooKeeper 默认端口说明 端口 用途 说明 2181 客户端连接端口 客户端通过这个端口访问 ZooKeeper 2888 集群内部通信 follower 与 leader 之间同步数据 3888 leader 选举端口 集群选举 leader 使用 8080 (可选) admin/metrics web端口 如果开启了 adminServer 123456789101112# 永久开启端口sudo firewall-cmd --permanent --add-port=2181/tcpsudo firewall-cmd --permanent --add-port=2888/tcpsudo firewall-cmd --permanent --add-port=3888/tcp# 如果使用 adminServersudo firewall-cmd --permanent --add-port=8080/tcp# 重新加载防火墙配置sudo firewall-cmd --reload# 查看是否开放成功sudo firewall-cmd --list-all 客户端连接 命令行 1234# 默认连接 127.0.0.1:2181bin/zkCli.sh# 指定 -server ip:port，如果是集群，则连接任意一个节点，ZooKeeper 会自动处理与 Leader/Follower 的交互bin/zkCli.sh -server 127.0.0.1:2181 客户端命令简介：参考官网 命令 语法示例 功能描述 常用参数及说明 示例 help help 显示所有操作命令 无 help version version 查看客户端和服务器版本信息 无 version connect connect host:port 连接到指定 ZooKeeper 服务器 host:port: 服务器地址 connect 127.0.0.1:2181 close close 关闭当前会话 ,通过 connect 可重连 无 close quit quit 退出客户端 无 quit ls ls [-s] [-w] [-R] path 查看节点的子节点 - -w: 监听子节点变化- -s: 显示节点状态信息- -R: 递归查看 ls -s -w /zk_test getAllChildrenNumber getAllChildrenNumber path 获取某节点所有子节点的总数 无 getAllChildrenNumber /zk_test getEphemerals getEphemerals path 获取某路径下所有临时节点 无 getEphemerals /zk_test create create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 - -s: 顺序节点- -e: 临时节点- -c: 容器节点- -t ttl: TTL节点，单位毫秒 create -e /zk_test_ephemeral &quot;temp_data&quot; get get [-s] [-w] path 获取节点数据信息 - -s: 显示节点状态信息- -w: 监听节点变化 get -s -w /zk_test set set [-s] [-v version] path data 设置节点数据 - -s: 显示节点状态信息- -v: 指定版本号 set /zk_test &quot;new_data&quot; stat stat [-w] path 查看节点状态信息 - -w: 监听节点变化 stat -w /zk_test sync sync path 同步指定节点数据 无 sync /zk_test delete delete [-v version] path 删除某一节点（无子节点） - -v: 节点版本号 delete /zk_test deleteall deleteall path 递归删除某一节点及其子节点 无 deleteall /zk_test getAcl getAcl [-s] path 获取节点访问控制信息 - -s: 显示节点状态信息 getAcl /zk_test setAcl setAcl [-s] [-v version] [-R] path acl 设置节点访问控制列表 - -s: 显示节点状态信息- -v: 指定版本号- -R: 递归设置 setAcl /zk_test world:anyone:r listquota listquota path 查看节点配额信息 无 listquota /zk_test setquota setquota [-n] [-b] val path 对节点增加限制 - -n: 子节点最大个数- -b: 数据值最大长度，-1 表示无限制 setquota -n 5 /zk_test delquota delquota [-n | -b] path 删除节点配额限制 - -n: 删除子节点数限制- -b: 删除数据值大小限制 delquota -n /zk_test config config 查看服务器配置 无 config whoami whoami 查看当前会话身份 无 whoami GUI 工具 名称 类型 / 运行方式 优点 注意事项 PrettyZoo 桌面应用（JavaFX）(GitHub) 支持 Mac/Windows/Linux，界面友好；支持节点创建/删除/更新/查询，ACL 管理，多 ZK 实例管理，SSH 隧道等功能。(GitHub) 项目已经 archived，维护可能不活跃。最新版可能在兼容性或 Bug 修复方面不如活跃项目。也可能需要自己构建或调试。(GitHub) ZooNavigator Web 界面 + 可 Docker 部署或本地启动(GitHub) 功能丰富；支持多个 Zookeeper 版本（如 3.5.x ～ 3.9.x）；浏览 / 编辑 /搜索节点；导入导出配置；支持浏览器访问，无需本地 heavy GUI。(GitHub) 因为 Web 应用，可能对浏览器安全策略与网络延迟敏感；需要部署自己版本或 Docker；如果要求本地脱机操作时，有些功能可能稍不如桌面应用。 ZooKeeper Assistant 桌面／管理员面板类型（支持监控界面等）(DEV Community) 除了浏览节点树以外，还提供健康状态监控（延迟、请求数等）、不同数据格式支持（JSON/XML 等）、导入/导出节点数据、命令行操作集成。(DEV Community) 有些功能可能在 Mac 上兼容性或视觉体验需要调试；具体版本支持情况要看最近更新。某些监控界面可能依赖于 ZK 的指标或插件。 Zookeeper 节点类型 节点类型 生命周期说明 创建命令示例 特点说明 持久节点 (Persistent) 节点一直存在，除非手动删除，即使客户端会话关闭，节点也不会消失 create /locks 适合存储配置信息、元数据等持久数据 临时节点 (Ephemeral) 客户端会话关闭（异常或超时）时，节点自动被删除 create -e /locks/DBLock 常用于分布式锁、临时会话数据 有序节点 (Sequential) 在持久或临时节点基础上，增加有序编号，ZooKeeper 自动在节点名后加递增序号 create -e -s /jobs/job 常用于分布式锁、队列等需要顺序的场景 容器节点 (Container) V3.5.3+，当容器节点下的最后一个子节点被删除后，容器节点也会自动删除 create -c /work 适合分布式任务临时目录、动态数据目录 TTL 节点 (TTL) 在指定 TTL 时间内未修改且无子节点，节点会被自动删除（需开启 extendedTypesEnabled=true 配置） create -t 3000 /ttl_node 适合临时缓存、临时状态数据，过期自动清理 注意 同一级节点 key 名称是唯一的 创建节点时，必须要带上全路径 节点状态信息 123456789101112[zk: localhost:2181(CONNECTED) 16] stat /testcZxid = 0x100000002 # Znode创建的事务idctime = Mon Sep 15 09:44:51 UTC 2025 # 创建时间mZxid = 0x100000004 # 最后一次修改事务idmtime = Mon Sep 15 09:47:12 UTC 2025 # 最后一次修改时间pZxid = 0x400000004 # 表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID（注意: 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）cversion = 1 # 子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。dataVersion = 1 # znode的数据版本号。每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据），可有效避免了数据更新时出现的先后顺序问题aclVersion = 0 # znode的ACL版本号。每次对节点进行ACL设置，aclVersion的值都会增加1ephemeralOwner = 0x0 # 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id。如果不是, ephemeralOwner值为0(持久节点)。dataLength = 3 # znode的数据长度numChildren = 1 # znode的子节点数量（只统计直接子节点的数量） Zookeeper 监听机制 watch机制，顾名思义是一个监听机制。Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发生时才会触发监听，通知给客户端。 监听的对象是事件，支持的事件类型如下： 1234567- None: 连接建立事件- NodeCreated： 节点创建- NodeDeleted： 节点删除- NodeDataChanged：节点数据变化- NodeChildrenChanged：子节点列表变化- DataWatchRemoved：节点监听被移除- ChildWatchRemoved：子节点监听被移除 监听特性 特性 说明 一次性触发 Watch 是一次性的，一旦被触发就会被移除。再次使用时需要重新注册。 客户端顺序回调 Watch 回调是顺序串行执行的，客户端只有在回调完成后才能看到最新的数据状态。 轻量级 Watcher 回调逻辑不应过多，以免阻塞或影响其他 Watch 的执行。 最小通信单位 WatchEvent 是最小的通信单位，只包含通知状态、事件类型和节点路径，不包含节点数据变化前后的具体内容。 时效性 Watcher 仅在当前 Session 完全失效时才无效。如果 Session 快速重连成功，Watcher 依然有效，可继续接收通知。 可以开启监听的命令 123456#监听节点数据的变化get -w pathstat -w path#监听子节点增减的变化ls -w path 永久性 Watch 在被触发之后，仍然保留，可以继续监听ZNode上的变更，是Zookeeper 3.6.0版本新增的功能 创建监听 12345addWatch [-m mode] path# mode:# - PERSISTENT: 持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。# - PERSISTENT_RECURSIVE: 持久化递归订阅(这个是默认值)，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性） 删除监听 123456# 普通一次性 Watch 不需要手动删除，触发后会自动移除；removewatches 主要用于持久 Watch（persistent watch）。removewatches path [-c|-d|-a] [-l]# -c: 仅删除当前客户端的 Watch# -d: 删除指定节点的所有 Watch(包括其他客户端注册的)# -a: 删除所有节点的所有 Watch（包括其他客户端的 Watch），慎用！！！# -l: 显示被删除的 Watch 列表 监听器应用场景 类型 特点 应用场景举例 适合的节点类型 临时监听（一次性 Watch） - 触发一次后自动移除- 客户端需手动重新注册- 轻量级，适合单次通知 1. 配置中心：配置变化时通知客户端，客户端收到通知后重新拉取最新配置 2. 分布式锁：节点删除（锁释放）后通知等待的客户端重新竞争锁 3. 主从选举：主节点宕机后，其他节点收到通知重新选主 持久节点（Persistent） 临时节点（Ephemeral，用于锁和选主） 永久监听（Persistent Watch） - 注册后持续有效，直到客户端主动移除- 支持子节点变化、数据变化的长期监听 1. 服务发现：客户端长期监听服务节点变化，节点上线/下线时自动更新本地服务列表 2. 监控告警：监控重要节点状态，节点数据变化或被删除时自动触发告警 3. 分布式缓存：缓存节点变化时，通知客户端刷新缓存 持久节点（Persistent） ACL权限控制 ZooKeeper 默认情况下，所有节点的权限都是 OPEN_ACL_UNSAFE ，任何客户端都可以读写任意节点数据。 生产环境中，通常需要限制对节点的访问权限，即 ACL 权限控制。 ZooKeeper 里的 ACL（Access Control List，访问控制列表） 主要用于控制 谁可以对某个节点做什么操作，它是 ZooKeeper 提供的安全机制之一。 ACL 的作用 限制访问：只允许授权用户或客户端对指定节点进行读、写、删除等操作。 防止误操作：保护重要节点不被未授权的客户端修改或删除。 安全隔离：不同的应用或团队可以在同一 ZooKeeper 集群里安全共存。 ACL 的组成 zookeeper 的 acl 通过 scheme:id:permissions 来构成权限列表。 scheme：授权的模式，代表采用的某种权限机制，包括 world、auth、digest、ip、super 几种。 id：授权对象，代表允许访问的用户。如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。 permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限， 创建权限 create©、删除权限 delete(d)、读权限 read®、写权限 write(w)、管理权限admin(a)。 常见的 scheme 类型 Scheme 说明 示例 world 开放给所有用户，仅可设置为 anyone 代表所有客户端 world:anyone:r auth 已通过 addauth 添加认证的客户端 auth:user1:rw digest 用户名+密码认证（常用），user:pwd 需要加密存储 digest:user1:password:rw ip 基于 IP 地址控制访问 ip:192.168.1.10:r super 超级用户，拥有所有权限 super:admin:secret 权限类型 权限字符 权限名称 允许的操作/命令示例 说明 r 读取(Read) get /node ls /node getAcl /node 允许读取节点数据和子节点列表 w 写入(Write) set /node data 允许修改节点数据 c 创建(Create) create /node/sub &quot;data&quot; 允许在当前节点下创建子节点 d 删除(Delete) delete /node/sub 允许删除当前节点的子节点 a 管理(Admin) setAcl /node acl 允许修改 ACL 权限 典型应用场景 认证方式（scheme） 权限类型（permissions） 典型 ACL 配置示例 应用场景 特点说明 world r（只读） world:anyone:r 公共配置节点，所有客户端都可读取 简单、无认证，适合对安全性要求不高的只读场景 auth r,w,c,d,a（可组合） auth:user:rwcd 内部应用共享节点，需客户端认证 需先 addauth digest user1:password 添加认证，适合多客户端共享 digest（常用） r,w,c,d,a（可组合） digest:user:secret:crwda 高安全节点，配置中心，分布式锁 用户名+密码认证，需加密存储密码，灵活安全 ip r,w,c,d,a（可组合） ip:192.168.1.100:r 基于 IP 限制访问的场景 快速控制某些固定 IP 可访问，适合内部网络应用 ACL 相关命令 命令 语法 功能说明 示例 getAcl getAcl path 读取指定节点的 ACL getAcl /my_node setAcl setAcl path acl 设置指定节点的 ACL setAcl /my_node world:anyone:crdwa create create path data [acl] 创建节点时指定 ACL create /secure_node &quot;secret_data&quot; digest:user1:pwd:crwa addAuth addauth scheme auth 添加认证用户（类似登录） addauth digest user1:password deleteAcl(不存在) setAcl path world:anyone: 删除节点 ACL（设为空或全开放） setAcl /my_node world:anyone: auth 与 digest 的区别 使用 auth 时，需先 addauth digest user1:password 添加认证，setAcl 时，使用 auth:user1:rw，这里是为已经登录的用户设置节点权限，所以不需要设置密码 使用 digest 时，无需进行登录认证，所以需要指定密码，即setAcl 时，使用 digest:user1:password:rw digest 的密码是经过加密的，所以不能直接使用明文密码 12345678910# 加密密码echo -n user:123456 | openssl dgst -binary -sha1 | openssl base64# 输出6DY5WhzOfGsWQ1XFuIyzxkpwdPo=# zookeeper客户端中设置权限setAcl /name digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:cdrwa# 登录时密码是明文addauth digest user:123456 无论使用 digest 还是 auth，在需要访问节点前，都需要先登录。 super 超级管理员 拥有全部节点的所有权限: crwda 设置超级管理员 1234567# 加密密码，用户和密码可以随意设置echo -n admin:123456 | openssl dgst -binary -sha1 | openssl base64# 输出0uek/hZ/V9fgiM35b0Z2226acMQ=# 打开 conf/zoo.cfg 文件并编辑，在文件中添加下面内容DigestAuthenticationProvider.superDigest=admin:0uek/hZ/V9fgiM35b0Z2226acMQ= 重新启动服务后登录客户端进行测试 1234567891011# 创建节点并设置权限，这里将节点授权给用户user[zk: localhost:2181(CONNECTED) 10] create /testNode 666 digest:user:6DY5WhzOfGsWQ1XFuIyzxkpwdPo=:rwCreated /testNode# 查看节点内容被拒绝[zk: localhost:2181(CONNECTED) 11] get /testNodeInsufficient permission : /testNode# 登录super用户，验证超级用户是否有权限访问节点[zk: localhost:2181(CONNECTED) 12] addauth digest admin:123456# 此时查看节点内容就可以了[zk: localhost:2181(CONNECTED) 13] get /testNode666 4字母命令 什么是 4 字母命令? ZooKeeper 提供了一组简短的 4个字母的管理命令(Four Letter Words Commands, 4lw)，可以通过 TCP 连接 ZooKeeper 端口（默认 2181）发送这些命令，快速查看或管理 ZooKeeper 状态。 常用的 4字母命令 命令 引入版本 功能描述 示例 conf 3.3.0 打印服务相关配置的详细信息 echo conf | nc 127.0.0.1 2181 cons 3.3.0 列出所有连接到该服务器的客户端连接/会话详细信息，包括接收/发送的包数量、会话ID、操作延迟、最后操作执行时间等 echo cons | nc 127.0.0.1 2181 crst 3.3.0 重置所有连接的连接和会话统计信息 echo crst | nc 127.0.0.1 2181 dump - 列出重要的会话和临时节点信息，仅在 Leader 节点上有效 echo dump | nc 127.0.0.1 2181 envi - 打印服务环境的详细信息 echo envi | nc 127.0.0.1 2181 reqs - 列出未经处理的请求 echo reqs | nc 127.0.0.1 2181 ruok - 测试服务是否处于正常状态；正常返回 imok echo ruok | nc 127.0.0.1 2181 stat - 输出关于性能和客户端连接的列表信息 echo stat | nc 127.0.0.1 2181 srst - 重置服务器统计信息 echo srst | nc 127.0.0.1 2181 srvr 3.3.0 列出连接服务器的详细信息 echo srvr | nc 127.0.0.1 2181 wchs 3.3.0 列出服务器 Watch 的详细信息 echo wchs | nc 127.0.0.1 2181 wchc 3.3.0 通过会话列出服务器 Watch 的详细信息，输出与 Watch 相关的会话列表 echo wchc | nc 127.0.0.1 2181 wchp 3.3.0 通过路径列出服务器 Watch 的详细信息，输出与会话相关的路径 echo wchp | nc 127.0.0.1 2181 mntr 3.4.0 输出可用于检测集群健康状态的关键指标变量列表 echo mntr | nc 127.0.0.1 2181 开启 4字母命令 在 ZooKeeper 3.5.0 及之后的版本，4lw 命令默认是禁用的，必须在配置文件(zoo.cfg)中显式开启。 1234# 表示允许所有 4lw 命令都能用（风险最大）4lw.commands.whitelist=*# 这样只允许执行 stat、conf、ruok 这几个命令。4lw.commands.whitelist=stat,conf,ruok 使用方法 1234# 如果没有安装 nc，可以使用 yum 安装yum install nc -y# 查看节点状态echo stat | nc 127.0.0.1 2181 Zookeeper Java Client 项目示例：Github地址，单元测试。 Zookeeper 官方Java客户端 ZooKeeper官方的客户端API提供了基本的操作。例如，创建会话、创建节点、读取节点、更新数据、删除节点和检查节点是否存在等。不过，对于实际开发来说，ZooKeeper官方API有一些不足之处，具体如下： ZooKeeper的Watcher监测是一次性的，每次触发之后都需要重新进行注册。 会话超时之后没有实现重连机制。 异常处理烦琐，ZooKeeper提供了很多异常，对于开发人员来说可能根本不知道应该如何处理这些抛出的异常。 仅提供了简单的byte[]数组类型的接口，没有提供Java POJO级别的序列化数据处理接口。 创建节点时如果抛出异常，需要自行检查节点是否存在。 无法实现级联删除。 总之，ZooKeeper官方API功能比较简单，在实际开发过程中比较笨重，一般不推荐使用。 项目引入依赖时，最好保持与服务端版本一致，否则可能会有一些兼容性的问题 123456&lt;!-- zookeeper client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.8.4&lt;/version&gt;&lt;/dependency&gt; Zookeeper 第三方Java客户端 Curator Curator是Netflix公司开源的一套ZooKeeper客户端框架，和ZkClient一样它解决了非常底层的细节开发工作，包括连接、重连、反复注册Watcher的问题以及NodeExistsException异常等。 Curator是Apache基金会的顶级项目之一，Curator具有更加完善的文档，另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。 Curator还为ZooKeeper客户端框架提供了一些比较普遍的、开箱即用的、分布式开发用的解决方案，例如Recipe、共享锁服务、Master选举机制和分布式计算器等，帮助开发者避免了“重复造轮子”的无效开发工作。 在实际的开发场景中，使用Curator客户端就足以应付日常的ZooKeeper集群操作的需求。 引入依赖说明： 模块 依赖关系 功能定位 典型功能举例 常用场景 curator-client 依赖 zookeeper 连接管理、重试策略、底层 API 连接会话管理、RetryPolicy 需要最轻量的 ZooKeeper 客户端 curator-framework 依赖 curator-client 高层 API 封装，简化 ZK 操作 创建节点、Watcher 管理、自动重连 通用 ZooKeeper 客户端开发 curator-recipes 依赖 curator-framework → curator-client 分布式模式现成实现 分布式锁、Leader 选举、队列、Barrier 直接用分布式工具，无需自己实现 使用建议 如果你只想轻量访问 ZooKeeper → curator-client 就够了，但几乎没人单独用。 如果你想方便操作 ZooKeeper API → curator-framework，大部分情况都适用。 如果你想用分布式锁、选举、Barrier → curator-recipes（它会自动引入前两个）。 12345678910111213141516171819&lt;!-- zookeeper client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.8.4&lt;/version&gt;&lt;/dependency&gt;&lt;!--curator--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;","summary":"摘要 本文介绍 CentOS9 中 Zookeeper 的安装与使用。 Zookeeper官网 本文使用的 Zookeeper 版本为 3.8.4。","date_published":"2025-09-15T13:30:05.000Z","tags":["技术","zookeeper","分布式","zookeeper"]},{"id":"https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/","url":"https://blog.hanqunfeng.com/2025/09/11/springboot3-shardingsphere-proxy-distsql/","title":"ShardingSphere-Proxy5.5.2 DistSQL","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"DistSQL\">DistSQL</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a>（Distributed SQL）是 Apache ShardingSphere 特有的操作语言。 它与标准 SQL 的使用方式完全一致，用于提供增量功能的 SQL 级别操作能力。</p>\n</li>\n<li class=\"lvl-2\">\n<p>灵活的规则配置和资源管控能力是 Apache ShardingSphere 的特点之一。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在使用 4.x 及其之前版本时，开发者虽然可以像使用原生数据库一样操作数据，但却需要通过本地文件或注册中心配置资源和规则。然而，操作习惯变更，对于运维工程师并不友好。</p>\n</li>\n<li class=\"lvl-2\">\n<p>从 5.x 版本开始，DistSQL（Distributed SQL）让用户可以像操作数据库一样操作 Apache ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的数据库产品。</p>\n</li>\n<li class=\"lvl-2\">\n<p>DistSQL 细分为 RDL、RQL、RAL 和 RUL 四种类型。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">RDL: Resource &amp; Rule Definition Language，负责资源和规则的创建、修改和删除。</li>\n<li class=\"lvl-4\">RQL: Resource &amp; Rule Query Language，负责资源和规则的查询和展现。</li>\n<li class=\"lvl-4\">RAL: Resource &amp; Rule Administration Language，负责强制路由、熔断、配置导入导出、数据迁移控制等管理功能。</li>\n<li class=\"lvl-4\">RUL: Resource &amp; Rule Utility Language，负责 SQL 解析、SQL 格式化、执行计划预览等功能。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>DistSQL 仅可以在 ShardingSphere-Proxy 中使用，不能在 ShardingSphere-JDBC 中使用。</p>\n</li>\n</ul>\n<h2 id=\"示例准备\">示例准备</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>具体的语法，官网介绍的很详细，这里基于 <a href=\"/2025/09/04/springboot3-shardingsphere-proxy/\" title=\"SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表\">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 中的配置进行示例说明。</p>\n</li>\n<li class=\"lvl-2\">\n<p>为了尽可能多的使用 DistSQL 语法，这里仅在 <code>global.yaml</code> 中配置如下内容:</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置为基于 zookeeper 集群模式，为了演示 DistSQL 语法，这里需要将配置持久化，使用 JDBC 的单机模式也可以</span></span><br><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置用户和权限，因为 DistSQL 暂不支持 用户和权限管理，所以这里需要先配置用户和权限</span></span><br><span class=\"line\"><span class=\"attr\">authority:</span></span><br><span class=\"line\">  <span class=\"attr\">users:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">root@127.0.0.1</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">admin:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">sharding@%</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">sharding</span></span><br><span class=\"line\">  <span class=\"attr\">privilege:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">DATABASE_PERMITTED</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">user-database-mappings:</span> <span class=\"string\">root@127.0.0.1=*,sharding@%=sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 ShardingSphere-Proxy 服务，并登录</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动 ShardingSphere-Proxy</span></span><br><span class=\"line\">./shardingsphere-proxy-bin/bin/start.sh</span><br><span class=\"line\"><span class=\"comment\"># 使用管理员登录</span></span><br><span class=\"line\">mysql -h127.0.0.1 -uroot -proot -P3307</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看当前用户权限</span></span><br><span class=\"line\">mysql&gt; SHOW AUTHORITY RULE;</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">| <span class=\"built_in\">users</span>                      | provider           | props                                                                |</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">| root@127.0.0.1; sharding@% | DATABASE_PERMITTED | &#123;<span class=\"string\">&quot;user-database-mappings&quot;</span>:<span class=\"string\">&quot;root@127.0.0.1=*,sharding@%=sharding_db&quot;</span>&#125; |</span><br><span class=\"line\">+----------------------------+--------------------+----------------------------------------------------------------------+</span><br><span class=\"line\">1 row <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.49 sec)</span><br></pre></td></tr></table></figure>\n<h2 id=\"全局配置，即global-yaml中的配置\">全局配置，即<code>global.yaml</code>中的配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>全局配置对所有逻辑数据库有效</p>\n</li>\n</ul>\n<h3 id=\"属性配置\">属性配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">props:</span></span><br><span class=\"line\">  <span class=\"attr\">sql-show:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>设置属性，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/set-dist-vairable/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里要注意，属性名需要使用下划线格式</span></span><br><span class=\"line\">SET DIST VARIABLE sql_show = <span class=\"literal\">true</span>;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看属性，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/show-dist-variable/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; SHOW DIST VARIABLES;</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br><span class=\"line\">| variable_name                           | variable_value  |</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br><span class=\"line\">| agent_plugins_enabled                   | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">| cached_connections                      | 0               |</span><br><span class=\"line\">| cdc_server_port                         | 33071           |</span><br><span class=\"line\">| check_table_metadata_enabled            | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| kernel_executor_size                    | 0               |</span><br><span class=\"line\">| load_table_metadata_batch_size          | 1000            |</span><br><span class=\"line\">| max_connections_size_per_query          | 1               |</span><br><span class=\"line\">| proxy_backend_query_fetch_size          | -1              |</span><br><span class=\"line\">| proxy_default_port                      | 3307            |</span><br><span class=\"line\">| proxy_frontend_database_protocol_type   |                 |</span><br><span class=\"line\">| proxy_frontend_executor_size            | 0               |</span><br><span class=\"line\">| proxy_frontend_flush_threshold          | 128             |</span><br><span class=\"line\">| proxy_frontend_max_connections          | 0               |</span><br><span class=\"line\">| proxy_frontend_ssl_cipher               |                 |</span><br><span class=\"line\">| proxy_frontend_ssl_enabled              | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| proxy_frontend_ssl_version              | TLSv1.2,TLSv1.3 |</span><br><span class=\"line\">| proxy_meta_data_collector_enabled       | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| proxy_netty_backlog                     | 1024            |</span><br><span class=\"line\">| sql_show                                | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">| sql_simple                              | <span class=\"literal\">false</span>           |</span><br><span class=\"line\">| system_log_level                        | INFO            |</span><br><span class=\"line\">| system_schema_metadata_assembly_enabled | <span class=\"literal\">true</span>            |</span><br><span class=\"line\">+-----------------------------------------+-----------------+</span><br></pre></td></tr></table></figure>\n<h3 id=\"分布式事务配置\">分布式事务配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">transaction:</span></span><br><span class=\"line\">  <span class=\"attr\">defaultType:</span> <span class=\"string\">XA</span></span><br><span class=\"line\">  <span class=\"attr\">providerType:</span> <span class=\"string\">Atomikos</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-2\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看事务规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/show-transaction-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW TRANSACTION RULE;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改事务规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/ral/global-rule/alter-transaction-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER TRANSACTION RULE(</span><br><span class=\"line\">  DEFAULT=<span class=\"string\">&quot;XA&quot;</span>, TYPE(NAME=<span class=\"string\">&quot;Atomikos&quot;</span>)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h2 id=\"规则配置，即database-xxx-yaml中的配置\">规则配置，即<code>database-xxx.yaml</code>中的配置</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>以下 DistSQL 仅可以在逻辑库中执行，所以需要先创建一个逻辑数据库</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; CREATE DATABASE sharding_db;</span><br><span class=\"line\">Query OK, 0 rows affected (0.03 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; use sharding_db;</span><br><span class=\"line\">Database changed</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据源配置\">数据源配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 DistSQL中，官方将数据源叫做<code>存储单元(STORAGE UNIT)</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span>  <span class=\"comment\"># 注意这里属性为 url</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-3\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注册存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/register-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">REGISTER STORAGE UNIT ds_0 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span></span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">REGISTER STORAGE UNIT ds_1 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span></span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/storage-unit-query/show-storage-units/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW STORAGE UNITS FROM sharding_db \\G;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/alter-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER STORAGE UNIT ds_1 (</span><br><span class=\"line\">    URL=<span class=\"string\">&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class=\"line\">    USER=<span class=\"string\">&quot;root&quot;</span>,</span><br><span class=\"line\">    PASSWORD=<span class=\"string\">&quot;newpwd&quot;</span>,</span><br><span class=\"line\">    PROPERTIES(<span class=\"string\">&quot;maximumPoolSize&quot;</span>=10,<span class=\"string\">&quot;idleTimeout&quot;</span>=30000)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>取消注册存储单元，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/storage-unit-definition/unregister-storage-unit/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 无法移除已经被规则使用的存储单元</span></span><br><span class=\"line\">UNREGISTER STORAGE UNIT ds_0;</span><br></pre></td></tr></table></figure>\n<h3 id=\"单表配置\">单表配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置文件中的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SINGLE</span> <span class=\"comment\"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"comment\"># MySQL 风格</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">ds_0.t_address</span> <span class=\"comment\"># 加载指定单表</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-4\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>加载单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/load-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/single-table/show-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW SINGLE TABLES;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>卸载单表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/single-table/unload-single-table/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">UNLOAD SINGLE TABLE ds_0.t_address;</span><br></pre></td></tr></table></figure>\n<h3 id=\"广播表配置\">广播表配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>广播表，即所有数据源都包含的表，比如字典表</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!BROADCAST</span>  <span class=\"comment\"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">dict</span>    <span class=\"comment\"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"DistSQL-语法-5\">DistSQL 语法</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/create-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/broadcast-table/drop-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP BROADCAST TABLE RULE dict;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询广播表，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/broadcast-table/show-broadcast-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中具有广播规则的表</span></span><br><span class=\"line\">SHOW BROADCAST TABLE RULES;</span><br><span class=\"line\"><span class=\"comment\"># 查询指定数据库中具有广播规则的表</span></span><br><span class=\"line\">SHOW BROADCAST TABLE RULES FROM sharding_db;</span><br></pre></td></tr></table></figure>\n<h3 id=\"分库分表配置\">分库分表配置</h3>\n<h4 id=\"单分片键，Long-类型\">单分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">course:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class=\"comment\"># 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">cid</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_inline</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">cid</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">course_inline:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span> <span class=\"comment\"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 属性</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">course_$&#123;cid</span> <span class=\"string\">%</span> <span class=\"number\">2</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class=\"line\">          <span class=\"attr\">allow-range-query-with-inline-sharding:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 允许范围查询</span></span><br><span class=\"line\">      <span class=\"attr\">course_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表示 ds_0, ds_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-6\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/create-sharding-table-rule/#1%E6%A0%87%E5%87%86%E5%88%86%E7%89%87%E8%A7%84%E5%88%99\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE course (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.course_<span class=\"variable\">$&#123;1..2&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=cid,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;course_<span class=\"variable\">$&#123;cid % 2 + 1&#125;</span>&quot;</span>,<span class=\"string\">&quot;allow-range-query-with-inline-sharding&quot;</span>=<span class=\"literal\">true</span> )))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=cid,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"单分片键，String-类型\">单分片键，String 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span>  <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">id</span> <span class=\"comment\"># 自增列名称，字符串类型</span></span><br><span class=\"line\"><span class=\"comment\">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">custom_snowflake_string</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span> <span class=\"comment\"># 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span> <span class=\"comment\"># 分表，t_user_0, t_user_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式序列算法</span></span><br><span class=\"line\">      <span class=\"attr\">uuid:</span>    <span class=\"comment\"># 定义名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">UUID</span> <span class=\"comment\"># 字符串主键，String</span></span><br><span class=\"line\">      <span class=\"attr\">custom_snowflake_string:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CUSTOM_SNOWFLAKE_STRING</span> <span class=\"comment\"># 自定义雪花算法，String，spi</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">workerId:</span> <span class=\"number\">2</span></span><br><span class=\"line\">          <span class=\"attr\">datacenterId:</span> <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-7\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_user (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_user_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class=\"built_in\">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;Math.abs(id.hashCode()%2)&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=<span class=\"built_in\">id</span>,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;t_user_<span class=\"variable\">$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=<span class=\"built_in\">id</span>,TYPE(NAME=<span class=\"string\">&quot;CUSTOM_SNOWFLAKE_STRING&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"多分片键，Long-类型\">多分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order-complex-algorithm</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span>  <span class=\"comment\"># 分片列名称,多个逗号分隔</span></span><br><span class=\"line\"><span class=\"comment\">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_item-class-based-algorithm_spi</span> <span class=\"comment\"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order-complex-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">COMPLEX_INLINE</span> <span class=\"comment\"># 基于行表达式的复合分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_order_complex_$&#123;(user_id</span> <span class=\"string\">+</span> <span class=\"string\">order_id</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">)</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm_spi:</span> <span class=\"comment\"># SPI</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">T_ORDER_ITEM_COMPLEX</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-8\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_order_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;complex_inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;t_order_complex_<span class=\"variable\">$&#123;(user_id + order_id + 1) % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE SHARDING TABLE RULE t_order_item_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_item_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;SNOWFLAKE&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"自动分片规则\">自动分片规则</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">   <span class=\"comment\"># 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致</span></span><br><span class=\"line\">    <span class=\"attr\">bindingTables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">t_order,t_order_item</span></span><br><span class=\"line\">    <span class=\"attr\">autoTables:</span> <span class=\"comment\"># 自动分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">mod_2:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MOD</span> <span class=\"comment\"># 基于 MOD 的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">sharding-count:</span> <span class=\"number\">2</span> <span class=\"comment\"># 分片数量，即 对 2 进行取余</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-9\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE SHARDING TABLE RULE t_order (</span><br><span class=\"line\">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class=\"line\">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class=\"string\">&quot;mod&quot;</span>,PROPERTIES(<span class=\"string\">&quot;sharding-count&quot;</span>=<span class=\"string\">&quot;2&quot;</span>)),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE SHARDING TABLE RULE t_order_item (</span><br><span class=\"line\">  STORAGE_UNITS(ds_0,ds_1),</span><br><span class=\"line\">  SHARDING_COLUMN=user_id,TYPE(NAME=<span class=\"string\">&quot;mod&quot;</span>,PROPERTIES(<span class=\"string\">&quot;sharding-count&quot;</span>=<span class=\"string\">&quot;2&quot;</span>)),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;snowflake&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<h4 id=\"其它分片操作语句\">其它分片操作语句</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/sharding/show-sharding-table-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看当前逻辑库下的所有分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULES \\G;</span><br><span class=\"line\"><span class=\"comment\"># 查看指定逻辑库下的分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULES FROM sharding_db; \\G;</span><br><span class=\"line\"><span class=\"comment\"># 查看指定分片规则</span></span><br><span class=\"line\">SHOW SHARDING TABLE RULE t_user \\G;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/alter-sharding-table-rule/\">官网文档</a>，与创建分片规则类似，将<code>CREATE</code>改为<code>ALTER</code>即可</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER SHARDING TABLE RULE t_order_item_complex (</span><br><span class=\"line\">  DATANODES(<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;0..1&#125;</span>.t_order_item_complex_<span class=\"variable\">$&#123;0..1&#125;</span>&quot;</span>),</span><br><span class=\"line\">  DATABASE_STRATEGY(TYPE=<span class=\"string\">&quot;standard&quot;</span>,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;inline&quot;</span>,PROPERTIES(<span class=\"string\">&quot;algorithm-expression&quot;</span>=<span class=\"string\">&quot;ds_<span class=\"variable\">$&#123;user_id % 2&#125;</span>&quot;</span>)))),</span><br><span class=\"line\">  TABLE_STRATEGY(TYPE=<span class=\"string\">&quot;complex&quot;</span>,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=<span class=\"string\">&quot;T_ORDER_ITEM_COMPLEX&quot;</span>))),</span><br><span class=\"line\">  KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=<span class=\"string\">&quot;SNOWFLAKE&quot;</span>))</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除分片规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/sharding/drop-sharding-table-rule/\">官网文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP SHARDING TABLE RULE t_order;</span><br><span class=\"line\"><span class=\"comment\"># 删除多个表</span></span><br><span class=\"line\">DROP SHARDING TABLE RULE t_order,t_order_item;</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据加密规则\">数据加密规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!ENCRYPT</span>    <span class=\"comment\"># 数据加密配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 加密表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 加密列名称</span></span><br><span class=\"line\">            <span class=\"attr\">cipher:</span></span><br><span class=\"line\">              <span class=\"attr\">name:</span> <span class=\"string\">password</span> <span class=\"comment\"># 密文列名称</span></span><br><span class=\"line\">              <span class=\"attr\">encryptorName:</span> <span class=\"string\">aes_encryptor</span> <span class=\"comment\"># 密文列加密算法名称</span></span><br><span class=\"line\">    <span class=\"comment\"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class=\"line\">    <span class=\"attr\">encryptors:</span></span><br><span class=\"line\">      <span class=\"attr\">aes_encryptor:</span> <span class=\"comment\"># 加解密算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">AES</span> <span class=\"comment\"># 加解密算法类型</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 加解密算法属性配置</span></span><br><span class=\"line\">          <span class=\"attr\">aes-key-value:</span> <span class=\"string\">123456abc</span>     <span class=\"comment\"># AES 使用的 KEY</span></span><br><span class=\"line\">          <span class=\"attr\">digest-algorithm-name:</span> <span class=\"string\">SHA-1</span> <span class=\"comment\"># AES KEY 的摘要算法</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-10\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建加密规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/encrypt/create-encrypt-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE ENCRYPT RULE t_user (</span><br><span class=\"line\">COLUMNS(</span><br><span class=\"line\">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class=\"string\">&#x27;AES&#x27;</span>,PROPERTIES(<span class=\"string\">&#x27;aes-key-value&#x27;</span>=<span class=\"string\">&#x27;123456abc&#x27;</span>, <span class=\"string\">&#x27;digest-algorithm-name&#x27;</span>=<span class=\"string\">&#x27;SHA-1&#x27;</span>))))</span><br><span class=\"line\">));</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改加密规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER ENCRYPT RULE t_user (</span><br><span class=\"line\">COLUMNS(</span><br><span class=\"line\">  (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=<span class=\"string\">&#x27;AES&#x27;</span>,PROPERTIES(<span class=\"string\">&#x27;aes-key-value&#x27;</span>=<span class=\"string\">&#x27;123456abc&#x27;</span>, <span class=\"string\">&#x27;digest-algorithm-name&#x27;</span>=<span class=\"string\">&#x27;SHA-1&#x27;</span>))))</span><br><span class=\"line\">));</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除加密规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP ENCRYPT RULE t_user;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询加密规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/encrypt/show-encrypt-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中所有加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULES \\G;</span><br><span class=\"line\"><span class=\"comment\"># 获取指定逻辑库中的加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULES FROM sharding_db \\G;</span><br><span class=\"line\"><span class=\"comment\"># 获取指定逻辑表中的加密规则</span></span><br><span class=\"line\">SHOW ENCRYPT RULE t_user \\G;</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据脱敏规则\">数据脱敏规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!MASK</span>  <span class=\"comment\"># 数据脱敏配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 脱敏表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span>  <span class=\"comment\"># 脱敏列配置</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 脱敏列名称</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">md5_mask</span> <span class=\"comment\"># 脱敏算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">email:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">mask_before_special_chars_mask</span></span><br><span class=\"line\">          <span class=\"attr\">telephone:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">keep_first_n_last_m_mask</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">my_mask</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">maskAlgorithms:</span> <span class=\"comment\"># 脱敏算法配置</span></span><br><span class=\"line\">      <span class=\"attr\">md5_mask:</span> <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span>  <span class=\"comment\"># 脱敏算法类型，md5加密后展示</span></span><br><span class=\"line\">      <span class=\"attr\">mask_before_special_chars_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MASK_BEFORE_SPECIAL_CHARS</span> <span class=\"comment\"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">special-chars:</span> <span class=\"string\">&#x27;@&#x27;</span>  <span class=\"comment\"># 遇到 @ 之前的部分做脱敏</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span>   <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">keep_first_n_last_m_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">KEEP_FIRST_N_LAST_M</span> <span class=\"comment\"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">first-n:</span> <span class=\"number\">3</span>     <span class=\"comment\"># 保留前 3 位</span></span><br><span class=\"line\">          <span class=\"attr\">last-m:</span> <span class=\"number\">4</span>      <span class=\"comment\"># 保留后 4 位</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span> <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">my_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MY_CUSTOM_MASK</span>  <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&quot;#&quot;</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"DistSQL-语法-11\">DistSQL 语法</h5>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建脱敏规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/rule-definition/mask/create-mask-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE MASK RULE t_user (</span><br><span class=\"line\">  COLUMNS(</span><br><span class=\"line\">    (NAME=password, TYPE(NAME=<span class=\"string\">&#x27;MD5&#x27;</span>)),</span><br><span class=\"line\">    (NAME=email, TYPE(NAME=<span class=\"string\">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;special-chars&quot;</span>=<span class=\"string\">&quot;@&quot;</span>,  <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=telephone, TYPE(NAME=<span class=\"string\">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;first-n&quot;</span>=3, <span class=\"string\">&quot;last-m&quot;</span>=4, <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=`name`, TYPE(NAME=<span class=\"string\">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;#&quot;</span>)))</span><br><span class=\"line\">  )</span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"comment\"># 这里注意 name 是关键字，所以需要用 `` 包起来</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>修改脱敏规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER MASK RULE t_user (</span><br><span class=\"line\">  COLUMNS(</span><br><span class=\"line\">    (NAME=password, TYPE(NAME=<span class=\"string\">&#x27;MD5&#x27;</span>)),</span><br><span class=\"line\">    (NAME=email, TYPE(NAME=<span class=\"string\">&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;special-chars&quot;</span>=<span class=\"string\">&quot;@&quot;</span>,  <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=telephone, TYPE(NAME=<span class=\"string\">&#x27;KEEP_FIRST_N_LAST_M&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;first-n&quot;</span>=3, <span class=\"string\">&quot;last-m&quot;</span>=4, <span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;*&quot;</span>))),</span><br><span class=\"line\">    (NAME=`name`, TYPE(NAME=<span class=\"string\">&#x27;MY_CUSTOM_MASK&#x27;</span>, PROPERTIES(<span class=\"string\">&quot;replace-char&quot;</span>=<span class=\"string\">&quot;#&quot;</span>)))</span><br><span class=\"line\">  )</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除脱敏规则</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DROP MASK RULE t_user;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查询脱敏规则，<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/syntax/rql/rule-query/mask/show-mask-rule/\">官方文档</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查询当前逻辑库中所有脱敏规则</span></span><br><span class=\"line\">SHOW MASK RULES;</span><br><span class=\"line\"><span class=\"comment\"># 仅查询指定逻辑库中的脱敏规则</span></span><br><span class=\"line\">SHOW MASK RULES FROM sharding_db;</span><br><span class=\"line\"><span class=\"comment\"># 查询指定规则</span></span><br><span class=\"line\">mysql&gt; SHOW MASK RULE t_user;</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class=\"line\">| table  | column    | algorithm_type            | algorithm_props                                 |</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br><span class=\"line\">| t_user | password  | MD5                       |                                                 |</span><br><span class=\"line\">| t_user | email     | MASK_BEFORE_SPECIAL_CHARS | &#123;<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;*&quot;</span>,<span class=\"string\">&quot;special-chars&quot;</span>:<span class=\"string\">&quot;@&quot;</span>&#125;        |</span><br><span class=\"line\">| t_user | telephone | KEEP_FIRST_N_LAST_M       | &#123;<span class=\"string\">&quot;first-n&quot;</span>:<span class=\"string\">&quot;3&quot;</span>,<span class=\"string\">&quot;last-m&quot;</span>:<span class=\"string\">&quot;4&quot;</span>,<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;*&quot;</span>&#125; |</span><br><span class=\"line\">| t_user | name      | MY_CUSTOM_MASK            | &#123;<span class=\"string\">&quot;replace-char&quot;</span>:<span class=\"string\">&quot;#&quot;</span>&#125;                            |</span><br><span class=\"line\">+--------+-----------+---------------------------+-------------------------------------------------+</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。 ShardingSphere官网 DistSQL DistSQL（Distributed SQL）是 Apache ShardingSphere 特有的操作语言。 它与标准 SQL 的使用方式完全一致，用于提供增量功能的 SQL 级别操作能力。 灵活的规则配置和资源管控能力是 Apache ShardingSphere 的特点之一。 在使用 4.x 及其之前版本时，开发者虽然可以像使用原生数据库一样操作数据，但却需要通过本地文件或注册中心配置资源和规则。然而，操作习惯变更，对于运维工程师并不友好。 从 5.x 版本开始，DistSQL（Distributed SQL）让用户可以像操作数据库一样操作 Apache ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的数据库产品。 DistSQL 细分为 RDL、RQL、RAL 和 RUL 四种类型。 RDL: Resource &amp; Rule Definition Language，负责资源和规则的创建、修改和删除。 RQL: Resource &amp; Rule Query Language，负责资源和规则的查询和展现。 RAL: Resource &amp; Rule Administration Language，负责强制路由、熔断、配置导入导出、数据迁移控制等管理功能。 RUL: Resource &amp; Rule Utility Language，负责 SQL 解析、SQL 格式化、执行计划预览等功能。 DistSQL 仅可以在 ShardingSphere-Proxy 中使用，不能在 ShardingSphere-JDBC 中使用。 示例准备 具体的语法，官网介绍的很详细，这里基于 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 中的配置进行示例说明。 为了尽可能多的使用 DistSQL 语法，这里仅在 global.yaml 中配置如下内容: 12345678910111213141516171819202122232425# 配置为基于 zookeeper 集群模式，为了演示 DistSQL 语法，这里需要将配置持久化，使用 JDBC 的单机模式也可以mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型 props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。# 配置用户和权限，因为 DistSQL 暂不支持 用户和权限管理，所以这里需要先配置用户和权限authority: users: - user: root@127.0.0.1 password: root admin: true - user: sharding@% password: sharding privilege: type: DATABASE_PERMITTED props: user-database-mappings: root@127.0.0.1=*,sharding@%=sharding_db 启动 ShardingSphere-Proxy 服务，并登录 12345678910111213# 启动 ShardingSphere-Proxy./shardingsphere-proxy-bin/bin/start.sh# 使用管理员登录mysql -h127.0.0.1 -uroot -proot -P3307# 查看当前用户权限mysql&gt; SHOW AUTHORITY RULE;+----------------------------+--------------------+----------------------------------------------------------------------+| users | provider | props |+----------------------------+--------------------+----------------------------------------------------------------------+| root@127.0.0.1; sharding@% | DATABASE_PERMITTED | &#123;&quot;user-database-mappings&quot;:&quot;root@127.0.0.1=*,sharding@%=sharding_db&quot;&#125; |+----------------------------+--------------------+----------------------------------------------------------------------+1 row in set (0.49 sec) 全局配置，即global.yaml中的配置 全局配置对所有逻辑数据库有效 属性配置 配置文件中的配置 12props: sql-show: true # 控制台打印改写后的 SQL，便于排错，默认为 false DistSQL 语法 设置属性，官方文档 12# 这里要注意，属性名需要使用下划线格式SET DIST VARIABLE sql_show = true; 查看属性，官方文档 123456789101112131415161718192021222324252627mysql&gt; SHOW DIST VARIABLES;+-----------------------------------------+-----------------+| variable_name | variable_value |+-----------------------------------------+-----------------+| agent_plugins_enabled | true || cached_connections | 0 || cdc_server_port | 33071 || check_table_metadata_enabled | false || kernel_executor_size | 0 || load_table_metadata_batch_size | 1000 || max_connections_size_per_query | 1 || proxy_backend_query_fetch_size | -1 || proxy_default_port | 3307 || proxy_frontend_database_protocol_type | || proxy_frontend_executor_size | 0 || proxy_frontend_flush_threshold | 128 || proxy_frontend_max_connections | 0 || proxy_frontend_ssl_cipher | || proxy_frontend_ssl_enabled | false || proxy_frontend_ssl_version | TLSv1.2,TLSv1.3 || proxy_meta_data_collector_enabled | false || proxy_netty_backlog | 1024 || sql_show | true || sql_simple | false || system_log_level | INFO || system_schema_metadata_assembly_enabled | true |+-----------------------------------------+-----------------+ 分布式事务配置 配置文件中的配置 123transaction: defaultType: XA providerType: Atomikos DistSQL 语法 查看事务规则，官方文档 1SHOW TRANSACTION RULE; 修改事务规则，官方文档 123ALTER TRANSACTION RULE( DEFAULT=&quot;XA&quot;, TYPE(NAME=&quot;Atomikos&quot;)); 规则配置，即database-xxx.yaml中的配置 以下 DistSQL 仅可以在逻辑库中执行，所以需要先创建一个逻辑数据库 12345mysql&gt; CREATE DATABASE sharding_db;Query OK, 0 rows affected (0.03 sec)mysql&gt; use sharding_db;Database changed 数据源配置 在 DistSQL中，官方将数据源叫做存储单元(STORAGE UNIT) 配置文件中的配置 12345678910dataSources: ds_0: # 逻辑数据源名称 url: jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 # 注意这里属性为 url username: root password: newpwd ds_1: url: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd DistSQL 语法 注册存储单元，官方文档 1234567891011REGISTER STORAGE UNIT ds_0 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;);REGISTER STORAGE UNIT ds_1 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;); 查询存储单元，官方文档 1SHOW STORAGE UNITS FROM sharding_db \\G; 修改存储单元，官方文档 123456ALTER STORAGE UNIT ds_1 ( URL=&quot;jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;, USER=&quot;root&quot;, PASSWORD=&quot;newpwd&quot;, PROPERTIES(&quot;maximumPoolSize&quot;=10,&quot;idleTimeout&quot;=30000)); 取消注册存储单元，官方文档 12# 无法移除已经被规则使用的存储单元UNREGISTER STORAGE UNIT ds_0; 单表配置 配置文件中的配置 12345rules: - !SINGLE # 单表规则配置，单表规则优先级高于分库分表规则 tables: # MySQL 风格 - ds_0.t_address # 加载指定单表 DistSQL 语法 加载单表，官方文档 1LOAD SINGLE TABLE ds_0.t_address; 查询单表，官方文档 1SHOW SINGLE TABLES; 卸载单表，官方文档 1UNLOAD SINGLE TABLE ds_0.t_address; 广播表配置 广播表，即所有数据源都包含的表，比如字典表 1234rules: - !BROADCAST # 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个 tables: - dict # 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。 DistSQL 语法 创建广播表，官方文档 1CREATE BROADCAST TABLE RULE dict; 删除广播表，官方文档 1DROP BROADCAST TABLE RULE dict; 查询广播表，官方文档 1234# 查询当前逻辑库中具有广播规则的表SHOW BROADCAST TABLE RULES;# 查询指定数据库中具有广播规则的表SHOW BROADCAST TABLE RULES FROM sharding_db; 分库分表配置 单分片键，Long 类型 12345678910111213141516171819202122232425262728293031rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 course: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.course_$&#123;1..2&#125; # 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: course_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: cid shardingAlgorithmName: course_inline keyGenerateStrategy: # 分布式序列策略 column: cid # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 course_inline: # 定义名称，在上面引用 type: INLINE # 基于行表达式的分片算法，这里使用 MOD 会报错 props: # 属性 algorithm-expression: course_$&#123;cid % 2 + 1&#125; # 表达式，这是因为表名称为 course_1, course_2 allow-range-query-with-inline-sharding: true # 允许范围查询 course_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; # 表示 ds_0, ds_1 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则，官方文档 123456CREATE SHARDING TABLE RULE course ( DATANODES(&quot;ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=cid,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;course_$&#123;cid % 2 + 1&#125;&quot;,&quot;allow-range-query-with-inline-sharding&quot;=true )))), KEY_GENERATE_STRATEGY(COLUMN=cid,TYPE(NAME=&quot;snowflake&quot;))); 单分片键，String 类型 123456789101112131415161718192021222324252627282930313233343536rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_user: actualDataNodes: ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_inline # 分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: id # 自增列名称，字符串类型# keyGeneratorName: uuid # 分布式序列算法名称 keyGeneratorName: custom_snowflake_string # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_user_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;Math.abs(id.hashCode()%2)&#125; # 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算 t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125; # 分表，t_user_0, t_user_1 keyGenerators: # 分布式序列算法 uuid: # 定义名称 type: UUID # 字符串主键，String custom_snowflake_string: type: CUSTOM_SNOWFLAKE_STRING # 自定义雪花算法，String，spi props: workerId: 2 datacenterId: 2 DistSQL 语法 创建分片规则 123456CREATE SHARDING TABLE RULE t_user ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;Math.abs(id.hashCode()%2)&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;&quot;)))), KEY_GENERATE_STRATEGY(COLUMN=id,TYPE(NAME=&quot;CUSTOM_SNOWFLAKE_STRING&quot;))); 多分片键，Long 类型 12345678910111213141516171819202122232425262728293031323334353637383940414243444546rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_order_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id shardingAlgorithmName: t_order-complex-algorithm keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id # 分片列名称,多个逗号分隔# shardingAlgorithmName: t_order_item-class-based-algorithm # 基于自定义类的分片算法 shardingAlgorithmName: t_order_item-class-based-algorithm_spi # 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_order_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; t_order-complex-algorithm: type: COMPLEX_INLINE # 基于行表达式的复合分片算法 props: algorithm-expression: t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125; t_order_item-class-based-algorithm_spi: # SPI type: T_ORDER_ITEM_COMPLEX # 基于自定义类的分片算法 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则 12345678910111213CREATE SHARDING TABLE RULE t_order_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;complex_inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125;&quot;)))), KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=&quot;snowflake&quot;)));CREATE SHARDING TABLE RULE t_order_item_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;T_ORDER_ITEM_COMPLEX&quot;))), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;SNOWFLAKE&quot;))); 自动分片规则 上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则 12345678910111213141516171819202122232425262728293031323334rules: - !SHARDING # 分片规则配置 # 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致 bindingTables: - t_order,t_order_item autoTables: # 自动分片规则配置 t_order: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 mod_2: type: MOD # 基于 MOD 的分片算法 props: sharding-count: 2 # 分片数量，即 对 2 进行取余 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long DistSQL 语法 创建分片规则 1234567891011CREATE SHARDING TABLE RULE t_order ( STORAGE_UNITS(ds_0,ds_1), SHARDING_COLUMN=user_id,TYPE(NAME=&quot;mod&quot;,PROPERTIES(&quot;sharding-count&quot;=&quot;2&quot;)), KEY_GENERATE_STRATEGY(COLUMN=order_id,TYPE(NAME=&quot;snowflake&quot;)));CREATE SHARDING TABLE RULE t_order_item ( STORAGE_UNITS(ds_0,ds_1), SHARDING_COLUMN=user_id,TYPE(NAME=&quot;mod&quot;,PROPERTIES(&quot;sharding-count&quot;=&quot;2&quot;)), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;snowflake&quot;))); 其它分片操作语句 查询分片规则，官方文档 123456# 查看当前逻辑库下的所有分片规则SHOW SHARDING TABLE RULES \\G;# 查看指定逻辑库下的分片规则SHOW SHARDING TABLE RULES FROM sharding_db; \\G;# 查看指定分片规则SHOW SHARDING TABLE RULE t_user \\G; 修改分片规则，官网文档，与创建分片规则类似，将CREATE改为ALTER即可 123456ALTER SHARDING TABLE RULE t_order_item_complex ( DATANODES(&quot;ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;&quot;), DATABASE_STRATEGY(TYPE=&quot;standard&quot;,SHARDING_COLUMN=user_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;inline&quot;,PROPERTIES(&quot;algorithm-expression&quot;=&quot;ds_$&#123;user_id % 2&#125;&quot;)))), TABLE_STRATEGY(TYPE=&quot;complex&quot;,SHARDING_COLUMNS=user_id,order_id,SHARDING_ALGORITHM(TYPE(NAME=&quot;T_ORDER_ITEM_COMPLEX&quot;))), KEY_GENERATE_STRATEGY(COLUMN=item_id,TYPE(NAME=&quot;SNOWFLAKE&quot;))); 删除分片规则，官网文档 123DROP SHARDING TABLE RULE t_order;# 删除多个表DROP SHARDING TABLE RULE t_order,t_order_item; 数据加密规则 12345678910111213141516rules: - !ENCRYPT # 数据加密配置 tables: t_user: # 加密表名称 columns: password: # 加密列名称 cipher: name: password # 密文列名称 encryptorName: aes_encryptor # 密文列加密算法名称 # 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/ encryptors: aes_encryptor: # 加解密算法名称 type: AES # 加解密算法类型 props: # 加解密算法属性配置 aes-key-value: 123456abc # AES 使用的 KEY digest-algorithm-name: SHA-1 # AES KEY 的摘要算法 DistSQL 语法 创建加密规则，官方文档 1234CREATE ENCRYPT RULE t_user (COLUMNS( (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=&#x27;AES&#x27;,PROPERTIES(&#x27;aes-key-value&#x27;=&#x27;123456abc&#x27;, &#x27;digest-algorithm-name&#x27;=&#x27;SHA-1&#x27;)))))); 修改加密规则 1234ALTER ENCRYPT RULE t_user (COLUMNS( (NAME=password,CIPHER=password,ENCRYPT_ALGORITHM(TYPE(NAME=&#x27;AES&#x27;,PROPERTIES(&#x27;aes-key-value&#x27;=&#x27;123456abc&#x27;, &#x27;digest-algorithm-name&#x27;=&#x27;SHA-1&#x27;)))))); 删除加密规则 1DROP ENCRYPT RULE t_user; 查询加密规则，官方文档 123456# 查询当前逻辑库中所有加密规则SHOW ENCRYPT RULES \\G;# 获取指定逻辑库中的加密规则SHOW ENCRYPT RULES FROM sharding_db \\G;# 获取指定逻辑表中的加密规则SHOW ENCRYPT RULE t_user \\G; 数据脱敏规则 1234567891011121314151617181920212223242526272829303132rules: - !MASK # 数据脱敏配置 tables: t_user: # 脱敏表名称 columns: # 脱敏列配置 password: # 脱敏列名称 maskAlgorithm: md5_mask # 脱敏算法名称 email: maskAlgorithm: mask_before_special_chars_mask telephone: maskAlgorithm: keep_first_n_last_m_mask name: maskAlgorithm: my_mask maskAlgorithms: # 脱敏算法配置 md5_mask: # 自定义脱敏算法名称 type: MD5 # 脱敏算法类型，md5加密后展示 mask_before_special_chars_mask: type: MASK_BEFORE_SPECIAL_CHARS # 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com props: special-chars: &#x27;@&#x27; # 遇到 @ 之前的部分做脱敏 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 keep_first_n_last_m_mask: type: KEEP_FIRST_N_LAST_M # 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678 props: first-n: 3 # 保留前 3 位 last-m: 4 # 保留后 4 位 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 my_mask: type: MY_CUSTOM_MASK # 自定义脱敏算法名称 props: replace-char: &quot;#&quot; DistSQL 语法 创建脱敏规则，官方文档 123456789CREATE MASK RULE t_user ( COLUMNS( (NAME=password, TYPE(NAME=&#x27;MD5&#x27;)), (NAME=email, TYPE(NAME=&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;, PROPERTIES(&quot;special-chars&quot;=&quot;@&quot;, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=telephone, TYPE(NAME=&#x27;KEEP_FIRST_N_LAST_M&#x27;, PROPERTIES(&quot;first-n&quot;=3, &quot;last-m&quot;=4, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=`name`, TYPE(NAME=&#x27;MY_CUSTOM_MASK&#x27;, PROPERTIES(&quot;replace-char&quot;=&quot;#&quot;))) ));# 这里注意 name 是关键字，所以需要用 `` 包起来 修改脱敏规则 12345678ALTER MASK RULE t_user ( COLUMNS( (NAME=password, TYPE(NAME=&#x27;MD5&#x27;)), (NAME=email, TYPE(NAME=&#x27;MASK_BEFORE_SPECIAL_CHARS&#x27;, PROPERTIES(&quot;special-chars&quot;=&quot;@&quot;, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=telephone, TYPE(NAME=&#x27;KEEP_FIRST_N_LAST_M&#x27;, PROPERTIES(&quot;first-n&quot;=3, &quot;last-m&quot;=4, &quot;replace-char&quot;=&quot;*&quot;))), (NAME=`name`, TYPE(NAME=&#x27;MY_CUSTOM_MASK&#x27;, PROPERTIES(&quot;replace-char&quot;=&quot;#&quot;))) )); 删除脱敏规则 1DROP MASK RULE t_user; 查询脱敏规则，官方文档 1234567891011121314# 查询当前逻辑库中所有脱敏规则SHOW MASK RULES;# 仅查询指定逻辑库中的脱敏规则SHOW MASK RULES FROM sharding_db;# 查询指定规则mysql&gt; SHOW MASK RULE t_user;+--------+-----------+---------------------------+-------------------------------------------------+| table | column | algorithm_type | algorithm_props |+--------+-----------+---------------------------+-------------------------------------------------+| t_user | password | MD5 | || t_user | email | MASK_BEFORE_SPECIAL_CHARS | &#123;&quot;replace-char&quot;:&quot;*&quot;,&quot;special-chars&quot;:&quot;@&quot;&#125; || t_user | telephone | KEEP_FIRST_N_LAST_M | &#123;&quot;first-n&quot;:&quot;3&quot;,&quot;last-m&quot;:&quot;4&quot;,&quot;replace-char&quot;:&quot;*&quot;&#125; || t_user | name | MY_CUSTOM_MASK | &#123;&quot;replace-char&quot;:&quot;#&quot;&#125; |+--------+-----------+---------------------------+-------------------------------------------------+","summary":"摘要 本文介绍 ShardingSphere-Proxy5.5.2 DistSQL 的使用。 ShardingSphere官网","date_published":"2025-09-11T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/","url":"https://blog.hanqunfeng.com/2025/09/10/springboot3-shardingsphere-proxy-mode/","title":"SpringBoot3 + ShardingSphere-Proxy5.5.2 运行模式","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文在 <a href=\"/2025/09/04/springboot3-shardingsphere-proxy/\" title=\"SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表\">SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表</a> 的基础上进行修改。</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"运行模式说明\">运行模式说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/dev-manual/mode/\">运行模式</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 运行模式分为两种：单机模式(Standalone) 和 集群模式(Cluster)。</p>\n</li>\n<li class=\"lvl-2\">\n<p>运行模式就是指定将<code>元数据</code>(认证、数据源、分片规则等等)持久化的存储方式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>默认运行模式为单机模式，使用<code>H2</code>的内存方式。</p>\n</li>\n</ul>\n<h2 id=\"单机模式-Standalone\">单机模式(Standalone)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>单机模式能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知。 通过某一实例更新元数据之后，会导致其他实例由于获取不到最新的元数据而产生不一致的错误。</p>\n</li>\n<li class=\"lvl-2\">\n<p>适用于工程师在本地搭建 Apache ShardingSphere 环境。</p>\n</li>\n<li class=\"lvl-2\">\n<p>单机模式目前仅支持一种：JDBC，即数据库持久化。以下为默认值(<code>JDBCRepositoryPropertyKey</code>)。</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>数据类型</th>\n<th>说明</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provider</td>\n<td>String</td>\n<td>元数据存储类型，可选值为 <code>H2</code>、<code>MySQL</code> 、<code>EmbeddedDerby</code>、<code>DerbyNetworkServer</code>、<code>HSQLDB</code></td>\n<td>H2</td>\n</tr>\n<tr>\n<td>jdbc_url</td>\n<td>String</td>\n<td>JDBC URL</td>\n<td><code>jdbc:h2:mem:config;DB_CLOSE_DELAY=0;DATABASE_TO_UPPER=false;MODE=MYSQL</code></td>\n</tr>\n<tr>\n<td>username</td>\n<td>String</td>\n<td>账号</td>\n<td>sa</td>\n</tr>\n<tr>\n<td>password</td>\n<td>String</td>\n<td>密码</td>\n<td>空（无默认值）</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里以 Mysql 存储元数据为例，相关属性参考<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#jdbc-%E6%8C%81%E4%B9%85%E5%8C%96\">官网说明</a></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">JDBC</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">provider:</span> <span class=\"string\">MySQL</span></span><br><span class=\"line\">      <span class=\"attr\">jdbc_url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">      <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>此时需要将 mysql 的驱动 jar 包 添加到 <code>ext-lib</code> 目录下</p>\n</li>\n<li class=\"lvl-2\">\n<p>启动 ShardingSphere Proxy 成功后会自动在上面的数据库中创建一张表，并将配置文件的中的元数据存储进去</p>\n</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `repository` (</span><br><span class=\"line\">  `id` <span class=\"type\">varchar</span>(<span class=\"number\">36</span>) <span class=\"keyword\">COLLATE</span> utf8mb4_bin <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `key` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  `<span class=\"keyword\">value</span>` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  `parent` text <span class=\"keyword\">COLLATE</span> utf8mb4_bin,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB <span class=\"keyword\">DEFAULT</span> CHARSET<span class=\"operator\">=</span>utf8mb4 <span class=\"keyword\">COLLATE</span><span class=\"operator\">=</span>utf8mb4_bin;</span><br></pre></td></tr></table></figure>\n<h3 id=\"重点说明\">重点说明</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当数据库中不存在该表时，会自动创建该表，并将配置文件的元数据插入该表中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当数据库中已存在该表时，会读取该表中的数据并将其加载到内存，而不会读取配置文件中的元数据。即此时配置文件中的元数据不会生效。</p>\n</li>\n<li class=\"lvl-2\">\n<p>若此时想修改配置规则，有三种方法：</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">1.删除该表，修改配置文件后重新启动Proxy，此时会重新创建该表并加载配置文件中的元数据。</li>\n<li class=\"lvl-4\">2.手工修改数据表中的元数据，但修改后需要重新启动Proxy才会加载新的元数据。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li>\n<li class=\"lvl-4\">3.<code>[推荐]</code>登录逻辑数据库后，使用 <a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a> 动态修改配置，修改后的配置会被保存在该表中，并立即生效，无需重启Proxy。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>开发和测试环境可以直接使用默认的 H2 内存数据库，生产环境可以使用 MySQL等数据库对元数据进行持久化保存或者使用下面的集群模式。</p>\n</li>\n</ul>\n<h2 id=\"集群模式-Cluster\">集群模式(Cluster)</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>集群模式提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调的能力。 它能够提供计算能力水平扩展和高可用等分布式系统必备的能力，集群环境需要通过独立部署的注册中心来存储元数据和协调节点状态。</p>\n</li>\n<li class=\"lvl-2\">\n<p>在生产环境建议使用集群模式。</p>\n</li>\n<li class=\"lvl-2\">\n<p>这里以 zookeeper 集群模式为例，相关属性参考<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/common-config/builtin-algorithm/metadata-repository/#zookeeper-%E6%8C%81%E4%B9%85%E5%8C%96\">官网说明</a></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型，当前版本仅支持 ZooKeeper 和 etcd</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"重点说明-2\">重点说明</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>不要手工修改 Zookeeper 集群中的 namespace 下的配置信息!</p>\n</li>\n<li class=\"lvl-2\">\n<p>既然是集群，就需要多个 ShardingSphere-Proxy 实例。 当第一个 ShardingSphere-Proxy 实例 启动后，其它相同配置的 ShardingSphere-Proxy 实例仅需要一个 <code>global.yaml</code> 全局配置文件即可，并仅需在其中配置上面的<code>运行模式</code>信息，而不需要再配置其它配置，比如认证、数据源、分片规则等信息，这些信息会通过 Zookeeper 集群中的 namespace 获取并保存到本地内存中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>每个 ShardingSphere-Proxy 实例启动时，都会自动将自己注册到 Zookeeper 集群中指定的 namespace 下，并自动获取该 namespace 下的配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中不存在指定的 namespace 时，此时第一次启动 ShardingSphere-Proxy 会自动在 Zookeeper 中创建 namespace，并写入配置文件中的配置信息到 Zookeeper 中。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中已存在指定的 namespace 时，此时再启动 ShardingSphere-Proxy 会自动从 Zookeeper 中读取 namespace 下的配置信息，并将其加载到内存中，不会再读取本地配置文件中的配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当 Zookeeper 集群中已存在指定的 namespace 时，根据上面的规则，此时修改本地的配置文件中的分片规则后重启ShardingSphere-Proxy 并不会生效。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">此时有三种方法：\n<ul class=\"lvl-4\">\n<li class=\"lvl-6\">\n<ol>\n<li class=\"lvl-9\">删除 Zookeeper 集群中指定的 namespace，然后重启 ShardingSphere-Proxy。这种方法有个弊端，即会导致连接到相同 ZooKeeper 集群的 namespace 的其它 ShardingSphere-Proxy 实例数据丢失(完全不可用)，也需要重启才能重新获取到数据。</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"2\">\n<li class=\"lvl-9\">手工修改 Zookeeper 集群中指定的 namespace 下的分片规则，修改后会立即同步到所有 ShardingSphere-Proxy 实例。但手工修改需要对数据的组织形式非常清楚，否则极易出错。</li>\n</ol>\n</li>\n<li class=\"lvl-6\">\n<ol start=\"3\">\n<li class=\"lvl-9\"><code>[推荐]</code>登录逻辑数据库后，使用 <a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-proxy/distsql/\">DistSQL</a> 动态修改配置，此时会自动同步到所有 ShardingSphere-Proxy 实例。所以，灵活掌握 <code>DistSQL</code> 是维护 ShardingSphere-Proxy 集群的关键。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>多个 ShardingSphere-Proxy 实例 可以通过负载均衡器，比如 Nginx，将请求路由到不同的 ShardingSphere-Proxy 实例。比如：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream&#123;</span><br><span class=\"line\">    upstream shardingsphere_proxy&#123;</span><br><span class=\"line\">        server  10.10.21.35:3307;</span><br><span class=\"line\">        server  10.10.21.36:3307;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 3310;</span><br><span class=\"line\">        proxy_connect_timeout 20s;</span><br><span class=\"line\">        proxy_timeout 5m;</span><br><span class=\"line\">        proxy_pass shardingsphere_proxy;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"与-Spring-Boot3-整合\">与 Spring Boot3 整合</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>无论是 <code>单机模式</code> 还是 <code>集群模式</code>，其目的都是将 <code>配置</code> 保存到独立的 <code>配置中心(数据库 或 Zookeeper)</code>中，并让其它 <code>ShardingSphere-Proxy</code> 实例从该配置中心中读取配置信息。</p>\n</li>\n<li class=\"lvl-2\">\n<p>前文我们介绍过 <code>Spring Boot3</code> + <code>ShardingSphere-Proxy</code> 就相当于是集成普通的MySql数据库，而 <code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code> 就需要单独在本地配置各种规则。</p>\n</li>\n<li class=\"lvl-2\">\n<p>实际上 <code>ShardingSphere-JDBC</code> 也可以从 <code>配置中心</code> 中读取配置信息，这样我们就不需要在本地配置任何规则了，我们仅需要在 <code>sharding.yaml</code> 中配置好<code>运行模式</code>，并配置好 <code>databaseName</code> 的名称即可。注意，此时配置中心的的事务不能是 <code>XA</code>，因为<code>Spring Boot3</code> + <code>ShardingSphere-JDBC</code>目前不支持 <code>XA</code> 事务。</p>\n</li>\n<li class=\"lvl-2\">\n<p>此时，springboot项目启动后会拉取<code>配置中心</code>中的配置信息并将其保存到本地内存，本地配置文件中的其它配置信息会被忽略。<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/G3kESF.png\" alt=\"\"></p>\n</li>\n</ul>\n<h3 id=\"单机模式\">单机模式</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-03\">代码示例</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 DistSQL 改规则后，必须重启应用才能生效</p>\n</li>\n<li class=\"lvl-2\">\n<p>sharding.yaml</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">JDBC</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">provider:</span> <span class=\"string\">MySQL</span></span><br><span class=\"line\">      <span class=\"attr\">jdbc_url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">      <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">      <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"><span class=\"comment\"># 数据库名称，默认值：logic_db</span></span><br><span class=\"line\"><span class=\"attr\">databaseName:</span> <span class=\"string\">sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Maven 依赖</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mysql<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mysql-connector-j<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.baomidou<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.5.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-jdbc<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.hanqf<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>algorithm-swapper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"集群模式\">集群模式</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-04\">代码示例</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>通过 DistSQL 改规则后，立即推送到所有实例，无需重启应用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>sharding.yaml，注意这里一定要配置 <code>databaseName</code></p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># # 开启集群模式</span></span><br><span class=\"line\"><span class=\"attr\">mode:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">Cluster</span>                 <span class=\"comment\"># 运行模式，默认是单机模式 Standalone</span></span><br><span class=\"line\">  <span class=\"attr\">repository:</span></span><br><span class=\"line\">    <span class=\"attr\">type:</span> <span class=\"string\">ZooKeeper</span>             <span class=\"comment\"># 注册中心类型</span></span><br><span class=\"line\">    <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">namespace:</span> <span class=\"string\">governance_ds</span>  <span class=\"comment\"># ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下</span></span><br><span class=\"line\">      <span class=\"attr\">server-lists:</span> <span class=\"string\">localhost:2181</span> <span class=\"comment\"># ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表</span></span><br><span class=\"line\">      <span class=\"attr\">retryIntervalMilliseconds:</span> <span class=\"number\">500</span> <span class=\"comment\"># 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。</span></span><br><span class=\"line\">      <span class=\"attr\">timeToLiveSeconds:</span> <span class=\"number\">60</span>     <span class=\"comment\"># 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略</span></span><br><span class=\"line\">      <span class=\"attr\">maxRetries:</span> <span class=\"number\">3</span>             <span class=\"comment\"># 最大重试次数（超过则认为操作失败）。</span></span><br><span class=\"line\">      <span class=\"attr\">operationTimeoutMilliseconds:</span> <span class=\"number\">500</span>  <span class=\"comment\"># 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。</span></span><br><span class=\"line\"><span class=\"comment\"># 数据库名称，默认值：logic_db</span></span><br><span class=\"line\"><span class=\"attr\">databaseName:</span> <span class=\"string\">sharding_db</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Maven 依赖，注意要加上 <code>shardingsphere-cluster-mode-repository-zookeeper</code> 的依赖</p>\n</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- MySQL Connector/J --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mysql<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mysql-connector-j<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.baomidou<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.5.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-jdbc<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 自定义 的 SPI --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.hanqf<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>algorithm-swapper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.0.0<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- shardingsphere-cluster-mode-repository-zookeeper --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-cluster-mode-repository-zookeeper<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"如何选择\">如何选择</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当我使用<code>springboot3+shardingSphere-JDBC5.5.2</code>时，我应该使用本地<code>配置文件</code>的方式还是使用<code>配置中心</code>（比如：zookeeper）的方式呢？</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>方式</th>\n<th>部署复杂度</th>\n<th>配置动态更新</th>\n<th>多实例共享配置</th>\n<th>热更新支持</th>\n<th>适用环境</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>本地配置文件</td>\n<td>简单</td>\n<td>不支持</td>\n<td>不支持</td>\n<td>否</td>\n<td>开发/测试/小型项目</td>\n</tr>\n<tr>\n<td>配置中心（ZooKeeper/etcd）</td>\n<td>略高</td>\n<td>支持</td>\n<td>支持</td>\n<td>是</td>\n<td>生产/分布式环境</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>注意</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">DistSQL 目前确实只支持在 ShardingSphere-Proxy 上执行，并且 Proxy 只支持 MySQL 和 PostgreSQL 协议。</li>\n<li class=\"lvl-4\">如果你在 Spring Boot + ShardingSphere-JDBC 里用 其它数据库（比如 SQL Server、Oracle、DB2 等），就无法直接通过 DistSQL 去动态改配置。</li>\n<li class=\"lvl-4\">此时你可以选择通过 Zookeeper 的客户端直接修改或配置规则，也可以不选择 <code>配置中心</code> 的方式，直接使用 <code>本地配置文件</code>。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"什么时候需要分库分表\">什么时候需要分库分表</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分库分表的主要目的是 <strong>解决数据量大带来的性能、可用性和可扩展性问题</strong>。通常需要考虑的几个关键指标：</p>\n</li>\n</ul>\n<h3 id=\"1-数据量指标\">1. 数据量指标</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>单表数据量过大</strong>：一般来说，单表数据量在 <strong>千万级</strong> 以上时，查询、写入和索引的性能会明显下降。</p>\n</li>\n<li class=\"lvl-2\">\n<p>例如：一个订单表一天有上百万条数据，一年下来可能有上亿条，单表性能会成为瓶颈。</p>\n</li>\n</ul>\n<h3 id=\"2-访问量指标\">2. 访问量指标</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>高并发写入或查询</strong>：数据库连接、事务锁、IO 等资源会成为瓶颈。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果你的系统每天有上千万的请求，数据库可能无法承受。</p>\n</li>\n</ul>\n<h3 id=\"3-业务隔离需求\">3. 业务隔离需求</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>不同业务的数据分离，避免单个业务影响整个数据库的稳定性。</p>\n</li>\n<li class=\"lvl-2\">\n<p>例如：电商系统中的订单和日志数据，日志量非常大，和订单分开存储更合理。</p>\n</li>\n</ul>\n<h3 id=\"4-运营与成本因素\">4. 运营与成本因素</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分库分表后，可以分布到多个数据库实例上，支持 <strong>水平扩展</strong>，而不必依赖昂贵的单机数据库。</p>\n</li>\n</ul>\n<h2 id=\"使用-ShardingSphere-可能带来的问题\">使用 ShardingSphere 可能带来的问题</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用 <strong>ShardingSphere</strong> 可以方便地解决分库分表问题，但在实际生产中，它会带来一些新的复杂性和潜在问题，主要体现在性能、运维、功能限制等方面。</p>\n</li>\n</ul>\n<h3 id=\"1-性能与延迟\">1. 性能与延迟</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>跨库 JOIN 性能差</strong><br>\n分库分表后，跨库的 <code>JOIN</code> 查询会在各个分片上分别执行，然后在 ShardingSphere 层合并结果，性能明显下降。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">例如：订单表在多个库，查询订单 + 用户信息时必须跨库 JOIN，执行效率比单库低很多。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p><strong>分页查询慢</strong><br>\n分库分表后，如果要全局排序 + 分页，需要所有分片查出数据再合并，代价非常大。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">解决方式：使用分片键范围分页，或引入 ElasticSearch/ClickHouse 做搜索和统计。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p><strong>广播表压力</strong><br>\n配置了广播表（每个库一份完整数据）后，更新需要同步所有库，写入性能下降。</p>\n</li>\n</ul>\n<h3 id=\"2-SQL-兼容性限制\">2. SQL 兼容性限制</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>复杂 SQL 支持不完整</strong><br>\nShardingSphere 对某些复杂 SQL（如子查询、窗口函数）支持有限，可能报错或性能极差。</p>\n</li>\n<li class=\"lvl-2\">\n<p><strong>存储过程、触发器受限</strong><br>\n分库分表后，存储过程、触发器在分片数据库执行可能不一致，维护成本高。</p>\n</li>\n</ul>\n<h3 id=\"3-分布式事务问题\">3. 分布式事务问题</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere 支持 <strong>XA 分布式事务</strong>，但性能不如单机事务，出现网络抖动时可能会卡住。</p>\n</li>\n<li class=\"lvl-2\">\n<p>如果业务需要强一致性，必须结合可靠消息或 TCC、SAGA 等分布式事务模式，架构会更复杂。</p>\n</li>\n</ul>\n<h3 id=\"4-运维与管理复杂度\">4. 运维与管理复杂度</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><strong>分片规则变更困难</strong><br>\n例如，最初按 <code>user_id % 2</code> 分成两个库，后续想增加到 4 个库，需要迁移数据，非常麻烦。</p>\n</li>\n<li class=\"lvl-2\">\n<p><strong>监控与调优</strong><br>\nShardingSphere 增加了中间层，SQL 路由、执行计划、数据节点状态都需要额外的监控工具支持。</p>\n</li>\n</ul>\n<h3 id=\"5-成本与学习曲线\">5. 成本与学习曲线</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置相对复杂：分片规则、读写分离、分布式事务、弹性扩容都需要仔细设计。</p>\n</li>\n<li class=\"lvl-2\">\n<p>学习曲线较陡：开发和运维人员必须了解 ShardingSphere 的工作机制，否则定位问题很困难。</p>\n</li>\n</ul>\n<h3 id=\"6-高可用与扩展问题\">6. 高可用与扩展问题</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere-JDBC 是应用内库，无法独立扩展，需要依赖应用扩容。</p>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 支持集群，但需要自己搭建高可用架构，涉及负载均衡、故障切换等问题。</p>\n</li>\n</ul>\n<h2 id=\"其它技术方案：分布式数据库\">其它技术方案：分布式数据库</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>开源产品: 核心功能完全开源，企业版提供额外商业特性</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>数据库</th>\n<th>架构类型</th>\n<th>SQL 兼容性</th>\n<th>分布式事务支持</th>\n<th>数据存储模型</th>\n<th>主要特点</th>\n<th>典型应用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><a href=\"https://www.pingcap.com/\">TiDB</a></strong></td>\n<td>分布式 HTAP</td>\n<td>MySQL 协议兼容</td>\n<td>支持（Percolator 模型）</td>\n<td>行存 + 列存混合</td>\n<td>开源、云原生、强一致性、弹性扩展</td>\n<td>在线事务处理 + 实时分析</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://en.oceanbase.com/\">OceanBase</a></strong></td>\n<td>分布式关系型数据库</td>\n<td>MySQL/Oracle 兼容</td>\n<td>支持（两阶段提交）</td>\n<td>行存</td>\n<td>高性能、金融级事务、阿里蚂蚁金服核心系统使用</td>\n<td>金融、电商、核心交易系统</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.cockroachlabs.com/\">CockroachDB</a></strong></td>\n<td>分布式 NewSQL</td>\n<td>PostgreSQL 兼容</td>\n<td>支持（分布式事务）</td>\n<td>行存</td>\n<td>类 Spanner 架构，全球分布，强一致性</td>\n<td>全球化分布式应用</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.citusdata.com/\">Citus</a> (PostgreSQL)</strong></td>\n<td>PostgreSQL 扩展</td>\n<td>PostgreSQL 兼容</td>\n<td>部分支持（基于逻辑分片）</td>\n<td>行存</td>\n<td>基于 PostgreSQL 的分布式扩展，支持大规模 OLAP</td>\n<td>大数据实时分析、BI 场景</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://vitess.io/\">Vitess</a></strong></td>\n<td>分布式中间件 + 存储</td>\n<td>MySQL 协议兼容</td>\n<td>弱事务（最终一致性）</td>\n<td>行存</td>\n<td>YouTube 开源，K8s 友好，分库分表自动化</td>\n<td>大规模 Web 应用，在线服务</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.yugabyte.com/\">YugabyteDB</a></strong></td>\n<td>分布式 SQL + NoSQL</td>\n<td>PostgreSQL 兼容</td>\n<td>支持（两阶段提交）</td>\n<td>行存 + 列存混合</td>\n<td>融合 NewSQL 和 NoSQL，强一致性，跨区域部署</td>\n<td>金融级事务 + 分析混合场景</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>商业产品</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>数据库</th>\n<th>架构类型</th>\n<th>SQL 兼容性</th>\n<th>分布式事务支持</th>\n<th>数据存储模型</th>\n<th>主要特点</th>\n<th>典型应用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><a href=\"https://www.alibabacloud.com/product/polardb\">PolarDB</a></strong></td>\n<td>云原生分布式数据库</td>\n<td>MySQL/PostgreSQL 兼容</td>\n<td>支持（云端分布式事务）</td>\n<td>行存</td>\n<td>阿里云产品，弹性扩容，存储计算分离</td>\n<td>云上企业数据库解决方案</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://www.huaweicloud.com/product/gaussdb.html\">GaussDB</a></strong></td>\n<td>分布式关系型数据库</td>\n<td>MySQL/Oracle 兼容</td>\n<td>支持（分布式事务）</td>\n<td>行存 + 列存混合</td>\n<td>华为推出，分布式 HTAP，云原生架构</td>\n<td>企业级 OLTP + OLAP 混合负载</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://cloud.google.com/spanner\">Spanner</a></strong></td>\n<td>全球分布式数据库</td>\n<td>类 SQL</td>\n<td>支持（TrueTime 协议）</td>\n<td>行存</td>\n<td>Google 云产品，全球分布式强一致事务</td>\n<td>全球化分布式事务，金融场景</td>\n</tr>\n<tr>\n<td><strong><a href=\"https://aws.amazon.com/rds/aurora/\">Amazon Aurora</a></strong></td>\n<td>云原生分布式关系型数据库</td>\n<td>MySQL/PostgreSQL 兼容</td>\n<td>支持（单实例事务，多 AZ 高可用）</td>\n<td>行存</td>\n<td>AWS 托管，自动扩展存储，多可用区高可用</td>\n<td>OLTP、企业级业务</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。 ShardingSphere官网 本文在 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 的基础上进行修改。 运行模式说明 运行模式 ShardingSphere-Proxy 运行模式分为两种：单机模式(Standalone) 和 集群模式(Cluster)。 运行模式就是指定将元数据(认证、数据源、分片规则等等)持久化的存储方式。 默认运行模式为单机模式，使用H2的内存方式。 单机模式(Standalone) 单机模式能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知。 通过某一实例更新元数据之后，会导致其他实例由于获取不到最新的元数据而产生不一致的错误。 适用于工程师在本地搭建 Apache ShardingSphere 环境。 单机模式目前仅支持一种：JDBC，即数据库持久化。以下为默认值(JDBCRepositoryPropertyKey)。 名称 数据类型 说明 默认值 provider String 元数据存储类型，可选值为 H2、MySQL 、EmbeddedDerby、DerbyNetworkServer、HSQLDB H2 jdbc_url String JDBC URL jdbc:h2:mem:config;DB_CLOSE_DELAY=0;DATABASE_TO_UPPER=false;MODE=MYSQL username String 账号 sa password String 密码 空（无默认值） 这里以 Mysql 存储元数据为例，相关属性参考官网说明 123456789mode: type: Standalone repository: type: JDBC props: provider: MySQL jdbc_url: jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd 此时需要将 mysql 的驱动 jar 包 添加到 ext-lib 目录下 启动 ShardingSphere Proxy 成功后会自动在上面的数据库中创建一张表，并将配置文件的中的元数据存储进去 1234567CREATE TABLE `repository` ( `id` varchar(36) COLLATE utf8mb4_bin NOT NULL, `key` text COLLATE utf8mb4_bin, `value` text COLLATE utf8mb4_bin, `parent` text COLLATE utf8mb4_bin, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 重点说明 当数据库中不存在该表时，会自动创建该表，并将配置文件的元数据插入该表中。 当数据库中已存在该表时，会读取该表中的数据并将其加载到内存，而不会读取配置文件中的元数据。即此时配置文件中的元数据不会生效。 若此时想修改配置规则，有三种方法： 1.删除该表，修改配置文件后重新启动Proxy，此时会重新创建该表并加载配置文件中的元数据。 2.手工修改数据表中的元数据，但修改后需要重新启动Proxy才会加载新的元数据。但手工修改需要对数据的组织形式非常清楚，否则极易出错。 3.[推荐]登录逻辑数据库后，使用 DistSQL 动态修改配置，修改后的配置会被保存在该表中，并立即生效，无需重启Proxy。 开发和测试环境可以直接使用默认的 H2 内存数据库，生产环境可以使用 MySQL等数据库对元数据进行持久化保存或者使用下面的集群模式。 集群模式(Cluster) 集群模式提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调的能力。 它能够提供计算能力水平扩展和高可用等分布式系统必备的能力，集群环境需要通过独立部署的注册中心来存储元数据和协调节点状态。 在生产环境建议使用集群模式。 这里以 zookeeper 集群模式为例，相关属性参考官网说明 1234567891011mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型，当前版本仅支持 ZooKeeper 和 etcd props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。 重点说明 不要手工修改 Zookeeper 集群中的 namespace 下的配置信息! 既然是集群，就需要多个 ShardingSphere-Proxy 实例。 当第一个 ShardingSphere-Proxy 实例 启动后，其它相同配置的 ShardingSphere-Proxy 实例仅需要一个 global.yaml 全局配置文件即可，并仅需在其中配置上面的运行模式信息，而不需要再配置其它配置，比如认证、数据源、分片规则等信息，这些信息会通过 Zookeeper 集群中的 namespace 获取并保存到本地内存中。 每个 ShardingSphere-Proxy 实例启动时，都会自动将自己注册到 Zookeeper 集群中指定的 namespace 下，并自动获取该 namespace 下的配置信息。 当 Zookeeper 集群中不存在指定的 namespace 时，此时第一次启动 ShardingSphere-Proxy 会自动在 Zookeeper 中创建 namespace，并写入配置文件中的配置信息到 Zookeeper 中。 当 Zookeeper 集群中已存在指定的 namespace 时，此时再启动 ShardingSphere-Proxy 会自动从 Zookeeper 中读取 namespace 下的配置信息，并将其加载到内存中，不会再读取本地配置文件中的配置信息。 当 Zookeeper 集群中已存在指定的 namespace 时，根据上面的规则，此时修改本地的配置文件中的分片规则后重启ShardingSphere-Proxy 并不会生效。 此时有三种方法： 删除 Zookeeper 集群中指定的 namespace，然后重启 ShardingSphere-Proxy。这种方法有个弊端，即会导致连接到相同 ZooKeeper 集群的 namespace 的其它 ShardingSphere-Proxy 实例数据丢失(完全不可用)，也需要重启才能重新获取到数据。 手工修改 Zookeeper 集群中指定的 namespace 下的分片规则，修改后会立即同步到所有 ShardingSphere-Proxy 实例。但手工修改需要对数据的组织形式非常清楚，否则极易出错。 [推荐]登录逻辑数据库后，使用 DistSQL 动态修改配置，此时会自动同步到所有 ShardingSphere-Proxy 实例。所以，灵活掌握 DistSQL 是维护 ShardingSphere-Proxy 集群的关键。 多个 ShardingSphere-Proxy 实例 可以通过负载均衡器，比如 Nginx，将请求路由到不同的 ShardingSphere-Proxy 实例。比如： 123456789101112stream&#123; upstream shardingsphere_proxy&#123; server 10.10.21.35:3307; server 10.10.21.36:3307; &#125; server&#123; listen 3310; proxy_connect_timeout 20s; proxy_timeout 5m; proxy_pass shardingsphere_proxy; &#125;&#125; 与 Spring Boot3 整合 无论是 单机模式 还是 集群模式，其目的都是将 配置 保存到独立的 配置中心(数据库 或 Zookeeper)中，并让其它 ShardingSphere-Proxy 实例从该配置中心中读取配置信息。 前文我们介绍过 Spring Boot3 + ShardingSphere-Proxy 就相当于是集成普通的MySql数据库，而 Spring Boot3 + ShardingSphere-JDBC 就需要单独在本地配置各种规则。 实际上 ShardingSphere-JDBC 也可以从 配置中心 中读取配置信息，这样我们就不需要在本地配置任何规则了，我们仅需要在 sharding.yaml 中配置好运行模式，并配置好 databaseName 的名称即可。注意，此时配置中心的的事务不能是 XA，因为Spring Boot3 + ShardingSphere-JDBC目前不支持 XA 事务。 此时，springboot项目启动后会拉取配置中心中的配置信息并将其保存到本地内存，本地配置文件中的其它配置信息会被忽略。 单机模式 代码示例 通过 DistSQL 改规则后，必须重启应用才能生效 sharding.yaml 1234567891011mode: type: Standalone repository: type: JDBC props: provider: MySQL jdbc_url: jdbc:mysql://127.0.0.1:3306/shardingsphere?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd# 数据库名称，默认值：logic_dbdatabaseName: sharding_db Maven 依赖 123456789101112131415161718192021222324&lt;!-- MySQL Connector/J --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mybatis plus，本项目用到，非必须 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 自定义 的 SPI --&gt;&lt;dependency&gt; &lt;groupId&gt;com.hanqf&lt;/groupId&gt; &lt;artifactId&gt;algorithm-swapper&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 集群模式 代码示例 通过 DistSQL 改规则后，立即推送到所有实例，无需重启应用。 sharding.yaml，注意这里一定要配置 databaseName 1234567891011121314# # 开启集群模式mode: type: Cluster # 运行模式，默认是单机模式 Standalone repository: type: ZooKeeper # 注册中心类型 props: namespace: governance_ds # ZooKeeper 上的根路径（逻辑命名空间），ShardingSphere 会把所有元数据（schema 的 data_sources、rules、版本信息、运行时实例节点等）放在该 namespace 下 server-lists: localhost:2181 # ZooKeeper 集群地址列表，以逗号分隔的 host:port 列表 retryIntervalMilliseconds: 500 # 与注册中心交互失败后的重试间隔（毫秒）。网络不稳定或短暂故障时用于重试回退。 timeToLiveSeconds: 60 # 表示“临时/短期数据”的生存时间（秒），用于控制某些临时节点/实例信息的存活策略 maxRetries: 3 # 最大重试次数（超过则认为操作失败）。 operationTimeoutMilliseconds: 500 # 单次 ZooKeeper 操作（读写）的超时时间（毫秒）。# 数据库名称，默认值：logic_dbdatabaseName: sharding_db Maven 依赖，注意要加上 shardingsphere-cluster-mode-repository-zookeeper 的依赖 123456789101112131415161718192021222324252627282930&lt;!-- MySQL Connector/J --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mybatis plus，本项目用到，非必须 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 自定义 的 SPI --&gt;&lt;dependency&gt; &lt;groupId&gt;com.hanqf&lt;/groupId&gt; &lt;artifactId&gt;algorithm-swapper&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- shardingsphere-cluster-mode-repository-zookeeper --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-cluster-mode-repository-zookeeper&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt; 如何选择 当我使用springboot3+shardingSphere-JDBC5.5.2时，我应该使用本地配置文件的方式还是使用配置中心（比如：zookeeper）的方式呢？ 方式 部署复杂度 配置动态更新 多实例共享配置 热更新支持 适用环境 本地配置文件 简单 不支持 不支持 否 开发/测试/小型项目 配置中心（ZooKeeper/etcd） 略高 支持 支持 是 生产/分布式环境 注意 DistSQL 目前确实只支持在 ShardingSphere-Proxy 上执行，并且 Proxy 只支持 MySQL 和 PostgreSQL 协议。 如果你在 Spring Boot + ShardingSphere-JDBC 里用 其它数据库（比如 SQL Server、Oracle、DB2 等），就无法直接通过 DistSQL 去动态改配置。 此时你可以选择通过 Zookeeper 的客户端直接修改或配置规则，也可以不选择 配置中心 的方式，直接使用 本地配置文件。 什么时候需要分库分表 分库分表的主要目的是 解决数据量大带来的性能、可用性和可扩展性问题。通常需要考虑的几个关键指标： 1. 数据量指标 单表数据量过大：一般来说，单表数据量在 千万级 以上时，查询、写入和索引的性能会明显下降。 例如：一个订单表一天有上百万条数据，一年下来可能有上亿条，单表性能会成为瓶颈。 2. 访问量指标 高并发写入或查询：数据库连接、事务锁、IO 等资源会成为瓶颈。 如果你的系统每天有上千万的请求，数据库可能无法承受。 3. 业务隔离需求 不同业务的数据分离，避免单个业务影响整个数据库的稳定性。 例如：电商系统中的订单和日志数据，日志量非常大，和订单分开存储更合理。 4. 运营与成本因素 分库分表后，可以分布到多个数据库实例上，支持 水平扩展，而不必依赖昂贵的单机数据库。 使用 ShardingSphere 可能带来的问题 使用 ShardingSphere 可以方便地解决分库分表问题，但在实际生产中，它会带来一些新的复杂性和潜在问题，主要体现在性能、运维、功能限制等方面。 1. 性能与延迟 跨库 JOIN 性能差 分库分表后，跨库的 JOIN 查询会在各个分片上分别执行，然后在 ShardingSphere 层合并结果，性能明显下降。 例如：订单表在多个库，查询订单 + 用户信息时必须跨库 JOIN，执行效率比单库低很多。 分页查询慢 分库分表后，如果要全局排序 + 分页，需要所有分片查出数据再合并，代价非常大。 解决方式：使用分片键范围分页，或引入 ElasticSearch/ClickHouse 做搜索和统计。 广播表压力 配置了广播表（每个库一份完整数据）后，更新需要同步所有库，写入性能下降。 2. SQL 兼容性限制 复杂 SQL 支持不完整 ShardingSphere 对某些复杂 SQL（如子查询、窗口函数）支持有限，可能报错或性能极差。 存储过程、触发器受限 分库分表后，存储过程、触发器在分片数据库执行可能不一致，维护成本高。 3. 分布式事务问题 ShardingSphere 支持 XA 分布式事务，但性能不如单机事务，出现网络抖动时可能会卡住。 如果业务需要强一致性，必须结合可靠消息或 TCC、SAGA 等分布式事务模式，架构会更复杂。 4. 运维与管理复杂度 分片规则变更困难 例如，最初按 user_id % 2 分成两个库，后续想增加到 4 个库，需要迁移数据，非常麻烦。 监控与调优 ShardingSphere 增加了中间层，SQL 路由、执行计划、数据节点状态都需要额外的监控工具支持。 5. 成本与学习曲线 配置相对复杂：分片规则、读写分离、分布式事务、弹性扩容都需要仔细设计。 学习曲线较陡：开发和运维人员必须了解 ShardingSphere 的工作机制，否则定位问题很困难。 6. 高可用与扩展问题 ShardingSphere-JDBC 是应用内库，无法独立扩展，需要依赖应用扩容。 ShardingSphere-Proxy 支持集群，但需要自己搭建高可用架构，涉及负载均衡、故障切换等问题。 其它技术方案：分布式数据库 开源产品: 核心功能完全开源，企业版提供额外商业特性 数据库 架构类型 SQL 兼容性 分布式事务支持 数据存储模型 主要特点 典型应用场景 TiDB 分布式 HTAP MySQL 协议兼容 支持（Percolator 模型） 行存 + 列存混合 开源、云原生、强一致性、弹性扩展 在线事务处理 + 实时分析 OceanBase 分布式关系型数据库 MySQL/Oracle 兼容 支持（两阶段提交） 行存 高性能、金融级事务、阿里蚂蚁金服核心系统使用 金融、电商、核心交易系统 CockroachDB 分布式 NewSQL PostgreSQL 兼容 支持（分布式事务） 行存 类 Spanner 架构，全球分布，强一致性 全球化分布式应用 Citus (PostgreSQL) PostgreSQL 扩展 PostgreSQL 兼容 部分支持（基于逻辑分片） 行存 基于 PostgreSQL 的分布式扩展，支持大规模 OLAP 大数据实时分析、BI 场景 Vitess 分布式中间件 + 存储 MySQL 协议兼容 弱事务（最终一致性） 行存 YouTube 开源，K8s 友好，分库分表自动化 大规模 Web 应用，在线服务 YugabyteDB 分布式 SQL + NoSQL PostgreSQL 兼容 支持（两阶段提交） 行存 + 列存混合 融合 NewSQL 和 NoSQL，强一致性，跨区域部署 金融级事务 + 分析混合场景 商业产品 数据库 架构类型 SQL 兼容性 分布式事务支持 数据存储模型 主要特点 典型应用场景 PolarDB 云原生分布式数据库 MySQL/PostgreSQL 兼容 支持（云端分布式事务） 行存 阿里云产品，弹性扩容，存储计算分离 云上企业数据库解决方案 GaussDB 分布式关系型数据库 MySQL/Oracle 兼容 支持（分布式事务） 行存 + 列存混合 华为推出，分布式 HTAP，云原生架构 企业级 OLTP + OLAP 混合负载 Spanner 全球分布式数据库 类 SQL 支持（TrueTime 协议） 行存 Google 云产品，全球分布式强一致事务 全球化分布式事务，金融场景 Amazon Aurora 云原生分布式关系型数据库 MySQL/PostgreSQL 兼容 支持（单实例事务，多 AZ 高可用） 行存 AWS 托管，自动扩展存储，多可用区高可用 OLTP、企业级业务","summary":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 运行模式的配置与使用。 ShardingSphere官网 本文在 SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表 的基础上进行修改。","date_published":"2025-09-10T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/","url":"https://blog.hanqunfeng.com/2025/09/08/maven-nexus-upgrade/","title":"Maven 私服 Nexus 升级实录","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 Mavne 私服 Nexus 升级的全过程，从 <code>3.29.2-02</code> 升级到 <code>3.83.2-01</code></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://help.sonatype.com/en/sonatype-nexus-repository.html\">Nexus官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://mirrors.tuna.tsinghua.edu.cn/Adoptium/\">OpenJdk下载地址</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://help.sonatype.com/en/sonatype-nexus-repository-system-requirements.html\">Nexus系统配置要求</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"升级过程说明\">升级过程说明</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Nexus 从 <code>3.71.x</code> 开始，不再支持 <code>OrientDB</code>，后续版本仅支持 <code>H2</code> 和 <code>PostgreSQL</code> ，根据<a href=\"https://help.sonatype.com/en/upgrading-to-nexus-repository-3-71-0-and-beyond.html\">官网说明</a>，<code>3.70.x</code> 以下的版本需要将 Nexus 先升级到 <code>3.70.x</code> 的最新版本，然后使用官方提供的数据库迁移工具，将数据库迁移到 <code>H2</code> 后，再升级到 <code>3.71.x</code> 以后的版本</p>\n</li>\n</ul>\n<h2 id=\"从-3-29-2-02-升级到-nexus-3-70-4-02\">从 <code>3.29.2-02</code> 升级到 <code>nexus-3.70.4-02</code></h2>\n<h3 id=\"安装-OpenJDK\">安装 <code>OpenJDK</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>需要先安装好 <code>OpenJDK</code>，原因是<code>Nexus的数据库迁移工具</code>仅支持 <code>OpenJDK</code>，不支持 <code>Oracle JDK</code>，我这里选择安装 <code>OpenJDK11</code></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /usr/local</span><br><span class=\"line\">curl -O https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\">tar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s /usr/local/jdk-11.0.28+6/bin/java /usr/bin/java</span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/local/jdk-11.0.28+6</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"安装-nexus-3-70-x\">安装 <code>nexus-3.70.x</code></h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>目前官网发布的<code>nexus-3.70.x</code>的最新版本为 <code>nexus-3.70.4-02</code>，<a href=\"https://help.sonatype.com/en/orientdb-downloads.html\">下载页面</a>，其对应的数据库迁移工具也可以从该页面下载。</p>\n</li>\n<li class=\"lvl-2\">\n<p>这里我们选择 <a href=\"https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz\">Java 11 的版本</a>，升级安装与第一次安装方式一样。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 切换到 nexus 用户，原 nexus-3.29.2-02 就安装在 该用户的 `home` 目录下</span></span><br><span class=\"line\">su - nexus</span><br><span class=\"line\"><span class=\"comment\"># 关闭 原 nexus 服务，关于如何将 Nexus 配置为系统服务，可以参考：https://help.sonatype.com/en/run-as-a-service.html</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\">#~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 需要科学上网</span></span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class=\"line\">tar -zxvf nexus-3.70.4-02-java11-unix.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">rm</span> -f ~/nexus3</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s /usr/local/nexus-3.70.4-02 ~/nexus3</span><br><span class=\"line\"><span class=\"comment\"># 启动 nexus</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"迁移数据到-H2\">迁移数据到 H2</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>下载数据库迁移工具</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> ~/backup</span><br><span class=\"line\"><span class=\"built_in\">cd</span> ~/backup</span><br><span class=\"line\"><span class=\"comment\"># 与 nexus 版本一致</span></span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/nxrm3-migrator/nexus-db-migrator-3.70.4-02.jar</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>登录 Nexus 导出数据: 设置 -&gt; System -&gt; Tasks -&gt; Create task -&gt; Admin - Export databases for backup<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/MS26e5.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>任务创建后点击<code>Run</code>，即可在 <code>/home/nexus/backup</code> 目录下看到备份文件</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ll /home/nexus/backup</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   121066 Sep  8 07:25 analytics-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus 19349428 Sep  8 07:25 component-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   266208 Sep  8 07:25 config-2025-09-08-07-25-57-3.70.4-02.bak</span><br><span class=\"line\">-rw-r--r-- 1 nexus nexus 56809625 Sep  8 06:41 nexus-db-migrator-3.70.4-02.jar</span><br><span class=\"line\">-rw-rw-r-- 1 nexus nexus   132802 Sep  8 07:25 security-2025-09-08-07-25-57-3.70.4-02.bak</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>使用迁移工具生成H2数据库文件，官网参考资料: <a href=\"https://help.sonatype.com/en/migrating-to-a-new-database.html#migrating-from-orientdb-to-h2\">Migrating From OrientDB to H2</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开始迁移前需要先关闭 nexus 服务</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"><span class=\"comment\"># 进入备份目录</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> /home/nexus/backup</span><br><span class=\"line\"><span class=\"comment\"># 这里要使用 OpenJDK 11 运行，根据需要适当调整内存参数</span></span><br><span class=\"line\">java -Xmx2G -Xms2G -XX:+UseG1GC -jar nexus-db-migrator-3.70.4-02.jar --migration_type=h2</span><br><span class=\"line\"><span class=\"comment\"># 运行后会提示你迁移数据库前需要先关闭 nexus 服务，我们输入 y 继续</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>运行成功后会生成 <code>nexus.mv.db</code>，将其移动到 <code>/home/nexus/sonatype-work/nexus3/db/</code> 目录下</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mv</span> nexus.mv.db /home/nexus/sonatype-work/nexus3/db/</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>编辑<code>/home/nexus/sonatype-work/nexus3/etc/nexus.properties</code> 文件，添加如下内容</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># enable db h2</span></span><br><span class=\"line\">nexus.datastore.enabled=<span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>启动 nexus，此时我们就完成了 从 <code>3.29.2-02</code> 到 <code>nexus-3.70.4-02</code> 的升级</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"从-nexus-3-70-4-02-升级到-nexus-3-83-2-01\">从 <code>nexus-3.70.4-02</code> 升级到 <code>nexus-3.83.2-01</code></h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这个升级就比较简单了，和我们此前的升级方式是一样的，下载解压后替换安装目录即可，这里要注意，从<code>nexus-3.71.0+</code>开始仅支持<code>jdk17</code>，所以需要提前安装好<code>jdk17</code>，另外从<code>nexus-3.78.0</code>开始，Nexus 内置了<code>openjdk17</code>，所以不需要再额外安装jdk。</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>nexus-3.83.2-01</code> 是目前的最新版，<a href=\"https://help.sonatype.com/en/download.html\">最新版下载页面</a>，<a href=\"https://help.sonatype.com/en/download-archives---repository-manager-3.html\">历史版本下载页面地址</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关闭 Nexus 服务</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl stop nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus stop</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> ~</span><br><span class=\"line\">curl -O https://download.sonatype.com/nexus/3/nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class=\"line\">tar -zxvf nexus-3.83.2-01-linux-x86_64.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">rm</span> -f nexus3</span><br><span class=\"line\"><span class=\"built_in\">ln</span> -s nexus-3.83.2-01 nexus3</span><br><span class=\"line\"><span class=\"comment\"># 启动 Nexus，nexus-3.83.2-01 自带 openjdk17，所以不需要单独安装 openjdk</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl start nexus</span><br><span class=\"line\"><span class=\"comment\"># ~/nexus3/bin/nexus start</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/rgLwWf.png\" alt=\"\"><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/mdWh22.png\" alt=\"\" width=\"1400\" height=\"1000\"><br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/56aOWz.png\" alt=\"\"></p>\n","content_text":"摘要 本文介绍 Mavne 私服 Nexus 升级的全过程，从 3.29.2-02 升级到 3.83.2-01 Nexus官网 OpenJdk下载地址 Nexus系统配置要求 升级过程说明 Nexus 从 3.71.x 开始，不再支持 OrientDB，后续版本仅支持 H2 和 PostgreSQL ，根据官网说明，3.70.x 以下的版本需要将 Nexus 先升级到 3.70.x 的最新版本，然后使用官方提供的数据库迁移工具，将数据库迁移到 H2 后，再升级到 3.71.x 以后的版本 从 3.29.2-02 升级到 nexus-3.70.4-02 安装 OpenJDK 需要先安装好 OpenJDK，原因是Nexus的数据库迁移工具仅支持 OpenJDK，不支持 Oracle JDK，我这里选择安装 OpenJDK11 123456cd /usr/localcurl -O https://mirrors.tuna.tsinghua.edu.cn/Adoptium/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gztar -zxvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.28_6.tar.gzln -s /usr/local/jdk-11.0.28+6/bin/java /usr/bin/javaexport JAVA_HOME=/usr/local/jdk-11.0.28+6export PATH=$JAVA_HOME/bin:$PATH 安装 nexus-3.70.x 目前官网发布的nexus-3.70.x的最新版本为 nexus-3.70.4-02，下载页面，其对应的数据库迁移工具也可以从该页面下载。 这里我们选择 Java 11 的版本，升级安装与第一次安装方式一样。 1234567891011121314# 切换到 nexus 用户，原 nexus-3.29.2-02 就安装在 该用户的 `home` 目录下su - nexus# 关闭 原 nexus 服务，关于如何将 Nexus 配置为系统服务，可以参考：https://help.sonatype.com/en/run-as-a-service.htmlsudo systemctl stop nexus#~/nexus3/bin/nexus stop# 需要科学上网curl -O https://download.sonatype.com/nexus/3/nexus-3.70.4-02-java11-unix.tar.gztar -zxvf nexus-3.70.4-02-java11-unix.tar.gzrm -f ~/nexus3ln -s /usr/local/nexus-3.70.4-02 ~/nexus3# 启动 nexussudo systemctl start nexus# ~/nexus3/bin/nexus start 迁移数据到 H2 下载数据库迁移工具 1234mkdir ~/backupcd ~/backup# 与 nexus 版本一致curl -O https://download.sonatype.com/nexus/nxrm3-migrator/nexus-db-migrator-3.70.4-02.jar 登录 Nexus 导出数据: 设置 -&gt; System -&gt; Tasks -&gt; Create task -&gt; Admin - Export databases for backup 任务创建后点击Run，即可在 /home/nexus/backup 目录下看到备份文件 123456ll /home/nexus/backup-rw-rw-r-- 1 nexus nexus 121066 Sep 8 07:25 analytics-2025-09-08-07-25-57-3.70.4-02.bak-rw-rw-r-- 1 nexus nexus 19349428 Sep 8 07:25 component-2025-09-08-07-25-57-3.70.4-02.bak-rw-rw-r-- 1 nexus nexus 266208 Sep 8 07:25 config-2025-09-08-07-25-57-3.70.4-02.bak-rw-r--r-- 1 nexus nexus 56809625 Sep 8 06:41 nexus-db-migrator-3.70.4-02.jar-rw-rw-r-- 1 nexus nexus 132802 Sep 8 07:25 security-2025-09-08-07-25-57-3.70.4-02.bak 使用迁移工具生成H2数据库文件，官网参考资料: Migrating From OrientDB to H2 12345678# 开始迁移前需要先关闭 nexus 服务sudo systemctl stop nexus# ~/nexus3/bin/nexus stop# 进入备份目录cd /home/nexus/backup# 这里要使用 OpenJDK 11 运行，根据需要适当调整内存参数java -Xmx2G -Xms2G -XX:+UseG1GC -jar nexus-db-migrator-3.70.4-02.jar --migration_type=h2# 运行后会提示你迁移数据库前需要先关闭 nexus 服务，我们输入 y 继续 运行成功后会生成 nexus.mv.db，将其移动到 /home/nexus/sonatype-work/nexus3/db/ 目录下 1mv nexus.mv.db /home/nexus/sonatype-work/nexus3/db/ 编辑/home/nexus/sonatype-work/nexus3/etc/nexus.properties 文件，添加如下内容 12# enable db h2nexus.datastore.enabled=true 启动 nexus，此时我们就完成了 从 3.29.2-02 到 nexus-3.70.4-02 的升级 12sudo systemctl start nexus# ~/nexus3/bin/nexus start 从 nexus-3.70.4-02 升级到 nexus-3.83.2-01 这个升级就比较简单了，和我们此前的升级方式是一样的，下载解压后替换安装目录即可，这里要注意，从nexus-3.71.0+开始仅支持jdk17，所以需要提前安装好jdk17，另外从nexus-3.78.0开始，Nexus 内置了openjdk17，所以不需要再额外安装jdk。 nexus-3.83.2-01 是目前的最新版，最新版下载页面，历史版本下载页面地址 1234567891011# 关闭 Nexus 服务sudo systemctl stop nexus# ~/nexus3/bin/nexus stopcd ~curl -O https://download.sonatype.com/nexus/3/nexus-3.83.2-01-linux-x86_64.tar.gztar -zxvf nexus-3.83.2-01-linux-x86_64.tar.gzrm -f nexus3ln -s nexus-3.83.2-01 nexus3# 启动 Nexus，nexus-3.83.2-01 自带 openjdk17，所以不需要单独安装 openjdksudo systemctl start nexus# ~/nexus3/bin/nexus start","summary":"摘要 本文介绍 Mavne 私服 Nexus 升级的全过程，从 3.29.2-02 升级到 3.83.2-01 Nexus官网 OpenJdk下载地址 Nexus系统配置要求","date_published":"2025-09-08T13:30:05.000Z","tags":["技术","maven","nexus","mavne","nexus"]},{"id":"https://blog.hanqunfeng.com/2025/09/04/springboot3-shardingsphere-proxy/","url":"https://blog.hanqunfeng.com/2025/09/04/springboot3-shardingsphere-proxy/","title":"SpringBoot3 + ShardingSphere-Proxy5.5.2 分库分表","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 分库分表的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy\">本文项目代码Github地址</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>本文将 <a href=\"/2025/09/01/springboot3-shardingsphere/\" title=\"SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表\">SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表</a> 修改为 <code>ShardingSphere-Proxy</code> 的模式</p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"ShardingSphere-Proxy-简介\">ShardingSphere-Proxy 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 定位为透明化的数据库代理端，通过实现数据库二进制协议，对异构语言提供支持。 目前提供 MySQL 和 PostgreSQL 协议，透明化数据库操作，对 DBA 更加友好。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">向应用程序完全透明，可直接当做 MySQL/PostgreSQL 使用；</li>\n<li class=\"lvl-4\">兼容 MariaDB 等基于 MySQL 协议的数据库，以及 openGauss 等基于 PostgreSQL 协议的数据库；</li>\n<li class=\"lvl-4\">适用于任何兼容 MySQL/PostgreSQL 协议的的客户端，如：MySQL Command Client, MySQL Workbench, Navicat 等。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 独立部署架构图<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/AMn2pu.png\" alt=\"\"></p>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 与 ShardingSphere-JDBC 的特性比较</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>ShardingSphere-JDBC</th>\n<th>ShardingSphere-Proxy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>数据库支持</strong></td>\n<td>任意数据库</td>\n<td>MySQL / PostgreSQL</td>\n</tr>\n<tr>\n<td><strong>连接消耗数</strong></td>\n<td>高</td>\n<td>低</td>\n</tr>\n<tr>\n<td><strong>异构语言支持</strong></td>\n<td>仅支持 Java</td>\n<td>支持任意语言</td>\n</tr>\n<tr>\n<td><strong>性能</strong></td>\n<td>损耗低</td>\n<td>损耗略高</td>\n</tr>\n<tr>\n<td><strong>无中心化</strong></td>\n<td>是</td>\n<td>否</td>\n</tr>\n<tr>\n<td><strong>静态入口</strong></td>\n<td>无</td>\n<td>有</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"部署-ShardingSphere-Proxy\">部署 ShardingSphere-Proxy</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>运行 ShardingSphere-Proxy 要求 JDK 1.8+</p>\n</li>\n<li class=\"lvl-2\">\n<p>下载 <a href=\"https://shardingsphere.apache.org/document/current/cn/downloads/\">ShardingSphere-Proxy5.5.2</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://www.apache.org/dyn/closer.lua/shardingsphere/5.5.2/apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\">tar -zxvf apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置-ShardingSphere-Proxy\">配置 ShardingSphere-Proxy</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>conf/global.yaml</code>: 全局配置，所谓全局，就是对所有逻辑库都生效的配置</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/authority/</span></span><br><span class=\"line\"><span class=\"attr\">authority:</span></span><br><span class=\"line\"> <span class=\"attr\">users:</span></span><br><span class=\"line\">   <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">root@127.0.0.1</span> <span class=\"comment\"># 格式：用户名@IP</span></span><br><span class=\"line\">     <span class=\"attr\">password:</span> <span class=\"string\">root</span></span><br><span class=\"line\">     <span class=\"attr\">admin:</span> <span class=\"literal\">true</span>          <span class=\"comment\"># 是否是管理员</span></span><br><span class=\"line\">   <span class=\"bullet\">-</span> <span class=\"attr\">user:</span> <span class=\"string\">sharding@%</span>     <span class=\"comment\"># 所有IP都可以访问</span></span><br><span class=\"line\">     <span class=\"attr\">password:</span> <span class=\"string\">sharding</span></span><br><span class=\"line\"> <span class=\"attr\">privilege:</span></span><br><span class=\"line\">   <span class=\"attr\">type:</span> <span class=\"string\">DATABASE_PERMITTED</span> <span class=\"comment\"># 权限类型</span></span><br><span class=\"line\">   <span class=\"attr\">props:</span></span><br><span class=\"line\">      <span class=\"attr\">user-database-mappings:</span> <span class=\"string\">root@127.0.0.1=*,sharding@%=sharding_db</span> <span class=\"comment\"># 用户权限映射，*表示所有数据库</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 开启XA事务，如果是 springboot项目，只需要在方法上加上 @Transactional 注解即可开启事务(从 MySQL 5.7 开始就全面支持 XA 分布式事务)</span></span><br><span class=\"line\"><span class=\"comment\"># https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/</span></span><br><span class=\"line\"><span class=\"attr\">transaction:</span>  <span class=\"comment\"># 配置事务</span></span><br><span class=\"line\">  <span class=\"attr\">defaultType:</span> <span class=\"string\">XA</span>        <span class=\"comment\"># 事务类型，默认 LOCAL</span></span><br><span class=\"line\">  <span class=\"attr\">providerType:</span> <span class=\"string\">Atomikos</span> <span class=\"comment\"># 事务管理器具体实现，默认就是 Atomikos</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/props/</span></span><br><span class=\"line\"><span class=\"attr\">props:</span></span><br><span class=\"line\">  <span class=\"attr\">sql-show:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class=\"line\">  <span class=\"attr\">check-table-metadata-enabled:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>conf/database-my.yaml</code>: 自定义分配规则配置</p>\n</li>\n</ul>\n<blockquote>\n<p>注意:<br>\n1.名称必须以 <code>database-</code>开头，实际上<code>conf</code>目录下有很多示例，我们可以根据需要进行配置<br>\n2.<code>global.yaml</code>中的配置项不能配置到 <code>database-my.yaml</code>中</p>\n</blockquote>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据库名称，默认值：logic_db</span></span><br><span class=\"line\"><span class=\"attr\">databaseName:</span> <span class=\"string\">sharding_db</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/</span></span><br><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"comment\"># dataSourceClassName: com.zaxxer.hikari.HikariDataSource # 不要指定</span></span><br><span class=\"line\">    <span class=\"comment\"># driverClassName: com.mysql.cj.jdbc.Driver               # 不要指定</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span>  <span class=\"comment\"># 注意这里属性为 url</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"comment\"># dataSourceClassName: com.zaxxer.hikari.HikariDataSource</span></span><br><span class=\"line\">    <span class=\"comment\"># driverClassName: com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 以下规则与前文中的 shardingsphere-jdbc 中的 rules 相同</span></span><br><span class=\"line\"><span class=\"comment\"># 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"comment\"># 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致</span></span><br><span class=\"line\">    <span class=\"attr\">bindingTables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">t_order,t_order_item</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">course:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">cid</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_inline</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">cid</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order-complex-algorithm</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span>  <span class=\"comment\"># 分片列名称,多个逗号分隔</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_item-class-based-algorithm_spi</span> <span class=\"comment\"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span>  <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">id</span> <span class=\"comment\"># 自增列名称，字符串类型</span></span><br><span class=\"line\">          <span class=\"comment\">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">custom_snowflake_string</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#       t_address:      # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明</span></span><br><span class=\"line\">    <span class=\"comment\">#         actualDataNodes: ds_0.t_address # 实际数据节点</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">autoTables:</span> <span class=\"comment\"># 自动分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/</span></span><br><span class=\"line\">      <span class=\"attr\">course_inline:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span> <span class=\"comment\"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 属性</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">course_$&#123;cid</span> <span class=\"string\">%</span> <span class=\"number\">2</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class=\"line\">          <span class=\"attr\">allow-range-query-with-inline-sharding:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 允许范围查询</span></span><br><span class=\"line\">      <span class=\"attr\">course_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表示 ds_0, ds_1</span></span><br><span class=\"line\">      <span class=\"attr\">mod_2:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MOD</span> <span class=\"comment\"># 基于 MOD 的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">sharding-count:</span> <span class=\"number\">2</span> <span class=\"comment\"># 分片数量，即 对 2 进行取余</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order-complex-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">COMPLEX_INLINE</span> <span class=\"comment\"># 基于行表达式的复合分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_order_complex_$&#123;(user_id</span> <span class=\"string\">+</span> <span class=\"string\">order_id</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">)</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm_spi:</span> <span class=\"comment\"># SPI</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">T_ORDER_ITEM_COMPLEX</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br><span class=\"line\">      <span class=\"attr\">uuid:</span> <span class=\"comment\"># 定义名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">UUID</span> <span class=\"comment\"># 字符串主键，String</span></span><br><span class=\"line\">      <span class=\"attr\">custom_snowflake_string:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CUSTOM_SNOWFLAKE_STRING</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">workerId:</span> <span class=\"number\">2</span></span><br><span class=\"line\">          <span class=\"attr\">datacenterId:</span> <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!BROADCAST</span>  <span class=\"comment\"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">dict</span>    <span class=\"comment\"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!ENCRYPT</span>    <span class=\"comment\"># 数据加密配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span> <span class=\"comment\"># 加密表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 加密列名称</span></span><br><span class=\"line\">            <span class=\"attr\">cipher:</span></span><br><span class=\"line\">              <span class=\"attr\">name:</span> <span class=\"string\">password</span> <span class=\"comment\"># 密文列名称</span></span><br><span class=\"line\">              <span class=\"attr\">encryptorName:</span> <span class=\"string\">aes_encryptor</span> <span class=\"comment\"># 密文列加密算法名称</span></span><br><span class=\"line\">    <span class=\"comment\"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class=\"line\">    <span class=\"attr\">encryptors:</span></span><br><span class=\"line\">      <span class=\"attr\">aes_encryptor:</span> <span class=\"comment\"># 加解密算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">AES</span> <span class=\"comment\"># 加解密算法类型</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 加解密算法属性配置</span></span><br><span class=\"line\">          <span class=\"attr\">aes-key-value:</span> <span class=\"string\">123456abc</span>     <span class=\"comment\"># AES 使用的 KEY</span></span><br><span class=\"line\">          <span class=\"attr\">digest-algorithm-name:</span> <span class=\"string\">SHA-1</span> <span class=\"comment\"># AES KEY 的摘要算法</span></span><br><span class=\"line\">      <span class=\"attr\">md5_encryptor:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">salt:</span> <span class=\"number\">123456</span>  <span class=\"comment\"># 盐值（可选）</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!MASK</span>  <span class=\"comment\"># 数据脱敏配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span> <span class=\"comment\"># 脱敏表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span> <span class=\"comment\"># 脱敏列配置</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 脱敏列名称</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">md5_mask</span> <span class=\"comment\"># 脱敏算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">email:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">mask_before_special_chars_mask</span></span><br><span class=\"line\">          <span class=\"attr\">telephone:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">keep_first_n_last_m_mask</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">my_mask</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">maskAlgorithms:</span> <span class=\"comment\"># 脱敏算法配置</span></span><br><span class=\"line\">      <span class=\"attr\">md5_mask:</span> <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span>  <span class=\"comment\"># 脱敏算法类型，md5加密后展示</span></span><br><span class=\"line\">      <span class=\"attr\">mask_before_special_chars_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MASK_BEFORE_SPECIAL_CHARS</span> <span class=\"comment\"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">special-chars:</span> <span class=\"string\">&#x27;@&#x27;</span>  <span class=\"comment\"># 遇到 @ 之前的部分做脱敏</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span>   <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">keep_first_n_last_m_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">KEEP_FIRST_N_LAST_M</span> <span class=\"comment\"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">first-n:</span> <span class=\"number\">3</span>     <span class=\"comment\"># 保留前 3 位</span></span><br><span class=\"line\">          <span class=\"attr\">last-m:</span> <span class=\"number\">4</span>      <span class=\"comment\"># 保留后 4 位</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span> <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">my_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MY_CUSTOM_MASK</span>  <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&quot;#&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SINGLE</span> <span class=\"comment\"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"comment\"># MySQL 风格</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">ds_0.t_address</span> <span class=\"comment\"># 加载指定单表</span></span><br><span class=\"line\"><span class=\"comment\">#       - ds_1.* # 加载指定数据源中的全部单表</span></span><br><span class=\"line\"><span class=\"comment\">#       - &quot;*.*&quot; # 加载全部单表</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面的<code>rules</code>中使用的是<code>mysql</code>数据库，所以我们需要引入<code>mysql</code>数据库的依赖</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/</span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> ext-lib</span><br><span class=\"line\"><span class=\"built_in\">cd</span> ext-lib</span><br><span class=\"line\">wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.11/mysql-connector-java-8.0.11.jar</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>同时<code>rules</code>中包含一些自定义的算法，我们也需要将这些算法作为依赖进行引入，将这些算法类打成<code>jar</code>，然后也拷贝到<code>ext-lib</code>目录下，我已经将其发布到了github上，实际上和前文中的 <code>shardingsphere-jdbc</code> 项目中将算法配置为 <code>spi</code> 的方式是一致的。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 只克隆仓库的基本信息，不下载所有文件</span></span><br><span class=\"line\">git <span class=\"built_in\">clone</span> --filter=blob:none --sparse https://github.com/hanqunfeng/springbootchapter.git</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 进入仓库目录</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> springbootchapter</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 设置只检出你需要的目录</span></span><br><span class=\"line\">git sparse-checkout <span class=\"built_in\">set</span> springboot3-demo/shardingsphere-demo/algorithm-swapper</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 编译打包</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> springboot3-demo/shardingsphere-demo/algorithm-swapper</span><br><span class=\"line\">mvn clean package -DskipTests</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 将打好的包复制到 shardingsphere-proxy 的 ext-lib 目录下</span></span><br><span class=\"line\"><span class=\"built_in\">cp</span> target/algorithm-swapper-1.0.0.jar <span class=\"variable\">$shardingsphere</span>-proxy$/ext-lib</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动与关闭-ShardingSphere-Proxy\">启动与关闭 ShardingSphere Proxy</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere Proxy 要求 JDK 1.8 或以上版本</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> <span class=\"variable\">$shardingsphere</span>-proxy$/bin</span><br><span class=\"line\"><span class=\"comment\"># 启动</span></span><br><span class=\"line\">./start.sh</span><br><span class=\"line\"><span class=\"comment\"># 关闭</span></span><br><span class=\"line\">./stop.sh</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>参数说明</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>-a</code></td>\n<td>绑定地址，可以是 IPv4、IPv6 或主机名，多个地址用逗号分隔。</td>\n<td><code>0.0.0.0</code></td>\n</tr>\n<tr>\n<td><code>-p</code></td>\n<td>绑定端口号，可以在 <code>global.yaml</code> 中修改。<code>-p</code> 优先级更高</td>\n<td><code>3307</code></td>\n</tr>\n<tr>\n<td><code>-c</code></td>\n<td>ShardingSphere-Proxy 配置目录路径。</td>\n<td><code>conf</code></td>\n</tr>\n<tr>\n<td><code>-f</code></td>\n<td>强制启动 ShardingSphere-Proxy。</td>\n<td>无</td>\n</tr>\n<tr>\n<td><code>-g</code></td>\n<td>如果在 <code>agent</code> 目录下部署了 <code>shardingsphere-agent</code>，启用 agent 功能。</td>\n<td>无</td>\n</tr>\n<tr>\n<td><code>-s</code></td>\n<td>指定用于连接的 socket 文件路径。</td>\n<td>无</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere-Proxy 启动命令速查表</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>命令示例</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>默认启动</strong></td>\n<td><code>./start.sh</code></td>\n<td>默认端口 <code>3307</code>，配置目录 <code>conf</code></td>\n</tr>\n<tr>\n<td><strong>指定端口和配置目录</strong></td>\n<td><code>./start.sh 3308 /opt/shardingsphere-proxy/conf</code></td>\n<td>简写模式，指定端口和配置目录</td>\n</tr>\n<tr>\n<td><strong>参数形式启动</strong></td>\n<td><code>./start.sh -p 3308 -c /opt/shardingsphere-proxy/conf</code></td>\n<td>与上面等效，但更明确</td>\n</tr>\n<tr>\n<td><strong>指定监听地址</strong></td>\n<td><code>./start.sh -a 192.168.1.100 -p 3307 -c conf</code></td>\n<td>指定单个 IP 地址</td>\n</tr>\n<tr>\n<td><strong>指定多个监听地址</strong></td>\n<td><code>./start.sh -a 192.168.1.100,127.0.0.1 -p 3307 -c conf</code></td>\n<td>多个地址用逗号分隔</td>\n</tr>\n<tr>\n<td><strong>强制启动</strong></td>\n<td><code>./start.sh -p 3307 -c conf -f</code></td>\n<td>遇到残留 PID 文件时使用</td>\n</tr>\n<tr>\n<td><strong>启用 agent</strong></td>\n<td><code>./start.sh -p 3307 -c conf -g</code></td>\n<td>启动 ShardingSphere-Agent</td>\n</tr>\n<tr>\n<td><strong>使用 Unix Socket</strong></td>\n<td><code>./start.sh -p 3307 -c conf -s /tmp/sharding-proxy.sock</code></td>\n<td>通过 Socket 文件进行连接</td>\n</tr>\n<tr>\n<td><strong>多选项组合</strong></td>\n<td><code>./start.sh -a 127.0.0.1 -p 3310 -c /opt/proxy/conf -f -g -s /tmp/proxy.sock</code></td>\n<td>一次性指定多个选项</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"项目连接-ShardingSphere-Proxy-时，就像连接普通的-mysql-服务一样\">项目连接 ShardingSphere-Proxy 时，就像连接普通的 mysql 服务一样</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>示例项目：<a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy\">https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy</a></p>\n</li>\n</ul>\n<h2 id=\"后记\">后记</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>在 <code>ShardingSphere-JDBC</code> 和 <code>ShardingSphere-Proxy</code> 中，存在部分 MySQL(其它数据库也类似) 的 SQL 语法或功能目前还不完全支持的情况。<code>ShardingSphere</code> 在做 SQL 路由、改写、执行时，必须能解析 SQL 并理解其语义，但并不是 MySQL 的 100% 完全代理。因此，有些复杂或特定场景下的 SQL 可能无法被正确解析或执行。</p>\n</li>\n<li class=\"lvl-2\">\n<p>支持良好的 SQL 语法</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">基础 DML<br>\nSELECT、INSERT、UPDATE、DELETE<br>\n基本的条件查询、排序、分页、分组、聚合函数（如 COUNT、SUM、AVG）</li>\n<li class=\"lvl-4\">DCL<br>\n基本的事务语句：BEGIN、COMMIT、ROLLBACK</li>\n<li class=\"lvl-4\">DDL<br>\n部分表结构管理语句：CREATE TABLE、ALTER TABLE、DROP TABLE</li>\n<li class=\"lvl-4\">函数支持<br>\n大部分常用的 MySQL 内置函数，如字符串、数学、日期函数</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"在-ShardingSphere-MySQL-下建议避免或谨慎使用的-SQL-清单\">在 ShardingSphere + MySQL 下建议避免或谨慎使用的 SQL 清单</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol>\n<li class=\"lvl-5\">跨分片复杂查询</li>\n</ol>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>SQL 场景</th>\n<th>原因</th>\n<th>建议处理方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>多表复杂 JOIN（特别是跨分片）</td>\n<td>需要跨库数据聚合，性能差，可能报错</td>\n<td>使用广播表/绑定表，或在应用层完成</td>\n</tr>\n<tr>\n<td>跨分片子查询</td>\n<td>SQL 路由困难，可能不支持</td>\n<td>尽量改成单表查询或分步查询</td>\n</tr>\n<tr>\n<td>跨分片的 GROUP BY / ORDER BY</td>\n<td>在 Proxy 层聚合，性能很差</td>\n<td>尽量避免，或控制数据量</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol start=\"2\">\n<li class=\"lvl-5\">DDL 相关</li>\n</ol>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>SQL 场景</th>\n<th>原因</th>\n<th>建议处理方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ALTER TABLE</code> 复杂变更</td>\n<td>需在所有分片执行，可能执行失败</td>\n<td>手动在每个分片库执行</td>\n</tr>\n<tr>\n<td><code>CREATE TRIGGER</code>、<code>PROCEDURE</code></td>\n<td>Proxy 不解析这些语法，直接透传不安全</td>\n<td>尽量在单库手动创建</td>\n</tr>\n<tr>\n<td><code>CREATE FUNCTION</code></td>\n<td>同上</td>\n<td>单库执行或应用层替代</td>\n</tr>\n<tr>\n<td><code>FULLTEXT INDEX</code>、<code>SPATIAL INDEX</code></td>\n<td>分片环境下无法自动维护索引</td>\n<td>单库手动维护或避免使用</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol start=\"3\">\n<li class=\"lvl-5\">文件导入导出</li>\n</ol>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>SQL 场景</th>\n<th>原因</th>\n<th>建议处理方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>LOAD DATA INFILE</code></td>\n<td>Proxy 不支持文件系统直接访问</td>\n<td>在分片库手动执行或通过应用导入</td>\n</tr>\n<tr>\n<td><code>SELECT ... INTO OUTFILE</code></td>\n<td>同上</td>\n<td>应用层处理导出</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<ol start=\"4\">\n<li class=\"lvl-5\">MySQL 特有功能</li>\n</ol>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>功能</th>\n<th>支持情况</th>\n<th>建议</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MySQL 8.0 公共表表达式（CTE）</td>\n<td>部分支持</td>\n<td>避免跨分片使用</td>\n</tr>\n<tr>\n<td>窗口函数（<code>OVER() PARTITION BY</code>）</td>\n<td>部分支持</td>\n<td>避免跨分片大数据量使用</td>\n</tr>\n<tr>\n<td>JSON 函数</td>\n<td>基本支持</td>\n<td>单表场景可用，跨分片需谨慎</td>\n</tr>\n</tbody>\n</table>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>分布式事务</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>问题原因</th>\n<th>建议处理方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>跨分片原生事务</td>\n<td>MySQL 原生事务不支持跨库</td>\n<td>使用 ShardingSphere XA / BASE</td>\n</tr>\n<tr>\n<td>大事务 + 分布式事务</td>\n<td>性能开销大</td>\n<td>尽量控制事务范围</td>\n</tr>\n</tbody>\n</table>\n","content_text":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 分库分表的使用。 ShardingSphere官网 本文项目代码Github地址 本文将 SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表 修改为 ShardingSphere-Proxy 的模式 ShardingSphere-Proxy 简介 ShardingSphere-Proxy 定位为透明化的数据库代理端，通过实现数据库二进制协议，对异构语言提供支持。 目前提供 MySQL 和 PostgreSQL 协议，透明化数据库操作，对 DBA 更加友好。 向应用程序完全透明，可直接当做 MySQL/PostgreSQL 使用； 兼容 MariaDB 等基于 MySQL 协议的数据库，以及 openGauss 等基于 PostgreSQL 协议的数据库； 适用于任何兼容 MySQL/PostgreSQL 协议的的客户端，如：MySQL Command Client, MySQL Workbench, Navicat 等。 ShardingSphere-Proxy 独立部署架构图 ShardingSphere-Proxy 与 ShardingSphere-JDBC 的特性比较 特性 ShardingSphere-JDBC ShardingSphere-Proxy 数据库支持 任意数据库 MySQL / PostgreSQL 连接消耗数 高 低 异构语言支持 仅支持 Java 支持任意语言 性能 损耗低 损耗略高 无中心化 是 否 静态入口 无 有 部署 ShardingSphere-Proxy 运行 ShardingSphere-Proxy 要求 JDK 1.8+ 下载 ShardingSphere-Proxy5.5.2 1234wget https://www.apache.org/dyn/closer.lua/shardingsphere/5.5.2/apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gztar -zxvf apache-shardingsphere-5.5.2-shardingsphere-proxy-bin.tar.gzcd apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/ 配置 ShardingSphere-Proxy conf/global.yaml: 全局配置，所谓全局，就是对所有逻辑库都生效的配置 1234567891011121314151617181920212223# https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/authority/authority: users: - user: root@127.0.0.1 # 格式：用户名@IP password: root admin: true # 是否是管理员 - user: sharding@% # 所有IP都可以访问 password: sharding privilege: type: DATABASE_PERMITTED # 权限类型 props: user-database-mappings: root@127.0.0.1=*,sharding@%=sharding_db # 用户权限映射，*表示所有数据库# 开启XA事务，如果是 springboot项目，只需要在方法上加上 @Transactional 注解即可开启事务(从 MySQL 5.7 开始就全面支持 XA 分布式事务)# https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/transaction: # 配置事务 defaultType: XA # 事务类型，默认 LOCAL providerType: Atomikos # 事务管理器具体实现，默认就是 Atomikos# 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/yaml-config/props/props: sql-show: true # 控制台打印改写后的 SQL，便于排错，默认为 false check-table-metadata-enabled: false # 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false conf/database-my.yaml: 自定义分配规则配置 注意: 1.名称必须以 database-开头，实际上conf目录下有很多示例，我们可以根据需要进行配置 2.global.yaml中的配置项不能配置到 database-my.yaml中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214# 数据库名称，默认值：logic_dbdatabaseName: sharding_db# 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/dataSources: ds_0: # 逻辑数据源名称 # dataSourceClassName: com.zaxxer.hikari.HikariDataSource # 不要指定 # driverClassName: com.mysql.cj.jdbc.Driver # 不要指定 url: jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 # 注意这里属性为 url username: root password: newpwd ds_1: # dataSourceClassName: com.zaxxer.hikari.HikariDataSource # driverClassName: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd# 以下规则与前文中的 shardingsphere-jdbc 中的 rules 相同# 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/rules: - !SHARDING # 分片规则配置 # 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致 bindingTables: - t_order,t_order_item tables: # 手工分片规则配置 course: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.course_$&#123;1..2&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: course_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: cid shardingAlgorithmName: course_inline keyGenerateStrategy: # 分布式序列策略 column: cid # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id shardingAlgorithmName: t_order-complex-algorithm keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id # 分片列名称,多个逗号分隔 shardingAlgorithmName: t_order_item-class-based-algorithm_spi # 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_user: actualDataNodes: ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_inline # 分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: id # 自增列名称，字符串类型 # keyGeneratorName: uuid # 分布式序列算法名称 keyGeneratorName: custom_snowflake_string # 分布式序列算法名称 # t_address: # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明 # actualDataNodes: ds_0.t_address # 实际数据节点 autoTables: # 自动分片规则配置 t_order: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/ course_inline: # 定义名称，在上面引用 type: INLINE # 基于行表达式的分片算法，这里使用 MOD 会报错 props: # 属性 algorithm-expression: course_$&#123;cid % 2 + 1&#125; # 表达式，这是因为表名称为 course_1, course_2 allow-range-query-with-inline-sharding: true # 允许范围查询 course_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; # 表示 ds_0, ds_1 mod_2: type: MOD # 基于 MOD 的分片算法 props: sharding-count: 2 # 分片数量，即 对 2 进行取余 t_order_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; t_order-complex-algorithm: type: COMPLEX_INLINE # 基于行表达式的复合分片算法 props: algorithm-expression: t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125; t_order_item-class-based-algorithm_spi: # SPI type: T_ORDER_ITEM_COMPLEX # 基于自定义类的分片算法 t_user_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;Math.abs(id.hashCode()%2)&#125; t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125; keyGenerators: # 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/ snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long uuid: # 定义名称 type: UUID # 字符串主键，String custom_snowflake_string: type: CUSTOM_SNOWFLAKE_STRING props: workerId: 2 datacenterId: 2 - !BROADCAST # 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个 tables: - dict # 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。 - !ENCRYPT # 数据加密配置 tables: t_user: # 加密表名称 columns: password: # 加密列名称 cipher: name: password # 密文列名称 encryptorName: aes_encryptor # 密文列加密算法名称 # 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/ encryptors: aes_encryptor: # 加解密算法名称 type: AES # 加解密算法类型 props: # 加解密算法属性配置 aes-key-value: 123456abc # AES 使用的 KEY digest-algorithm-name: SHA-1 # AES KEY 的摘要算法 md5_encryptor: type: MD5 props: salt: 123456 # 盐值（可选） - !MASK # 数据脱敏配置 tables: t_user: # 脱敏表名称 columns: # 脱敏列配置 password: # 脱敏列名称 maskAlgorithm: md5_mask # 脱敏算法名称 email: maskAlgorithm: mask_before_special_chars_mask telephone: maskAlgorithm: keep_first_n_last_m_mask name: maskAlgorithm: my_mask maskAlgorithms: # 脱敏算法配置 md5_mask: # 自定义脱敏算法名称 type: MD5 # 脱敏算法类型，md5加密后展示 mask_before_special_chars_mask: type: MASK_BEFORE_SPECIAL_CHARS # 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com props: special-chars: &#x27;@&#x27; # 遇到 @ 之前的部分做脱敏 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 keep_first_n_last_m_mask: type: KEEP_FIRST_N_LAST_M # 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678 props: first-n: 3 # 保留前 3 位 last-m: 4 # 保留后 4 位 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 my_mask: type: MY_CUSTOM_MASK # 自定义脱敏算法名称 props: replace-char: &quot;#&quot; - !SINGLE # 单表规则配置，单表规则优先级高于分库分表规则 tables: # MySQL 风格 - ds_0.t_address # 加载指定单表# - ds_1.* # 加载指定数据源中的全部单表# - &quot;*.*&quot; # 加载全部单表 上面的rules中使用的是mysql数据库，所以我们需要引入mysql数据库的依赖 1234cd apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/mkdir ext-libcd ext-libwget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.11/mysql-connector-java-8.0.11.jar 同时rules中包含一些自定义的算法，我们也需要将这些算法作为依赖进行引入，将这些算法类打成jar，然后也拷贝到ext-lib目录下，我已经将其发布到了github上，实际上和前文中的 shardingsphere-jdbc 项目中将算法配置为 spi 的方式是一致的。 123456789101112131415# 1. 只克隆仓库的基本信息，不下载所有文件git clone --filter=blob:none --sparse https://github.com/hanqunfeng/springbootchapter.git# 2. 进入仓库目录cd springbootchapter# 3. 设置只检出你需要的目录git sparse-checkout set springboot3-demo/shardingsphere-demo/algorithm-swapper# 4. 编译打包cd springboot3-demo/shardingsphere-demo/algorithm-swappermvn clean package -DskipTests# 5. 将打好的包复制到 shardingsphere-proxy 的 ext-lib 目录下cp target/algorithm-swapper-1.0.0.jar $shardingsphere-proxy$/ext-lib 启动与关闭 ShardingSphere Proxy ShardingSphere Proxy 要求 JDK 1.8 或以上版本 12345cd $shardingsphere-proxy$/bin# 启动./start.sh# 关闭./stop.sh 参数说明 参数 说明 默认值 -a 绑定地址，可以是 IPv4、IPv6 或主机名，多个地址用逗号分隔。 0.0.0.0 -p 绑定端口号，可以在 global.yaml 中修改。-p 优先级更高 3307 -c ShardingSphere-Proxy 配置目录路径。 conf -f 强制启动 ShardingSphere-Proxy。 无 -g 如果在 agent 目录下部署了 shardingsphere-agent，启用 agent 功能。 无 -s 指定用于连接的 socket 文件路径。 无 ShardingSphere-Proxy 启动命令速查表 场景 命令示例 说明 默认启动 ./start.sh 默认端口 3307，配置目录 conf 指定端口和配置目录 ./start.sh 3308 /opt/shardingsphere-proxy/conf 简写模式，指定端口和配置目录 参数形式启动 ./start.sh -p 3308 -c /opt/shardingsphere-proxy/conf 与上面等效，但更明确 指定监听地址 ./start.sh -a 192.168.1.100 -p 3307 -c conf 指定单个 IP 地址 指定多个监听地址 ./start.sh -a 192.168.1.100,127.0.0.1 -p 3307 -c conf 多个地址用逗号分隔 强制启动 ./start.sh -p 3307 -c conf -f 遇到残留 PID 文件时使用 启用 agent ./start.sh -p 3307 -c conf -g 启动 ShardingSphere-Agent 使用 Unix Socket ./start.sh -p 3307 -c conf -s /tmp/sharding-proxy.sock 通过 Socket 文件进行连接 多选项组合 ./start.sh -a 127.0.0.1 -p 3310 -c /opt/proxy/conf -f -g -s /tmp/proxy.sock 一次性指定多个选项 项目连接 ShardingSphere-Proxy 时，就像连接普通的 mysql 服务一样 示例项目：https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-proxy 后记 在 ShardingSphere-JDBC 和 ShardingSphere-Proxy 中，存在部分 MySQL(其它数据库也类似) 的 SQL 语法或功能目前还不完全支持的情况。ShardingSphere 在做 SQL 路由、改写、执行时，必须能解析 SQL 并理解其语义，但并不是 MySQL 的 100% 完全代理。因此，有些复杂或特定场景下的 SQL 可能无法被正确解析或执行。 支持良好的 SQL 语法 基础 DML SELECT、INSERT、UPDATE、DELETE 基本的条件查询、排序、分页、分组、聚合函数（如 COUNT、SUM、AVG） DCL 基本的事务语句：BEGIN、COMMIT、ROLLBACK DDL 部分表结构管理语句：CREATE TABLE、ALTER TABLE、DROP TABLE 函数支持 大部分常用的 MySQL 内置函数，如字符串、数学、日期函数 在 ShardingSphere + MySQL 下建议避免或谨慎使用的 SQL 清单 跨分片复杂查询 SQL 场景 原因 建议处理方式 多表复杂 JOIN（特别是跨分片） 需要跨库数据聚合，性能差，可能报错 使用广播表/绑定表，或在应用层完成 跨分片子查询 SQL 路由困难，可能不支持 尽量改成单表查询或分步查询 跨分片的 GROUP BY / ORDER BY 在 Proxy 层聚合，性能很差 尽量避免，或控制数据量 DDL 相关 SQL 场景 原因 建议处理方式 ALTER TABLE 复杂变更 需在所有分片执行，可能执行失败 手动在每个分片库执行 CREATE TRIGGER、PROCEDURE Proxy 不解析这些语法，直接透传不安全 尽量在单库手动创建 CREATE FUNCTION 同上 单库执行或应用层替代 FULLTEXT INDEX、SPATIAL INDEX 分片环境下无法自动维护索引 单库手动维护或避免使用 文件导入导出 SQL 场景 原因 建议处理方式 LOAD DATA INFILE Proxy 不支持文件系统直接访问 在分片库手动执行或通过应用导入 SELECT ... INTO OUTFILE 同上 应用层处理导出 MySQL 特有功能 功能 支持情况 建议 MySQL 8.0 公共表表达式（CTE） 部分支持 避免跨分片使用 窗口函数（OVER() PARTITION BY） 部分支持 避免跨分片大数据量使用 JSON 函数 基本支持 单表场景可用，跨分片需谨慎 分布式事务 场景 问题原因 建议处理方式 跨分片原生事务 MySQL 原生事务不支持跨库 使用 ShardingSphere XA / BASE 大事务 + 分布式事务 性能开销大 尽量控制事务范围","summary":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-Proxy5.5.2 分库分表的使用。 ShardingSphere官网 本文项目代码Github地址 本文将 SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表 修改为 ShardingSphere-Proxy 的模式","date_published":"2025-09-04T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/09/01/springboot3-shardingsphere/","url":"https://blog.hanqunfeng.com/2025/09/01/springboot3-shardingsphere/","title":"SpringBoot3 + ShardingSphere-JDBC5.5.2 分库分表","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 SpringBoot3.5.5 + ShardingSphere-JDBC5.5.2 分库分表的使用。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://shardingsphere.apache.org/index_zh.html\">ShardingSphere官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/hanqunfeng/springbootchapter/tree/master/springboot3-demo/shardingsphere-demo/shardingsphere-demo-01\">本文项目代码Github地址</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"ShardingSphere-JDBC-简介\">ShardingSphere-JDBC 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。</p>\n<ul class=\"lvl-2\">\n<li class=\"lvl-4\">适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC；</li>\n<li class=\"lvl-4\">支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, HikariCP 等；</li>\n<li class=\"lvl-4\">支持任意实现 JDBC 规范的数据库，目前支持 MySQL，PostgreSQL，Oracle，SQLServer 以及任何可使用 JDBC 访问的数据库。</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>ShardingSphere-JDBC 独立部署架构图<br>\n<img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/RgXClY.png\" alt=\"\"></p>\n</li>\n</ul>\n<h2 id=\"maven依赖\">maven依赖</h2>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- 本项目 基于 mysql --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.mysql<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mysql-connector-j<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>runtime<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- mybatis plus，本项目用到，非必须 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.baomidou<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>mybatis-plus-spring-boot3-starter<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.5.12<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.shardingsphere<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>shardingsphere-jdbc<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>5.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"application-yml\">application.yml</h2>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">spring:</span></span><br><span class=\"line\">  <span class=\"attr\">datasource:</span></span><br><span class=\"line\">    <span class=\"attr\">driver-class-name:</span> <span class=\"string\">org.apache.shardingsphere.driver.ShardingSphereDriver</span></span><br><span class=\"line\">    <span class=\"comment\"># 指向类路径下的 sharding.yaml（也可 absolute path / file: / http: 等，见官方说明）</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:shardingsphere:classpath:sharding.yaml</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>也可以不在 <code>application.yml</code> 中配置，而是通过 <code>@Configuration</code> 创建 <code>@Bean</code>，这样就可以配置多数据源了。</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">DataSourceConfig</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Bean(name = &quot;shardingDataSource&quot;)</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> DataSource <span class=\"title function_\">shardingDataSource</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> SQLException, IOException &#123;</span><br><span class=\"line\">        <span class=\"comment\">// ShardingSphere 提供的工厂方法，根据配置构建 DataSource</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> (<span class=\"type\">InputStream</span> <span class=\"variable\">inputStream</span> <span class=\"operator\">=</span> getClass().getClassLoader().getResourceAsStream(<span class=\"string\">&quot;sharding.yaml&quot;</span>)) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (inputStream == <span class=\"literal\">null</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"title class_\">IllegalStateException</span>(<span class=\"string\">&quot;Cannot find sharding.yaml in classpath&quot;</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"type\">byte</span>[] yamlBytes = inputStream.readAllBytes();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> YamlShardingSphereDataSourceFactory.createDataSource(yamlBytes);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"sharding-yaml\">sharding.yaml</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>完整配置，下文会介绍部分配置</p>\n</li>\n</ul>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/</span></span><br><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.zaxxer.hikari.HikariDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">jdbcUrl:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.zaxxer.hikari.HikariDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">jdbcUrl:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"comment\"># 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致</span></span><br><span class=\"line\">    <span class=\"attr\">bindingTables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">t_order,t_order_item</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">course:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">cid</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_inline</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">cid</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order-complex-algorithm</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span>  <span class=\"comment\"># 分片列名称,多个逗号分隔</span></span><br><span class=\"line\"><span class=\"comment\">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_item-class-based-algorithm_spi</span> <span class=\"comment\"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span>  <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">id</span> <span class=\"comment\"># 自增列名称，字符串类型</span></span><br><span class=\"line\"><span class=\"comment\">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">custom_snowflake_string</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#       t_address:      # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明</span></span><br><span class=\"line\"><span class=\"comment\">#         actualDataNodes: ds_0.t_address # 实际数据节点</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">autoTables:</span> <span class=\"comment\"># 自动分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/</span></span><br><span class=\"line\">      <span class=\"attr\">course_inline:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span> <span class=\"comment\"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 属性</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">course_$&#123;cid</span> <span class=\"string\">%</span> <span class=\"number\">2</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class=\"line\">          <span class=\"attr\">allow-range-query-with-inline-sharding:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 允许范围查询</span></span><br><span class=\"line\">      <span class=\"attr\">course_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表示 ds_0, ds_1</span></span><br><span class=\"line\">      <span class=\"attr\">mod_2:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MOD</span> <span class=\"comment\"># 基于 MOD 的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">sharding-count:</span> <span class=\"number\">2</span> <span class=\"comment\"># 分片数量，即 对 2 进行取余</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order-complex-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">COMPLEX_INLINE</span> <span class=\"comment\"># 基于行表达式的复合分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_order_complex_$&#123;(user_id</span> <span class=\"string\">+</span> <span class=\"string\">order_id</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">)</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CLASS_BASED</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">strategy:</span> <span class=\"string\">COMPLEX</span> <span class=\"comment\"># 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略</span></span><br><span class=\"line\">          <span class=\"attr\">algorithmClassName:</span> <span class=\"string\">com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm</span> <span class=\"comment\"># 指定算法类</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm_spi:</span> <span class=\"comment\"># SPI</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">T_ORDER_ITEM_COMPLEX</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br><span class=\"line\">      <span class=\"attr\">uuid:</span>    <span class=\"comment\"># 定义名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">UUID</span> <span class=\"comment\"># 字符串主键，String</span></span><br><span class=\"line\">      <span class=\"attr\">custom_snowflake_string:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CUSTOM_SNOWFLAKE_STRING</span>  <span class=\"comment\"># 自定义雪花算法，String</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">workerId:</span> <span class=\"number\">2</span></span><br><span class=\"line\">          <span class=\"attr\">datacenterId:</span> <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!BROADCAST</span>  <span class=\"comment\"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">dict</span>    <span class=\"comment\"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!ENCRYPT</span>    <span class=\"comment\"># 数据加密配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 加密表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 加密列名称</span></span><br><span class=\"line\">            <span class=\"attr\">cipher:</span></span><br><span class=\"line\">              <span class=\"attr\">name:</span> <span class=\"string\">password</span> <span class=\"comment\"># 密文列名称</span></span><br><span class=\"line\">              <span class=\"attr\">encryptorName:</span> <span class=\"string\">aes_encryptor</span> <span class=\"comment\"># 密文列加密算法名称</span></span><br><span class=\"line\">    <span class=\"comment\"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class=\"line\">    <span class=\"attr\">encryptors:</span></span><br><span class=\"line\">      <span class=\"attr\">aes_encryptor:</span> <span class=\"comment\"># 加解密算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">AES</span> <span class=\"comment\"># 加解密算法类型</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 加解密算法属性配置</span></span><br><span class=\"line\">          <span class=\"attr\">aes-key-value:</span> <span class=\"string\">123456abc</span>     <span class=\"comment\"># AES 使用的 KEY</span></span><br><span class=\"line\">          <span class=\"attr\">digest-algorithm-name:</span> <span class=\"string\">SHA-1</span> <span class=\"comment\"># AES KEY 的摘要算法</span></span><br><span class=\"line\">      <span class=\"attr\">md5_encryptor:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">salt:</span> <span class=\"number\">123456</span>  <span class=\"comment\"># 盐值（可选）</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!MASK</span>  <span class=\"comment\"># 数据脱敏配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 脱敏表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span>  <span class=\"comment\"># 脱敏列配置</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 脱敏列名称</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">md5_mask</span> <span class=\"comment\"># 脱敏算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">email:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">mask_before_special_chars_mask</span></span><br><span class=\"line\">          <span class=\"attr\">telephone:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">keep_first_n_last_m_mask</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">my_mask</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">maskAlgorithms:</span> <span class=\"comment\"># 脱敏算法配置</span></span><br><span class=\"line\">      <span class=\"attr\">md5_mask:</span> <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span>  <span class=\"comment\"># 脱敏算法类型，md5加密后展示</span></span><br><span class=\"line\">      <span class=\"attr\">mask_before_special_chars_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MASK_BEFORE_SPECIAL_CHARS</span> <span class=\"comment\"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">special-chars:</span> <span class=\"string\">&#x27;@&#x27;</span>  <span class=\"comment\"># 遇到 @ 之前的部分做脱敏</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span>   <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">keep_first_n_last_m_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">KEEP_FIRST_N_LAST_M</span> <span class=\"comment\"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">first-n:</span> <span class=\"number\">3</span>     <span class=\"comment\"># 保留前 3 位</span></span><br><span class=\"line\">          <span class=\"attr\">last-m:</span> <span class=\"number\">4</span>      <span class=\"comment\"># 保留后 4 位</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span> <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">my_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MY_CUSTOM_MASK</span>  <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&quot;#&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SINGLE</span> <span class=\"comment\"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"comment\"># MySQL 风格</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">ds_0.t_address</span> <span class=\"comment\"># 加载指定单表</span></span><br><span class=\"line\"><span class=\"comment\">#       - ds_1.* # 加载指定数据源中的全部单表</span></span><br><span class=\"line\"><span class=\"comment\">#       - &quot;*.*&quot; # 加载全部单表</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/</span></span><br><span class=\"line\"><span class=\"attr\">props:</span></span><br><span class=\"line\">  <span class=\"attr\">sql-show:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class=\"line\">  <span class=\"attr\">check-table-metadata-enabled:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"数据源配置\">数据源配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>hikari + mysql</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.zaxxer.hikari.HikariDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">jdbcUrl:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.zaxxer.hikari.HikariDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">jdbcUrl:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>druid + mysql</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_1:</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.mysql.cj.jdbc.Driver</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\">    <span class=\"comment\"># Druid 特有配置</span></span><br><span class=\"line\">    <span class=\"attr\">initialSize:</span> <span class=\"number\">5</span></span><br><span class=\"line\">    <span class=\"attr\">minIdle:</span> <span class=\"number\">5</span></span><br><span class=\"line\">    <span class=\"attr\">maxActive:</span> <span class=\"number\">20</span></span><br><span class=\"line\">    <span class=\"attr\">maxWait:</span> <span class=\"number\">60000</span></span><br><span class=\"line\">    <span class=\"attr\">testWhileIdle:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">validationQuery:</span> <span class=\"string\">SELECT</span> <span class=\"number\">1</span> <span class=\"string\">FROM</span> <span class=\"string\">DUAL</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>druid + mysql + p6spy</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">dataSources:</span></span><br><span class=\"line\">  <span class=\"attr\">ds_0:</span> <span class=\"comment\"># 逻辑数据源名称</span></span><br><span class=\"line\">    <span class=\"attr\">dataSourceClassName:</span> <span class=\"string\">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class=\"line\">    <span class=\"attr\">driverClassName:</span> <span class=\"string\">com.p6spy.engine.spy.P6SpyDriver</span></span><br><span class=\"line\">    <span class=\"attr\">url:</span> <span class=\"string\">jdbc:p6spy:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC</span></span><br><span class=\"line\">    <span class=\"attr\">username:</span> <span class=\"string\">root</span></span><br><span class=\"line\">    <span class=\"attr\">password:</span> <span class=\"string\">newpwd</span></span><br><span class=\"line\">    <span class=\"comment\"># Druid 特有配置</span></span><br><span class=\"line\">    <span class=\"attr\">initialSize:</span> <span class=\"number\">5</span></span><br><span class=\"line\">    <span class=\"attr\">minIdle:</span> <span class=\"number\">5</span></span><br><span class=\"line\">    <span class=\"attr\">maxActive:</span> <span class=\"number\">20</span></span><br><span class=\"line\">    <span class=\"attr\">maxWait:</span> <span class=\"number\">60000</span></span><br><span class=\"line\">    <span class=\"attr\">testWhileIdle:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">validationQuery:</span> <span class=\"string\">SELECT</span> <span class=\"number\">1</span> <span class=\"string\">FROM</span> <span class=\"string\">DUAL</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"分库分表配置\">分库分表配置</h3>\n<h4 id=\"单分片键，Long-类型\">单分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">course:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.course_$&#123;1..2&#125;</span> <span class=\"comment\"># 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">cid</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">course_inline</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">cid</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">course_inline:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span> <span class=\"comment\"># 基于行表达式的分片算法，这里使用 MOD 会报错</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 属性</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">course_$&#123;cid</span> <span class=\"string\">%</span> <span class=\"number\">2</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表达式，这是因为表名称为 course_1, course_2</span></span><br><span class=\"line\">          <span class=\"attr\">allow-range-query-with-inline-sharding:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 允许范围查询</span></span><br><span class=\"line\">      <span class=\"attr\">course_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span> <span class=\"comment\"># 表示 ds_0, ds_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里分库与分表采用了不同的字段，分库使用 user_id，分表使用 cid</p>\n</li>\n<li class=\"lvl-2\">\n<p>allow-range-query-with-inline-sharding: true ，这里设置为允许范围查询，默认值是 false，不允许 between 查询</p>\n</li>\n</ul>\n<h4 id=\"单分片键，String-类型\">单分片键，String 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">id</span>  <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_user_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">id</span> <span class=\"comment\"># 自增列名称，字符串类型</span></span><br><span class=\"line\"><span class=\"comment\">#           keyGeneratorName: uuid # 分布式序列算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">custom_snowflake_string</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;Math.abs(id.hashCode()%2)&#125;</span> <span class=\"comment\"># 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算</span></span><br><span class=\"line\">      <span class=\"attr\">t_user_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125;</span> <span class=\"comment\"># 分表，t_user_0, t_user_1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式序列算法</span></span><br><span class=\"line\">      <span class=\"attr\">uuid:</span>    <span class=\"comment\"># 定义名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">UUID</span> <span class=\"comment\"># 字符串主键，String</span></span><br><span class=\"line\">      <span class=\"attr\">custom_snowflake_string:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CUSTOM_SNOWFLAKE_STRING</span> <span class=\"comment\"># 自定义雪花算法，String，spi</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">workerId:</span> <span class=\"number\">2</span></span><br><span class=\"line\">          <span class=\"attr\">datacenterId:</span> <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>这里分库与分表采用了相同的字段，即主键id，因其为字符串类型，所以需要使用 hashCode() 获取数字，再进行运算</p>\n</li>\n<li class=\"lvl-2\">\n<p>主键获取规则使用的自定义的雪花算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.infra.algorithm.keygen.core.KeyGenerateAlgorithm</code>，这里注意，从 <code>5.5.3</code> 开始会更换为 <code>org.apache.shardingsphere.infra.algorithm.keygen.spi.KeyGenerateAlgorithm</code></p>\n</li>\n</ul>\n<h4 id=\"多分片键，Long-类型\">多分片键，Long 类型</h4>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span> <span class=\"comment\"># 手工分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order-complex-algorithm</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item_complex:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataNodes:</span> <span class=\"string\">ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125;</span> <span class=\"comment\"># 实际数据节点</span></span><br><span class=\"line\">        <span class=\"attr\">databaseStrategy:</span> <span class=\"comment\"># 分库策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_db_inline</span> <span class=\"comment\"># 分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">tableStrategy:</span> <span class=\"comment\"># 分表策略</span></span><br><span class=\"line\">          <span class=\"attr\">complex:</span> <span class=\"comment\"># 用于多分片键的复杂分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumns:</span> <span class=\"string\">user_id,order_id</span>  <span class=\"comment\"># 分片列名称,多个逗号分隔</span></span><br><span class=\"line\"><span class=\"comment\">#             shardingAlgorithmName: t_order_item-class-based-algorithm   # 基于自定义类的分片算法</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">t_order_item-class-based-algorithm_spi</span> <span class=\"comment\"># 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_db_inline:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">INLINE</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">ds_$&#123;user_id</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order-complex-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">COMPLEX_INLINE</span> <span class=\"comment\"># 基于行表达式的复合分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">algorithm-expression:</span> <span class=\"string\">t_order_complex_$&#123;(user_id</span> <span class=\"string\">+</span> <span class=\"string\">order_id</span> <span class=\"string\">+</span> <span class=\"number\">1</span><span class=\"string\">)</span> <span class=\"string\">%</span> <span class=\"number\">2</span><span class=\"string\">&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">CLASS_BASED</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">strategy:</span> <span class=\"string\">COMPLEX</span> <span class=\"comment\"># 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略</span></span><br><span class=\"line\">          <span class=\"attr\">algorithmClassName:</span> <span class=\"string\">com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm</span> <span class=\"comment\"># 指定算法类</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item-class-based-algorithm_spi:</span> <span class=\"comment\"># SPI</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">T_ORDER_ITEM_COMPLEX</span> <span class=\"comment\"># 基于自定义类的分片算法</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>多个分片键，<code>t_order_complex</code>表使用了内置的<code>COMPLEX_INLINE</code>算法，而<code>t_order_item_complex</code>表使用了自定义的的分片算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.sharding.spi.ShardingAlgorithm</code></p>\n</li>\n</ul>\n<h4 id=\"自动分片规则\">自动分片规则</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SHARDING</span> <span class=\"comment\"># 分片规则配置</span></span><br><span class=\"line\">   <span class=\"comment\"># 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致</span></span><br><span class=\"line\">    <span class=\"attr\">bindingTables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">t_order,t_order_item</span></span><br><span class=\"line\">    <span class=\"attr\">autoTables:</span> <span class=\"comment\"># 自动分片规则配置</span></span><br><span class=\"line\">      <span class=\"attr\">t_order:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">order_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\">      <span class=\"attr\">t_order_item:</span> <span class=\"comment\"># 逻辑表名称</span></span><br><span class=\"line\">        <span class=\"attr\">actualDataSources:</span> <span class=\"string\">ds_$&#123;0..1&#125;</span> <span class=\"comment\"># 数据源名称</span></span><br><span class=\"line\">        <span class=\"attr\">shardingStrategy:</span> <span class=\"comment\"># 切分策略</span></span><br><span class=\"line\">          <span class=\"attr\">standard:</span> <span class=\"comment\"># 用于单分片键的标准分片场景</span></span><br><span class=\"line\">            <span class=\"attr\">shardingColumn:</span> <span class=\"string\">user_id</span> <span class=\"comment\"># 分片列名称</span></span><br><span class=\"line\">            <span class=\"attr\">shardingAlgorithmName:</span> <span class=\"string\">mod_2</span> <span class=\"comment\"># 自动分片算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">keyGenerateStrategy:</span> <span class=\"comment\"># 分布式序列策略</span></span><br><span class=\"line\">          <span class=\"attr\">column:</span> <span class=\"string\">item_id</span> <span class=\"comment\"># 自增列名称</span></span><br><span class=\"line\">          <span class=\"attr\">keyGeneratorName:</span> <span class=\"string\">snowflake</span> <span class=\"comment\"># 分布式序列算法名称</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">shardingAlgorithms:</span> <span class=\"comment\"># 分片算法</span></span><br><span class=\"line\">      <span class=\"attr\">mod_2:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MOD</span> <span class=\"comment\"># 基于 MOD 的分片算法</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">sharding-count:</span> <span class=\"number\">2</span> <span class=\"comment\"># 分片数量，即 对 2 进行取余</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">keyGenerators:</span> <span class=\"comment\"># 分布式主键生成器</span></span><br><span class=\"line\">      <span class=\"attr\">snowflake:</span> <span class=\"comment\"># 定义名称，在上面引用</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">SNOWFLAKE</span> <span class=\"comment\"># 使用雪花算法，Long</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>自动分片规则需要声明数据库，但不需要声明表分配规则，其根据分片算法自动确定具体的数据表。</p>\n</li>\n<li class=\"lvl-2\">\n<p>同时这里还配置了<code>bindingTables</code>，用来指定其分片路由一致。</p>\n</li>\n</ul>\n<h3 id=\"广播表配置\">广播表配置</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>广播表，即所有数据源都包含的表，比如字典表</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!BROADCAST</span>  <span class=\"comment\"># 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">dict</span>    <span class=\"comment\"># 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"数据加密规则\">数据加密规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!ENCRYPT</span>    <span class=\"comment\"># 数据加密配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 加密表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 加密列名称</span></span><br><span class=\"line\">            <span class=\"attr\">cipher:</span></span><br><span class=\"line\">              <span class=\"attr\">name:</span> <span class=\"string\">password</span> <span class=\"comment\"># 密文列名称</span></span><br><span class=\"line\">              <span class=\"attr\">encryptorName:</span> <span class=\"string\">aes_encryptor</span> <span class=\"comment\"># 密文列加密算法名称</span></span><br><span class=\"line\">    <span class=\"comment\"># 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/</span></span><br><span class=\"line\">    <span class=\"attr\">encryptors:</span></span><br><span class=\"line\">      <span class=\"attr\">aes_encryptor:</span> <span class=\"comment\"># 加解密算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">AES</span> <span class=\"comment\"># 加解密算法类型</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span> <span class=\"comment\"># 加解密算法属性配置</span></span><br><span class=\"line\">          <span class=\"attr\">aes-key-value:</span> <span class=\"string\">123456abc</span>     <span class=\"comment\"># AES 使用的 KEY</span></span><br><span class=\"line\">          <span class=\"attr\">digest-algorithm-name:</span> <span class=\"string\">SHA-1</span> <span class=\"comment\"># AES KEY 的摘要算法</span></span><br><span class=\"line\">      <span class=\"attr\">md5_encryptor:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">salt:</span> <span class=\"number\">123456</span>  <span class=\"comment\"># 盐值（可选）</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>配置加密字段规则后，新增数据时，会自动对加密字段加密后存储，查询时也会加密后进行比较查询。</p>\n</li>\n</ul>\n<h3 id=\"数据脱敏规则\">数据脱敏规则</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!MASK</span>  <span class=\"comment\"># 数据脱敏配置</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"attr\">t_user:</span>  <span class=\"comment\"># 脱敏表名称</span></span><br><span class=\"line\">        <span class=\"attr\">columns:</span>  <span class=\"comment\"># 脱敏列配置</span></span><br><span class=\"line\">          <span class=\"attr\">password:</span> <span class=\"comment\"># 脱敏列名称</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">md5_mask</span> <span class=\"comment\"># 脱敏算法名称</span></span><br><span class=\"line\">          <span class=\"attr\">email:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">mask_before_special_chars_mask</span></span><br><span class=\"line\">          <span class=\"attr\">telephone:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">keep_first_n_last_m_mask</span></span><br><span class=\"line\">          <span class=\"attr\">name:</span></span><br><span class=\"line\">            <span class=\"attr\">maskAlgorithm:</span> <span class=\"string\">my_mask</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attr\">maskAlgorithms:</span> <span class=\"comment\"># 脱敏算法配置</span></span><br><span class=\"line\">      <span class=\"attr\">md5_mask:</span> <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MD5</span>  <span class=\"comment\"># 脱敏算法类型，md5加密后展示</span></span><br><span class=\"line\">      <span class=\"attr\">mask_before_special_chars_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MASK_BEFORE_SPECIAL_CHARS</span> <span class=\"comment\"># 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">special-chars:</span> <span class=\"string\">&#x27;@&#x27;</span>  <span class=\"comment\"># 遇到 @ 之前的部分做脱敏</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span>   <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">keep_first_n_last_m_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">KEEP_FIRST_N_LAST_M</span> <span class=\"comment\"># 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">first-n:</span> <span class=\"number\">3</span>     <span class=\"comment\"># 保留前 3 位</span></span><br><span class=\"line\">          <span class=\"attr\">last-m:</span> <span class=\"number\">4</span>      <span class=\"comment\"># 保留后 4 位</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&#x27;*&#x27;</span> <span class=\"comment\"># 脱敏字符用 * 代替</span></span><br><span class=\"line\">      <span class=\"attr\">my_mask:</span></span><br><span class=\"line\">        <span class=\"attr\">type:</span> <span class=\"string\">MY_CUSTOM_MASK</span>  <span class=\"comment\"># 自定义脱敏算法名称</span></span><br><span class=\"line\">        <span class=\"attr\">props:</span></span><br><span class=\"line\">          <span class=\"attr\">replace-char:</span> <span class=\"string\">&quot;#&quot;</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>被脱敏的字段在查询时会进行脱敏展示。</p>\n</li>\n<li class=\"lvl-2\">\n<p>这里还自定义了脱敏算法，spi，详见<code>src/main/resources/META-INF/services/org.apache.shardingsphere.mask.spi.MaskAlgorithm</code></p>\n</li>\n</ul>\n<h3 id=\"单表规则\">单表规则</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>即不需要进行分库分表的表</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"type\">!SINGLE</span> <span class=\"comment\"># 单表规则配置，单表规则优先级高于分库分表规则</span></span><br><span class=\"line\">    <span class=\"attr\">tables:</span></span><br><span class=\"line\">      <span class=\"comment\"># MySQL 风格</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">ds_0.t_address</span> <span class=\"comment\"># 加载指定单表</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"属性配置\">属性配置</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/</span></span><br><span class=\"line\"><span class=\"attr\">props:</span></span><br><span class=\"line\">  <span class=\"attr\">sql-show:</span> <span class=\"literal\">true</span> <span class=\"comment\"># 控制台打印改写后的 SQL，便于排错，默认为 false</span></span><br><span class=\"line\">  <span class=\"attr\">check-table-metadata-enabled:</span> <span class=\"literal\">false</span> <span class=\"comment\"># 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"事务配置\">事务配置</h3>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/</span></span><br><span class=\"line\"><span class=\"attr\">transaction:</span></span><br><span class=\"line\">  <span class=\"attr\">defaultType:</span> <span class=\"string\">LOCAL</span> <span class=\"comment\"># 默认事务类型就是 LOCAL</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"后记\">后记</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>springboot3 集成 shardingsphere-JDBC5.5.2 与 springboot2 不同，不再提供 <code>springboot-starter-shardingsphere</code>，相关配置也采用了独立的配置文件。</p>\n</li>\n<li class=\"lvl-2\">\n<p>代码中包含两个库中使用到的数据库脚本，<code>shardingsphere-demo/shardingsphere-demo-01/sql</code></p>\n</li>\n<li class=\"lvl-2\">\n<p>具体使用效果可以通过项目中提供的单元测试类进行验证。</p>\n</li>\n<li class=\"lvl-2\">\n<p>springboot3 集成 shardingsphere-JDBC5.5.2 目前<a href=\"https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/jdbc-driver/spring-boot/\">尚不支持 <code>XA</code> 分布式事务</a>，这是因为从 <code>Spring Boot 3.x</code> 开始，就全面迁移到了 <code>Jakarta EE 9+</code>，也就是说，所有 <code>javax.*</code> 的类都迁移到 <code>jakarta.*</code> 命名空间(事务、JPA、Servlet 等 API 都受影响)，而 <code>ShardingSphere 5.5</code> 中的 XA 事务主要依赖 <code>Atomikos</code> 或 <code>Narayana</code> 等第三方分布式事务管理器，这些库目前大部分还是基于 <code>javax.transaction.*</code> 的 API。</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-JDBC5.5.2 分库分表的使用。 ShardingSphere官网 本文项目代码Github地址 ShardingSphere-JDBC 简介 ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。 适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC； 支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, HikariCP 等； 支持任意实现 JDBC 规范的数据库，目前支持 MySQL，PostgreSQL，Oracle，SQLServer 以及任何可使用 JDBC 访问的数据库。 ShardingSphere-JDBC 独立部署架构图 maven依赖 123456789101112131415161718&lt;!-- 本项目 基于 mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mybatis plus，本项目用到，非必须 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- ShardingSphere JDBC 主依赖（5.5.2 建议） --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc&lt;/artifactId&gt; &lt;version&gt;5.5.2&lt;/version&gt;&lt;/dependency&gt; application.yml 12345spring: datasource: driver-class-name: org.apache.shardingsphere.driver.ShardingSphereDriver # 指向类路径下的 sharding.yaml（也可 absolute path / file: / http: 等，见官方说明） url: jdbc:shardingsphere:classpath:sharding.yaml 也可以不在 application.yml 中配置，而是通过 @Configuration 创建 @Bean，这样就可以配置多数据源了。 123456789101112131415@Configurationpublic class DataSourceConfig &#123; @Bean(name = &quot;shardingDataSource&quot;) public DataSource shardingDataSource() throws SQLException, IOException &#123; // ShardingSphere 提供的工厂方法，根据配置构建 DataSource try (InputStream inputStream = getClass().getClassLoader().getResourceAsStream(&quot;sharding.yaml&quot;)) &#123; if (inputStream == null) &#123; throw new IllegalStateException(&quot;Cannot find sharding.yaml in classpath&quot;); &#125; byte[] yamlBytes = inputStream.readAllBytes(); return YamlShardingSphereDataSourceFactory.createDataSource(yamlBytes); &#125; &#125;&#125; sharding.yaml 完整配置，下文会介绍部分配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221# 数据源配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/data-source/dataSources: ds_0: # 逻辑数据源名称 dataSourceClassName: com.zaxxer.hikari.HikariDataSource driverClassName: com.mysql.cj.jdbc.Driver jdbcUrl: jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd ds_1: dataSourceClassName: com.zaxxer.hikari.HikariDataSource driverClassName: com.mysql.cj.jdbc.Driver jdbcUrl: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd# 分片规则配置: https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/sharding/rules: - !SHARDING # 分片规则配置 # 绑定表：同分片键 join 时走同路由，减少广播,多个逗号分隔，要求分片规则一致 bindingTables: - t_order,t_order_item tables: # 手工分片规则配置 course: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.course_$&#123;1..2&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: course_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: cid shardingAlgorithmName: course_inline keyGenerateStrategy: # 分布式序列策略 column: cid # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id shardingAlgorithmName: t_order-complex-algorithm keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id # 分片列名称,多个逗号分隔# shardingAlgorithmName: t_order_item-class-based-algorithm # 基于自定义类的分片算法 shardingAlgorithmName: t_order_item-class-based-algorithm_spi # 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_user: actualDataNodes: ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_inline # 分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: id # 自增列名称，字符串类型# keyGeneratorName: uuid # 分布式序列算法名称 keyGeneratorName: custom_snowflake_string # 分布式序列算法名称# t_address: # 普通表（不分库分表，绑定到 ds_0）,没有默认的数据源配置，所以每个都要显示声明# actualDataNodes: ds_0.t_address # 实际数据节点 autoTables: # 自动分片规则配置 t_order: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/ course_inline: # 定义名称，在上面引用 type: INLINE # 基于行表达式的分片算法，这里使用 MOD 会报错 props: # 属性 algorithm-expression: course_$&#123;cid % 2 + 1&#125; # 表达式，这是因为表名称为 course_1, course_2 allow-range-query-with-inline-sharding: true # 允许范围查询 course_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; # 表示 ds_0, ds_1 mod_2: type: MOD # 基于 MOD 的分片算法 props: sharding-count: 2 # 分片数量，即 对 2 进行取余 t_order_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; t_order-complex-algorithm: type: COMPLEX_INLINE # 基于行表达式的复合分片算法 props: algorithm-expression: t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125; t_order_item-class-based-algorithm: type: CLASS_BASED # 基于自定义类的分片算法 props: strategy: COMPLEX # 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略 algorithmClassName: com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm # 指定算法类 t_order_item-class-based-algorithm_spi: # SPI type: T_ORDER_ITEM_COMPLEX # 基于自定义类的分片算法 t_user_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;Math.abs(id.hashCode()%2)&#125; t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125; keyGenerators: # 分布式主键生成器: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/ snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long uuid: # 定义名称 type: UUID # 字符串主键，String custom_snowflake_string: type: CUSTOM_SNOWFLAKE_STRING # 自定义雪花算法，String props: workerId: 2 datacenterId: 2 - !BROADCAST # 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个 tables: - dict # 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。 - !ENCRYPT # 数据加密配置 tables: t_user: # 加密表名称 columns: password: # 加密列名称 cipher: name: password # 密文列名称 encryptorName: aes_encryptor # 密文列加密算法名称 # 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/ encryptors: aes_encryptor: # 加解密算法名称 type: AES # 加解密算法类型 props: # 加解密算法属性配置 aes-key-value: 123456abc # AES 使用的 KEY digest-algorithm-name: SHA-1 # AES KEY 的摘要算法 md5_encryptor: type: MD5 props: salt: 123456 # 盐值（可选） - !MASK # 数据脱敏配置 tables: t_user: # 脱敏表名称 columns: # 脱敏列配置 password: # 脱敏列名称 maskAlgorithm: md5_mask # 脱敏算法名称 email: maskAlgorithm: mask_before_special_chars_mask telephone: maskAlgorithm: keep_first_n_last_m_mask name: maskAlgorithm: my_mask maskAlgorithms: # 脱敏算法配置 md5_mask: # 自定义脱敏算法名称 type: MD5 # 脱敏算法类型，md5加密后展示 mask_before_special_chars_mask: type: MASK_BEFORE_SPECIAL_CHARS # 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com props: special-chars: &#x27;@&#x27; # 遇到 @ 之前的部分做脱敏 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 keep_first_n_last_m_mask: type: KEEP_FIRST_N_LAST_M # 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678 props: first-n: 3 # 保留前 3 位 last-m: 4 # 保留后 4 位 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 my_mask: type: MY_CUSTOM_MASK # 自定义脱敏算法名称 props: replace-char: &quot;#&quot; - !SINGLE # 单表规则配置，单表规则优先级高于分库分表规则 tables: # MySQL 风格 - ds_0.t_address # 加载指定单表# - ds_1.* # 加载指定数据源中的全部单表# - &quot;*.*&quot; # 加载全部单表# 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/props: sql-show: true # 控制台打印改写后的 SQL，便于排错，默认为 false check-table-metadata-enabled: false # 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false 数据源配置 hikari + mysql 1234567891011121314dataSources: ds_0: # 逻辑数据源名称 dataSourceClassName: com.zaxxer.hikari.HikariDataSource driverClassName: com.mysql.cj.jdbc.Driver jdbcUrl: jdbc:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd ds_1: dataSourceClassName: com.zaxxer.hikari.HikariDataSource driverClassName: com.mysql.cj.jdbc.Driver jdbcUrl: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: newpwd druid + mysql 1234567891011121314dataSources: ds_1: dataSourceClassName: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/shardingdb1?useSSL=false&amp;serverTimezone=UTC username: root password: newpwd # Druid 特有配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 testWhileIdle: true validationQuery: SELECT 1 FROM DUAL druid + mysql + p6spy 1234567891011121314dataSources: ds_0: # 逻辑数据源名称 dataSourceClassName: com.alibaba.druid.pool.DruidDataSource driverClassName: com.p6spy.engine.spy.P6SpyDriver url: jdbc:p6spy:mysql://127.0.0.1:3306/shardingdb0?useSSL=false&amp;serverTimezone=UTC username: root password: newpwd # Druid 特有配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 testWhileIdle: true validationQuery: SELECT 1 FROM DUAL 分库分表配置 单分片键，Long 类型 12345678910111213141516171819202122232425262728293031rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 course: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.course_$&#123;1..2&#125; # 实际数据节点，建表时写成了 1和2，懒得改了，所以下面分表规则中对2取余后要+1 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: course_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: cid shardingAlgorithmName: course_inline keyGenerateStrategy: # 分布式序列策略 column: cid # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 course_inline: # 定义名称，在上面引用 type: INLINE # 基于行表达式的分片算法，这里使用 MOD 会报错 props: # 属性 algorithm-expression: course_$&#123;cid % 2 + 1&#125; # 表达式，这是因为表名称为 course_1, course_2 allow-range-query-with-inline-sharding: true # 允许范围查询 course_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; # 表示 ds_0, ds_1 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long 这里分库与分表采用了不同的字段，分库使用 user_id，分表使用 cid allow-range-query-with-inline-sharding: true ，这里设置为允许范围查询，默认值是 false，不允许 between 查询 单分片键，String 类型 123456789101112131415161718192021222324252627282930313233343536rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_user: actualDataNodes: ds_$&#123;0..1&#125;.t_user_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_db_inline # 分片算法名称 tableStrategy: # 分表策略 standard: shardingColumn: id # 分片列名称 shardingAlgorithmName: t_user_inline # 分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: id # 自增列名称，字符串类型# keyGeneratorName: uuid # 分布式序列算法名称 keyGeneratorName: custom_snowflake_string # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_user_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;Math.abs(id.hashCode()%2)&#125; # 分库，ds_0, ds_1，id 为字符串，所以要转换为数字再进行运算 t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;Math.abs(id.hashCode()%4).intdiv(2)&#125; # 分表，t_user_0, t_user_1 keyGenerators: # 分布式序列算法 uuid: # 定义名称 type: UUID # 字符串主键，String custom_snowflake_string: type: CUSTOM_SNOWFLAKE_STRING # 自定义雪花算法，String，spi props: workerId: 2 datacenterId: 2 这里分库与分表采用了相同的字段，即主键id，因其为字符串类型，所以需要使用 hashCode() 获取数字，再进行运算 主键获取规则使用的自定义的雪花算法，spi，详见src/main/resources/META-INF/services/org.apache.shardingsphere.infra.algorithm.keygen.core.KeyGenerateAlgorithm，这里注意，从 5.5.3 开始会更换为 org.apache.shardingsphere.infra.algorithm.keygen.spi.KeyGenerateAlgorithm 多分片键，Long 类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051rules: - !SHARDING # 分片规则配置 tables: # 手工分片规则配置 t_order_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id shardingAlgorithmName: t_order-complex-algorithm keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item_complex: # 逻辑表名称 actualDataNodes: ds_$&#123;0..1&#125;.t_order_item_complex_$&#123;0..1&#125; # 实际数据节点 databaseStrategy: # 分库策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: t_order_db_inline # 分片算法名称 tableStrategy: # 分表策略 complex: # 用于多分片键的复杂分片场景 shardingColumns: user_id,order_id # 分片列名称,多个逗号分隔# shardingAlgorithmName: t_order_item-class-based-algorithm # 基于自定义类的分片算法 shardingAlgorithmName: t_order_item-class-based-algorithm_spi # 基于 SPI 的分片算法，效果同上，建议生产环境使用 SPI keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 t_order_db_inline: type: INLINE props: algorithm-expression: ds_$&#123;user_id % 2&#125; t_order-complex-algorithm: type: COMPLEX_INLINE # 基于行表达式的复合分片算法 props: algorithm-expression: t_order_complex_$&#123;(user_id + order_id + 1) % 2&#125; t_order_item-class-based-algorithm: type: CLASS_BASED # 基于自定义类的分片算法 props: strategy: COMPLEX # 指定策略 STANDARD|COMPLEX|HINT ，告诉 ShardingSphere 分片算法类实现了什么策略 algorithmClassName: com.hanqf.demo.support.algorithm.OrderItemComplexAlgorithm # 指定算法类 t_order_item-class-based-algorithm_spi: # SPI type: T_ORDER_ITEM_COMPLEX # 基于自定义类的分片算法 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long 多个分片键，t_order_complex表使用了内置的COMPLEX_INLINE算法，而t_order_item_complex表使用了自定义的的分片算法，spi，详见src/main/resources/META-INF/services/org.apache.shardingsphere.sharding.spi.ShardingAlgorithm 自动分片规则 上面介绍的都是手工配置分片规则，用于配置较为复杂的分片规则，如果分片规则比价简单，可以使用自动分片规则 12345678910111213141516171819202122232425262728293031323334rules: - !SHARDING # 分片规则配置 # 绑定表：同分片键 join 时走同路由，多个逗号分隔，要求分片规则一致 bindingTables: - t_order,t_order_item autoTables: # 自动分片规则配置 t_order: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: order_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 t_order_item: # 逻辑表名称 actualDataSources: ds_$&#123;0..1&#125; # 数据源名称 shardingStrategy: # 切分策略 standard: # 用于单分片键的标准分片场景 shardingColumn: user_id # 分片列名称 shardingAlgorithmName: mod_2 # 自动分片算法名称 keyGenerateStrategy: # 分布式序列策略 column: item_id # 自增列名称 keyGeneratorName: snowflake # 分布式序列算法名称 shardingAlgorithms: # 分片算法 mod_2: type: MOD # 基于 MOD 的分片算法 props: sharding-count: 2 # 分片数量，即 对 2 进行取余 keyGenerators: # 分布式主键生成器 snowflake: # 定义名称，在上面引用 type: SNOWFLAKE # 使用雪花算法，Long 自动分片规则需要声明数据库，但不需要声明表分配规则，其根据分片算法自动确定具体的数据表。 同时这里还配置了bindingTables，用来指定其分片路由一致。 广播表配置 广播表，即所有数据源都包含的表，比如字典表 1234rules: - !BROADCAST # 广播表配置，即所有的库中都包含指定的表，写入数据时同时写入多个库，查询时随机读一个 tables: - dict # 广播表名称，⼴播表不能配置分表逻辑，只往多个库的同⼀个表中插⼊数据。 数据加密规则 1234567891011121314151617181920rules: - !ENCRYPT # 数据加密配置 tables: t_user: # 加密表名称 columns: password: # 加密列名称 cipher: name: password # 密文列名称 encryptorName: aes_encryptor # 密文列加密算法名称 # 加密算法配置: https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/encrypt/ encryptors: aes_encryptor: # 加解密算法名称 type: AES # 加解密算法类型 props: # 加解密算法属性配置 aes-key-value: 123456abc # AES 使用的 KEY digest-algorithm-name: SHA-1 # AES KEY 的摘要算法 md5_encryptor: type: MD5 props: salt: 123456 # 盐值（可选） 配置加密字段规则后，新增数据时，会自动对加密字段加密后存储，查询时也会加密后进行比较查询。 数据脱敏规则 1234567891011121314151617181920212223242526272829303132rules: - !MASK # 数据脱敏配置 tables: t_user: # 脱敏表名称 columns: # 脱敏列配置 password: # 脱敏列名称 maskAlgorithm: md5_mask # 脱敏算法名称 email: maskAlgorithm: mask_before_special_chars_mask telephone: maskAlgorithm: keep_first_n_last_m_mask name: maskAlgorithm: my_mask maskAlgorithms: # 脱敏算法配置 md5_mask: # 自定义脱敏算法名称 type: MD5 # 脱敏算法类型，md5加密后展示 mask_before_special_chars_mask: type: MASK_BEFORE_SPECIAL_CHARS # 在特殊字符（比如邮箱里的 @）前面做脱敏，示例：myemail@example.com → *******@example.com props: special-chars: &#x27;@&#x27; # 遇到 @ 之前的部分做脱敏 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 keep_first_n_last_m_mask: type: KEEP_FIRST_N_LAST_M # 保留前 n 位和后 m 位，其余用替换字符填充，示例：13812345678 → 138****5678 props: first-n: 3 # 保留前 3 位 last-m: 4 # 保留后 4 位 replace-char: &#x27;*&#x27; # 脱敏字符用 * 代替 my_mask: type: MY_CUSTOM_MASK # 自定义脱敏算法名称 props: replace-char: &quot;#&quot; 被脱敏的字段在查询时会进行脱敏展示。 这里还自定义了脱敏算法，spi，详见src/main/resources/META-INF/services/org.apache.shardingsphere.mask.spi.MaskAlgorithm 单表规则 即不需要进行分库分表的表 12345rules: - !SINGLE # 单表规则配置，单表规则优先级高于分库分表规则 tables: # MySQL 风格 - ds_0.t_address # 加载指定单表 属性配置 1234# 属性配置：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/props/props: sql-show: true # 控制台打印改写后的 SQL，便于排错，默认为 false check-table-metadata-enabled: false # 在程序启动和更新时，是否检查分片元数据的结构一致性，默认为 false 事务配置 123# https://shardingsphere.apache.org/document/5.5.2/cn/user-manual/shardingsphere-jdbc/yaml-config/rules/transaction/transaction: defaultType: LOCAL # 默认事务类型就是 LOCAL 后记 springboot3 集成 shardingsphere-JDBC5.5.2 与 springboot2 不同，不再提供 springboot-starter-shardingsphere，相关配置也采用了独立的配置文件。 代码中包含两个库中使用到的数据库脚本，shardingsphere-demo/shardingsphere-demo-01/sql 具体使用效果可以通过项目中提供的单元测试类进行验证。 springboot3 集成 shardingsphere-JDBC5.5.2 目前尚不支持 XA 分布式事务，这是因为从 Spring Boot 3.x 开始，就全面迁移到了 Jakarta EE 9+，也就是说，所有 javax.* 的类都迁移到 jakarta.* 命名空间(事务、JPA、Servlet 等 API 都受影响)，而 ShardingSphere 5.5 中的 XA 事务主要依赖 Atomikos 或 Narayana 等第三方分布式事务管理器，这些库目前大部分还是基于 javax.transaction.* 的 API。","summary":"摘要 本文介绍 SpringBoot3.5.5 + ShardingSphere-JDBC5.5.2 分库分表的使用。 ShardingSphere官网 本文项目代码Github地址","date_published":"2025-09-01T13:30:05.000Z","tags":["技术","springboot","sharding-sphere","springboot","sharding-sphere"]},{"id":"https://blog.hanqunfeng.com/2025/07/25/k8s-ui-rancher/","url":"https://blog.hanqunfeng.com/2025/07/25/k8s-ui-rancher/","title":"K8S UI 之 Rancher","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 K8S 的 UI 管理工具 Rancher ，本文以 CentOS 8 为例。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/\">K8S官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/kubernetes/kubernetes\">k8s Github</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://ranchermanager.docs.rancher.com/zh/\">Rancher 官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/rancher/rancher\">Rancher Github</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Rancher-简介\">Rancher 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Rancher 是一个 开源的 Kubernetes 管理平台，用于帮助用户部署、管理和运维多个 Kubernetes 集群，具有易用的 Web UI、权限控制、集群监控、应用管理等功能，广泛应用于企业的云原生平台建设中。</p>\n</li>\n</ul>\n<h2 id=\"部署-Rancher\">部署 Rancher</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://ranchermanager.docs.rancher.com/zh/getting-started/quick-start-guides/deploy-rancher-manager/helm-cli#%E4%BD%BF%E7%94%A8-helm-%E6%9D%A5%E5%AE%89%E8%A3%85-rancher\">使用 Helm 安装 Rancher</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 添加 rancher 的 Helm 仓库</span></span><br><span class=\"line\">helm repo add rancher-latest https://releases.rancher.com/server-charts/latest</span><br><span class=\"line\"><span class=\"comment\"># 更新 rancher 的 Helm 仓库</span></span><br><span class=\"line\">helm repo update</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 rancher 的版本</span></span><br><span class=\"line\">$ helm search repo rancher -l | <span class=\"built_in\">head</span></span><br><span class=\"line\">NAME                  \tCHART VERSION\tAPP VERSION\tDESCRIPTION</span><br><span class=\"line\">rancher-latest/rancher\t2.11.3       \tv2.11.3    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.11.2       \tv2.11.2    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.11.1       \tv2.11.1    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.11.0       \tv2.11.0    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.10.3       \tv2.10.3    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.10.2       \tv2.10.2    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.10.1       \tv2.10.1    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.10.0       \tv2.10.0    \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\">rancher-latest/rancher\t2.9.3        \tv2.9.3     \tInstall Rancher Server to manage Kubernetes clu...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建命名空间</span></span><br><span class=\"line\">kubectl create namespace cattle-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建证书，证书是机构颁发的</span></span><br><span class=\"line\">kubectl create secret tls tls-rancher-ingress \\</span><br><span class=\"line\">  --key=nginx_ssl/nginx.hanqunfeng.com.key \\</span><br><span class=\"line\">  --cert=nginx_ssl/nginx.hanqunfeng.com.pem \\</span><br><span class=\"line\">  -n cattle-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装 Rancher  --version v2.11.3 可以指定版本，默认最新版</span></span><br><span class=\"line\">helm install rancher rancher-latest/rancher \\</span><br><span class=\"line\">  --namespace cattle-system \\</span><br><span class=\"line\">  --create-namespace \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> hostname=rancher.hanqunfeng.com \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> ingress.tls.source=secret \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> replicas=3 \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> bootstrapPassword=rancher#2025</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 参数说明</span></span><br><span class=\"line\"><span class=\"comment\"># --set hostname=rancher.hanqunfeng.com 设置 rancher 的域名</span></span><br><span class=\"line\"><span class=\"comment\"># --set ingress.tls.source=secret 配置 rancher 的证书，名称为 tls-rancher-ingress</span></span><br><span class=\"line\"><span class=\"comment\"># --set replicas=3 设置 rancher 的副本数</span></span><br><span class=\"line\"><span class=\"comment\"># --set bootstrapPassword=rancher#2025 设置 rancher 的初始密码</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 不过执行上面的安装命令会报错，应该是当前的 rancher 版本不支持 Kubernetes v1.33.2</span></span><br><span class=\"line\">Error: INSTALLATION FAILED: chart requires kubeVersion: &lt; 1.33.0-0 <span class=\"built_in\">which</span> is incompatible with Kubernetes v1.33.2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 解决办法</span></span><br><span class=\"line\"><span class=\"comment\"># 下载并解压 rancher 安装包</span></span><br><span class=\"line\">helm pull rancher-latest/rancher --untar --untardir ./</span><br><span class=\"line\"><span class=\"comment\"># 修改其中的 Chart.yaml 文件</span></span><br><span class=\"line\">kubeVersion: &lt; 1.33.0-0 ==&gt; kubeVersion: &lt; 1.34.0-0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装 rancher</span></span><br><span class=\"line\">helm install rancher rancher \\</span><br><span class=\"line\">  --namespace cattle-system \\</span><br><span class=\"line\">  --create-namespace \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> hostname=rancher.hanqunfeng.com \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> ingress.tls.source=secret \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> replicas=3 \\</span><br><span class=\"line\">  --<span class=\"built_in\">set</span> bootstrapPassword=rancher#2025</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">NAME: rancher</span><br><span class=\"line\">LAST DEPLOYED: Thu Jul 24 23:55:24 2025</span><br><span class=\"line\">NAMESPACE: cattle-system</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Rancher Server has been installed.</span><br><span class=\"line\"></span><br><span class=\"line\">NOTE: Rancher may take several minutes to fully initialize. Please standby <span class=\"keyword\">while</span> Certificates are being issued, Containers are started and the Ingress rule comes up.</span><br><span class=\"line\"></span><br><span class=\"line\">Check out our docs at https://rancher.com/docs/</span><br><span class=\"line\"></span><br><span class=\"line\">If you provided your own bootstrap password during installation, browse to https://rancher.hanqunfeng.com to get started.</span><br><span class=\"line\"></span><br><span class=\"line\">If this is the first time you installed Rancher, get started by running this <span class=\"built_in\">command</span> and clicking the URL it generates:</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> https://rancher.hanqunfeng.com/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=<span class=\"string\">&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">To get just the bootstrap password on its own, run:</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=<span class=\"string\">&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#123;&#123; &quot;\\n&quot; &#125;&#125;&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">Happy Containering!</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看创建的资源</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ k get all,ing -n cattle-system</span><br><span class=\"line\">NAME                                   READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">pod/helm-operation-8257k               0/2     Completed   0          11m</span><br><span class=\"line\">pod/helm-operation-g8blp               0/2     Completed   0          12m</span><br><span class=\"line\">pod/helm-operation-hwpbp               0/2     Completed   0          10m</span><br><span class=\"line\">pod/helm-operation-qbs5n               0/2     Completed   0          10m</span><br><span class=\"line\">pod/helm-operation-wlptb               0/2     Completed   0          13m</span><br><span class=\"line\">pod/rancher-56689b7d8c-v7hpd           1/1     Running     0          21m</span><br><span class=\"line\">pod/rancher-56689b7d8c-xnrbf           1/1     Running     0          21m</span><br><span class=\"line\">pod/rancher-56689b7d8c-xvqgs           1/1     Running     0          21m</span><br><span class=\"line\">pod/rancher-webhook-5fd5fc44f9-8xwjk   1/1     Running     0          11m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">service/imperative-api-extension   ClusterIP   10.96.188.28   &lt;none&gt;        6666/TCP         15m</span><br><span class=\"line\">service/rancher                    ClusterIP   10.96.21.41    &lt;none&gt;        80/TCP,443/TCP   21m</span><br><span class=\"line\">service/rancher-webhook            ClusterIP   10.96.85.153   &lt;none&gt;        443/TCP          11m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                              READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">deployment.apps/rancher           3/3     3            3           21m</span><br><span class=\"line\">deployment.apps/rancher-webhook   1/1     1            1           11m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">replicaset.apps/rancher-56689b7d8c           3         3         3       21m</span><br><span class=\"line\">replicaset.apps/rancher-webhook-5fd5fc44f9   1         1         1       11m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                CLASS   HOSTS                    ADDRESS         PORTS     AGE</span><br><span class=\"line\">ingress.networking.k8s.io/rancher   nginx   rancher.hanqunfeng.com   10.211.55.201   80, 443   21m</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>浏览器访问：<a href=\"https://rancher.hanqunfeng.com\">https://rancher.hanqunfeng.com</a>，输入上面设置的密码即可。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 如果忘记初始密码可以通过如下命令查看密码</span></span><br><span class=\"line\">kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=<span class=\"string\">&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#123;&#123;&quot;\\n&quot;&#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/rHDDMN.png\" alt=\"\"></p>\n<h2 id=\"卸载-Rancher\">卸载 Rancher</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 卸载 Rancher</span></span><br><span class=\"line\">helm uninstall rancher -n cattle-system</span><br><span class=\"line\"><span class=\"comment\"># 删除 cattle-system 命名空间</span></span><br><span class=\"line\">kubectl delete namespace cattle-system</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 K8S 的 UI 管理工具 Rancher ，本文以 CentOS 8 为例。 K8S官网 k8s Github Rancher 官网 Rancher Github Rancher 简介 Rancher 是一个 开源的 Kubernetes 管理平台，用于帮助用户部署、管理和运维多个 Kubernetes 集群，具有易用的 Web UI、权限控制、集群监控、应用管理等功能，广泛应用于企业的云原生平台建设中。 部署 Rancher 使用 Helm 安装 Rancher 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# 添加 rancher 的 Helm 仓库helm repo add rancher-latest https://releases.rancher.com/server-charts/latest# 更新 rancher 的 Helm 仓库helm repo update# 查看 rancher 的版本$ helm search repo rancher -l | headNAME CHART VERSION APP VERSION DESCRIPTIONrancher-latest/rancher 2.11.3 v2.11.3 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.11.2 v2.11.2 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.11.1 v2.11.1 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.11.0 v2.11.0 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.10.3 v2.10.3 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.10.2 v2.10.2 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.10.1 v2.10.1 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.10.0 v2.10.0 Install Rancher Server to manage Kubernetes clu...rancher-latest/rancher 2.9.3 v2.9.3 Install Rancher Server to manage Kubernetes clu...# 创建命名空间kubectl create namespace cattle-system# 创建证书，证书是机构颁发的kubectl create secret tls tls-rancher-ingress \\ --key=nginx_ssl/nginx.hanqunfeng.com.key \\ --cert=nginx_ssl/nginx.hanqunfeng.com.pem \\ -n cattle-system# 安装 Rancher --version v2.11.3 可以指定版本，默认最新版helm install rancher rancher-latest/rancher \\ --namespace cattle-system \\ --create-namespace \\ --set hostname=rancher.hanqunfeng.com \\ --set ingress.tls.source=secret \\ --set replicas=3 \\ --set bootstrapPassword=rancher#2025## 参数说明# --set hostname=rancher.hanqunfeng.com 设置 rancher 的域名# --set ingress.tls.source=secret 配置 rancher 的证书，名称为 tls-rancher-ingress# --set replicas=3 设置 rancher 的副本数# --set bootstrapPassword=rancher#2025 设置 rancher 的初始密码## 不过执行上面的安装命令会报错，应该是当前的 rancher 版本不支持 Kubernetes v1.33.2Error: INSTALLATION FAILED: chart requires kubeVersion: &lt; 1.33.0-0 which is incompatible with Kubernetes v1.33.2## 解决办法# 下载并解压 rancher 安装包helm pull rancher-latest/rancher --untar --untardir ./# 修改其中的 Chart.yaml 文件kubeVersion: &lt; 1.33.0-0 ==&gt; kubeVersion: &lt; 1.34.0-0# 安装 rancherhelm install rancher rancher \\ --namespace cattle-system \\ --create-namespace \\ --set hostname=rancher.hanqunfeng.com \\ --set ingress.tls.source=secret \\ --set replicas=3 \\ --set bootstrapPassword=rancher#2025## 输出NAME: rancherLAST DEPLOYED: Thu Jul 24 23:55:24 2025NAMESPACE: cattle-systemSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:Rancher Server has been installed.NOTE: Rancher may take several minutes to fully initialize. Please standby while Certificates are being issued, Containers are started and the Ingress rule comes up.Check out our docs at https://rancher.com/docs/If you provided your own bootstrap password during installation, browse to https://rancher.hanqunfeng.com to get started.If this is the first time you installed Rancher, get started by running this command and clicking the URL it generates:echo https://rancher.hanqunfeng.com/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#x27;)To get just the bootstrap password on its own, run:kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#123;&#123; &quot;\\n&quot; &#125;&#125;&#x27;Happy Containering! 查看创建的资源 123456789101112131415161718192021222324252627$ k get all,ing -n cattle-systemNAME READY STATUS RESTARTS AGEpod/helm-operation-8257k 0/2 Completed 0 11mpod/helm-operation-g8blp 0/2 Completed 0 12mpod/helm-operation-hwpbp 0/2 Completed 0 10mpod/helm-operation-qbs5n 0/2 Completed 0 10mpod/helm-operation-wlptb 0/2 Completed 0 13mpod/rancher-56689b7d8c-v7hpd 1/1 Running 0 21mpod/rancher-56689b7d8c-xnrbf 1/1 Running 0 21mpod/rancher-56689b7d8c-xvqgs 1/1 Running 0 21mpod/rancher-webhook-5fd5fc44f9-8xwjk 1/1 Running 0 11mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/imperative-api-extension ClusterIP 10.96.188.28 &lt;none&gt; 6666/TCP 15mservice/rancher ClusterIP 10.96.21.41 &lt;none&gt; 80/TCP,443/TCP 21mservice/rancher-webhook ClusterIP 10.96.85.153 &lt;none&gt; 443/TCP 11mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/rancher 3/3 3 3 21mdeployment.apps/rancher-webhook 1/1 1 1 11mNAME DESIRED CURRENT READY AGEreplicaset.apps/rancher-56689b7d8c 3 3 3 21mreplicaset.apps/rancher-webhook-5fd5fc44f9 1 1 1 11mNAME CLASS HOSTS ADDRESS PORTS AGEingress.networking.k8s.io/rancher nginx rancher.hanqunfeng.com 10.211.55.201 80, 443 21m 浏览器访问：https://rancher.hanqunfeng.com，输入上面设置的密码即可。 12# 如果忘记初始密码可以通过如下命令查看密码kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#123;&#123;&quot;\\n&quot;&#125;&#125;&#x27; 卸载 Rancher 1234# 卸载 Rancherhelm uninstall rancher -n cattle-system# 删除 cattle-system 命名空间kubectl delete namespace cattle-system","summary":"摘要 本文介绍 K8S 的 UI 管理工具 Rancher ，本文以 CentOS 8 为例。 K8S官网 k8s Github Rancher 官网 Rancher Github","date_published":"2025-07-25T14:33:05.000Z","tags":["技术","k8s","K8S"]},{"id":"https://blog.hanqunfeng.com/2025/07/24/k8s-ui-kubesphere/","url":"https://blog.hanqunfeng.com/2025/07/24/k8s-ui-kubesphere/","title":"K8S UI 之 Kubesphere","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 K8S 的 UI 管理工具 Kubesphere，本文以 CentOS 8 为例。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/\">K8S官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/kubernetes/kubernetes\">k8s Github</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubesphere.io/zh/\">Kubesphere 官网</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Kubesphere-简介\">Kubesphere 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>KubeSphere 是一个基于 Kubernetes 构建的 企业级多租户容器管理平台，提供了一套完整的容器平台解决方案，让用户以图形化方式轻松使用 Kubernetes 和 DevOps 能力，不需要深入理解复杂的底层架构。</p>\n</li>\n<li class=\"lvl-2\">\n<p>与 K8S 的 Dashboard 相比具有如下优势：</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>功能 / 特性</th>\n<th>Kubernetes Dashboard</th>\n<th><strong>KubeSphere</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>✅ 基础资源管理</td>\n<td>✅ 支持</td>\n<td>✅ 更丰富，支持更多细粒度控制</td>\n</tr>\n<tr>\n<td>👥 多租户支持</td>\n<td>❌ 无</td>\n<td>✅ 内建企业级多租户、空间（Workspace）隔离</td>\n</tr>\n<tr>\n<td>🔐 身份认证与权限控制</td>\n<td>⚠️ 需手动整合 RBAC</td>\n<td>✅ 内建用户管理、角色、团队、企业组织架构</td>\n</tr>\n<tr>\n<td>🌐 多集群支持</td>\n<td>❌ 不支持</td>\n<td>✅ 支持跨区域多集群统一管理</td>\n</tr>\n<tr>\n<td>🚀 DevOps（CI/CD 流水线）</td>\n<td>❌ 无</td>\n<td>✅ 内置图形化流水线（Jenkins 驱动）</td>\n</tr>\n<tr>\n<td>📊 监控与指标（Prometheus）</td>\n<td>❌ 手动安装</td>\n<td>✅ 内置，图形化展示 Pod/Node/服务等监控数据</td>\n</tr>\n<tr>\n<td>📁 日志查询与分析（EFK）</td>\n<td>❌ 无</td>\n<td>✅ 内建 Fluent Bit + Elasticsearch + Kibana</td>\n</tr>\n<tr>\n<td>💡 微服务治理（Istio）</td>\n<td>❌ 无</td>\n<td>✅ 可选启用，支持服务拓扑、灰度发布、流量治理等</td>\n</tr>\n<tr>\n<td>🧰 应用商店（Helm 可视化部署）</td>\n<td>❌ 无</td>\n<td>✅ 支持 Helm 应用市场，点击即可安装常见中间件</td>\n</tr>\n<tr>\n<td>🔌 插件架构</td>\n<td>❌ 无</td>\n<td>✅ 支持模块按需启用/关闭</td>\n</tr>\n<tr>\n<td>🧪 容器镜像仓库（Harbor）</td>\n<td>❌ 无</td>\n<td>✅ 可集成或内建 Harbor 容器仓库</td>\n</tr>\n<tr>\n<td>📦 安装复杂度</td>\n<td>✅ 简单</td>\n<td>⚠️ 略复杂，但可按需启用模块</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"部署-Kubesphere\">部署 Kubesphere</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kubesphere 对系统资源有最低要求，具体参考<a href=\"https://kubesphere.io/zh/docs/v4.1/03-installation-and-upgrade/01-preparations/01-supported-k8s/\">官网:环境要求</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>部署</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 如果无法访问 charts.kubesphere.io, 可将 charts.kubesphere.io 替换为 charts.kubesphere.com.cn</span></span><br><span class=\"line\">helm upgrade --install -n kubesphere-system --create-namespace ks-core https://charts.kubesphere.io/main/ks-core-1.1.4.tgz --debug --<span class=\"built_in\">wait</span></span><br><span class=\"line\"><span class=\"comment\">## 安装成功后会输出如下信息：</span></span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Thank you <span class=\"keyword\">for</span> choosing KubeSphere Helm Chart.</span><br><span class=\"line\"></span><br><span class=\"line\">Please be patient and <span class=\"built_in\">wait</span> <span class=\"keyword\">for</span> several seconds <span class=\"keyword\">for</span> the KubeSphere deployment to complete.</span><br><span class=\"line\"></span><br><span class=\"line\">1. Wait <span class=\"keyword\">for</span> Deployment Completion</span><br><span class=\"line\"></span><br><span class=\"line\">    Confirm that all KubeSphere components are running by executing the following <span class=\"built_in\">command</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    kubectl get pods -n kubesphere-system</span><br><span class=\"line\">2. Access the KubeSphere Console</span><br><span class=\"line\"></span><br><span class=\"line\">    Once the deployment is complete, you can access the KubeSphere console using the following URL:</span><br><span class=\"line\"></span><br><span class=\"line\">    http://10.211.55.11:30880</span><br><span class=\"line\"></span><br><span class=\"line\">3. Login to KubeSphere Console</span><br><span class=\"line\"></span><br><span class=\"line\">    Use the following credentials to <span class=\"built_in\">log</span> <span class=\"keyword\">in</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    Account: admin</span><br><span class=\"line\">    Password: P@88w0rd</span><br><span class=\"line\"></span><br><span class=\"line\">NOTE: It is highly recommended to change the default password immediately after the first login.</span><br><span class=\"line\">For additional information and details, please visit https://kubesphere.io.</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看所有组件</span></span><br><span class=\"line\">$ kubectl get pod,deploy,svc -n kubesphere-system</span><br><span class=\"line\">NAME                                         READY   STATUS    RESTARTS       AGE</span><br><span class=\"line\">pod/extensions-museum-ffd8bd9d8-fvcw4        1/1     Running   1 (28m ago)    5h5m</span><br><span class=\"line\">pod/ks-apiserver-7b4479d5f5-2k4c9            1/1     Running   2 (27m ago)    5h5m</span><br><span class=\"line\">pod/ks-console-6bd9b9f5d9-xqlzs              1/1     Running   0              26m</span><br><span class=\"line\">pod/ks-controller-manager-547f9fc8c9-5b88z   1/1     Running   10 (27m ago)   5h5m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">deployment.apps/extensions-museum       1/1     1            1           5h14m</span><br><span class=\"line\">deployment.apps/ks-apiserver            1/1     1            1           5h14m</span><br><span class=\"line\">deployment.apps/ks-console              1/1     1            1           5h14m</span><br><span class=\"line\">deployment.apps/ks-controller-manager   1/1     1            1           5h14m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">service/extensions-museum       ClusterIP   10.96.95.71    &lt;none&gt;        443/TCP        5h14m</span><br><span class=\"line\">service/ks-apiserver            ClusterIP   10.96.12.106   &lt;none&gt;        80/TCP         5h14m</span><br><span class=\"line\">service/ks-console              NodePort    10.96.55.165   &lt;none&gt;        80:30880/TCP   5h14m</span><br><span class=\"line\">service/ks-controller-manager   ClusterIP   10.96.13.243   &lt;none&gt;        443/TCP        5h14m</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>浏览器访问：<a href=\"http://10.211.55.11:30880\">http://10.211.55.11:30880</a>，输入账号密码：admin/P@88w0rd，首次登录需要修改密码。</p>\n</li>\n</ul>\n<h2 id=\"配置-ingress\">配置 ingress</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建证书</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create secret tls nginx-tls \\</span><br><span class=\"line\">    --key=nginx_ssl/nginx.hanqunfeng.com.key \\</span><br><span class=\"line\">    --cert=nginx_ssl/nginx.hanqunfeng.com.pem \\</span><br><span class=\"line\">    -n kubesphere-system</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建 ingress</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># kubesphere-ingress.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">networking.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Ingress</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">kubesphere-nginx</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kubesphere-system</span></span><br><span class=\"line\">  <span class=\"attr\">annotations:</span></span><br><span class=\"line\">    <span class=\"attr\">nginx.ingress.kubernetes.io/force-ssl-redirect:</span> <span class=\"string\">&quot;true&quot;</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">ingressClassName:</span> <span class=\"string\">nginx</span></span><br><span class=\"line\">  <span class=\"attr\">tls:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">hosts:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">kubesphere.hanqunfeng.com</span></span><br><span class=\"line\">    <span class=\"attr\">secretName:</span> <span class=\"string\">nginx-tls</span></span><br><span class=\"line\">  <span class=\"attr\">rules:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">host:</span> <span class=\"string\">kubesphere.hanqunfeng.com</span></span><br><span class=\"line\">    <span class=\"attr\">http:</span></span><br><span class=\"line\">      <span class=\"attr\">paths:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">pathType:</span> <span class=\"string\">Prefix</span></span><br><span class=\"line\">        <span class=\"attr\">path:</span> <span class=\"string\">/</span></span><br><span class=\"line\">        <span class=\"attr\">backend:</span></span><br><span class=\"line\">          <span class=\"attr\">service:</span></span><br><span class=\"line\">            <span class=\"attr\">name:</span> <span class=\"string\">ks-console</span></span><br><span class=\"line\">            <span class=\"attr\">port:</span></span><br><span class=\"line\">              <span class=\"attr\">number:</span> <span class=\"number\">80</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"卸载-Kubesphere\">卸载 Kubesphere</h2>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm uninstall ks-core -n kubesphere-system</span><br><span class=\"line\">kubectl delete namespace kubesphere-system</span><br></pre></td></tr></table></figure>","content_text":"摘要 本文介绍 K8S 的 UI 管理工具 Kubesphere，本文以 CentOS 8 为例。 K8S官网 k8s Github Kubesphere 官网 Kubesphere 简介 KubeSphere 是一个基于 Kubernetes 构建的 企业级多租户容器管理平台，提供了一套完整的容器平台解决方案，让用户以图形化方式轻松使用 Kubernetes 和 DevOps 能力，不需要深入理解复杂的底层架构。 与 K8S 的 Dashboard 相比具有如下优势： 功能 / 特性 Kubernetes Dashboard KubeSphere ✅ 基础资源管理 ✅ 支持 ✅ 更丰富，支持更多细粒度控制 👥 多租户支持 ❌ 无 ✅ 内建企业级多租户、空间（Workspace）隔离 🔐 身份认证与权限控制 ⚠️ 需手动整合 RBAC ✅ 内建用户管理、角色、团队、企业组织架构 🌐 多集群支持 ❌ 不支持 ✅ 支持跨区域多集群统一管理 🚀 DevOps（CI/CD 流水线） ❌ 无 ✅ 内置图形化流水线（Jenkins 驱动） 📊 监控与指标（Prometheus） ❌ 手动安装 ✅ 内置，图形化展示 Pod/Node/服务等监控数据 📁 日志查询与分析（EFK） ❌ 无 ✅ 内建 Fluent Bit + Elasticsearch + Kibana 💡 微服务治理（Istio） ❌ 无 ✅ 可选启用，支持服务拓扑、灰度发布、流量治理等 🧰 应用商店（Helm 可视化部署） ❌ 无 ✅ 支持 Helm 应用市场，点击即可安装常见中间件 🔌 插件架构 ❌ 无 ✅ 支持模块按需启用/关闭 🧪 容器镜像仓库（Harbor） ❌ 无 ✅ 可集成或内建 Harbor 容器仓库 📦 安装复杂度 ✅ 简单 ⚠️ 略复杂，但可按需启用模块 部署 Kubesphere Kubesphere 对系统资源有最低要求，具体参考官网:环境要求 部署 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 如果无法访问 charts.kubesphere.io, 可将 charts.kubesphere.io 替换为 charts.kubesphere.com.cnhelm upgrade --install -n kubesphere-system --create-namespace ks-core https://charts.kubesphere.io/main/ks-core-1.1.4.tgz --debug --wait## 安装成功后会输出如下信息：NOTES:Thank you for choosing KubeSphere Helm Chart.Please be patient and wait for several seconds for the KubeSphere deployment to complete.1. Wait for Deployment Completion Confirm that all KubeSphere components are running by executing the following command: kubectl get pods -n kubesphere-system2. Access the KubeSphere Console Once the deployment is complete, you can access the KubeSphere console using the following URL: http://10.211.55.11:308803. Login to KubeSphere Console Use the following credentials to log in: Account: admin Password: P@88w0rdNOTE: It is highly recommended to change the default password immediately after the first login.For additional information and details, please visit https://kubesphere.io.# 查看所有组件$ kubectl get pod,deploy,svc -n kubesphere-systemNAME READY STATUS RESTARTS AGEpod/extensions-museum-ffd8bd9d8-fvcw4 1/1 Running 1 (28m ago) 5h5mpod/ks-apiserver-7b4479d5f5-2k4c9 1/1 Running 2 (27m ago) 5h5mpod/ks-console-6bd9b9f5d9-xqlzs 1/1 Running 0 26mpod/ks-controller-manager-547f9fc8c9-5b88z 1/1 Running 10 (27m ago) 5h5mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/extensions-museum 1/1 1 1 5h14mdeployment.apps/ks-apiserver 1/1 1 1 5h14mdeployment.apps/ks-console 1/1 1 1 5h14mdeployment.apps/ks-controller-manager 1/1 1 1 5h14mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/extensions-museum ClusterIP 10.96.95.71 &lt;none&gt; 443/TCP 5h14mservice/ks-apiserver ClusterIP 10.96.12.106 &lt;none&gt; 80/TCP 5h14mservice/ks-console NodePort 10.96.55.165 &lt;none&gt; 80:30880/TCP 5h14mservice/ks-controller-manager ClusterIP 10.96.13.243 &lt;none&gt; 443/TCP 5h14m 浏览器访问：http://10.211.55.11:30880，输入账号密码：admin/P@88w0rd，首次登录需要修改密码。 配置 ingress 创建证书 1234kubectl create secret tls nginx-tls \\ --key=nginx_ssl/nginx.hanqunfeng.com.key \\ --cert=nginx_ssl/nginx.hanqunfeng.com.pem \\ -n kubesphere-system 创建 ingress 12345678910111213141516171819202122232425# kubesphere-ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: kubesphere-nginx namespace: kubesphere-system annotations: nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;spec: ingressClassName: nginx tls: - hosts: - kubesphere.hanqunfeng.com secretName: nginx-tls rules: - host: kubesphere.hanqunfeng.com http: paths: - pathType: Prefix path: / backend: service: name: ks-console port: number: 80 卸载 Kubesphere 12helm uninstall ks-core -n kubesphere-systemkubectl delete namespace kubesphere-system","summary":"摘要 本文介绍 K8S 的 UI 管理工具 Kubesphere，本文以 CentOS 8 为例。 K8S官网 k8s Github Kubesphere 官网","date_published":"2025-07-24T14:33:05.000Z","tags":["技术","k8s","K8S"]},{"id":"https://blog.hanqunfeng.com/2025/07/24/k8s-ui-dashboard/","url":"https://blog.hanqunfeng.com/2025/07/24/k8s-ui-dashboard/","title":"K8S UI 之 Dashboard","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍 K8S 的 UI 管理工具 Dashboard，本文以 CentOS 8 为例。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/\">K8S官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/kubernetes/kubernetes\">k8s Github</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/docs/tasks/access-application-cluster/web-ui-dashboard/\">Dashboard k8s介绍</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"Dashboard-简介\">Dashboard 简介</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Dashboard 是基于网页的 Kubernetes 用户界面。</p>\n</li>\n<li class=\"lvl-2\">\n<p>你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。</p>\n</li>\n<li class=\"lvl-2\">\n<p>你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment、Job、DaemonSet 等等）。 例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。</p>\n</li>\n<li class=\"lvl-2\">\n<p>Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。</p>\n</li>\n</ul>\n<h2 id=\"部署-Dashboard\">部署 Dashboard</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Kubernetes Dashboard 目前仅支持基于 Helm 的安装，因为它速度更快， 并且可以让我们更好地控制 Dashboard 运行所需的所有依赖项。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 添加 kubernetes-dashboard 仓库</span></span><br><span class=\"line\">helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/</span><br><span class=\"line\"><span class=\"comment\"># 使用 kubernetes-dashboard Chart 部署名为 `kubernetes-dashboard` 的 Helm Release</span></span><br><span class=\"line\">$ helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \\</span><br><span class=\"line\">    --create-namespace \\</span><br><span class=\"line\">    --namespace kubernetes-dashboard</span><br><span class=\"line\"><span class=\"comment\">## 输出</span></span><br><span class=\"line\">Release <span class=\"string\">&quot;kubernetes-dashboard&quot;</span> does not exist. Installing it now.</span><br><span class=\"line\">NAME: kubernetes-dashboard</span><br><span class=\"line\">LAST DEPLOYED: Sun Jul  6 00:40:02 2025</span><br><span class=\"line\">NAMESPACE: kubernetes-dashboard</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">*************************************************************************************************</span><br><span class=\"line\">*** PLEASE BE PATIENT: Kubernetes Dashboard may need a few minutes to get up and become ready ***</span><br><span class=\"line\">*************************************************************************************************</span><br><span class=\"line\"></span><br><span class=\"line\">Congratulations! You have just installed Kubernetes Dashboard <span class=\"keyword\">in</span> your cluster.</span><br><span class=\"line\"></span><br><span class=\"line\">To access Dashboard run:</span><br><span class=\"line\">  kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443</span><br><span class=\"line\"></span><br><span class=\"line\">NOTE: In <span class=\"keyword\">case</span> port-forward <span class=\"built_in\">command</span> does not work, make sure that kong service name is correct.</span><br><span class=\"line\">      Check the services <span class=\"keyword\">in</span> Kubernetes Dashboard namespace using:</span><br><span class=\"line\">        kubectl -n kubernetes-dashboard get svc</span><br><span class=\"line\"></span><br><span class=\"line\">Dashboard will be available at:</span><br><span class=\"line\">  https://localhost:8443</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 helm 安装的包，注意指定 命名空间</span></span><br><span class=\"line\">$ helm list -n kubernetes-dashboard</span><br><span class=\"line\">NAME                \tNAMESPACE           \tREVISION\tUPDATED                                \tSTATUS  \tCHART                      \tAPP VERSION</span><br><span class=\"line\">kubernetes-dashboard\tkubernetes-dashboard\t1       \t2025-07-24 14:01:06.678570212 +0800 CST\tdeployed\tkubernetes-dashboard-7.13.0</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>查看启动的资源</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n kubernetes-dashboard get all</span><br><span class=\"line\">NAME                                                       READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">pod/kubernetes-dashboard-api-568f47ddd7-tx6f8              1/1     Running   0          20m</span><br><span class=\"line\">pod/kubernetes-dashboard-auth-645b944589-t6v2m             1/1     Running   0          20m</span><br><span class=\"line\">pod/kubernetes-dashboard-kong-648658d45f-7qsm9             1/1     Running   0          20m</span><br><span class=\"line\">pod/kubernetes-dashboard-metrics-scraper-547874fcf-87mrv   1/1     Running   0          20m</span><br><span class=\"line\">pod/kubernetes-dashboard-web-7796b9fbbb-xsdlw              1/1     Running   0          20m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class=\"line\">service/kubernetes-dashboard-api               ClusterIP   10.96.149.59    &lt;none&gt;        8000/TCP   20m</span><br><span class=\"line\">service/kubernetes-dashboard-auth              ClusterIP   10.96.145.120   &lt;none&gt;        8000/TCP   20m</span><br><span class=\"line\">service/kubernetes-dashboard-kong-proxy        ClusterIP   10.96.171.40    &lt;none&gt;        443/TCP    20m</span><br><span class=\"line\">service/kubernetes-dashboard-metrics-scraper   ClusterIP   10.96.79.48     &lt;none&gt;        8000/TCP   20m</span><br><span class=\"line\">service/kubernetes-dashboard-web               ClusterIP   10.96.247.143   &lt;none&gt;        8000/TCP   20m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                                   READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">deployment.apps/kubernetes-dashboard-api               1/1     1            1           20m</span><br><span class=\"line\">deployment.apps/kubernetes-dashboard-auth              1/1     1            1           20m</span><br><span class=\"line\">deployment.apps/kubernetes-dashboard-kong              1/1     1            1           20m</span><br><span class=\"line\">deployment.apps/kubernetes-dashboard-metrics-scraper   1/1     1            1           20m</span><br><span class=\"line\">deployment.apps/kubernetes-dashboard-web               1/1     1            1           20m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                                             DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">replicaset.apps/kubernetes-dashboard-api-568f47ddd7              1         1         1       20m</span><br><span class=\"line\">replicaset.apps/kubernetes-dashboard-auth-645b944589             1         1         1       20m</span><br><span class=\"line\">replicaset.apps/kubernetes-dashboard-kong-648658d45f             1         1         1       20m</span><br><span class=\"line\">replicaset.apps/kubernetes-dashboard-metrics-scraper-547874fcf   1         1         1       20m</span><br><span class=\"line\">replicaset.apps/kubernetes-dashboard-web-7796b9fbbb              1         1         1       20m</span><br></pre></td></tr></table></figure>\n<div class=\"tips\">\n<p><em><strong>小贴士</strong></em></p>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">第一次创建kubernetes-dashboard时，有几个 pod 一直处于 ContainerCreating 状态，通过 describe 命令，查看 pod 的状态发现报如下错误：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Warning  FailedCreatePodSandBox  4m52s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network <span class=\"keyword\">for</span> sandbox <span class=\"string\">&quot;cfa0b6062fabd77353e6d832ab0e62f96787b4d59346d9e57c28dbc0e19a3127&quot;</span>: plugin <span class=\"built_in\">type</span>=<span class=\"string\">&quot;calico&quot;</span> failed (add): error getting ClusterInformation: connection is unauthorized: Unauthorized</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-1\">\n<li class=\"lvl-2\">\n<p>这条错误说明：</p>\n<ul class=\"lvl-3\">\n<li class=\"lvl-6\">容器网络插件（CNI）使用的是 Calico</li>\n<li class=\"lvl-6\">Calico 在尝试获取 Kubernetes 集群的 ClusterInformation 时 认证失败</li>\n<li class=\"lvl-6\">错误关键词：connection is unauthorized: Unauthorized</li>\n</ul>\n</li>\n<li class=\"lvl-2\">\n<p>不确定导致这一问题的原因，我的解决方法是重新安装 Calico</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl delete -f calico.yaml</span><br><span class=\"line\">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>\n</div>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>开放代理端口</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在哪个机器上运行的命令，开放的就是哪个机器的端口</span></span><br><span class=\"line\">kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>访问：在开放代理端口的机器上使用浏览器访问：<a href=\"https://localhost:8443\">https://localhost:8443</a></p>\n</li>\n</ul>\n<h2 id=\"登录帐号\">登录帐号</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建管理员用户</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># dashboard-adminuser.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span>                    <span class=\"comment\"># 创建 ServiceAccount</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">admin-user</span>                      <span class=\"comment\"># SA 名称</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kubernetes-dashboard</span>       <span class=\"comment\"># SA 所在命名空间</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span>                <span class=\"comment\"># 集群角色绑定</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">admin-user</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span>   <span class=\"comment\"># 集群角色组，这个是 k8s 内置的</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span>                     <span class=\"comment\"># 集群角色</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">cluster-admin</span>                   <span class=\"comment\"># 集群管理员角色</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span>                  <span class=\"comment\"># 服务账号</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">admin-user</span>                      <span class=\"comment\"># 服务账号名称</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kubernetes-dashboard</span>       <span class=\"comment\"># 服务账号命名空间</span></span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>创建并获取token</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f dashboard-adminuser.yaml</span><br><span class=\"line\"><span class=\"comment\"># 获取token，该 token 有效期为 1 小时，token格式为 jwt，可以通过 jwt.io 解析</span></span><br><span class=\"line\">kubectl -n kubernetes-dashboard create token admin-user</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>获取长效token</p>\n</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># dashboard-secret.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Secret</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">admin-user</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kubernetes-dashboard</span></span><br><span class=\"line\">  <span class=\"attr\">annotations:</span></span><br><span class=\"line\">    <span class=\"attr\">kubernetes.io/service-account.name:</span> <span class=\"string\">&quot;admin-user&quot;</span></span><br><span class=\"line\"><span class=\"attr\">type:</span> <span class=\"string\">kubernetes.io/service-account-token</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f dashboard-secret.yaml</span><br><span class=\"line\"><span class=\"comment\"># 该命令获取token，永不过期，将其保存下来</span></span><br><span class=\"line\">kubectl get secret admin-user -n kubernetes-dashboard -o jsonpath=<span class=\"string\">&quot;&#123;.data.token&#125;&quot;</span> | <span class=\"built_in\">base64</span> -d</span><br></pre></td></tr></table></figure>\n<h2 id=\"卸载-kubernetes-dashboard\">卸载 kubernetes-dashboard</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>卸载 kubernetes-dashboard</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm uninstall kubernetes-dashboard --namespace kubernetes-dashboard</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>清理用户信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl -n kubernetes-dashboard delete serviceaccount admin-user</span><br><span class=\"line\">kubectl -n kubernetes-dashboard delete clusterrolebinding admin-user</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 也可以直接删除 命名空间，删除命名空间会同时删除所有资源</span></span><br><span class=\"line\">kubectl delete namespace kubernetes-dashboard</span><br></pre></td></tr></table></figure>\n","content_text":"摘要 本文介绍 K8S 的 UI 管理工具 Dashboard，本文以 CentOS 8 为例。 K8S官网 k8s Github Dashboard k8s介绍 Dashboard 简介 Dashboard 是基于网页的 Kubernetes 用户界面。 你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。 你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment、Job、DaemonSet 等等）。 例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。 Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。 部署 Dashboard Kubernetes Dashboard 目前仅支持基于 Helm 的安装，因为它速度更快， 并且可以让我们更好地控制 Dashboard 运行所需的所有依赖项。 1234567891011121314151617181920212223242526272829303132333435# 添加 kubernetes-dashboard 仓库helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/# 使用 kubernetes-dashboard Chart 部署名为 `kubernetes-dashboard` 的 Helm Release$ helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \\ --create-namespace \\ --namespace kubernetes-dashboard## 输出Release &quot;kubernetes-dashboard&quot; does not exist. Installing it now.NAME: kubernetes-dashboardLAST DEPLOYED: Sun Jul 6 00:40:02 2025NAMESPACE: kubernetes-dashboardSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:**************************************************************************************************** PLEASE BE PATIENT: Kubernetes Dashboard may need a few minutes to get up and become ready ****************************************************************************************************Congratulations! You have just installed Kubernetes Dashboard in your cluster.To access Dashboard run: kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443NOTE: In case port-forward command does not work, make sure that kong service name is correct. Check the services in Kubernetes Dashboard namespace using: kubectl -n kubernetes-dashboard get svcDashboard will be available at: https://localhost:8443# 查看 helm 安装的包，注意指定 命名空间$ helm list -n kubernetes-dashboardNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONkubernetes-dashboard kubernetes-dashboard 1 2025-07-24 14:01:06.678570212 +0800 CST deployed kubernetes-dashboard-7.13.0 查看启动的资源 12345678910111213141516171819202122232425262728$ kubectl -n kubernetes-dashboard get allNAME READY STATUS RESTARTS AGEpod/kubernetes-dashboard-api-568f47ddd7-tx6f8 1/1 Running 0 20mpod/kubernetes-dashboard-auth-645b944589-t6v2m 1/1 Running 0 20mpod/kubernetes-dashboard-kong-648658d45f-7qsm9 1/1 Running 0 20mpod/kubernetes-dashboard-metrics-scraper-547874fcf-87mrv 1/1 Running 0 20mpod/kubernetes-dashboard-web-7796b9fbbb-xsdlw 1/1 Running 0 20mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes-dashboard-api ClusterIP 10.96.149.59 &lt;none&gt; 8000/TCP 20mservice/kubernetes-dashboard-auth ClusterIP 10.96.145.120 &lt;none&gt; 8000/TCP 20mservice/kubernetes-dashboard-kong-proxy ClusterIP 10.96.171.40 &lt;none&gt; 443/TCP 20mservice/kubernetes-dashboard-metrics-scraper ClusterIP 10.96.79.48 &lt;none&gt; 8000/TCP 20mservice/kubernetes-dashboard-web ClusterIP 10.96.247.143 &lt;none&gt; 8000/TCP 20mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/kubernetes-dashboard-api 1/1 1 1 20mdeployment.apps/kubernetes-dashboard-auth 1/1 1 1 20mdeployment.apps/kubernetes-dashboard-kong 1/1 1 1 20mdeployment.apps/kubernetes-dashboard-metrics-scraper 1/1 1 1 20mdeployment.apps/kubernetes-dashboard-web 1/1 1 1 20mNAME DESIRED CURRENT READY AGEreplicaset.apps/kubernetes-dashboard-api-568f47ddd7 1 1 1 20mreplicaset.apps/kubernetes-dashboard-auth-645b944589 1 1 1 20mreplicaset.apps/kubernetes-dashboard-kong-648658d45f 1 1 1 20mreplicaset.apps/kubernetes-dashboard-metrics-scraper-547874fcf 1 1 1 20mreplicaset.apps/kubernetes-dashboard-web-7796b9fbbb 1 1 1 20m 小贴士 第一次创建kubernetes-dashboard时，有几个 pod 一直处于 ContainerCreating 状态，通过 describe 命令，查看 pod 的状态发现报如下错误： 1Warning FailedCreatePodSandBox 4m52s kubelet Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox &quot;cfa0b6062fabd77353e6d832ab0e62f96787b4d59346d9e57c28dbc0e19a3127&quot;: plugin type=&quot;calico&quot; failed (add): error getting ClusterInformation: connection is unauthorized: Unauthorized 这条错误说明： 容器网络插件（CNI）使用的是 Calico Calico 在尝试获取 Kubernetes 集群的 ClusterInformation 时 认证失败 错误关键词：connection is unauthorized: Unauthorized 不确定导致这一问题的原因，我的解决方法是重新安装 Calico 12kubectl delete -f calico.yamlkubectl apply -f calico.yaml 开放代理端口 12# 在哪个机器上运行的命令，开放的就是哪个机器的端口kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443 访问：在开放代理端口的机器上使用浏览器访问：https://localhost:8443 登录帐号 创建管理员用户 12345678910111213141516171819# dashboard-adminuser.yamlapiVersion: v1kind: ServiceAccount # 创建 ServiceAccountmetadata: name: admin-user # SA 名称 namespace: kubernetes-dashboard # SA 所在命名空间---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBinding # 集群角色绑定metadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io # 集群角色组，这个是 k8s 内置的 kind: ClusterRole # 集群角色 name: cluster-admin # 集群管理员角色subjects:- kind: ServiceAccount # 服务账号 name: admin-user # 服务账号名称 namespace: kubernetes-dashboard # 服务账号命名空间 创建并获取token 123kubectl apply -f dashboard-adminuser.yaml# 获取token，该 token 有效期为 1 小时，token格式为 jwt，可以通过 jwt.io 解析kubectl -n kubernetes-dashboard create token admin-user 获取长效token 123456789# dashboard-secret.yamlapiVersion: v1kind: Secretmetadata: name: admin-user namespace: kubernetes-dashboard annotations: kubernetes.io/service-account.name: &quot;admin-user&quot;type: kubernetes.io/service-account-token 123kubectl apply -f dashboard-secret.yaml# 该命令获取token，永不过期，将其保存下来kubectl get secret admin-user -n kubernetes-dashboard -o jsonpath=&quot;&#123;.data.token&#125;&quot; | base64 -d 卸载 kubernetes-dashboard 卸载 kubernetes-dashboard 1helm uninstall kubernetes-dashboard --namespace kubernetes-dashboard 清理用户信息 12345kubectl -n kubernetes-dashboard delete serviceaccount admin-userkubectl -n kubernetes-dashboard delete clusterrolebinding admin-user# 也可以直接删除 命名空间，删除命名空间会同时删除所有资源kubectl delete namespace kubernetes-dashboard","summary":"摘要 本文介绍 K8S 的 UI 管理工具 Dashboard，本文以 CentOS 8 为例。 K8S官网 k8s Github Dashboard k8s介绍","date_published":"2025-07-24T13:33:05.000Z","tags":["技术","k8s","K8S"]},{"id":"https://blog.hanqunfeng.com/2025/07/24/k8s-tools/","url":"https://blog.hanqunfeng.com/2025/07/24/k8s-tools/","title":"K8S 之 Tools","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-3\">\n<p>K8S 的 Tools: crictl、nerdctl、helm ，本文以 CentOS 8 为例。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/\">K8S官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/kubernetes/kubernetes\">k8s Github</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"crictl-命令\">crictl 命令</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>crictl</code> 是k8s官方出品的一个命令行工具，用于与 containerd 进行通信。</p>\n</li>\n<li class=\"lvl-2\">\n<p><code>crictl</code> 命令默认需要 sudo 权限，如果不想每次都加 sudo，可以将用户加入 containerd 的 socket 权限组</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># containerd 的默认 socket 是 /var/run/containerd/containerd.sock</span></span><br><span class=\"line\">$ <span class=\"built_in\">ls</span> -l /var/run/containerd/containerd.sock</span><br><span class=\"line\">srw-rw---- 1 root root 0 7月   1 10:57 /var/run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># 如果 group 是 root：你可以改为其它组，比如 docker</span></span><br><span class=\"line\"><span class=\"comment\"># 如果 docker 组不存在则创建</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> groupadd docker</span><br><span class=\"line\"><span class=\"comment\"># 修改文件所属组为 docker</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">chgrp</span> docker /var/run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># 为组添加读写权限</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">chmod</span> g+rw /var/run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># 添加用户到 docker 组</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> usermod -aG docker <span class=\"variable\">$USER</span></span><br><span class=\"line\"><span class=\"comment\"># 刷新权限</span></span><br><span class=\"line\">newgrp docker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 此时虽然已经可以不用 sudo 了，但是一旦重启 containerd 就会重新回到 root 权限，因此需要添加如下配置</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mkdir</span> -p /etc/systemd/system/containerd.service.d/</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">tee</span> /etc/systemd/system/containerd.service.d/override.conf &lt;&lt;<span class=\"string\">EOF</span></span><br><span class=\"line\"><span class=\"string\">[Service]</span></span><br><span class=\"line\"><span class=\"string\">ExecStartPost=/bin/bash -c &#x27;chmod 660 /run/containerd/containerd.sock &amp;&amp; chgrp docker /run/containerd/containerd.sock&#x27;</span></span><br><span class=\"line\"><span class=\"string\">EOF</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl daemon-reload</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl restart containerd</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><code>crictl</code> 命令的使用方式比较类似<code>docker</code>命令</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>操作</th>\n<th><code>docker</code> 命令</th>\n<th><code>crictl</code> 命令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>查看正在运行的容器</td>\n<td><code>docker ps</code></td>\n<td><code>crictl ps</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看所有容器（包括已停止）</td>\n<td><code>docker ps -a</code></td>\n<td><code>crictl ps -a</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看镜像</td>\n<td><code>docker images</code></td>\n<td><code>crictl images</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看容器日志</td>\n<td><code>docker logs &lt;container_id&gt;</code></td>\n<td><code>crictl logs &lt;container_id&gt;</code></td>\n<td></td>\n</tr>\n<tr>\n<td>进入容器交互</td>\n<td><code>docker exec -it &lt;id&gt; sh</code></td>\n<td><code>crictl exec -it &lt;id&gt; sh</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看容器详细信息</td>\n<td><code>docker inspect &lt;container_id&gt;</code></td>\n<td><code>crictl inspect &lt;container_id&gt;</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看 Pod 详细信息</td>\n<td>❌（不支持）</td>\n<td><code>crictl inspectp &lt;pod_id&gt;</code></td>\n<td>K8s 专属</td>\n</tr>\n<tr>\n<td>删除容器</td>\n<td><code>docker rm &lt;container_id&gt;</code></td>\n<td><code>crictl rm &lt;container_id&gt;</code></td>\n<td></td>\n</tr>\n<tr>\n<td>删除镜像</td>\n<td><code>docker rmi &lt;image_id&gt;</code></td>\n<td><code>crictl rmi &lt;image_id&gt;</code></td>\n<td></td>\n</tr>\n<tr>\n<td>拉取镜像</td>\n<td><code>docker pull nginx</code></td>\n<td><code>crictl pull nginx</code></td>\n<td></td>\n</tr>\n<tr>\n<td>运行容器（非 K8s 场景）</td>\n<td><code>docker run -it nginx</code></td>\n<td>❌（不支持）</td>\n<td><code>crictl</code> 不运行容器，仅调试现有容器</td>\n</tr>\n<tr>\n<td>列出容器运行时信息</td>\n<td><code>docker info</code></td>\n<td><code>crictl info</code></td>\n<td></td>\n</tr>\n<tr>\n<td>查看容器运行状态</td>\n<td><code>docker stats</code></td>\n<td><code>crictl stats</code></td>\n<td>简要版</td>\n</tr>\n<tr>\n<td>设置配置文件</td>\n<td><code>~/.docker/config.json</code></td>\n<td><code>/etc/crictl.yaml</code></td>\n<td>如设置 endpoint</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"nerdctl\">nerdctl</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/containerd/nerdctl\">nerdctl</a> 是一个 兼容 Docker CLI 的容器命令行工具，用于管理 containerd 容器运行时。</p>\n</li>\n<li class=\"lvl-2\">\n<p>它是 containerd 官方子项目，由 CNCF 维护，其命令语法与 Docker CLI 兼容，目标是让习惯 Docker 的用户也能轻松使用 containerd。</p>\n</li>\n<li class=\"lvl-2\">\n<p>安装 nerdctl</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 下载最新版本</span></span><br><span class=\"line\">VERSION=2.1.3</span><br><span class=\"line\">wget https://github.com/containerd/nerdctl/releases/download/v<span class=\"variable\">$&#123;VERSION&#125;</span>/nerdctl-<span class=\"variable\">$&#123;VERSION&#125;</span>-linux-amd64.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 解压</span></span><br><span class=\"line\">tar -xvf nerdctl-<span class=\"variable\">$&#123;VERSION&#125;</span>-linux-amd64.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 移动到系统 PATH</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> nerdctl /usr/local/bin/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># nerdctl 需要 sudo 权限</span></span><br><span class=\"line\"><span class=\"comment\">## 为 sudo 添加 PATH</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> visudo</span><br><span class=\"line\"><span class=\"comment\">## 找到这一行</span></span><br><span class=\"line\">Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin</span><br><span class=\"line\"><span class=\"comment\">## 修改为，即将 nerdctl 所在的目录加入 PATH</span></span><br><span class=\"line\">Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4.测试</span></span><br><span class=\"line\"><span class=\"comment\">## 查看版本</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> nerdctl version</span><br><span class=\"line\"><span class=\"comment\">## 列出容器，--namespace k8s.io 表示查看 k8s 中的容器</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> nerdctl ps --namespace k8s.io</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 如果不想每次都加上 --namespace k8s.io，可以设置别名</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;alias kps=&#x27;sudo nerdctl --namespace=k8s.io ps&#x27;&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br><span class=\"line\"><span class=\"comment\">## 测试</span></span><br><span class=\"line\">kps</span><br></pre></td></tr></table></figure>\n<h2 id=\"Helm\">Helm</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p><a href=\"https://helm.sh/zh/docs/\">官网文档</a></p>\n</li>\n<li class=\"lvl-2\">\n<p>Helm 是 Kubernetes 的包管理器，类似于 Linux 下的包管理工具如 yum、apt 等。可以方便的将之前打包好的 yaml 文件部署到 Kunernetes 上。</p>\n</li>\n</ul>\n<h3 id=\"Helm的安装\">Helm的安装</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>官网<a href=\"https://helm.sh/zh/docs/intro/install/\">安装方法</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://get.helm.sh/helm-v3.17.4-linux-amd64.tar.gz</span><br><span class=\"line\">tar -zxvf helm-v3.17.4-linux-amd64.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">mv</span> linux-amd64/helm /usr/local/bin/helm</span><br><span class=\"line\">$ helm version</span><br><span class=\"line\">version.BuildInfo&#123;Version:<span class=\"string\">&quot;v3.17.4&quot;</span>, GitCommit:<span class=\"string\">&quot;595a05da6166037d0abebaa27ac8a498fa4d7ed2&quot;</span>, GitTreeState:<span class=\"string\">&quot;clean&quot;</span>, GoVersion:<span class=\"string\">&quot;go1.23.10&quot;</span>&#125;</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>Helm<a href=\"https://helm.sh/zh/docs/helm/helm_completion_bash/\">自动补全</a></p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装 helm 的自动补全功能</span></span><br><span class=\"line\"><span class=\"comment\"># 1 当前用户</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;source &lt;(helm completion bash)&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2 所有用户</span></span><br><span class=\"line\">helm completion bash | <span class=\"built_in\">sudo</span> <span class=\"built_in\">tee</span> /etc/bash_completion.d/helm &gt; /dev/null</span><br><span class=\"line\"><span class=\"built_in\">sudo</span> <span class=\"built_in\">chmod</span> a+r /etc/bash_completion.d/helm</span><br></pre></td></tr></table></figure>\n<h3 id=\"Helm的使用\">Helm的使用</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>可以参考 <a href=\"/2023/07/10/aws-eks14-helm/\" title=\"AWS-EKS-14--Helm\">AWS-EKS-14--Helm</a></p>\n</li>\n</ul>\n<h4 id=\"仓库管理\">仓库管理</h4>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>add：添加图表存储库</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>list：列出图表存储库</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo list</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>remove：删除图表存储库</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo remove bitnami</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>update：从图表存储库更新本地可用图表的信息</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 更新所有仓库</span></span><br><span class=\"line\">helm repo update</span><br><span class=\"line\"><span class=\"comment\"># 更新指定的仓库</span></span><br><span class=\"line\">helm repo update bitnami</span><br></pre></td></tr></table></figure>\n<h4 id=\"在仓库中搜索\">在仓库中搜索</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在所有仓库中搜索，默认只展示最新的版本</span></span><br><span class=\"line\">helm search repo nginx</span><br><span class=\"line\"><span class=\"comment\"># 在指定的仓库中搜索</span></span><br><span class=\"line\">helm search repo bitnami/wordpress</span><br><span class=\"line\"><span class=\"comment\"># 显示所有版本</span></span><br><span class=\"line\">helm search repo nginx -l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在全部版本中搜索大于等于指定版本</span></span><br><span class=\"line\">$ helm search repo nginx --version ^21.0.0 -l</span><br><span class=\"line\">NAME         \tCHART VERSION\tAPP VERSION\tDESCRIPTION</span><br><span class=\"line\">bitnami/nginx\t21.0.8       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.7       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.6       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.4       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.3       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.2       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.1       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br><span class=\"line\">bitnami/nginx\t21.0.0       \t1.29.0     \tNGINX Open Source is a web server that can be a...</span><br></pre></td></tr></table></figure>\n<h4 id=\"安装包\">安装包</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装最新版</span></span><br><span class=\"line\">helm install nginx bitnami/nginx</span><br><span class=\"line\"><span class=\"comment\"># 安装指定版本</span></span><br><span class=\"line\">helm install nginx bitnami/nginx --version 21.0.3</span><br><span class=\"line\"><span class=\"comment\"># 安装包到指定命名空间</span></span><br><span class=\"line\">helm install nginx bitnami/nginx -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 安装包并创建命名空间</span></span><br><span class=\"line\">helm install nginx bitnami/nginx -n &lt;namespace&gt; --create-namespace</span><br><span class=\"line\"><span class=\"comment\"># oci： 从 docker 仓库中安装</span></span><br><span class=\"line\">helm pull oci://registry-1.docker.io/bitnamicharts/nginx --version 21.0.8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装本地 chart 目录</span></span><br><span class=\"line\">helm install my-release ./nginx</span><br><span class=\"line\"><span class=\"comment\"># 安装 .tgz 格式的打包 chart</span></span><br><span class=\"line\">helm install my-release ./nginx-1.2.3.tgz</span><br><span class=\"line\"><span class=\"comment\"># 从远程tgz安装</span></span><br><span class=\"line\">helm install my-release https://example.com/charts/nginx-1.2.3.tgz</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装 Git 仓库中的 chart（结合 plugin）</span></span><br><span class=\"line\">helm plugin install https://github.com/aslafy-z/helm-git</span><br><span class=\"line\">helm repo add mychart <span class=\"string\">&#x27;git+https://github.com/myorg/mychart.git&#x27;</span></span><br><span class=\"line\">helm install my-release mychart/nginx</span><br><span class=\"line\"><span class=\"comment\"># 卸载helm-git插件</span></span><br><span class=\"line\">helm plugin remove helm-git</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 --set 传递单个或多个值</span></span><br><span class=\"line\">helm install my-release bitnami/nginx --<span class=\"built_in\">set</span> service.type=NodePort</span><br><span class=\"line\"><span class=\"comment\"># 使用 --values 或 -f 加载 YAML 配置文件</span></span><br><span class=\"line\">helm install my-release bitnami/nginx -f custom-values.yaml</span><br><span class=\"line\"><span class=\"comment\"># 同时使用多种 values 文件 + --set</span></span><br><span class=\"line\">helm install my-release bitnami/nginx -f base.yaml -f prod.yaml --<span class=\"built_in\">set</span> replicaCount=3</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h4 id=\"查看已经安装的包\">查看已经安装的包</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看指定命名空间已安装的包</span></span><br><span class=\"line\">helm list -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 查看所有已安装的包</span></span><br><span class=\"line\">helm list -A</span><br><span class=\"line\"><span class=\"comment\"># 查看已安装的包状态</span></span><br><span class=\"line\">helm status ngxin -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"卸载包\">卸载包</h4>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm uninstall nginx -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure>","content_text":"摘要 K8S 的 Tools: crictl、nerdctl、helm ，本文以 CentOS 8 为例。 K8S官网 k8s Github crictl 命令 crictl 是k8s官方出品的一个命令行工具，用于与 containerd 进行通信。 crictl 命令默认需要 sudo 权限，如果不想每次都加 sudo，可以将用户加入 containerd 的 socket 权限组 123456789101112131415161718192021222324# containerd 的默认 socket 是 /var/run/containerd/containerd.sock$ ls -l /var/run/containerd/containerd.socksrw-rw---- 1 root root 0 7月 1 10:57 /var/run/containerd/containerd.sock# 如果 group 是 root：你可以改为其它组，比如 docker# 如果 docker 组不存在则创建sudo groupadd docker# 修改文件所属组为 dockersudo chgrp docker /var/run/containerd/containerd.sock# 为组添加读写权限sudo chmod g+rw /var/run/containerd/containerd.sock# 添加用户到 docker 组sudo usermod -aG docker $USER# 刷新权限newgrp docker# 此时虽然已经可以不用 sudo 了，但是一旦重启 containerd 就会重新回到 root 权限，因此需要添加如下配置sudo mkdir -p /etc/systemd/system/containerd.service.d/sudo tee /etc/systemd/system/containerd.service.d/override.conf &lt;&lt;EOF[Service]ExecStartPost=/bin/bash -c &#x27;chmod 660 /run/containerd/containerd.sock &amp;&amp; chgrp docker /run/containerd/containerd.sock&#x27;EOFsudo systemctl daemon-reloadsudo systemctl restart containerd crictl 命令的使用方式比较类似docker命令 操作 docker 命令 crictl 命令 说明 查看正在运行的容器 docker ps crictl ps 查看所有容器（包括已停止） docker ps -a crictl ps -a 查看镜像 docker images crictl images 查看容器日志 docker logs &lt;container_id&gt; crictl logs &lt;container_id&gt; 进入容器交互 docker exec -it &lt;id&gt; sh crictl exec -it &lt;id&gt; sh 查看容器详细信息 docker inspect &lt;container_id&gt; crictl inspect &lt;container_id&gt; 查看 Pod 详细信息 ❌（不支持） crictl inspectp &lt;pod_id&gt; K8s 专属 删除容器 docker rm &lt;container_id&gt; crictl rm &lt;container_id&gt; 删除镜像 docker rmi &lt;image_id&gt; crictl rmi &lt;image_id&gt; 拉取镜像 docker pull nginx crictl pull nginx 运行容器（非 K8s 场景） docker run -it nginx ❌（不支持） crictl 不运行容器，仅调试现有容器 列出容器运行时信息 docker info crictl info 查看容器运行状态 docker stats crictl stats 简要版 设置配置文件 ~/.docker/config.json /etc/crictl.yaml 如设置 endpoint nerdctl nerdctl 是一个 兼容 Docker CLI 的容器命令行工具，用于管理 containerd 容器运行时。 它是 containerd 官方子项目，由 CNCF 维护，其命令语法与 Docker CLI 兼容，目标是让习惯 Docker 的用户也能轻松使用 containerd。 安装 nerdctl 1234567891011121314151617181920212223242526272829# 1. 下载最新版本VERSION=2.1.3wget https://github.com/containerd/nerdctl/releases/download/v$&#123;VERSION&#125;/nerdctl-$&#123;VERSION&#125;-linux-amd64.tar.gz# 2. 解压tar -xvf nerdctl-$&#123;VERSION&#125;-linux-amd64.tar.gz# 3. 移动到系统 PATHsudo mv nerdctl /usr/local/bin/# nerdctl 需要 sudo 权限## 为 sudo 添加 PATHsudo visudo## 找到这一行Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin## 修改为，即将 nerdctl 所在的目录加入 PATHDefaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin# 4.测试## 查看版本sudo nerdctl version## 列出容器，--namespace k8s.io 表示查看 k8s 中的容器sudo nerdctl ps --namespace k8s.io## 如果不想每次都加上 --namespace k8s.io，可以设置别名echo &quot;alias kps=&#x27;sudo nerdctl --namespace=k8s.io ps&#x27;&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc## 测试kps Helm 官网文档 Helm 是 Kubernetes 的包管理器，类似于 Linux 下的包管理工具如 yum、apt 等。可以方便的将之前打包好的 yaml 文件部署到 Kunernetes 上。 Helm的安装 官网安装方法 12345wget https://get.helm.sh/helm-v3.17.4-linux-amd64.tar.gztar -zxvf helm-v3.17.4-linux-amd64.tar.gzsudo mv linux-amd64/helm /usr/local/bin/helm$ helm versionversion.BuildInfo&#123;Version:&quot;v3.17.4&quot;, GitCommit:&quot;595a05da6166037d0abebaa27ac8a498fa4d7ed2&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.23.10&quot;&#125; Helm自动补全 12345678# 安装 helm 的自动补全功能# 1 当前用户echo &#x27;source &lt;(helm completion bash)&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc# 2 所有用户helm completion bash | sudo tee /etc/bash_completion.d/helm &gt; /dev/nullsudo chmod a+r /etc/bash_completion.d/helm Helm的使用 可以参考 AWS-EKS-14--Helm 仓库管理 add：添加图表存储库 1helm repo add bitnami https://charts.bitnami.com/bitnami list：列出图表存储库 1helm repo list remove：删除图表存储库 1helm repo remove bitnami update：从图表存储库更新本地可用图表的信息 1234# 更新所有仓库helm repo update# 更新指定的仓库helm repo update bitnami 在仓库中搜索 123456789101112131415161718# 在所有仓库中搜索，默认只展示最新的版本helm search repo nginx# 在指定的仓库中搜索helm search repo bitnami/wordpress# 显示所有版本helm search repo nginx -l# 在全部版本中搜索大于等于指定版本$ helm search repo nginx --version ^21.0.0 -lNAME CHART VERSION APP VERSION DESCRIPTIONbitnami/nginx 21.0.8 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.7 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.6 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.4 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.3 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.2 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.1 1.29.0 NGINX Open Source is a web server that can be a...bitnami/nginx 21.0.0 1.29.0 NGINX Open Source is a web server that can be a... 安装包 123456789101112131415161718192021222324252627282930313233# 安装最新版helm install nginx bitnami/nginx# 安装指定版本helm install nginx bitnami/nginx --version 21.0.3# 安装包到指定命名空间helm install nginx bitnami/nginx -n &lt;namespace&gt;# 安装包并创建命名空间helm install nginx bitnami/nginx -n &lt;namespace&gt; --create-namespace# oci： 从 docker 仓库中安装helm pull oci://registry-1.docker.io/bitnamicharts/nginx --version 21.0.8# 安装本地 chart 目录helm install my-release ./nginx# 安装 .tgz 格式的打包 charthelm install my-release ./nginx-1.2.3.tgz# 从远程tgz安装helm install my-release https://example.com/charts/nginx-1.2.3.tgz# 安装 Git 仓库中的 chart（结合 plugin）helm plugin install https://github.com/aslafy-z/helm-githelm repo add mychart &#x27;git+https://github.com/myorg/mychart.git&#x27;helm install my-release mychart/nginx# 卸载helm-git插件helm plugin remove helm-git# 使用 --set 传递单个或多个值helm install my-release bitnami/nginx --set service.type=NodePort# 使用 --values 或 -f 加载 YAML 配置文件helm install my-release bitnami/nginx -f custom-values.yaml# 同时使用多种 values 文件 + --sethelm install my-release bitnami/nginx -f base.yaml -f prod.yaml --set replicaCount=3 查看已经安装的包 123456# 查看指定命名空间已安装的包helm list -n &lt;namespace&gt;# 查看所有已安装的包helm list -A# 查看已安装的包状态helm status ngxin -n &lt;namespace&gt; 卸载包 1helm uninstall nginx -n &lt;namespace&gt;","summary":"摘要 K8S 的 Tools: crictl、nerdctl、helm ，本文以 CentOS 8 为例。 K8S官网 k8s Github","date_published":"2025-07-24T13:30:05.000Z","tags":["技术","k8s","K8S"]},{"id":"https://blog.hanqunfeng.com/2025/07/24/k8s-connection/","url":"https://blog.hanqunfeng.com/2025/07/24/k8s-connection/","title":"K8S 之 远程连接","content_html":"<!--\n **加粗**\n *斜体*\n ***加粗并斜体***\n ~~删除线~~\n ==突出显示==\n `突出显示(推荐)`\n ++下划线++\n ~下标~\n ^上标^\n 脚注，参考文献[^1]，然后在文档最下方要添加这个1对应的内容，如：[^1]: My reference.\n 图片设置宽度和高度(通过uPic上传后，需要将upic修改过为blog，用于添加水印) ![](https://upic-oss.oss-cn-beijing.aliyuncs.com/blog/innodb_buffer_pool.png =900x600)\n\n +++ **点击折叠**\n 这是被隐藏的内容\n +++\n\n::: tips success warning danger\n这里是容器内的内容\n:::\n\n% note info % success warning danger\n这里是容器内的内容\n% endnote %\n\n引用本地其它文章连接{}\n 大括号开始% post_link 文件名称(不包含.md) %大括号结束\n -->\n<h2 id=\"摘要\">摘要</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>本文介绍  K8S 的 远程连接 方法，本文以 CentOS 8 为例。</p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://kubernetes.io/zh-cn/\">K8S官网</a></p>\n</li>\n<li class=\"lvl-2\">\n<p><a href=\"https://github.com/kubernetes/kubernetes\">k8s Github</a></p>\n</li>\n</ul>\n<span id=\"more\"></span>\n<h2 id=\"远程连接-k8s-集群\">远程连接 k8s 集群</h2>\n<h3 id=\"本地不存在-kubeconfig-文件\">本地不存在 kubeconfig 文件</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>获取 kubeconfig 文件，位于 Master 节点：/etc/kubernetes/admin.conf，将其拷贝到本地</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp k8s-master:/etc/kubernetes/admin.conf ~/.kube/config</span><br></pre></td></tr></table></figure>\n<h3 id=\"本地已存在-kubeconfig-文件\">本地已存在 kubeconfig 文件</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>已经配置了一个集群的连接，还想再添加一个集群，可以通过通过合并的方式添加</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将新集群的 kubeconfig 文件拷贝到本地</span></span><br><span class=\"line\">scp k8s-master:/etc/kubernetes/admin.conf ~/.kube/new-cluster.conf</span><br><span class=\"line\"><span class=\"comment\"># 合并</span></span><br><span class=\"line\">KUBECONFIG=~/.kube/config:new-cluster.conf kubectl config view --flatten &gt; merged-config.yaml</span><br><span class=\"line\"><span class=\"comment\"># 替换</span></span><br><span class=\"line\"><span class=\"built_in\">mv</span> merged-config.yaml ~/.kube/config</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群配置相关命令\">集群配置相关命令</h3>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>获取集群配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获取所有集群配置</span></span><br><span class=\"line\">kubectl config get-contexts</span><br><span class=\"line\"><span class=\"comment\"># 查看当前默认的 context</span></span><br><span class=\"line\">kubectl config current-context</span><br><span class=\"line\"><span class=\"comment\"># 切换 context</span></span><br><span class=\"line\">kubectl config use-context &lt;context_name&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取集群名称</span></span><br><span class=\"line\">kubectl config get-clusters</span><br><span class=\"line\"><span class=\"comment\"># 获取用户名称</span></span><br><span class=\"line\">kubectl config get-users</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>测试</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get node</span><br></pre></td></tr></table></figure>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>删除集群配置</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 删除 context</span></span><br><span class=\"line\">kubectl config delete-context &lt;context_name&gt;</span><br><span class=\"line\"><span class=\"comment\"># 删除 cluster</span></span><br><span class=\"line\">kubectl config delete-cluster &lt;cluster_name&gt;</span><br><span class=\"line\"><span class=\"comment\"># 删除 user</span></span><br><span class=\"line\">kubectl config delete-user &lt;user_name&gt;</span><br></pre></td></tr></table></figure>\n<h2 id=\"后记\">后记</h2>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>也可以直接编辑 kubeconfig（~/.kube/config） 文件，添加或删除不需要的集群、用户、上下文等信息</p>\n</li>\n</ul>\n","content_text":"摘要 本文介绍 K8S 的 远程连接 方法，本文以 CentOS 8 为例。 K8S官网 k8s Github 远程连接 k8s 集群 本地不存在 kubeconfig 文件 获取 kubeconfig 文件，位于 Master 节点：/etc/kubernetes/admin.conf，将其拷贝到本地 1scp k8s-master:/etc/kubernetes/admin.conf ~/.kube/config 本地已存在 kubeconfig 文件 已经配置了一个集群的连接，还想再添加一个集群，可以通过通过合并的方式添加 123456# 将新集群的 kubeconfig 文件拷贝到本地scp k8s-master:/etc/kubernetes/admin.conf ~/.kube/new-cluster.conf# 合并KUBECONFIG=~/.kube/config:new-cluster.conf kubectl config view --flatten &gt; merged-config.yaml# 替换mv merged-config.yaml ~/.kube/config 集群配置相关命令 获取集群配置 1234567891011# 获取所有集群配置kubectl config get-contexts# 查看当前默认的 contextkubectl config current-context# 切换 contextkubectl config use-context &lt;context_name&gt;# 获取集群名称kubectl config get-clusters# 获取用户名称kubectl config get-users 测试 1kubectl get node 删除集群配置 123456# 删除 contextkubectl config delete-context &lt;context_name&gt;# 删除 clusterkubectl config delete-cluster &lt;cluster_name&gt;# 删除 userkubectl config delete-user &lt;user_name&gt; 后记 也可以直接编辑 kubeconfig（~/.kube/config） 文件，添加或删除不需要的集群、用户、上下文等信息","summary":"摘要 本文介绍 K8S 的 远程连接 方法，本文以 CentOS 8 为例。 K8S官网 k8s Github","date_published":"2025-07-24T12:30:05.000Z","tags":["技术","k8s","K8S"]}]}